% This LaTeX document needs to be compiled with XeLaTeX.
\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{ucharclasses}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\graphicspath{ {./images/} }
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan,}
\urlstyle{same}
\usepackage{multirow}
\usepackage[fallback]{xeCJK}
\usepackage{polyglossia}
\usepackage{fontspec}
\setCJKmainfont{Noto Serif CJK JP}

\setmainlanguage{english}
\setotherlanguages{latin}
\newfontfamily\lgcfont{CMU Serif}
\setDefaultTransitions{\lgcfont}{}

\title{Differential Equations }


\author{5.1 Simple Harmonic Motion\\
5.2 Damped Motion\\
5.3 Forced Motion\\
5.4 Electric Circuits and Other Analogous Systems\\
Chapter 5 Review\\
Chapter 5 Review Exercises}
\date{}


%New command to display footnote whose markers will always be hidden
\let\svthefootnote\thefootnote
\newcommand\blfootnotetext[1]{%
  \let\thefootnote\relax\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \let\thefootnote\svthefootnote%
}

%Overriding the \footnotetext command to hide the marker if its value is `0`
\let\svfootnotetext\footnotetext
\renewcommand\footnotetext[2][?]{%
  \if\relax#1\relax%
    \ifnum\value{footnote}=0\blfootnotetext{#2}\else\svfootnotetext{#2}\fi%
  \else%
    \if?#1\ifnum\value{footnote}=0\blfootnotetext{#2}\else\svfootnotetext{#2}\fi%
    \else\svfootnotetext[#1]{#2}\fi%
  \fi
}

\begin{document}
\maketitle
The Clawic Fifth Edition

Dennis G. Zill

TABLE OF LAPLACE TRANSFORMS

\begin{center}
\begin{tabular}{|c|c|}
\hline
$f(r)$ & $\mathscr{\Phi}\{f(s)\}=F(s)$ \\
\hline
1. 1 & $\frac{1}{s}$ \\
\hline
2. i & $\frac{1}{s}$ \\
\hline
3. $i^{n}$ & $\frac{n!}{s^{n+1}}, n$ a positive integer \\
\hline
4. $t^{-14}$ & $\sqrt{\frac{\pi}{s}}$ \\
\hline
5. $t^{12}$ & $\frac{\sqrt{\pi}}{2 s^{3 / 2}}$ \\
\hline
6. $r^{m}$ & $\frac{\Gamma(\alpha+1)}{s^{\alpha+1}}, \quad \alpha>-1$ \\
\hline
7. $\sin k t$ & $\frac{k}{s^{2}+k^{2}}$ \\
\hline
8. $\cos k t$ & $\frac{s}{s^{2}+k^{2}}$ \\
\hline
9. $\sin ^{2} k t$ & $\frac{2 k^{2}}{s\left(s^{2}+4 k^{2}\right)}$ \\
\hline
10. $\cos ^{2} k t$ & $\frac{s^{2}+2 k^{2}}{s\left(s^{2}+4 k^{2}\right)}$ \\
\hline
11. $e^{=}$ & $\frac{1}{s-a}$ \\
\hline
12. $\sinh k t$ & $\frac{k}{s^{2}-k^{2}}$ \\
\hline
13. cosh kf & $\frac{s}{s^{2}-k^{2}}$ \\
\hline
14. $\sinh ^{2} k t$ & $\frac{2 k^{2}}{s\left(s^{2}-4 k^{2}\right)}$ \\
\hline
15. cosh ${ }^{2} k t$ & $\frac{s^{2}-2 k^{2}}{s\left(s^{2}-4 k^{2}\right)}$ \\
\hline
16. $e^{\amalg}$ & $\frac{1}{(s-a)^{2}}$ \\
\hline
17. $t^{6}$ & $\frac{n!}{(s-a)^{n+1}}, n$ a positive integer \\
\hline
18. $e^{\prime \prime} \cdot \sin k x$ & $\frac{k}{(s-a)^{2}+k^{2}}$ \\
\hline
19. $e^{2 \pi} \cos k t$ & $\frac{s-a}{(s-a)^{2}+k^{2}}$ \\
\hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|}
\hline
$f(\theta)$ & $\mathscr{L}\{f(t)\}=F(s)$ \\
\hline
20. $e^{a} \sinh k t$ & $\frac{k}{(s-a)^{2}-k^{2}}$ \\
\hline
21. $e^{\text {ar }} \cosh k t$ & $\frac{s-a}{(s-a)^{2}-k^{2}}$ \\
\hline
22. $I \sin k r$ & $\frac{2 k s}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
23. $t \cos k t$ & $\frac{s^{2}-k^{2}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
24. $\sin k t+k t \cos k t$ & $\frac{2 k s^{2}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
25. $\sin k t-k t \cos k t$ & $\frac{2 k^{7}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
26. $t \sinh k t$ & $\frac{2 k s}{\left(s^{2}-k^{2}\right)^{3}}$ \\
\hline
27. $t \cosh k t$ & $\frac{s^{2}+k^{2}}{\left(s^{2}-k^{2}\right)^{2}}$ \\
\hline
28. $\frac{e^{a t}-e^{n t}}{a-b}$ & $\frac{1}{(s-a)(s-b)}$ \\
\hline
29. $\frac{a e^{e d}-b e^{b i}}{a-b}$ & $\frac{s}{(s-a)(s-b)}$ \\
\hline
30. $1-\cos k t$ & $\frac{k^{2}}{s\left(s^{2}+k^{2}\right)}$ \\
\hline
31. $k t=\sin k t$ & $\frac{k}{s^{2}\left(s^{2}+k^{2}\right)}$ \\
\hline
32. $\frac{a \sin b t-b \sin a t}{a b\left(a^{2}-b^{2}\right)}$ & $\frac{1}{\left(s^{2}+a^{2}\right)\left(s^{2}+b^{2}\right)}$ \\
\hline
33. $\frac{\cos b t-\cos a t}{a^{2}-b^{2}}$ & $\frac{s}{\left(s^{2}+a^{2}\right)\left(s^{2}+b^{2}\right)}$ \\
\hline
34. $\sin k t \sinh k t$ & $\frac{2 k^{2} s}{s^{4}+4 k^{-4}}$ \\
\hline
35. $\sin k t \cosh k t$ & $\frac{k\left(s^{2}+2 k^{2}\right)}{s^{4}+4 k^{4}}$ \\
\hline
36. $\cos k t \sinh k t$ & $\frac{k\left(s^{2}-2 k^{2}\right)}{s^{2}+4 k^{4}}$ \\
\hline
37. $\cos k t$ cosh $k t$ & $\frac{s^{3}}{s^{4}+4 k}$ \\
\hline
38. $J_{0}(k t)$ & $\frac{1}{\sqrt{s^{2}+k^{2}}}$ \\
\hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|}
\hline
$f(t)$ & $\mathscr{L}\{f(t)\}=F(s)$ \\
\hline
39. $\underline{e^{b t}-e^{a t}}$ & $s-a$ \\
\hline
39. $\frac{t}{t}$ & $\ln \overline{s-b}$ \\
\hline
40. $\frac{2(1-\cos k t)}{2}$ & $\ln \frac{s^{2}+k^{2}}{s^{2}}$ \\
\hline
$2(1-\cosh k t)$ & $s^{2}-k^{2}$ \\
\hline
41. $\frac{2(2)}{t}$ & $\ln \frac{n}{s^{2}}$ \\
\hline
42. $\frac{\sin a t}{t}$ & $\arctan \left(\frac{a}{s}\right)$ \\
\hline
43. $\frac{\sin a t \cos b t}{t}$ & $\frac{1}{2} \arctan \frac{a+b}{s}+\frac{1}{2} \arctan \frac{a-b}{s}$ \\
\hline
44. $\frac{1}{\sqrt{\pi t}} e^{-a^{2} / 4 t}$ & $\frac{e^{-a \sqrt{x}}}{\sqrt{s}}$ \\
\hline
45. $\frac{a}{2 \sqrt{\pi t^{3}}} e^{-a^{2} / 4 t}$ & $e^{-a \sqrt{s}}$ \\
\hline
46. $\operatorname{erfc}\left(\frac{a}{2 \sqrt{t}}\right)$ & $\frac{e^{-a \sqrt{s}}}{s}$ \\
\hline
47. $2 \sqrt{\frac{t}{\pi}} e^{-a^{2} / 4 t}-a \operatorname{erfc}\left(\frac{a}{2 \sqrt{t}}\right)$ & $\frac{e^{-a \sqrt{s}}}{s \sqrt{s}}$ \\
\hline
48. $e^{a b} e^{b^{2}} \operatorname{erfc}\left(b \sqrt{t}+\frac{a}{2 \sqrt{t}}\right)$ & $\frac{e^{-a \sqrt{s}}}{\sqrt{s}(\sqrt{s}+b)}$ \\
\hline
49. $-e^{a b} e^{b^{z}} \operatorname{erfc}\left(b \sqrt{t}+\frac{a}{2 \sqrt{t}}\right)$ & $\frac{b e^{-a \sqrt{s}}}{s(\sqrt{s}+b)}$ \\
\hline
$+\operatorname{erfc}\left(\frac{a}{2 \sqrt{t}}\right)$ &  \\
\hline
50. $\delta(t)$ & 1 \\
\hline
51. $\delta\left(t-t_{0}\right)$ & $e^{-x_{0}}$ \\
\hline
52. $e^{a \|} f(t)$ & $F(s-a)$ \\
\hline
53. $f(t-a) U(t-a)$ & $e^{-a s} F(s)$ \\
\hline
54. $U(t-a)$ & $\frac{e^{-\alpha s}}{s}$ \\
\hline
55. $f^{(n)}(t)$ & $s^{n} F(s)-s^{(n-1)} f(0)-\cdots-f^{(n-1)}(0)$ \\
\hline
56. $t^{n} f(t)$ & $(-1)^{n} \frac{d^{n}}{d s^{n}} F(s)$ \\
\hline
57. $\int_{0}^{t} f(\tau) g(t-\tau) d \tau$ & $F(s) G(s)$ \\
\hline
\end{tabular}
\end{center}

\section*{A FIRST COURSE IN DIFFERENTIAL EQUATIONS}
\section*{A FIRST COURSE IN DIFFERENTIAL EQUATIONS}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-006}
\end{center}

\section*{DENNIS G. ZILL}
\section*{Loyola Marymount University}
\section*{BROOKS/COLE CENGAGE Learning}
\section*{A First Course in Differential Equations The Classic 5th Edition}
Dennis G. Zill

\section*{Publisher: Gary Ostedt}
Marketing Team: Karin Sandberg, Samantha Cabaluna

Marketing Associate: Beth Kroenke

Assistant Editor: Carol Benedict

Editorial Assistant: Daniel Thiem

Production Editor: Keith Faivre

Production Service: Lifland et al., Bookmakers

Manucript Editor: Gail Magin/Lifland

Cover Design: Roy R. Neuhaus

Cover Photo: The Stock Market/ M. Mastrorillo

Interior Illustration: Network Graphics

Photo Researcher: Gail Magin/Lifland

Print Buyer: Vena Dyer

Typesetting: The PRD Group

\section*{(c) 2001 Brooks/Cole, Cengage Learning}
ALL RIGHTS RESERVED. No part of this work covered by the copyright herein may be reproduced, transmitted, stored or used in any form or by any means graphic, electronic, or mechanical, including but not limited to photocopying, recording, scanning, digitizing, taping, Web distribution, information networks, or information storage and retrieval systems, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without the prior written permission of the publisher.

For product information and technology assistance, contact us at Cengage Learning Customer \& Sales Support, 1-800-354-9706

For permission to use material from this text or product, submit all requests online at \href{http://cengage.com/permissions}{cengage.com/permissions}

Further permissions questions can be emailed to \href{mailto:permissionrequest@cengage.com}{permissionrequest@cengage.com}

\section*{ISBN-13: 978-0-534-37388-7}
ISBN-10: 0.534-37388-7

\section*{Brooks/Cole}
10 Davis Drive

Belmont Drive, CA $94002-3098$

USA

Cengage Learning is a leading provider of customized learning solutions with office locations around the globe, including Singapore, the United Kingdom, Australia, Mexico, Brazil, and Japan. Locate your local office at: \href{http://international.cengage.com/region}{international.cengage.com/region}

Cengage Learning products are represented in Canada by Nelson Education, Ltd.

For your course and learning solutions, visit \href{http://academic.cengage.com}{academic.cengage.com}

Purchase any of our products at your local college store or at our preferred online store \href{http://www.ichapters.com}{www.ichapters.com}

\section*{CONTENTS}
A WORD FROM THE PUBLISHER ix\\
PREFACE TO THE FIFTH EDITION ..... xi\\
CHAPTER\\
INTRODUCTION TO DIFFERENTIAL\\
EQUATIONS 1\\
1.1 Basic Definitions and Terminology ..... 2\\
1.2 Some Mathematical Models ..... 11\\
Chapter 1 Review ..... 25\\
Chapter 1 Review Exercises ..... 26\\
CHAPTER FIRST-ORDER DIFFERENTIAL EQUATIONS ..... 28\\
2.1 Preliminary Theory ..... 29\\
2.2 Separable Variables ..... 33\\
2.3 Homogeneous Equations ..... 40\\
2.4 Exact Equations ..... 46\\
2.5 Linear Equations ..... 54\\
2.6 Equations of Bernoulli, Ricatti, and Clairaut ..... 62\\
2.7 Substitutions ..... 67\\
*2.8 Picard's Method ..... 70\\
Chapter 2 Review ..... 72\\
Chapter 2 Review Exercises ..... 73\\
CHAPTER APPLICATIONS OF FIRST-ORDER DIFFERENTIAL\\
EQUATIONS ..... 75\\
3.1 Orthogonal Trajectories ..... 76\\
3.2 Applications of Linear Equations ..... 81\\
3.3 Applications of Nonlinear Equations ..... 93\\
Chapter 3 Review ..... 103\\
Chapter 3 Review Exercises ..... 104\\
Essay: Population Dynamics, by Michael Olinick ..... 106
\footnotetext{\begin{itemize}
  \item Optional
\end{itemize}
}
CHAPTER LINEAR DIFFERENTIAL EQUATIONS OF\\
HIGHER-ORDER ..... 111\\
4.1 Preliminary Theory ..... 112\\
4.1.1 Initial-Value and Boundary-Value Problems ..... 112\\
4.1.2 Linear Dependence and Linear Independence ..... 115\\
4.1.3 Solutions of Linear Equations ..... 120\\
4.2 Constructing a Second Solution from a Known Solution ..... 133\\
4.3 Homogeneous Linear Equations with Constant Coefficients ..... 138\\
4.4 Undetermined Coefficients-Superposition Approach ..... 146\\
4.5 Differential Operators ..... 157\\
4.6 Undetermined Coefficient-Annihilator Approach ..... 162\\
4.7 Variation of Parameters ..... 169\\
Chapter 4 Review ..... 175\\
Chapter 4 Review Exercises ..... 177\\
Essay: Chaos, by John H. Hubbard ..... 179\\
CHAPTER APPLICATIONS OF SECOND-ORDER DIFFERENTIAL\\
EQUATIONS: VIBRATIONAL MODELS ..... 183\\
5.1 Simple Harmonic Motion ..... 184\\
5.2 Damped Motion ..... 192\\
5.3 Forced Motion ..... 200\\
5.4 Electric Circuits and Other Analogous Systems ..... 209\\
Chapter 5 Review ..... 214\\
Chapter 5 Review Exercises ..... 215\\
Essay: Tacoma Narrows Suspension Bridge Collapse,\\
by Gilbert N. Lewis 218\\
CHAPTER DIFFERENTIAL EQUATIONS WITH VARIABLE\\
COEFFICIENTS ..... 221\\
6.1 Cauchy-Euler Equation ..... 222\\
6.2 Review of Power Series; Power Series Solutions ..... 230\\
6.3 Solutions About Ordinary Points ..... 239\\
6.4 Solutions About Singular Points ..... 248\\
6.4.1 Regular Singular Points; Method of Frobenius-Case I ..... 248\\
6.4.2 Method of Frobenius-Cases II and III ..... 257\\
6.5 Two Special Equations ..... 265\\
6.5.1 Solution of Bessel's Equation ..... 266\\
6.5.2 Solution of Legendre's Equation ..... 271\\
Chapter 6 Review ..... 277\\
Chapter 6 Review Exercises ..... 278\\
CHAPTER LAPLACE TRANSFORM ..... 280\\
7.1 Laplace Transform ..... 281\\
7.2 Inverse Transform ..... 290\\
7.3 Translation Theorems and Derivatives of a Transform ..... 296\\
7.4 Transforms of Derivatives, Integrals, and Periodic Functions ..... 307\\
7.5 Applications ..... 314\\
*7.6 Dirac Delta Function ..... 328\\
Chapter 7 Review ..... 332\\
Chapter 7 Review Exercises ..... 332\\
CHAPTER SYSTEMS OF LINEAR DIFFERENTIAL\\
EQUATIONS 335\\
8.1 Operator Method ..... 336\\
8.2 Laplace Transform Method ..... 343\\
8.3 Systems of Linear First-Order Equations ..... 350\\
8.4 Introduction to Matrices ..... 355\\
8.4.1 Basic Definitions and Theory ..... 355\\
8.4.2 Gaussian and Gauss-Jordan Elimination Methods ..... 364\\
8.4.3 The Eigenvalue Problem ..... 368\\
8.5 Matrices and Systems of Linear First-Order Equations ..... 375\\
8.5.1 Preliminary Theory ..... 375\\
8.5.2 A Fundamental Matrix ..... 384\\
8.6 Homogeneous Linear Systems ..... 391\\
8.6.1 Distinct Real Eigenvalues ..... 391\\
8.6.2 Complex Eigenvalues ..... 394\\
8.6.3 Repeated Eigenvalues ..... 398\\
*8.7 Undetermined Coefficients ..... 405\\
8.8 Variation of Parameters ..... 409\\
*8.9 Matrix Exponential ..... 413\\
Chapter 8 Review ..... 416\\
Chapter 8 Review Exercises ..... 418\\
CHAPTER NUMERICAL METHODS FOR ORDINARY\\
DIFFERENTIAL EQUATIONS ..... 421\\
9.1 Direction Fields ..... 422\\
9.2 The Euler Methods ..... 426\\
9.3 The Three-Term Taylor Method ..... 432\\
9.4 The Runge-Kutta Method ..... 435\\
9.5 Multistep Methods ..... 439\\
9.6 Errors and Stability ..... 442\\
9.7 Higher-Order Equations and Systems ..... 448\\
9.8 Second-Order Boundary-Value Problems ..... 452\\
Chapter 9 Review ..... 456\\
Chapter 9 Review Exercises ..... 457\\
Essay: Nerve Impulse Models, by C. J. Knickerbocker ..... 459

\section*{APPENDIXES}
I Gamma Function APP-1

II Laplace Transforms APP-4

III Review of Determinants APP-7

IV Complex Numbers APP-11

ANSWERS TO ODD-NUMBERED PROBLEMS A-1

INDEX I-1

\section*{A WORD FROM THE PUBLISHER}
Because of its continued popularity and the requests that we have received from our many friends at the community colleges, we are pleased to provide a reprint of the 5th edition of A First Course in Differential Equations by Dennis G. Zill. To distinguish this reprint from the 7 th edition of the same text and from the other two texts in differential equations by the same author, we call this "The Classic Fifth Edition."

Gary W. Ostedt

\section*{PREFACE TO THE FIFTH EDITION}
My goal for the fifth edition was to achieve a balance between the concepts and presentation of materials that appealed to users of previous editions and the substantive changes made to strengthen and modernize the text. I feel I have achieved this balance, thus enabling the text to appeal to an even wider audience. Many of the additions and changes are the result of user and reviewer comments and suggestions. Moreover, these changes were made with the ultimate audience in mind-the students who will be using it. For this reason, solutions of every example have been read with an eye to improving their clarity. In various places I have added either further explanations where I thought they might be helpful or "guidance boxes" at crucial points in the flow of the solution.

NEW FEATURES

Some new features, that I hope students will find both interesting and motivational, have been added to the text. Essays written by mathematicians prominent in their specialty are included after Chapters 3, 4, 5, and 9 . Each essay reflects the thoughts, creativity, and opinions of the individual author and is intended to enhance the material found in the preceding chapter. It is my hope that the addition of these essays will spark the interest of the students, encourage them to read mathematics, and help them to gain a realization that differential equations is not simply a dry collection of methods, facts, and formulas, but a vibrant field in which people can, and do, work.

Color inserts also have been added at intervals in the text. These pages consist of illustrations matched with photographs relating to some of the applications found in the text. I feel that these contribute to the visualization of the applications and thereby provide an added insight to students.

\section*{CHANGES IN THIS EDITION}
\begin{itemize}
  \item Section 1.2 is now devoted solely to the concept of a differential equation as a mathematical model.
  \item The material on the differential equation of a family of curves has been deleted. A brief discussion of this concept is now given in Section 3.1 (Orthogonal Trajectories).
  \item The method of undetermined coefficients is one of the more controversial topics in a course in differential equations. In the last three editions, this topic was developed from the viewpoint of using a differential annihilator as an aid in determining the correct form of a particular solution. While preparing this revision, a substantial number of reviewers indicated that the annihilator approach was too sophisticated for their students and requested a simpler rule-based approach. Other reviewers, however, desired no change. In order to satisfy each of these preferences, both approaches are presented in this edition. The instructor can now choose between undetermined coefficients based on the superposition principle for nonhomogeneous linear differential equations (Section 4.4) or those based on the concept of differential annihilators (Section 4.6). Moreover, the notion of a differential operator is now introduced in a separate section (Section 4.5). Thus, covering Section 4.4 does not preclude coverage of the otherwise useful concept of a differential operator.
  \item The review of power series in Section 6.2 has been greatly expanded. A discussion of the arithmetic of powers series (addition, multiplication, and division of series) has been added.
  \item A brief discussion of the "cover-up method" for determining coefficients in a partial fraction decomposition and a historical note on Oliver Heaviside have been added to Section 7.2.
  \item The discussion on the operational properties of the Laplace transform has now been divided into two sections: Section 7.3, Translation Theorems and Derivatives of Transforms, and Section 7.4, Transforms of Derivatives, Integrals, and Periodic Functions. This separation allows for a clearer, more comprehensive treatment of these topics.
  \item Gaussian elimination, in addition to Gauss-Jordan elimination, is now discussed in Section 8.4. The notation for indicating row operations on an augmented matrix has been improved.
  \item Chapter 9, "Numerical Methods for Ordinary Differential Equations," has been significantly expanded and partially rewritten. The AdamsBashforth/Adams-Moulton multistep method has been added to Section 9.5. Section 9.6, Errors and Stability, and Section 9.8, Second-Order Boundary-Value Problems, are new to this edition.
  \item Chapter 10, on partial differential equations and Fourier series, has been eliminated from this edition. It was the consensus of users that this material was unnecessary in a beginning course. The topics: Fourier series, partial differential equations, and solutions of boundary-value problems by separation of variables, integral transforms, and numerical methods, are covered in detail in the expanded version of this text, Differential Equations with Boundary-Value Problems, Third Edition.
  \item New problems, applications, illustrations, remarks, and historical footnotes, have been added throughout the text.
\end{itemize}

\section*{SUPPLEMENTS AVAILABLE}
\section*{For Instructors}
Complete Solutions Manual, Warren S. Wright and Carol D. Wright, Loyola Marymount University. This manual contains complete, worked-out solutions to every problem in the text.

\section*{For Students}
Student Solutions Manual, Warren S. Wright and Carol D. Wright. This manual provides solutions to every third problem in each exercise set.

Dennis G. Zill

Los Angeles

\section*{A FIRST COURSE IN DIFFERENTIAL EQUATIONS}
\section*{INTRODUCTION TO DIFFERENTIAL EQUATIONS }
The words differential and equations certainly suggest solving some kind of equation that contains derivatives. So it is; in fact, the preceding sentence tells the complete story about the course that you are about to begin. But before you start solving anything, you must learn some of the basic definitions and terminology of the subject. This is what Section 1.1 is all about. Section 1.2 is intended to be motivational. Why should you, an erstwhile scientist or engineer, study this subject? The answer is simple: Differential equations are the mathematical backbone of many areas of science and engineering. Hence, in Section 1.2 we examine, albeit briefly, how differential equations arise from attempts to formulate, or describe, certain physical systems in terms of mathematics.

\subsection*{1.1 BASIC DEFINITIONS AND TERMINOLOGY \\
 - Ordinary differential equation - Partial differential equation \\
 - Order of an equation - Linear equation - Nonlinear equation - Solution \\
 - Trivial solution - Explicit and implicit solutions $\cdot$ n-parameter family of solutions \\
 - Particular solution $\cdot$ Singular solution $\cdot$General solution}
In calculus you learned that given a function $y=f(x)$, the derivative

$$
\frac{d y}{d x}=f^{\prime}(x)
$$

is itself a function of $x$ and is found by some appropriate rule. For example, if $y=e^{x^{2}}$, then


\begin{equation*}
\frac{d y}{d x}=2 x e^{x^{2}} \quad \text { or } \quad \frac{d y}{d x}=2 x y \tag{1}
\end{equation*}


The problem that we face in this course is not this: Given a function $y=f(x)$, find its derivative. Rather, our problem is this: If we are given an equation such as $d y / d x=2 x y$, we must somehow find a function $y=f(x)$ that satisfies the equation. In a word, we wish to solve differential equations.

\section*{DEFINITION 1.1 Differential Equation}
An equation containing the derivatives or differentials of one or more dependent variables, with respect to one or more independent variables, is said to be a differential equation (DE).

Differential equations are classified according to type, order, and linearity.

Classification by Type If an equation contains only ordinary derivatives of one or more dependent variables, with respect to a single independent variable, it is then said to be an ordinary differential equation (ODE). For example,

$$
(y-x) d x+4 x d y=0, \quad \frac{d u}{d x}-\frac{d v}{d x}=x, \quad \frac{d^{2} y}{d x^{2}}-2 \frac{d y}{d x}+6 y=0
$$

are ordinary differential equations. An equation involving the partial derivatives of one or more dependent variables of two or more independent variables is called a partial differential equation (PDE). For example,

$$
\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}, \quad x \frac{\partial u}{\partial x}+y \frac{\partial u}{\partial y}=u, \quad \frac{\partial^{2} u}{\partial x^{2}}=\frac{\partial^{2} u}{\partial t^{2}}-2 \frac{\partial u}{\partial t}
$$

are partial differential equations.

Classification by Order The order of the highest-order derivative in a differential equation is called the order of the equation. For example,

$$
\begin{aligned}
& \text { second-order } \\
& \frac{d^{2} y}{d x^{2}}+5\left(\frac{d y}{d x}\right)^{3}-4 y=e^{x}
\end{aligned}
$$

is a second-order ordinary differential equation. Since the differential equation $(y-x) d x+4 x d y=0$ can be put into the form

$$
4 x \frac{d y}{d x}+y=x
$$

by dividing by the differential $d x$, it is a first-order ordinary differential equation. The equation

$$
a^{2} \frac{\partial^{4} u}{\partial x^{4}}+\frac{\partial^{2} u}{\partial t^{2}}=0
$$

is a fourth-order partial differential equation.

Although partial differential equations are very important, their study demands a good foundation in the theory of ordinary differential equations. Consequently, in the discussion that follows we shall confine our attention to ordinary differential equations.

A general $n$ th-order, ordinary differential equation is often represented by the symbolism


\begin{equation*}
F\left(x, y, \frac{d y}{d x}, \ldots, \frac{d^{n} y}{d x^{n}}\right)=0 \tag{2}
\end{equation*}


The following is a special case of (2).

Classification as Linear or Nonlinear A differential equation is said to be linear if it can be written in the form

$$
a_{n}(x) \frac{d^{n} y}{d x^{n}}+a_{n-1}(x) \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x)
$$

It should be observed that linear differential equations are characterized by two properties:

(i) The dependent variable $y$ and all its derivatives are of the first degree; that is, the power of each term involving $y$ is 1 .

(ii) Each coefficient depends on only the independent variable $x$.

An equation that is not linear is said to be nonlinear. The equations

$$
x d y+y d x=0, \quad y^{\prime \prime}-2 y^{\prime}+y=0, \quad \text { and } \quad x^{3} \frac{d^{3} y}{d x^{3}}+3 x \frac{d y}{d x}+5 y=e^{x}
$$

are linear first-, second-, and third-order ordinary differential equations, respectively. On the other hand,

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-021}
\end{center}

are nonlinear second- and third-order ordinary differential equations, respectively.

Solutions As mentioned before, our goal in this course is to solve, or find solutions of, differential equations.

\section*{DEFINITION 1.2 Solution of a Differential Equation}
Any function $f$ defined on some interval $I$, which when substituted into a differential equation reduces the equation to an identity, is said to be a solution of the equation on the interval.

In other words, a solution of an ordinary differential equation

$$
F\left(x, y, y^{\prime}, \ldots, y^{(n)}\right)=0
$$

is a function $f$ that possesses at least $n$ derivatives and satisfies the equation; that is,

$$
F\left(x, f(x), f^{\prime}(x), \ldots, f^{(n)}(x)\right)=0
$$

for every $x$ in the interval $I$. The precise form of the interval $I$ is purposely left vague in Definition 1.2. Depending on the context of the discussion, $I$ could represent an open interval $(a, b)$, a closed interval $[a, b]$, an infinite interval $(0, \infty)$, and so on.

\section*{EXAMPLE 1 Verification of a Solution}
Verify that $y=x^{4} / 16$ is a solution of the nonlinear equation

$$
\frac{d y}{d x}=x y^{1 / 2}
$$

on the interval $(-\infty, \infty)$.

Solution One way of verifying that the given function is a solution is to write the differential equation as $d y / d x-x y^{1 / 2}=0$ and then see, after substituting, whether the sum $d y / d x-x y^{1 / 2}$ is zero for every $x$ in the interval. Using

$$
\frac{d y}{d x}=4 \frac{x^{3}}{16}=\frac{x^{3}}{4} \quad \text { and } \quad y^{1 / 2}=\left(\frac{x^{4}}{16}\right)^{1 / 2}=\frac{x^{2}}{4}
$$

we see that

$$
\frac{d y}{d x}-x y^{1 / 2}=\frac{x^{3}}{4}-x\left(\frac{x^{4}}{16}\right)^{1 / 2}=\frac{x^{3}}{4}-\frac{x^{3}}{4}=0
$$

for every real number.

\section*{EXAMPLE 2 Verification of a Solution}
The function $y=x e^{x}$ is a solution of the linear equation

$$
y^{\prime \prime}-2 y^{\prime}+y=0
$$

on $(-\infty, \infty)$. To see this, we compute

$$
y^{\prime}=x e^{x}+e^{x} \quad \text { and } \quad y^{\prime \prime}=x e^{x}+2 e^{x}
$$

Observe

$$
y^{\prime \prime}-2 y^{\prime}+y=\left(x e^{x}+2 e^{x}\right)-2\left(x e^{x}+e^{x}\right)+x e^{x}=0
$$

for every real number.

Notice that in Examples 1 and 2 the constant function $y=0$, for $-\infty<x<\infty$, also satisfies the given differential equation. A solution of a differential equation that is identically zero on an interval $I$ is often referred to as a trivial solution.

Not every differential equation that we write necessarily has a solution.

\section*{EXAMPLE 3 Some Special DEs}
(a) The first-order differential equations

$$
\left(\frac{d y}{d x}\right)^{2}+1=0 \quad \text { and } \quad\left(y^{\prime}\right)^{2}+y^{2}+4=0
$$

possess no real solutions. Why?

(b) The second-order equation $\left(y^{\prime \prime}\right)^{2}+10 y^{4}=0$ possesses only one real solution. What is it?

Explicit and Implicit Solutions You should be familiar with the notions of explicit and implicit functions from your study of calculus. Similarly, solutions of differential equations are distinguished as either explicit solutions or implicit solutions. A solution of an ordinary differential equation (2) that can be written in the form $y=f(x)$ is said to be an explicit solution. We saw in our initial discussion that $y=e^{x^{2}}$ is an explicit solution of $d y / d x=2 x y$. In Examples 1 and 2, $y=x^{4} / 16$ and $y=x e^{x}$ are explicit solutions of $d y / d x=x y^{1 / 2}$ and $y^{\prime \prime}-2 y^{\prime}+$ $y=0$, respectively. A relation $G(x, y)=0$ is said to be an implicit solution of an ordinary differential equation (2) on an interval $I$ provided it defines one or more explicit solutions on $I$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-023}
\end{center}

$y=c e^{x^{2}}$

Figure I.I

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-023(1)}
\end{center}

Figure 1.2

\section*{EXAMPLE 4 An Implicit Solution}
For $-2<x<2$ the relation $x^{2}+y^{2}-4=0$ is an implicit solution of the differential equation

$$
\frac{d y}{d x}=-\frac{x}{y}
$$

By implicit differentiation it follows that

$$
\begin{gathered}
\frac{d}{d x}\left(x^{2}\right)+\frac{d}{d x}\left(y^{2}\right)-\frac{d}{d x}(4)=0 \\
2 x+2 y \frac{d y}{d x}=0 \quad \text { or } \quad \frac{d y}{d x}=-\frac{x}{y}
\end{gathered}
$$

The relation $x^{2}+y^{2}-4=0$ in Example 4 defines two explicit differentiable functions: $y=\sqrt{4-x^{2}}$ and $y=-\sqrt{4-x^{2}}$ on the interval $(-2,2)$. Also note that any relation of the form $x^{2}+y^{2}-c=0$ formally satisfies $d y / d x=-x / y$ for any constant $c$. However, it is naturally understood that the relation should always make sense in the real number system; thus we cannot say that $x^{2}+y^{2}+1=0$ determines a solution of the differential equation.

Since the distinction between an explicit and an implicit solution should be intuitively clear, we shall not belabor the issue by always saying "here is an explicit (implicit) solution."

Number of Solutions You should become accustomed to the fact that a given differential equation usually possesses an infinite number of solutions. By direct substitution, we can prove that any curve-that is, function-in the oneparameter family $y=c e^{x^{2}}$, where $c$ is any arbitrary constant, also satisfies (1). As indicated in Figure 1.1, the trivial solution is a member of this family of solutions corresponding to $c=0$. In Example 2, tracing back through the work reveals that $y=c x e^{x}$ is a family of solutions of the given differential equation.

\section*{EXAMPLE 5 An Infinite Number of Solutions}
For any value of $c$ the function $y=c / x+1$ is a solution of the first-order differential equation

$$
x \frac{d y}{d x}+y=1
$$

on the interval $(0, \infty)$. We have

$$
\frac{d y}{d x}=c \frac{d}{d x}\left(x^{-1}\right)+\frac{d}{d x}(1)=-c x^{-2}=-\frac{c}{x^{2}}
$$

so

$$
x \frac{d y}{d x}+y=x\left(-\frac{c}{x^{2}}\right)+\left(\frac{c}{x}+1\right)=1
$$

By choosing $c$ to be any real number, we can generate an infinite number of solutions. In particular, for $c=0$ we obtain a constant solution $y=1$. See Figure 1.2.

In Example 5, $y=c / x+1$ is a solution of the differential equation on any interval not containing the origin. The function is not differentiable at $x=0$.

Under some circumstances when we add two solutions of a differential equation, we get another solution.

\section*{EXAMPLE 6 An Infinite Number of Solutions}
(a) The functions $y=c_{1} \cos 4 x$ and $y=c_{2} \sin 4 x$, where $c_{1}$ and $c_{2}$ are arbitrary constants, are solutions of the differential equation

$$
y^{\prime \prime}+16 y=0
$$

For $y=c_{1} \cos 4 x$, the first and second derivatives are

$$
y^{\prime}=-4 c_{1} \sin 4 x \quad \text { and } \quad y^{\prime \prime}=-16 c_{1} \cos 4 x
$$

and so

$$
y^{\prime \prime}+16 y=-16 c_{1} \cos 4 x+16\left(c_{1} \cos 4 x\right)=0
$$

Similarly, for $y=c_{2} \sin 4 x$,

$$
y^{\prime \prime}+16 y=-16 c_{2} \sin 4 x+16\left(c_{2} \sin 4 x\right)=0
$$

(b) The sum of the solutions in part (a), $y=c_{1} \cos 4 x+c_{2} \sin 4 x$, can also be shown to be a solution of $y^{\prime \prime}+16 y=0$.

\section*{EXAMPLE 7 An Infinite Number of Solutions}
You should be able to show that

$$
y=e^{x}, \quad y=e^{-x}, \quad y=c_{1} e^{x}, \quad y=c_{2} e^{-x}, \quad \text { and } \quad y=c_{1} e^{x}+c_{2} e^{-x}
$$

are all solutions of the linear second-order differential equation

$$
y^{\prime \prime}-y=0
$$

Note that $y=c_{1} e^{x}$ is a solution for any choice of $c_{1}$, but $y=e^{x}+c_{1}, c_{1} \neq 0$ does not satisfy the equation since, for this latter family of functions, we would get $y^{\prime \prime}-y=-c_{1}$.

The next example shows that a solution of a differential equation can be a piecewise-defined function.

\section*{EXAMPLE 8 A Piecewise-Defined Solution}
Any function in the one-parameter family $y=c x^{4}$ is a solution of the differential equation

$$
x y^{\prime}-4 y=0
$$

We have $x y^{\prime}-4 y=x\left(4 c x^{3}\right)-4 c x^{4}=0$. The piecewise-defined function

$$
y=\left\{\begin{aligned}
-x^{4}, & x<0 \\
x^{4}, & x \geq 0
\end{aligned}\right.
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-025}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-025(1)}
\end{center}

(b)

Figure 1.3

is also a solution. Observe that this function cannot be obtained from $y=c x^{4}$ by a single selection of the parameter $c$. See Figure 1.3(b).

Further Terminology The study of differential equations is similar to integral calculus. When evaluating an antiderivative or indefinite integral, we utilize a single constant of integration. In like manner, when solving a first-order differential equation $F\left(x, y, y^{\prime}\right)=0$, we usually obtain a family of curves or functions $G(x, y, c)=0$ containing one arbitrary parameter such that each member of the family is a solution of the differential equation. In fact, when solving an $n$ th-order equation $F\left(x, y, y^{\prime}, \ldots, y^{(n)}\right)=0$, where $y^{(n)}$ means $d^{n} y / d x^{n}$, we expect an $n$-parameter family of solutions $G\left(x, y, c_{1}, \ldots, c_{n}\right)=0$.

A solution of a differential equation that is free of arbitrary parameters is called a particular solution. One way of obtaining a particular solution is to choose specific values of the parameter(s) in a family of solutions. For example, it is readily seen that $y=c e^{x}$ is a one-parameter family of solutions of the simple first-order equation $y^{\prime}=y$. For $c=0,-2$, and 5 , we get the particular solutions $y=0, y=-2 e^{x}$, and $y=5 e^{x}$, respectively.

Sometimes a differential equation possesses a solution that cannot be obtained by specializing the parameters in a family of solutions. Such a solution is called a singular solution.

\section*{EXAMPLE 9 A One-Parameter Family of Solutions}
In Section 2.2 we shall prove that a one-parameter family of solutions of $y^{\prime}=x y^{1 / 2}$ is given by $y=\left(\frac{1}{4} x^{2}+c\right)^{2}$. When $c=0$, the resulting particular solution is $y=\frac{1}{16} x^{4}$. In this case the trivial solution $y=0$ is a singular solution of the equation, since it cannot be obtained from the family for any choice of the parameter $c$.

If every solution of $F\left(x, y, y^{\prime}, \ldots, y^{(n)}\right)=0$ on an interval $I$ can be obtained from $G\left(x, y, c_{1}, \ldots, c_{n}\right)=0$ by appropriate choices of the $c_{i}$, $i=1,2, \ldots, n$, we then say that the $n$-parameter family is the general, or complete, solution of the differential equation.

Remarks There are two schools of thought concerning the concept of a "general solution." An alternative viewpoint holds that a general solution of an $n$ th-order differential equation is a family of solutions containing $n$ essential* parameters. Period! In other words, the family is not required to contain all solutions of the differential equation on some interval. The difference in these opinions is really a distinction between the solutions to linear and nonlinear equations. In solving linear differential equations we
\footnotetext{\begin{itemize}
  \item We won't try to define this concept. But roughly it means: Don't play games with the constants. Certainly $y=x+c_{1}+c_{2}$ represents a family of solutions of $y^{\prime}=1$. If we rename $c_{1}+c_{2}$ as $c$ the family has essentially one constant: $y=x+c$. You should verify that $y=c_{1}+\ln c_{2} x$ is a solution of $x^{2} y^{\prime \prime}+x y^{\prime}=0$ on the interval $(0, \infty)$ for any choice of $c_{1}$ and $c_{2}>0$. Are $c_{1}$ and $c_{2}$ essential parameters?
\end{itemize}
}
shall impose relatively simple restrictions on the coefficients; with these restrictions one can always be assured not only that a solution does exist on an interval but also that a family of solutions indeed yields all possible solutions.

Another fact deserves mention at this time. Nonlinear equations, with the exception of some first-order equations, are usually difficult or impossible to solve in terms of familiar elementary functions such as algebraic functions, exponential and logarithmic functions, and trigonometric and inverse trigonometric functions. Furthermore, if we happen to have a family of solutions for a nonlinear equation, it is not obvious when this family constitutes a general solution. On a practical level, then, the designation "general solution" is applied only to linear differential equations.

\section*{EXERCISES 1.1}
\section*{Answers to odd-numbered problems begin on page A-1.}
In Problems 1-10 state whether the given differential equations are linear or nonlinear. Give the order of each equation.

\begin{enumerate}
  \item $(1-x) y^{\prime \prime}-4 x y^{\prime}+5 y=\cos x$
  \item $x \frac{d^{3} y}{d x^{3}}-2\left(\frac{d y}{d x}\right)^{4}+y=0$
  \item $y y^{\prime}+2 y=1+x^{2}$
  \item $x^{2} d y+\left(y-x y-x e^{x}\right) d x=0$
  \item $x^{3} y^{(4)}-x^{2} y^{\prime \prime}+4 x y^{\prime}-3 y=0$
  \item $\frac{d^{2} y}{d x^{2}}+9 y=\sin y$
  \item $\frac{d y}{d x}=\sqrt{1+\left(\frac{d^{2} y}{d x^{2}}\right)^{2}}$
  \item $\frac{d^{2} r}{d t^{2}}=-\frac{k}{r^{2}}$
  \item $(\sin x) y^{\prime \prime \prime}-(\cos x) y^{\prime}=2$
  \item $\left(1-y^{2}\right) d x+x d y=0$
\end{enumerate}

In Problems 11-40 verify that the indicated function is a solution of the given differential equation. Where appropriate, $c_{1}$ and $c_{2}$ denote constants.\\
11. $2 y^{\prime}+y=0 ; \quad y=e^{-x / 2}$\\
12. $y^{\prime}+4 y=32 ; \quad y=8$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $\frac{d y}{d x}-2 y=e^{3 x} ; \quad y=e^{3 x}+10 e^{2 x}$

  \item $\frac{d y}{d t}+20 y=24 ; \quad y=\frac{6}{5}-\frac{6}{5} e^{-20 t}$

  \item $y^{\prime}=25+y^{2} ; \quad y=5 \tan 5 x$

  \item $\frac{d y}{d x}=\sqrt{\frac{y}{x}} ; \quad y=\left(\sqrt{x}+c_{1}\right)^{2}, x>0, c_{1}>0$

  \item $y^{\prime}+y=\sin x ; \quad y=\frac{1}{2} \sin x-\frac{1}{2} \cos x+10 e^{-x}$

  \item $2 x y d x+\left(x^{2}+2 y\right) d y=0 ; \quad x^{2} y+y^{2}=c_{1}$

  \item $x^{2} d y+2 x y d x=0 ; \quad y=-\frac{1}{x^{2}}$

  \item $\left(y^{\prime}\right)^{3}+x y^{\prime}=y ; \quad y=x+1$

  \item $y=2 x y^{\prime}+y\left(y^{\prime}\right)^{2} ; \quad y^{2}=c_{1}\left(x+\frac{1}{4} c_{1}\right)$

  \item $y^{\prime}=2 \sqrt{|y|} ; \quad y=x|x|$

  \item $y^{\prime}-\frac{1}{x} y=1 ; \quad y=x \ln x, x>0$

  \item $\frac{d P}{d t}=P(a-b P) ; \quad P=\frac{a c_{1} e^{a t}}{1+b c_{1} e^{a t}}$

  \item $\frac{d X}{d t}=(2-X)(1-X) ; \quad \ln \frac{2-X}{1-X}=t$

  \item $y^{\prime}+2 x y=1 ; \quad y=e^{-x^{2}} \int_{0}^{x} e^{t^{2}} d t+c_{1} e^{-x^{2}}$

  \item $\left(x^{2}+y^{2}\right) d x+\left(x^{2}-x y\right) d y=0 ; \quad c_{1}(x+y)^{2}=x e^{y / x}$

  \item $y^{\prime \prime}+y^{\prime}-12 y=0 ; \quad y=c_{1} e^{3 x}+c_{2} e^{-4 x}$

  \item $y^{\prime \prime}-6 y^{\prime}+13 y=0 ; \quad y=e^{3 x} \cos 2 x$

  \item $\frac{d^{2} y}{d x^{2}}-4 \frac{d y}{d x}+4 y=0 ; \quad y=e^{2 x}+x e^{2 x}$

  \item $y^{\prime \prime}=y ; \quad y=\cosh x+\sinh x$

  \item $y^{\prime \prime}+25 y=0 ; \quad y=c_{1} \cos 5 x$

  \item $y^{\prime \prime}+\left(y^{\prime}\right)^{2}=0 ; \quad y=\ln \left|x+c_{1}\right|+c_{2}$

  \item $y^{\prime \prime}+y=\tan x ; \quad y=-\cos x \ln (\sec x+\tan x)$

  \item $x \frac{d^{2} y}{d x^{2}}+2 \frac{d y}{d x}=0 ; \quad y=c_{1}+c_{2} x^{-1}$

  \item $x^{2} y^{\prime \prime}-x y^{\prime}+2 y=0 ; \quad y=x \cos (\ln x), x>0$

  \item $x^{2} y^{\prime \prime}-3 x y^{\prime}+4 y=0 ; \quad y=x^{2}+x^{2} \ln x, x>0$

  \item $y^{\prime \prime \prime}-y^{\prime \prime}+9 y^{\prime}-9 y=0 ; \quad y=c_{1} \sin 3 x+c_{2} \cos 3 x+4 e^{x}$

  \item $y^{\prime \prime \prime}-3 y^{\prime \prime}+3 y^{\prime}-y=0 ; \quad y=x^{2} e^{x}$

  \item $x^{3} \frac{d^{3} y}{d x^{3}}+2 x^{2} \frac{d^{2} y}{d x^{2}}-x \frac{d y}{d x}+y=12 x^{2} ; \quad y=c_{1} x+c_{2} x \ln x+4 x^{2}, x>0$

\end{enumerate}

In Problems 41 and 42 verify that the indicated piecewise-defined function is a solution of the given differential equation.\\
41. $x y^{\prime}-2 y=0 ; \quad y=\left\{\begin{aligned}-x^{2}, & x<0 \\ x^{2}, & x \geq 0\end{aligned}\right.$\\
42. $\left(y^{\prime}\right)^{2}=9 x y ; \quad y= \begin{cases}0, & x<0 \\ x^{3}, & x \geq 0\end{cases}$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item Verify that a one-parameter family of solutions for
\end{enumerate}

$$
y=x y^{\prime}+\left(y^{\prime}\right)^{2} \text { is } \quad y=c x+c^{2}
$$

Determine a value of $k$ such that $y=k x^{2}$ is a singular solution of the differential equation.

\begin{enumerate}
  \setcounter{enumi}{43}
  \item Verify that a one-parameter family of solutions for
\end{enumerate}

$$
y=x y^{\prime}+\sqrt{1+\left(y^{\prime}\right)^{2}} \text { is } y=c x+\sqrt{1+c^{2}}
$$

Show that the relation $x^{2}+y^{2}=1$ defines a singular solution of the equation on the interval $(-1,1)$.

\begin{enumerate}
  \setcounter{enumi}{44}
  \item A one-parameter family of solutions for
\end{enumerate}

$$
y^{\prime}=y^{2}-1 \quad \text { is } \quad y=\frac{1+c e^{2 x}}{1-c e^{2 x}}
$$

By inspection,* determine a singular solution of the differential equation.

\begin{enumerate}
  \setcounter{enumi}{45}
  \item On page 6 we saw that $y=\sqrt{4-x^{2}}$ and $y=-\sqrt{4-x^{2}}$ are solutions of $d y / d x=-x / y$ on the interval $(-2,2)$. Explain why
\end{enumerate}

$$
y=\left\{\begin{array}{rr}
\sqrt{4-x^{2}}, & -2<x<0 \\
-\sqrt{4-x^{2}}, & 0 \leq x<2
\end{array}\right.
$$

is not a solution of the differential equation on the interval.

In Problems 47 and 48 find values of $m$ so that $y=e^{m x}$ is a solution of each differential equation.\\
47. $y^{\prime \prime}-5 y^{\prime}+6 y=0$\\
48. $y^{\prime \prime}+10 y^{\prime}+25 y=0$

In Problems 49 and 50 find values of $m$ so that $y=x^{m}$ is a solution of each differential equation.\\
49. $x^{2} y^{\prime \prime}-y=0$\\
50. $x^{2} y^{\prime \prime}+6 x y^{\prime}+4 y=0$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item Show that $y_{1}=x^{2}$ and $y_{2}=x^{3}$ are both solutions of
\end{enumerate}

$$
x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=0
$$

Are the constant multiples $c_{1} y_{1}$ and $c_{2} y_{2}$, with $c_{1}$ and $c_{2}$ arbitrary, also solutions? Is the sum $y_{1}+y_{2}$ a solution?

\begin{enumerate}
  \setcounter{enumi}{51}
  \item Show that $y_{1}=2 x+2$ and $y_{2}=-x^{2} / 2$ are both solutions of
\end{enumerate}

$$
y=x y^{\prime}+\frac{1}{2}\left(y^{\prime}\right)^{2}
$$

Are the constant multiples $c_{1} y_{1}$ and $c_{2} y_{2}$, with $c_{1}$ and $c_{2}$ arbitrary, also solutions? Is the sum $y_{1}+y_{2}$ a solution?

\begin{enumerate}
  \setcounter{enumi}{52}
  \item By inspection determine, if possible, a real solution of the given differential equation.\\
(a) $\left|\frac{d y}{d x}\right|+|y|=0$\\
(b) $\left|\frac{d y}{d x}\right|+|y|+1=0$\\
(c) $\left|\frac{d y}{d x}\right|+|y|=1$
\end{enumerate}

\subsection*{1.2 SOME MATHEMATICAL MODELS \\
 - Mathematical model $\cdot$ State of the system}
In science, engineering, economics, and even psychology, we often wish to describe or model the behavior of some system or phenomenon in mathematical terms. This descriptions starts with

(i) identifying the variables that are responsible for changing the system and

(ii) a set of reasonable assumptions about the system.
\footnotetext{\begin{itemize}
  \item Translated, this means take a good guess and see if it works.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-029}
\end{center}

Figure 1.4\\
These assumptions also include any empirical laws that are applicable to the system. The mathematical construct of all these assumptions, or the mathematical model of the system, is in many instances a differential equation or a system of differential equations. We expect a reasonable mathematical model of a system to have a solution that is consistent with the known behavior of the system.

A mathematical model of a physical system often involves the variable time. The solution of the model then gives the state of the system; in other words, for appropriate values of time $t$, the values of the dependent variable (or variables) describe the system in the past, present, and future.

Falling Body The mathematical description of a body falling vertically under the influence of gravity leads to a simple second-order differential equation. The solution of this equation gives the position of the body relative to the ground.

\section*{EXAMPLE 1 Freely Falling Body}
It is well known that free-falling objects close to the surface of the earth accelerate at a constant rate $g$. Acceleration is the derivative of the velocity, and this, in turn, is the derivative of the distance $s$. Suppose a rock is tossed upward from the roof of a building as illustrated in Figure 1.4. If we assume that the upward direction is positive, then the mathematical statement

$$
\frac{d^{2} s}{d t^{2}}=-g
$$

is the differential equation that governs the vertical distance that the body travels. The minus sign is used because the weight of the body is a force directed opposite to the positive direction.

If we suppose further that the height of the building is $s_{0}$ and the initial velocity of the rock is $v_{0}$, then we must find a solution of the differential equation

$$
\frac{d^{2} s}{d t^{2}}=-g, \quad 0<t<t_{1}
$$

that also satisfies the side conditions $s(0)=s_{0}$ and $s^{\prime}(0)=v_{0}$. Here $t=0$ is the initial time the rock leaves the roof of the building, and $t_{1}$ is the elapsed time when the rock hits the ground. Since the rock is thrown upward in the positive direction, it is naturally assumed that $v_{0}>0$.

Note that this formulation of the problem ignores other forces such as air resistance acting on the body.

Spring-Mass System When Newton's second law of motion is combined with Hooke's law, we can derive a differential equation governing the motion of a mass attached to a spring.

\section*{EXAMPLE 2 Vibrations of a Mass on a Spring}
To find the vertical displacement $x(t)$ of a mass attached to a spring, we use two different empirical laws: Newton's second law of motion and Hooke's law. The

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-030}
\end{center}

(a) (b) (c)

Figure 1.5 former law states that the net force acting on the system in motion is $F=m a$, where $m$ is the mass and $a$ is acceleration. Hooke's law states that the restoring force of a stretched spring is proportional to the elongation $s+x$; that is, the restoring force is $k(s+x)$, where $k>0$ is a constant. As shown in Figure 1.5(b), $s$ is the elongation of the spring after the mass has been attached and the system hangs at rest in the equilibrium position. When the system is in motion, the variable $x$ represents a directed distance of the mass beyond the equilibrium position. In Chapter 5 we shall prove that when the system is in motion, the net force acting on the mass is simply $F=-k x$. Thus, in the absence of damping and other external forces that might be impressed on the system, the differential equation of the vertical motion through the center of gravity of the mass can be obtained by equating

$$
m \frac{d^{2} x}{d t^{2}}=-k x
$$

Here the minus sign means that the restoring force of the spring acts opposite to the direction of motion-that is, toward the equilibrium position. In practice this second-order differential equation is often written as


\begin{equation*}
\frac{d^{2} x}{d t^{2}}+\omega^{2} x=0 \tag{1}
\end{equation*}


where $\omega^{2}=k / m$.

Units A word is in order regarding the system of units that is used in describing dynamic problems such as those illustrated in the last two examples. Three commonly used systems of units are summarized in Table 1.1. In each system the basic unit of time is the second.

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Quantity & \begin{tabular}{l}
Engineering \\
system* \\
\end{tabular} & SI system ${ }^{\dagger}$ & cgs \\
\hline
Force & pound (lb) & newton $(\mathrm{N})$ & dyne \\
\hline
Mass & slug & kilogram (kg) & gram $(\mathrm{g})$ \\
\hline
Distance & foot $(\mathrm{ft})$ & meter $(\mathrm{m})$ & centimeter $(\mathrm{cm})$ \\
\hline
\begin{tabular}{l}
Acceleration of \\
gravity $g$ (approximate) \\
\end{tabular} & $32 \mathrm{ft} / \mathrm{s}^{2}$ & $9.8 \mathrm{~m} / \mathrm{s}^{2}$ & $980 \mathrm{~cm} / \mathrm{s}^{2}$ \\
\hline
\end{tabular}
\end{center}

Table I.I Units of Measurement

\begin{itemize}
  \item Also known as the English gravitational system or British engineering system.
\end{itemize}

$\dagger$ International system of units. SI is the abbreviation for Systeme International.

The gravitational force exerted by the earth on a body of mass $m$ is called its weight $W$. In the absence of air resistance, the only force acting on a freely falling body is its weight. Hence, from Newton's second law of motion, it follows that mass $m$ and weight $W$ are related by

$$
W=m g .
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-031}
\end{center}

Figure 1.6\\
For example, in the engineering system a mass of $\frac{1}{4}$ slug corresponds to an $8-\mathrm{lb}$ weight. Since $m=W / g$, a $64-\mathrm{lb}$ weight corresponds to a mass of $\frac{64}{32}=2$ slugs. In the cgs system a weight of 2450 dynes has a mass of $\frac{2450}{980}=2.5$ grams. In the SI system a weight of 50 newtons has a mass of 50/9.8 $=5.1$ kilograms. We note that

$$
1 \text { newton }=10^{5} \text { dynes }=0.2247 \text { pound. }
$$

In the next example we derive the differential equation that describes the motion of a simple pendulum.

Simple Pendulum Any object that swings back and forth is called a physical pendulum. The simple pendulum is a special case of the physical pendulum and consists of a rod to which a mass is attached at one end. In describing the motion of a simple pendulum, we make the simplifying assumptions that the mass of the rod is negligible and that no external damping forces act on the system (such as air resistance).

\section*{EXAMPLE 3 Simple Pendulum}
A mass $m$ having weight $W$ is suspended from the end of a rod of constant length $l$. For motion in a vertical plane, we would like to determine the displacement angle $\theta$, measured from the vertical, as a function of time $t$ (we consider $\theta>0$ to the right of $O P$ and $\theta<0$ to left of $O P$ ). Recall that an arc $s$ of a circle of radius $l$ is related to the central angle $\theta$ through the formula $s=l \theta$. Hence the angular acceleration is

$$
a=\frac{d^{2} s}{d t^{2}}=l \frac{d^{2} \theta}{d t^{2}}
$$

From Newton's second law we then have

$$
F=m a=m l \frac{d^{2} \theta}{d t^{2}}
$$

From Figure 1.6 we see that the tangential component of the force due to the weight $W$ is $m g \sin \theta$. We equate the two different formulations of the tangential force to obtain


\begin{equation*}
m l \frac{d^{2} \theta}{d t^{2}}=-m g \sin \theta \quad \text { or } \quad \frac{d^{2} \theta}{d t^{2}}+\frac{g}{l} \sin \theta=0 \tag{2}
\end{equation*}


Because of the presence of $\sin \theta$, the differential equation (2) is nonlinear. It is also known that this equation cannot be solved in terms of elementary functions. Hence a further simplifying assumption is made. If the angular displacements $\theta$ are not too large, we can use the approximation $\sin \theta \approx \theta,{ }^{*}$ so (2) can be replaced with the linear second-order differential equation


\begin{equation*}
\frac{d^{2} \theta}{d t^{2}}+\frac{g}{l} \theta=0 \tag{3}
\end{equation*}

\footnotetext{\begin{itemize}
  \item For small values of $\theta$ (in radians), powers $\theta^{3}$ and higher can be ignored in the Maclaurin series $\sin \theta=\theta-\theta^{3} / 3!+\cdots$, and so we get $\sin \theta \approx \theta$. Use a calculator and compare the values of $\sin (0.05)$ and $\sin (0.005)$ with 0.05 and 0.005 .
\end{itemize}
}

If we set $\omega^{2}=g / l$, (3) has the exact same structure as the differential equation (1) governing the free vibrations of a weight on a spring. The fact that one basic differential equation can describe many diverse physical or even social/economic phenomena is a common occurrence in the study of applicable mathematics.

Rotating String We encounter equation (1) again in the analysis of a rotating string.

\section*{EXAMPLE 4 Shape of Rotating String}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-032}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-032(2)}
\end{center}

(b)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-032(1)}
\end{center}

(c)

Figure 1.7\\
Suppose a string of length $L$ with constant linear density $\rho$ (mass per unit length) is stretched along the $x$-axis and fixed at $x=0$ and $x=L$. Suppose the string is then rotated about that axis at a constant angular speed $\omega$. This is analogous to two persons holding a jump rope and then twirling it in a synchronous manner. See Figure 1.7(a). We want to find the differential equation that defines the shape $y(x)$ of the string, or the deflection curve away from its initial position. See Figure 1.7(b). To do this, consider a portion of the string on the interval $[x, x+\Delta x]$, where $\Delta x$ is small. If the magnitude $T$ of the tension $\mathbf{T}$ acting tangential to the string is constant along the string, then the desired differential equation can be obtained by equating two different formulations of the net force acting on the string on the interval $[x, x+\Delta x]$. First, we see from Figure 1.7(c) that the net vertical force is


\begin{equation*}
F=T \sin \theta_{2}-T \sin \theta_{1} \tag{4}
\end{equation*}


When the angles $\theta_{1}$ and $\theta_{2}$ (measured in radians) are small, we have

$$
\sin \theta_{2} \approx \tan \theta_{2} \approx y^{\prime}(x+\Delta x) \text { and } \quad \sin \theta_{1} \approx \tan \theta_{1} \approx y^{\prime}(x)
$$

and so (4) becomes


\begin{equation*}
F=T\left[y^{\prime}(x+\Delta x)-y^{\prime}(x)\right] \tag{5}
\end{equation*}


Second, the net force is also given by Newton's second law $F=m a$. Here the mass of string on the interval is $m=\rho \Delta x$; the centripetal acceleration of a point rotating with angular speed $\omega$ in a circle of radius $r$ is $a=r \omega^{2}$. With $\Delta x$ small we take $r=y$. Thus another formulation of the net force is


\begin{equation*}
F \approx-(\rho \Delta x) y \omega^{2}, \tag{6}
\end{equation*}


where the minus sign comes from the fact that the acceleration points in the direction opposite to the positive $y$ direction. Now by equating (5) and (6), we have


\begin{equation*}
T\left[y^{\prime}(x+\Delta x)-y^{\prime}(x)\right] \approx-(\rho \Delta x) y \omega^{2} \quad \text { or } \quad T \frac{y^{\prime}(x+\Delta x)-y^{\prime}(x)}{\Delta x} \approx-\rho \omega^{2} y \tag{7}
\end{equation*}


For $\Delta x$ close to zero, $\left[y^{\prime}(x+\Delta x)-y^{\prime}(x)\right] / \Delta x \approx d^{2} y / d x^{2}$, so the last expression in (7) gives


\begin{equation*}
T \frac{d^{2} y}{d x^{2}}=-\rho \omega^{2} y \quad \text { or } \quad T \frac{d^{2} y}{d x^{2}}+\rho \omega^{2} y=0 \tag{array}
\end{equation*}


Since the string is anchored at $x=0$ and $x=L$, we expect that the solution $y(x)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-033}
\end{center}

Figure 1.9 of the last equation would also satisfy the side conditions $y(0)=0$ and $y(L)=0$.

Dividing the last equation in (8) by $T$ gives

$$
\frac{d^{2} y}{d x^{2}}+\frac{\rho \omega^{2}}{T} y=0
$$

which is analogous to (1) and (3). If the magnitude $T$ of the tension is not constant throughout the interval $[0, L]$, then it can be shown that the differential equation for the deflection curve of the string is


\begin{equation*}
\frac{d}{d x}\left[T(x) \frac{d y}{d x}\right]+\rho \omega^{2} y=0 \tag{9}
\end{equation*}


Series Circuits According to Kirchhoff's second law, the impressed voltage $E(t)$ on a closed loop must equal the sum of the voltage drops in the loop. Figure 1.8 shows the symbols and the formulas for the respective voltage drops across an inductor, a capacitor, and a resistor. The current in a circuit after a switch is closed is denoted by $i(t)$; the charge on a capacitor at time $t$ is denoted by $q(t)$. The letters $L, C$, and $R$ are constants known as inductance, capacitance, and resistance, respectively.

\section*{EXAMPLE 5 Charge on a Capacitor}
Consider the single-loop series circuit containing an inductor, resistor, and capacitor shown in Figure 1.9. A second-order differential equation for the charge $q(t)$ on the capacitor can be obtained by adding the voltage drops

$$
\begin{aligned}
& \text { inductor }=L \frac{d i}{d t}=L \frac{d^{2} q}{d t^{2}} \quad \leftarrow_{\text {current } i \text { related }} \\
& d a \quad \text { to charge } q \text { by } i=d q / d t \\
& \text { resistor }=i R=R \frac{d q}{d t} \quad \leftarrow \\
& \text { capacitor }=\frac{1}{C} q
\end{aligned}
$$

and equating the sum to the impressed voltage $E(t)$ :


\begin{equation*}
L \frac{d^{2} q}{d t^{2}}+R \frac{d q}{d t}+\frac{1}{C} q=E(t) \tag{10}
\end{equation*}


Table I.2 Units of Measurement

\begin{center}
\begin{tabular}{ll}
\hline
Quantity & Unit \\
\hline
Impressed voltage, &  \\
$\quad$ or emf & volt $(\mathrm{V})$ \\
Inductance $L$ & henry (H) \\
Capacitance $C$ & farad (F) \\
Resistance $R$ & ohm $(\Omega)$ \\
Charge $q$ & coulomb (C) \\
Current $i$ & ampere (A) \\
\hline
\end{tabular}
\end{center}

In Example 5 the side conditions $q(0)$ and $q^{\prime}(0)$ represent the charge on the capacitor and the current in the circuit, respectively, at time $t=0$. Also, the impressed voltage $E(t)$ is said to be an electromotive force, or emf. An emf, as shows the basic units of measurement used in circuit analysis.

Newton's Law of Cooling According to Newton's empirical law of cooling, the rate at which a body cools is proportional to the difference between the temwell as a charge on a capacitor, causes the current in a circuit to flow. Table 1.2

\section*{ILLUSTRATED APPLICATIONS}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-034(1)}
\end{center}

The swinging bob in a grandfather's clock and a child's swing are examples of pendulums. The displacement angle $\theta$ of a simple plane pendulum of length $l$ is determined from the nonlinear second-order differential equation $d^{2} \theta / d t^{2}+(\mathrm{g} / \mathrm{l}) \sin \theta=0$. When the displacements of the pendulum are not too large, we can use the replacement $\sin \theta \approx \theta$ and thus approximate $\theta$ by solving the linear equation $d^{2} \theta / d t^{2}+(g / l) \theta=0$. See pages 14 and 212 .\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-034}

To determine the shape of a wire hanging under its own weight, such as a wire strung between two telephone poles, we must solve the nonlinear differential equation

$$
d^{2} y / d x^{2}+(w / T) \sqrt{1+(d y / d x)^{2}}=0
$$

It turns out that the wire has essentially the shape of the graph of a hyperbolic cosine. This graph of a hyperbolic cosine is called a catenary. The famous Gateway Arch in St. Louis has the shape of an inverted catenary. See pages 17-18.\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-035(1)}

Under some circumstances a body moving through the air encounters a resistance that is proportional to its velocity $v$. In general, air resistance is directly proportional to a positive power of the velocity of the body-the faster the body travels, the greater the resistance. For bodies moving at high speeds, such as projectiles or freely falling skydivers, air resistance is often taken to be proportional to $v^{2}$. See Problem 27, page 91 and Problem 8, pages 104-105.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-035}
\end{center}

(b)

Forces acting on beams and girders cause them to distort or deform. This deformation, or deflection, $y(x)$ is described by the fourth-order differential equation $E l y{ }^{(4)}=w(x)$. A beam that is clamped or embedded at one end and free at the other is called a cantilever beam. A diving board, an outstretched arm, and an airplane wing are common examples of such beams; but even flagpoles, skyscrapers, and the Washington Monument act as cantilever beams. See pages 19-20, 323,327 , and 331 .

Any phenomenon modeled by the simple differential equation $d x / d t=k x$ grows $(k>0)$ or decays $(k<0)$ exponentially. The growth in the population $P$ of bacteria, insects, or even humans can often be predicted over short time periods by the exponential solution $P(t)=c e^{k t}$. The study of substances decaying through radioactivity led to the discovery of carbon dating, which is a means of dating fossils or even a mummy. See Section 3.2 and the essay at the end of Chapter 3.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-036}
\end{center}

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-036(1)}\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-036(2)}

Imagine that a shaft is drilled from one side of the earth to the opposite side through its center, and a heavy object, such as a bowling ball, is dropped into the shaft. What would be the motion of the object? Would it drop straight through? Would it stop at the center? In Problem 20 of Exercise 1.2 you are asked to construct a mathematical model for the motion of the object. You can then solve this differential equation with the techniques discussed in Section 4.2.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-037(2)}
\end{center}

Suppose that a cell is suspended in a solution containing a solute, such as potassium, with a constant concentration and that the solute is absorbed into the cell through its permeable membrane. A mathematical model for the concentration $C(t)$ of the solute inside the cell at time $t$ can be found using Fick's principle of passive diffusion. See Problem 30, Exercises 3.2.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-037}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-037(3)}
\end{center}

Before taking the first sip of coffee, one usually waits a short time for the liquid to cool. A forgotten cup of coffee is almost undrinkable when it has cooled to room temperature. An empirical law of cooling, attributed to Isaac Newton, asserts that the rate at which the temperature of a body cools is proportional to the difference between the temperature of the body and the temperature of the surrounding medium. The preceding sentence is a verbal description of a differential equation. See pages 16-17 and 85 .

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-037(1)}\\
perature of the body and the temperature of the surrounding medium, the socalled ambient temperature.

\section*{EXAMPLE 6 Cooling of a Body}
Suppose $T(t)$ denotes the temperature of a body at time $t$ and $T_{\mathrm{m}}$ is the constant temperature of the surrounding medium. If $d T / d t$ represents the rate at which a body cools, then Newton's law of cooling translates into the mathematical statement


\begin{equation*}
\frac{d T}{d t} \propto T-T_{\mathrm{m}} \quad \text { or } \quad \frac{d T}{d t}=k\left(T-T_{\mathrm{m}}\right) \tag{11}
\end{equation*}


where $k$ is a constant of proportionality. Since the body is assumed to be cooling, we must have $T>T_{\mathrm{m}}$ and so it stands to reason that $k<0$.

Suspended Wire Suppose a suspended wire hangs under its own weight. As Figure 1.10(a) shows, a physical model for this could be a long telephone wire strung between two posts. As in Example 4, our goal in the example that follows is to determine the differential equation that describes the shape that the hanging wire assumes.

\section*{EXAMPLE 7 Shape of a Hanging Wire}
Let us examine only a portion of the wire between the lowest point $P_{1}$ and any arbitrary point $P_{2}$. See Figure 1.10(b). Three forces are acting on the wire: the weight of the segment $P_{1} P_{2}$ and the tensions $\mathbf{T}_{1}$ and $\mathbf{T}_{2}$ in the wire at $P_{1}$ and $P_{2}$, respectively. If $w$ is the linear density (measured, say, in $\mathrm{lb} / \mathrm{ft}$ ) and $s$ is the length of the segment $P_{1} P_{2}$, its weight is necessarily $w s$.

Now the tension $\mathbf{T}_{2}$ resolves into horizontal and vertical components (scalar quantities) $T_{2} \cos \theta$ and $T_{2} \sin \theta$. Because of equilibrium we can write

$$
\left|\mathbf{T}_{1}\right|=T_{1}=T_{2} \cos \theta \quad \text { and } \quad w s=T_{2} \sin \theta
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-038}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-038(1)}
\end{center}

(b)

Figure 1.10

Dividing the last two equations, we find


\begin{equation*}
\tan \theta=\frac{w s}{T_{1}} \quad \text { or } \quad \frac{d y}{d x}=\frac{w s}{T_{1}} \tag{12}
\end{equation*}


Now since the length of the arc between points $P_{1}$ and $P_{2}$ is

$$
s=\int_{0}^{x} \sqrt{1+\left(\frac{d y}{d x}\right)^{2}} d x
$$

it follows from one form of the fundamental theorem of calculus that


\begin{equation*}
\frac{d s}{d x}=\sqrt{1+\left(\frac{d y}{d x}\right)^{2}} \tag{13}
\end{equation*}


Differentiating (12) with respect to $x$ and using (13) lead to


\begin{equation*}
\frac{d^{2} y}{d x^{2}}=\frac{w}{T_{1}} \frac{d s}{d x} \quad \text { or } \frac{d^{2} y}{d x^{2}}=\frac{w}{T_{1}} \sqrt{1+\left(\frac{d y}{d x}\right)^{2}} \tag{14}
\end{equation*}


One might conclude from Figure 1.10 that the shape the hanging wire assumes is parabolic. However, this is not the case; a wire or heavy rope hanging under only its own weight takes the shape of a hyperbolic cosine. See Problem 12, Exercises 3.3. Recall that the graph of the hyperbolic cosine is called a catenary, which stems from the Latin word catena meaning "chain." The Romans used the catena as a dog leash. Probably the most graphic example of the shape of a catenary is the 630 -ft-high Gateway Arch in St. Louis, Missouri.

Discharge Through an Orifice In hydrodynamics, Torricelli's theorem states that the speed $v$ of efflux of water through a sharp-edged orifice at the bottom of a tank filled to a depth $h$ is the same as the speed that a body (in this case a drop of water) would acquire in falling freely from a height $h$ :

$$
v=\sqrt{2 g h}
$$

where $g$ is the acceleration due to gravity. This last expression comes from equating the kinetic energy $\frac{1}{2} m v^{2}$ with the potential energy $m g h$ and solving for $v$.

\section*{EXAMPLE 8 Depth of Water in a Draining Tank}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-039}
\end{center}

Suppose a tank filled with water is allowed to discharge through an orifice un-

Figure 1.1 I der the influence of gravity. We would like to find the depth $h$ of water remaining in the tank at time $t$.

Consider the tank shown in Figure 1.11. If the area of the orifice is $A_{\mathrm{o}}$ (in $\mathrm{ft}^{2}$ )and the speed of the water leaving the tank is $v=\sqrt{2 \mathrm{gh}}$ (in $\mathrm{ft} / \mathrm{s}$ ), then the volume of water leaving the tank per second is $A_{\mathrm{o}} \sqrt{2 g h}$ (in $\mathrm{ft}^{3} / \mathrm{s}$ ). Thus, if $V(t)$ denotes the volume of water in the tank at time $t$, then


\begin{equation*}
\frac{d V}{d t}=-A_{0} \sqrt{2 g h} \tag{15}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-040(2)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-040}
\end{center}

(b)

Figure 1.12

where the minus sign indicates that $V$ is decreasing. Note here that we are ignoring the possibility of friction at the orifice, which might reduce the rate of flow there.

Now if the tank is such that the volume of water in it at time $t$ can be written as $V(t)=A_{\mathrm{w}} h$, where $A_{\mathrm{w}}$ (in $\left.\mathrm{ft}^{2}\right)$ is the constant area of the upper surface of the water (see Figure 1.11), then $d V / d t=A_{\mathrm{w}}(d h / d t)$. Substituting this last expression into (15) gives us the desired differential equation for the height $h$ of the water:


\begin{equation*}
\frac{d h}{d t}=-\frac{A_{0}}{A_{\mathrm{w}}} \sqrt{2 g h} \tag{16}
\end{equation*}


It is interesting to observe that (16) remains valid even when $A_{\mathrm{w}}$ is not constant. In this case we must express the upper surface area of the water as a function of $h: A_{\mathrm{w}}=A(h)$. See Problem 9 in Exercises 1.2 and Problem 19 in the Chapter 1 Review Exercises.

Deflection of Beams In engineering an important problem is to determine the static deflection of an elastic beam caused by its weight or by an external load. We assume that the beam is homogeneous and has uniform cross sections along its length. Let $L$ denote the length of the beam. In the absence of any load on the beam (including its weight), a curve joining the centroids of all its cross sections is a straight line called the axis of symmetry. See Figure 1.12(a). If a load is applied to the beam in a vertical plane containing the axis of symmetry, then, as shown in Figure 1.12 (b), the beam undergoes a distortion and the curve connecting the centroids of all cross sections is called the deflection curve or elastic curve. In the next example we derive the differential equation of the deflection curve. This derivation uses principles from elasticity and a concept from calculus called curvature.

\section*{EXAMPLE 9 Deflection of a Cantilever Beam}
For the sake of illustration let us consider a cantilever beam embedded at its left end and free at its right end. As shown in Figure 1.13, we let the embedded end of the beam coincide with $x=0$ and its free end with $x=L$. The $x$-axis coincides with the axis of symmetry, and the deflection $y(x)$ is measured from this axis and is considered positive if downward. Now in the theory of elasticity it is shown that the bending moment $M(x)$ at a point $x$ along the beam is related to the load per unit length $w(x)$ by the equation


\begin{equation*}
\frac{d^{2} M}{d x^{2}}=w(x) \tag{17}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-040(1)}
\end{center}

Figure 1.13

In addition, the bending moment $M(x)$ is proportional to the curvature $\kappa$ of the elastic curve:


\begin{equation*}
M(x)=E I \kappa, \tag{18}
\end{equation*}


where $E$ and $I$ are constants; $E$ is Young's modulus of elasticity of the material of the beam and $I$ is the moment of inertia of a cross-section of the beam (about an axis known as the neutral axis). The product $E I$ is called the flexural rigidity of the beam.

Now, from calculus, curvature is given by

$$
\kappa=\frac{y^{\prime \prime}}{\left[1+\left(y^{\prime}\right)^{2}\right]^{3 / 2}}
$$

When the deflection $y(x)$ is small, the slope $y^{\prime} \approx 0$ and so $\left[1+\left(y^{\prime}\right)^{2}\right]^{3 / 2} \approx 1$. If we let $\kappa=y^{\prime \prime}$, equation (18) becomes $M=E I y^{\prime \prime}$. The second derivative of this last expression is


\begin{equation*}
\frac{d^{2} M}{d x^{2}}=E I \frac{d^{2}}{d x^{2}} y^{\prime \prime}=E I \frac{d^{4} y}{d x^{4}} \tag{19}
\end{equation*}


Using the given result in (17) to replace $d^{2} M / d x^{2}$ in (19), we see that the deflection $y(x)$ satisfies the fourth-order differential equation


\begin{equation*}
E I \frac{d^{4} y}{d x^{4}}=w(x) \tag{20}
\end{equation*}


As we shall see later on, it is extremely important to note any side conditions that accompany a differential equation in the mathematical description of a physical phenomenon. For the cantilever beam in Example 9, in addition to satisfying (20) we would expect the deflection $y(x)$ to satisfy the following conditions at the ends of the beam:

\begin{itemize}
  \item $y(0)=0$ since there is no deflection at the embedded end.
  \item $y^{\prime}(0)=0$ since the deflection curve is tangent to the $x$-axis at the embedded end.
  \item $y^{\prime \prime}(L)=0$ since the bending moment is zero at a free end.
  \item $y^{\prime \prime \prime}(L)=0$ since the shear force is zero at a free end.
\end{itemize}

The function $F(x)=d M / d x=E I\left(d^{3} y / d x^{3}\right)$ is called the shear force.

Population Growth In the next examples we examine some mathematical models of biological growth.

\section*{EXAMPLE 10 Population Growth}
It seems plausible to expect that the rate at which a population $P$ expands is proportional to the population that is present at time $t$. Roughly put, the more people there are, the more there are going to be. Thus one model for population growth is given by the differential equation


\begin{equation*}
\frac{d P}{d t}=k P \tag{2}
\end{equation*}


where $k$ is a constant of proportionality. Since we also expect the population to expand, we must have $d P / d t>0$ and thus $k>0$.

\section*{EXAMPLE 11 Spread of a Disease}
In the spread of a contagious disease, for example a flu virus, it is reasonable to assume that the rate, $d x / d t$, at which the disease spreads is proportional not only to the number of people, $x(t)$, who have contracted the disease but also to the number of people, $y(t)$, who have not yet been exposed; that is,


\begin{equation*}
\frac{d x}{d t}=k x y \tag{22}
\end{equation*}


where $k$ is the usual constant of proportionality. If one infected person is introduced into a fixed population of $n$ people, then $x$ and $y$ are related by


\begin{equation*}
x+y=n+1 \tag{23}
\end{equation*}


Using (23) to eliminate $y$ in (22), we get


\begin{equation*}
\frac{d x}{d t}=k x(n+1-x) \tag{2}
\end{equation*}


The obvious side condition accompanying equation (24) is $x(0)=1$.

Logistic Equation The nonlinear first-order equation (24) is a special case of a more general equation


\begin{equation*}
\frac{d P}{d t}=P(a-b P), \quad a \text { and } b \text { constants } \tag{25}
\end{equation*}


known as the logistic equation. See Section 3.3. The solution of this equation is very important in ecological, sociological, and even managerial sciences.

Continuous Compounding of Interest It is very common for savings institutions to advertise that interest is being compounded daily, by the hour, or even by the minute. Of course, there is no reason to stop there; interest could as well be compounded every second, every half-second, every microsecond, and so on. That is to say, interest could be compounded continuously.

\section*{EXAMPLE 12 Continuous Compound Interest}
When interest is compounded continuously, the rate at which an amount of money $S$ grows is proportional to the amount of money present at time $t$; that is,

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-043}
\end{center}

Figure 1.14


\begin{equation*}
\frac{d S}{d t}=r S \tag{26}
\end{equation*}


where $r$ is the annual rate of interest. This mathematical description is analogous to the population growth of Example 10. The rate of growth is large when the amount of money present in the account is also large. Translated geometrically, this means the tangent line is steep when $S$ is large. See Figure 1.14.

The definition of a derivative provides an interesting derivation of (26). Suppose $S(t)$ is the amount of money accrued in a savings account after $t$ years when the annual rate of interest $r$ is compounded continuously. If $h$ denotes an increment in time, then the interest obtained in the time span $(t+h)-t$ is the difference in the amounts accrued:


\begin{equation*}
S(t+h)-S(t) \tag{2}
\end{equation*}


Since interest is given by $($ rate $) \times($ time $) \times$ (principal), we can approximate the interest earned in this same time period by either

$$
r h S(t) \quad \text { or } \quad r h S(t+h)
$$

Intuitively we see that $r h S(t)$ and $r h S(t+h)$ are lower and upper bounds, respectively, for the actual interest (27); that is,

or


\begin{align*}
& r h S(t) \leq S(t+h)-S(t) \leq r h S(t+h) \\
& r S(t) \leq \frac{S(t+h)-S(t)}{h} \leq r S(t+h) \tag{28}
\end{align*}


Taking the limit of (28) as $h \rightarrow 0$, we get

$$
r S(t) \leq \lim _{h \rightarrow 0} \frac{S(t+h)-S(t)}{h} \leq r S(t)
$$

and so it must follow that

$$
\lim _{h \rightarrow 0} \frac{S(t+h)-S(t)}{h}=r S(t) \quad \text { or } \quad \frac{d S}{d t}=r S .
$$

EXERCISES 1.2

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-043(1)}
\end{center}

Figure $\mathbf{I . I 5}$\\
Answers to odd-numbered problems begin on page A-1.

In Problems 1-22 derive the differential equation(s) describing the given physical situation.

\begin{enumerate}
  \item Under some circumstances a falling body $B$ of mass $m$, such as the skydiver shown in Figure 1.15, encounters air resistance proportional to its instantaneous velocity $v$. Use Newton's second law to find the differential equation for the velocity $v$ of the body at time $t$. Recall that acceleration is $a=d v / d t$. Assume in this case that the positive direction is downward.

  \item What is the differential equation for the velocity $v$ of a body of mass $m$ falling vertically downward through a medium (such as water) that offers a resistance proportional to the square of its instantaneous velocity? Assume the positive direction is downward.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-044(1)}
\end{center}

Figure 1.16

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-044}
\end{center}

Figure 1.17

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-044(2)}
\end{center}

Figure 1.18

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-044(3)}
\end{center}

Figure 1.19\\
3. By Newton's universal law of gravitation the free-fall acceleration $a$ of a body, such as the satellite shown in Figure 1.16, falling a great distance to the surface is not the constant $g$. Rather, the acceleration $a$ is inversely proportional to the square of the distance $r$ from the center of the earth, $a=k / r^{2}$, where $k$ is the constant of proportionality.

(a) Use the fact that at the surface of the earth $r=R$ and $a=g$ to determine the constant of proportionality $k$.

(b) Use Newton's second law and part (a) to find a differential equation for the distance $r$.

(c) Use the chain rule in the form

$$
\frac{d^{2} r}{d t^{2}}=\frac{d v}{d t}=\frac{d v}{d r} \frac{d r}{d t}
$$

to express the differential equation in part (b) as a differential equation involving $v$ and $d v / d r$.

\begin{enumerate}
  \setcounter{enumi}{3}
  \item (a) Use part (b) of Problem 3 to find the differential equation for $r$ if the resistance to the falling satellite is proportional to its instantaneous velocity.
\end{enumerate}

(b) Near the surface of the earth, use the approximation $R \approx r$ to show that the differential equation in part (a) reduces to the equation derived in Problem 1 .

\begin{enumerate}
  \setcounter{enumi}{4}
  \item A series circuit contains a resistor and an inductor as shown in Figure 1.17. Determine the differential equation for the current $i(t)$ if the resistance is $R$, the inductance is $L$, and the impressed voltage is $E(t)$.

  \item A series circuit contains a resistor and a capacitor as shown in Figure 1.18. Determine the differential equation for the charge $q(t)$ on the capacitor if the resistance is $R$, the capacitance is $C$, and the impressed voltage is $E(t)$.

  \item Suppose a tank is discharging water through a circular orifice of crosssectional area $A_{\mathrm{o}}$ at its bottom. It has been shown experimentally that when friction at the orifice is taken into consideration, the volume of water leaving the tank per second is approximately $0.6 A_{\mathrm{o}} \sqrt{2 g h}$. Find the differential equation for the height $h$ of water at time $t$ for the cubical tank in Figure 1.19. The radius of the orifice is 2 in . and $g=32 \mathrm{ft} / \mathrm{s}^{2}$.

  \item A tank in the form of a right circular cylinder of radius 2 ft and height 10 ft is standing on end. The tank is initially full of water, and water leaks from a circular hole of radius $\frac{1}{2}$ in. at its bottom. Use the information in Problem 7 to obtain the differential equation for the height $h$ of the water at time $t$.

  \item A water tank has the shape of a hemisphere with radius 5 ft . Water leaks out of a circular hole of radius 1 in . at its flat bottom. Use the information in Problem 7 to obtain the differential equation for the height $h$ of the water at time $t$.

  \item The rate at which a radioactive substance decays is proportional to the amount $A(t)$ of the substance remaining at time $t$. Determine the differential equation for the amount $A(t)$.

  \item A drug is infused into a patient's bloodstream at a constant rate of $r$ grams per second. Simultaneously, the drug is removed at a rate proportional to the amount $x(t)$ of the drug present at time $t$. Determine the differential equation governing the amount $x(t)$.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-045(2)}
\end{center}

Figure 1.20

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-045(3)}
\end{center}

Figure 1.21

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-045}
\end{center}

Figure 1.22\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-045(1)}

Figure 1.23\\
12. A projectile shot from a gun has weight $w=m g$ and velocity $\mathbf{v}$ tangent to its path of motion. Ignoring air resistance and all other forces except its weight, find the system of differential equations that describes the motion. See Figure 1.20. [Hint: Use Newton's second law in the $x$ and $y$ direction.]

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Determine the equations of motion if the projectile in Problem 12 encounters a retarding force $\mathbf{k}$ (of magnitude $k$ ) acting tangent to the path but opposite to the motion. See Figure 1.21. [Hint: $\mathbf{k}$ is a multiple of the velocity, say $c \mathbf{v}$.]

  \item Two chemicals $A$ and $B$ react to form a new chemical $C$. Assuming that the concentrations of both $A$ and $B$ decrease by the amount of $C$ formed, find the differential equation governing the concentration $x(t)$ of the chemical $C$ if the rate at which the chemical reaction takes place is proportional to the product of the remaining concentrations of $A$ and $B$.

  \item Light strikes a plane curve $C$ in such a manner that all beams $L$ parallel to the $y$-axis are reflected to a single point $O$. Determine the differential equation for the function $y=f(x)$ describing the shape of the curve. (The fact that the angle of incidence is equal to the angle of reflection is a principle of optics.) [Hint: Inspection of Figure 1.22 shows that the inclination of the tangent line from the horizontal at $P(x, y)$ is $\pi / 2-\theta$ and that we can write $\phi=2 \theta$. (Why?) Also, don't be afraid to use a trigonometric identity.]

  \item A cylindrical barrel $s$ feet in diameter of weight $w \mathrm{lb}$ is floating in water. After an initial depression, the barrel exhibits an up-and-down bobbing motion along a vertical line. Using Figure 1.23(b), determine the differential equation for the vertical displacements $y(t)$ if the origin is taken to be on the vertical axis at the surface of the water when the barrel is at rest. Use Archimedes' principle that the buoyancy, or upward force of the water on the barrel, is equal to the weight of the water displaced and the fact that the density of water is $62.4 \mathrm{lb} / \mathrm{ft}^{3}$. Assume that the downward direction is positive. Ignore the resistance of the water.

  \item A rocket is shot vertically upward from the surface of the earth. After all its fuel has been expended, the mass of the rocket is a constant $m$. Use Newton's second law of motion and the fact that the force of gravity varies inversely as the square of the distance to find the differential equation for distance $y$ from the earth's center to the rocket at time $t$ after burnout. State appropriate conditions at $t=0$ associated with this differential equation.

  \item Newton's second law $F=m a$ can be written $F=\frac{d}{d t}(m v)$. When the mass of an object is variable, this latter formulation is used. The mass $m(t)$ of a rocket launched upward changes as its fuel is consumed.* If $v(t)$ denotes its velocity at any time, it can be shown that

\end{enumerate}


\begin{equation*}
-m g=m \frac{d v}{d t}-V \frac{d m}{d t} \tag{29}
\end{equation*}

\footnotetext{\begin{itemize}
  \item It is assumed that the total mass,
\end{itemize}

mass of vehicle + mass of fuel + mass of exhaust gases,

is constant. In this case $m(t)=$ mass of vehicle + mass of fuel.
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-046(1)}
\end{center}

Figure 1.24

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-046}
\end{center}

Figure 1.25 where $V$ is the constant velocity of the exhaust gases relative to the rocket. Use (29) to find the differential equation for $v$ if it is known that $m(t)=m_{0}-a t$ and $V=-b$, where $m_{0}, a$, and $b$ are constants.

\begin{enumerate}
  \setcounter{enumi}{18}
  \item A person $P$, starting at the origin, moves in the direction of the positive $x$-axis, pulling a weight along the curve $C$ (called a tractrix) as shown in Figure 1.24. The weight, initially located on the $y$-axis at $(0, s)$, is pulled by a rope of constant length $s$, which is kept taut throughout the motion. Find the differential equation of the path of motion. [Hint: The rope is always tangent to $C$; consider the angle of inclination $\theta$ as shown in the figure.]

  \item Suppose a hole is drilled through the center of the earth. A body with mass $m$ is dropped into the hole. Let the distance from the center of the earth to the mass at time $t$ be denoted by $r$. See Figure 1.25.

\end{enumerate}

(a) Let $M$ denote the mass of the earth and $M_{r}$ denote the mass of that portion of the earth within a sphere of radius $r$. The gravitational force on $m$ is $F=-k M_{r} m / r^{2}$, where the minus sign indicates that the force is one of attraction. Use this fact to show that

$$
F=-k \frac{m M}{R^{3}} r
$$

[Hint: Assume that the earth is homogeneous-that is, has a constant density $\delta$. Use mass $=$ density $\times$ volume.]

(b) Use Newton's second law and the result in part (a) to derive the differential equation

$$
\frac{d^{2} r}{d t^{2}}+\omega^{2} r=0
$$

where $\omega^{2}=k M / R^{3}=g / R$.

\begin{enumerate}
  \setcounter{enumi}{20}
  \item In the theory of learning, the rate at which a subject is memorized is assumed to be proportional to the amount that is left to be memorized. If $M$ denotes the total amount that is to be memorized and $A(t)$ the amount memorized in time $t$, find the differential equation for $A$.

  \item In Problem 21 assume that the amount of material forgotten is proportional to the amount memorized in time $t$. What is the differential equation for $A$ when forgetfulness is taken into account?

\end{enumerate}

\section*{CHAPTER 1 REVIEW}
We classify a differential equation by its type, ordinary or partial; by its order; and by whether it is linear or nonlinear.

A solution of a differential equation is any function having a sufficient number of derivatives that satisfies the equation identically on some interval.

When solving an $n$ th-order ordinary differential equation, we expect to find an $n$-parameter family of solutions. A particular solution is any solution free\\
of arbitrary parameters that satisfies the differential equation. A singular solution is any solution that cannot be obtained from an $n$-parameter family of solutions by assigning values to the parameters. When an $n$-parameter family of solutions gives every solution of a differential equation on some interval, it is called a general, or complete, solution.

In the analysis of physical problems, many differential equations can be obtained by equating two different empirical formulations of the same situation. For example, a differential equation of motion can sometimes be obtained by simply equating Newton's second law of motion with the net forces acting on a body.

\section*{CHAPTER 1 REVIEW EXERCISES}
\section*{Answers to odd-numbered problems begin on page A-2.}
In Problems 1-4 classify the given differential equation as to type and order. Classify the ordinary differential equations as to linearity.

\begin{enumerate}
  \item $\left(2 x y-y^{2}\right) d x+e^{x} d y=0$
  \item $(\sin x y) y^{\prime \prime \prime}+4 x y^{\prime}=0$
  \item $\frac{\partial^{2} u}{\partial x^{2}}+\frac{\partial^{2} u}{\partial y^{2}}=u$
  \item $x^{2} \frac{d^{2} y}{d x^{2}}-3 x \frac{d y}{d x}+y=x^{2}$
\end{enumerate}

In Problems 5-8 verify that the indicated function is a solution of the given differential equation.\\
5. $y^{\prime}+2 x y=2+x^{2}+y^{2} ; \quad y=x+\tan x$\\
6. $x^{2} y^{\prime \prime}+x y^{\prime}+y=0 ; \quad y=c_{1} \cos (\ln x)+c_{2} \sin (\ln x), x>0$\\
7. $y^{\prime \prime \prime}-2 y^{\prime \prime}-y^{\prime}+2 y=6 ; \quad y=c_{1} e^{x}+c_{2} e^{-x}+c_{3} e^{2 x}+3$\\
8. $y^{(4)}-16 y=0 ; \quad y=\sin 2 x+\cosh 2 x$

In Problems 9-16 determine by inspection at least one solution for the given differential equation.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-047}
\end{center}

Figure 1.26\\
9. $y^{\prime}=2 x$\\
10. $\frac{d y}{d x}=5 y$\\
11. $y^{\prime \prime}=1$\\
12. $y^{\prime}=y^{3}-8$\\
13. $y^{\prime \prime}=y^{\prime}$\\
14. $2 y \frac{d y}{d x}=1$\\
15. $y^{\prime \prime}=-y$\\
16. $y^{\prime \prime}=y$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Determine an interval on which $y^{2}-2 y=x^{2}-x-1$ defines a solution of $2(y-1) d y+(1-2 x) d x=0$.

  \item Explain why the differential equation

\end{enumerate}

$$
\left(\frac{d y}{d x}\right)^{2}=\frac{4-y^{2}}{4-x^{2}}
$$

possesses no real solutions for $|x|<2,|y|>2$. Are there other regions in the $x y$-plane for which the equation has no solutions?

\begin{enumerate}
  \setcounter{enumi}{18}
  \item The conical tank shown in Figure 1.26 loses water out of an orifice at its bottom. If the cross-sectional area of the orifice is $\frac{1}{4} \mathrm{ft}^{2}$, find the differential
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-048}
\end{center}

Figure 1.27 equation representing the height of the water $h$ at time $t$. Ignore friction at the orifice.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item A weight of 96 lb slides down an incline making a $30^{\circ}$ angle with the horizontal. If the coefficient of sliding friction is $\mu$, determine the differential equation for the velocity $v(t)$ of the weight at time $t$. Use the fact that the force of friction opposing the motion is $\mu N$, where $N$ is the normal component of the weight. See Figure 1.27.
\end{enumerate}

\section*{FIRST-ORDER DIFFERENTIAL EQUATIONS }

\footnotetext{INTRODUCTION We are now in a position to solve some differential equations. We begin with first-order differential equations.

If a first-order differential equation can be solved, we shall see that the technique or method for solving it depends on what kind of first-order equation it is. Over the years mathematicians struggled to solve many specialized kinds of equations. Thus there are many methods of solution; what works for one kind of first-order equation does not necessarily apply to another kind of equation. Although we consider solution methods for seven classical types of equations in this chapter, our focus is on four types of equations. Some of these four types are important in applications.
}

\section*{2. 1 PRELIMINARY THEORY \\
 - Initial-value problem \\
 - Initial condition \\
 - Existence of a solution \\
 - Uniqueness of a solution}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-050}
\end{center}

Figure $\mathbf{2 . 1}$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-050(1)}
\end{center}

Figure 2.2\\
Initial-Value Problem We are often interested in solving a first-order differential equation*


\begin{equation*}
\frac{d y}{d x}=f(x, y) \tag{1}
\end{equation*}


subject to a side condition $y\left(x_{0}\right)=y_{0}$, where $x_{0}$ is a number in an interval $I$ and $y_{0}$ is an arbitrary real number. The problem

\[
\begin{array}{ll}
\text { Solve: } & \frac{d y}{d x}=f(x, y)  \tag{2}\\
\text { Subject to: } & y\left(x_{0}\right)=y_{0}
\end{array}
\]

is called an initial-value problem (IVP). The side condition is known as an initial condition. In geometric terms we are seeking at least one solution of the differential equation defined on some interval $I$ such that the graph of the solution passes through a prescribed point $\left(x_{0}, y_{0}\right)$. See Figure 2.1.

\section*{EXAMPLE 1 First-Order IVPs}
We have seen (page 8) that $y=c e^{x}$ is a one-parameter family of solutions for $y^{\prime}=y$ on the interval $(-\infty, \infty)$. If we specify, say, $y(0)=3$, then substituting $x=0, y=3$ in the family yields $3=c e^{0}=c$. Thus, as shown in Figure 2.2, the function $y=3 e^{x}$ is a solution of the initial-value problem

$$
y^{\prime}=y, \quad y(0)=3
$$

Had we demanded that a solution of $y^{\prime}=y$ pass through the point $(1,3)$ rather than $(0,3)$, then $y(1)=3$ would yield $c=3 e^{-1}$ and so $y=3 e^{x-1}$. The graph of this function is also indicated in Figure 2.2.

Two fundamental questions arise in considering an initial-value problem such as (2):

Does a solution of the problem exist?

If a solution exists, is it unique?

In other words, does the differential equation $d y / d x=f(x, y)$ possess a solution whose graph passes through $\left(x_{0}, y_{0}\right)$, and if it does, is there precisely one such solution?

As the next example shows, the answer to the second question is sometimes no.
\footnotetext{\begin{itemize}
  \item In this text we assume that a differential equation $F\left(x, y, y^{\prime}, \ldots, y^{(n)}\right)=0$ can be solved for the highest order derivative: $y^{(n)}=f\left(x, y, y^{\prime}, \ldots, y^{(n-1)}\right)$. There are exceptions.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-051(1)}
\end{center}

Figure 2.3

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-051}
\end{center}

Figure 2.4

\section*{EXAMPLE 2 An IVP Can Have Several Solutions}
You should verify that each of the functions $y=0$ and $y=x^{4} / 16$ satisfies the differential equation and initial condition in the problem

$$
\frac{d y}{d x}=x y^{1 / 2}, \quad y(0)=0
$$

As illustrated in Figure 2.3, the graphs of both functions pass through the same point $(0,0)$.

It is often desirable to know before tackling an initial-value problem whether a solution exists and, when it does, whether it is the only solution of the problem. The following theorem due to Picard* gives conditions that are sufficient to guarantee that a solution exists and that it is also a unique solution.

\section*{THEOREM 2.1 Existence of a Unique Solution}
Let $R$ be a rectangular region in the $x y$-plane defined by $a \leq x \leq b$, $c \leq y \leq d$ that contains the point $\left(x_{0}, y_{0}\right)$ in its interior. If $f(x, y)$ and $\partial f / \partial y$ are continuous on $R$, then there exist an interval $I$ centered at $x_{0}$ and a unique function $y(x)$ defined on $I$ satisfying the initial-value problem (2).

The foregoing is one of the most popular existence and uniqueness theorems for first-order differential equations because the criteria of continuity of $f(x, y)$ and $\partial f / \partial y$ are relatively easy to check. In general, it is not always possible to find a specific interval $I$ on which a solution is defined without actually solving the differential equation (see Problem 16). The geometry of Theorem 2.1 is illustrated in Figure 2.4.

\section*{EXAMPLE 3 Example 2 Revisited}
We saw in Example 2 that the differential equation

$$
\frac{d y}{d x}=x y^{1 / 2}
$$

possesses at least two solutions whose graphs pass through $(0,0)$. The functions

$$
f(x, y)=x y^{1 / 2} \quad \text { and } \quad \frac{\partial f}{\partial y}=\frac{x}{2 y^{1 / 2}}
$$
\footnotetext{\begin{itemize}
  \item CHARLES EMILE PICARD (1856-1941) Picard was one of the prominent French mathematicians of the latter nineteenth and early twentieth centuries. He made significant contributions to the fields of differential equations and complex variables. In 1899 Picard lectured at Clark University in Worcester, Massachusetts.
\end{itemize}
}
are continuous in the upper half-plane defined by $y>0$. We conclude from Theorem 2.1 that through any point $\left(x_{0}, y_{0}\right), y_{0}>0$ (say, for example, $(0,1)$ ), there is some interval around $x_{0}$ on which the given differential equation has a unique solution.

\section*{EXAMPLE 4 Using Theorem 2.1}
Theorem 2.1 guarantees that there exists an interval about $x=0$ on which $y=3 e^{x}$ is the only solution of the initial-value problem of Example 1:

$$
y^{\prime}=y, \quad y(0)=3 .
$$

This follows from the fact that $f(x, y)=y$ and $\partial f / \partial y=1$ are continuous throughout the entire $x y$-plane. It can be further shown that this interval is $(-\infty, \infty)$.

\section*{EXAMPLE 5 Using Theorem 2.1}
For

$$
\frac{d y}{d x}=x^{2}+y^{2}
$$

we observe that $f(x, y)=x^{2}+y^{2}$ and $\partial f / \partial y=2 y$ are continuous throughout the entire $x y$-plane. Therefore, through any given point $\left(x_{0}, y_{0}\right)$ there passes one and only one solution of the differential equation.

Remarks (i) You should be aware of the distinction between a solution existing and exhibiting a solution. Clearly if we find a solution by exhibiting it, we can say that it exists, but on the other hand a solution can exist and we may not be able to display it. From Example 5 we know that a solution of the problem $d y / d x=x^{2}+y^{2}, y(0)=1$ exists on some interval around $x=0$ and is unique. However, the equation cannot be solved in terms of elementary functions; we can approximate the solution using the methods in Chapter 9.

(ii) The conditions stated in Theorem 2.1 are sufficient but not necessary. When $f(x, y)$ and $\partial f / \partial y$ are continuous on a rectangular region $R$, it must always follow that there exists a unique solution of (2) when $\left(x_{0}, y_{0}\right)$ is a point interior to $R$. However, if the conditions stated in the hypothesis of the theorem do not hold, then the initial-value problem (2) may still have (a) no solution, (b) more than one solution, or (c) a unique solution. Furthermore, the continuity condition on $\partial f / \partial y$ can be relaxed somewhat without changing the conclusion of the theorem. This results in a stronger theorem but is, unfortunately, not as easy to apply as Theorem 2.1. Indeed, if we are not interested in uniqueness, then a famous theorem due to the Italian mathematician Guiseppe Peano states that the continuity of $f(x, y)$ on $R$ is sufficient to guarantee the existence of at least one solution of $d y / d x=f(x, y)$ through a point $\left(x_{0}, y_{0}\right)$ interior to $R$.

\section*{EXERCISES 2.1}
\section*{Answers to odd-numbered problems begin on page A-2.}
In Problems 1-10 determine a region of the $x y$-plane for which the given differential equation would have a unique solution through a point $\left(x_{0}, y_{0}\right)$ in the region.

\begin{enumerate}
  \item $\frac{d y}{d x}=y^{2 / 3}$
  \item $\frac{d y}{d x}=\sqrt{x y}$
  \item $x \frac{d y}{d x}=y$
  \item $\frac{d y}{d x}-y=x$
  \item $\left(4-y^{2}\right) y^{\prime}=x^{2}$
  \item $\left(1+y^{3}\right) y^{\prime}=x^{2}$
  \item $\left(x^{2}+y^{2}\right) y^{\prime}=y^{2}$
  \item $(y-x) y^{\prime}=y+x$
  \item $\frac{d y}{d x}=x^{3} \cos y$
  \item $\frac{d y}{d x}=(x-1) e^{y /(x-1)}$
\end{enumerate}

In Problems 11 and 12 determine by inspection at least two solutions of the given initial-value problem.\\
11. $y^{\prime}=3 y^{2 / 3}, \quad y(0)=0$\\
12. $x \frac{d y}{d x}=2 y, \quad y(0)=0$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item By inspection determine a solution of the nonlinear differential equation $y^{\prime}=y^{3}$ satisfying $y(0)=0$. Is the solution unique?

  \item By inspection find a solution of the initial-value problem

\end{enumerate}

$$
y^{\prime}=|y-1|, \quad y(0)=1
$$

State why the conditions of Theorem 2.1 do not hold for this differential equation. Although we shall not prove it, the solution to this initial-value problem is unique.

\begin{enumerate}
  \setcounter{enumi}{14}
  \item Verify that $y=c x$ is a solution of the differential equation $x y^{\prime}=y$ for every value of the parameter $c$. Find at least two solutions of the initialvalue problem
\end{enumerate}

$$
x y^{\prime}=y, \quad y(0)=0 \text {. }
$$

Observe that the piecewise-defined function

$$
y= \begin{cases}0, & x<0 \\ x, & x \geq 0\end{cases}
$$

satisfies the condition $y(0)=0$. Is it a solution of the initial-value problem?

\begin{enumerate}
  \setcounter{enumi}{15}
  \item (a) Consider the differential equation
\end{enumerate}

$$
\frac{d y}{d x}=1+y^{2}
$$

Determine a region of the $x y$-plane for which the equation has a unique solution through a point $\left(x_{0}, y_{0}\right)$ in the region.

(b) Formally show that $y=\tan x$ satisfies the differential equation and the condition $y(0)=0$.\\
(c) Explain why $y=\tan x$ is not a solution of the initial-value problem

$$
\frac{d y}{d x}=1+y^{2}, \quad y(0)=0
$$

on the interval $(-2,2)$.

(d) Explain why $y=\tan x$ is a solution of the initial-value problem in part (c) on the interval $(-1,1)$.

In Problems 17-20 determine whether Theorem 2.1 guarantees that the differential equation $y^{\prime}=\sqrt{y^{2}-9}$ possesses a unique solution through the given point.\\
17. $(1,4)$\\
18. $(5,3)$\\
19. $(2,-3)$\\
20. $(-1,1)$

\subsection*{2.2 SEPARABLE VARIABLES}
Note to the Student In solving a differential equation you will often have to utilize, say, integration by parts, partial fractions, or possibly a substitution. It will be worth a few minutes of your time to review some techniques of integration.

We begin our study of the methodology of solving first-order equations with the simplest of all differential equations.

If $g(x)$ is a continuous function, then the first-order equation


\begin{equation*}
\frac{d y}{d x}=g(x) \tag{1}
\end{equation*}


can be solved by integration. The solution of (1) is

$$
y=\int g(x) d x=G(x)+c
$$

where $G(x)$ is an antiderivative (indefinite integral) of $g(x)$.

\section*{EXAMPLE 1 Solution by Integration}
Solve (a) $\frac{d y}{d x}=1+e^{2 x}$ and (b) $\frac{d y}{d x}=\sin x$.

Solution As illustrated above, both equations can be solved by integration.

(a) $y=\int\left(1+e^{2 x}\right) d x=x+\frac{1}{2} e^{2 x}+c$

(b) $y=\int \sin x d x=-\cos x+c$

Equation (1), as well as its method of solution, is just a special case of the following:

\section*{DEFINITION 2.1 Separable Equation}
A differential equation of the form

$$
\frac{d y}{d x}=\frac{g(x)}{h(y)}
$$

is said to be separable or to have separable variables.

Observe that a separable equation can be written as


\begin{equation*}
h(y) \frac{d y}{d x}=g(x) \tag{2}
\end{equation*}


It is seen immediately that (2) reduces to (1) when $h(y)=1$.

Now if $y=f(x)$ denotes a solution of (2), we must have

$$
h(f(x)) f^{\prime}(x)=g(x)
$$

and therefore


\begin{equation*}
\int h(f(x)) f^{\prime}(x) d x=\int g(x) d x+c \tag{3}
\end{equation*}


But $d y=f^{\prime}(x) d x$, so (3) is the same as


\begin{equation*}
\int h(y) d y=\int g(x) d x+c \tag{4}
\end{equation*}


Method of Solution Equation (4) indicates the procedure for solving separable differential equations. A one-parameter family of solutions, usually given implicitly, is obtained by integrating both sides of $h(y) d y=g(x) d x$.

Note There is no need to use two constants in the integration of a separable equation, since $\int h(y) d y+c_{1}=\int g(x) d x+c_{2}$ can be written $\int h(y) d y=$ $\int g(x) d x+c_{2}-c_{1}=\int g(x) d x+c$, where $c$ is completely arbitrary. In many instances throughout the following chapters, we shall not hesitate to relabel constants in a manner that may prove convenient for a given equation. For example, multiples of constants or combinations of constants can sometimes be replaced by one constant.

\section*{EXAMPLE 2 Solving a Separable DE}
Solve $(1+x) d y-y d x=0$.

Solution Dividing by $(1+x) y$, we can write $d y / y=d x /(1+x)$, from which it follows that

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-056}
\end{center}

Figure 2.5

$$
\begin{aligned}
\int \frac{d y}{y} & =\int \frac{d x}{1+x} \\
\ln |y| & =\ln |1+x|+c_{1} \\
y & =e^{\ln |1+x|+c_{1}} \\
& =e^{\ln |1+x|} \cdot e^{c_{1}} \\
& =|1+x| e^{c_{1}} \\
& = \pm e^{c_{1}}(1+x) \quad\left\{\begin{array}{l}
11+x \mid=1+x, x \geq-1 \\
11+x \mid=-(1+x), x<-1
\end{array}\right.
\end{aligned}
$$

Relabeling $\pm e^{c_{1}}$ as $c$ then gives $y=c(1+x)$.

Alternative Solution Since each integral results in a logarithm, a judicious choice for the constant of integration is $\ln |c|$ rather than $c$ :

$$
\begin{gathered}
\ln |y|=\ln |1+x|+\ln |c| \text { or } \ln |y|=\ln |c(1+x)| \\
y=c(1+x)
\end{gathered}
$$

Even if not all the indefinite integrals are logarithms, it may still be advantageous to use $\ln |c|$. However, no firm rule can be given.

\section*{EXAMPLE 3 An Initial-Value Problem}
Solve the initial-value problem $\frac{d y}{d x}=-\frac{x}{y}, y(4)=3$.

Solution From $y d y=-x d x$ we get

$$
\int y d y=-\int x d x \text { and } \frac{y^{2}}{2}=-\frac{x^{2}}{2}+c_{1}
$$

This solution can be written as $x^{2}+y^{2}=c^{2}$ by replacing the constant $2 c_{1}$ by $c^{2}$. The solution represents a family of concentric circles.

Now when $x=4, y=3$, so $16+9=25=c^{2}$. Thus the initial-value problem determines $x^{2}+y^{2}=25$. In view of Theorem 2.1 , we can conclude that it is the only circle of the family passing through the point $(4,3)$. See Figure 2.5 .

\section*{EXAMPLE 4 Solving a Separable DE}
Solve $x e^{-y} \sin x d x-y d y=0$.

Solution After multiplying by $e^{y}$, we get

$$
x \sin x d x=y e^{y} d y
$$

Integration by parts on both sides of the equality gives

$$
-x \cos x+\sin x=y e^{y}-e^{y}+c
$$

Solve $x y^{4} d x+\left(y^{2}+2\right) e^{-3 x} d y=0$.

Solution By multiplying the given equation by $e^{3 x}$ and dividing by $y^{4}$, we obtain


\begin{equation*}
x e^{3 x} d x+\frac{y^{2}+2}{y^{4}} d y=0 \quad \text { or } \quad x e^{3 x} d x+\left(y^{-2}+2 y^{-4}\right) d y=0 \tag{6}
\end{equation*}


Using integration by parts on the first term yields

$$
\frac{1}{3} x e^{3 x}-\frac{1}{9} e^{3 x}-y^{-1}-\frac{2}{3} y^{-3}=c_{1}
$$

The one-parameter family of solutions can also be written as


\begin{equation*}
e^{3 x}(3 x-1)=\frac{9}{y}+\frac{6}{y^{3}}+c \tag{7}
\end{equation*}


where the constant $9 c_{1}$ is rewritten as $c$.

Two points are worth mentioning at this time. First, unless it is important or convenient there is no need to try to solve an expression representing a family of solutions for $y$ explicitly in terms of $x$. Equation (7) shows that this task may present more problems than just the drudgery of symbol pushing. As a consequence it is often the case that the interval over which a solution is valid is not apparent. Second, some care should be exercised when separating variables to make certain that divisors are not zero. A constant solution may sometimes get lost in the shuffle of solving the problem. In Example 5 observe that $y=0$ is a perfectly good solution of (5) but is not a member of the set of solutions defined by (7).

\section*{EXAMPLE 6 Losing a Solution}
Solve the initial-value problem $\frac{d y}{d x}=y^{2}-4, y(0)=-2$.

Solution We put the equation into the form


\begin{equation*}
\frac{d y}{y^{2}-4}=d x \tag{8}
\end{equation*}


and use partial fractions on the left side. We have

so


\begin{gather*}
{\left[\frac{-\frac{1}{4}}{y+2}+\frac{\frac{1}{4}}{y-2}\right] d y=d x}  \tag{9}\\
-\frac{1}{4} \ln |y+2|+\frac{1}{4} \ln |y-2|=x+c_{1}  \tag{10}\\
\ln \left|\frac{y-2}{y+2}\right|=4 x+c_{2} \text { and } \frac{y-2}{y+2}=c e^{4 x}
\end{gather*}


Thus

where we have replaced $4 c_{1}$ by $c_{2}$ and $e^{c_{2}}$ by $c$. Finally, solving the last equation for $y$, we get


\begin{equation*}
y=2 \frac{1+c e^{4 x}}{1-c e^{4 x}} \tag{11}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-058}
\end{center}

Figure 2.6\\
Substituting $x=0, y=-2$ leads to the dilemma

$$
\begin{gathered}
-2=2 \frac{1+c}{1-c} \\
-1+c=1+c \text { or }-1=1
\end{gathered}
$$

Let us consider the differential equation a little more carefully. The fact is, the equation

$$
\frac{d y}{d x}=(y+2)(y-2)
$$

is satisfied by two constant functions-namely, $y=-2$ and $y=2$. Inspection of equations (8), (9), and (10) clearly indicates we must preclude $y=-2$ and $y=2$ at those steps in our solution. But it is interesting to observe that we can subsequently recover the solution $y=2$ by setting $c=0$ in equation (11). However, there is no finite value of $c$ that will ever yield the solution $y=-2$. This latter constant function is the only solution to the original initial-value problem. See Figure 2.6.

If, in Example 6, we had used $\ln |c|$ for the constant of integration, then the form of the one-parameter family of solutions would be


\begin{equation*}
y=2 \frac{c+e^{4 x}}{c-e^{4 x}} \tag{12}
\end{equation*}


Note that (12) reduces to $y=-2$ when $c=0$, but now there is no finite value of $c$ that will give the constant solution $y=2$.

If an initial condition leads to a particular solution by finding a specific value of the parameter $c$ in a family of solutions for a first-order differential equation, it is a natural inclination of most students (and instructors) to relax and be content. In Section 2.1 we saw, however, that a solution of an initial-value problem may not be unique. For example, the problem


\begin{equation*}
\frac{d y}{d x}=x y^{1 / 2}, \quad y(0)=0 \tag{13}
\end{equation*}


has at least two solutions-namely, $y=0$ and $y=x^{4} / 16$. We are now in a position to solve the equation. Separating variables

$$
y^{-1 / 2} d y=x d x
$$

and integrating gives

$$
2 y^{1 / 2}=\frac{x^{2}}{2}+c_{1} \text { or } y=\left(\frac{x^{2}}{4}+c\right)^{2}
$$

When $x=0, y=0$, so necessarily $c=0$. Therefore $y=x^{4} / 16$. The solution $y=0$ was lost by dividing by $y^{1 / 2}$. In addition, the initial-value problem (13) possesses infinitely more solutions, since for any choice of the parameter $a \geq 0$ the piecewise-defined function

$$
y= \begin{cases}0, & x<a \\ \frac{\left(x^{2}-a^{2}\right)^{2}}{16}, & x \geq a\end{cases}
$$

satisfies both the differential equation and the initial condition. See Figure 2.7.

Remarks We saw in some of the preceding examples that the constant in the one-parameter family of solutions for a first-order differential equation can be relabeled when convenient. Also, it can easily happen that two individuals solving the same equation arrive at dissimilar answers. For example, by separation of variables we can show that one-parameter families of solutions for $\left(1+y^{2}\right) d x+\left(1+x^{2}\right) d y=0$ are

$\arctan x+\arctan y=c$ or $\arctan x+\arctan y=\arctan c$ or $\frac{x+y}{1-x y}=c$.

As you work your way through the next several sections, bear in mind that families of solutions may be equivalent in the sense that one family may be obtained from another by either relabeling the constant or applying algebra and trigonometry.

\section*{EXERCISES 2.2}
Answers to odd-numbered problems begin on page A-2.

In Problems 1-40 solve the given differential equation by separation of variables.

\begin{enumerate}
  \item $\frac{d y}{d x}=\sin 5 x$

  \item $\frac{d y}{d x}=(x+1)^{2}$

  \item $d x+e^{3 x} d y=0$

  \item $d x-x^{2} d y=0$

  \item $(x+1) \frac{d y}{d x}=x+6$

  \item $e^{x} \frac{d y}{d x}=2 x$

  \item $x y^{\prime}=4 y$

  \item $\frac{d y}{d x}+2 x y=0$

  \item $\frac{d y}{d x}=\frac{y^{3}}{x^{2}}$

  \item $\frac{d y}{d x}=\frac{y+1}{x}$

  \item $\frac{d x}{d y}=\frac{x^{2} y^{2}}{1+x}$

  \item $\frac{d x}{d y}=\frac{1+2 y^{2}}{y \sin x}$

  \item $\frac{d y}{d x}=e^{3 x+2 y}$

  \item $e^{x} y \frac{d y}{d x}=e^{-y}+e^{-2 x-y}$

  \item $\left(4 y+y x^{2}\right) d y-\left(2 x+x y^{2}\right) d x=0$

  \item $\left(1+x^{2}+y^{2}+x^{2} y^{2}\right) d y=y^{2} d x$

  \item $2 y(x+1) d y=x d x$

  \item $x^{2} y^{2} d y=(y+1) d x$

  \item $y \ln x \frac{d x}{d y}=\left(\frac{y+1}{x}\right)^{2}$

  \item $\frac{d y}{d x}=\left(\frac{2 y+3}{4 x+5}\right)^{2}$

  \item $\frac{d S}{d r}=k S$

  \item $\frac{d Q}{d t}=k(Q-70)$

  \item $\frac{d P}{d t}=P-P^{2}$

  \item $\frac{d N}{d t}+N=N t e^{t+2}$

  \item $\sec ^{2} x d y+\csc y d x=0$

  \item $\sin 3 x d x+2 y \cos ^{3} 3 x d y=0$

  \item $e^{y} \sin 2 x d x+\cos x\left(e^{2 y}-y\right) d y=0$

  \item $\sec x d y=x \cot y d x$

  \item $\left(e^{y}+1\right)^{2} e^{-y} d x+\left(e^{x}+1\right)^{3} e^{-x} d y=0$

  \item $\frac{y}{x} \frac{d y}{d x}=\left(1+x^{2}\right)^{-1 / 2}\left(1+y^{2}\right)^{1 / 2}$

  \item $\left(y-y x^{2}\right) \frac{d y}{d x}=(y+1)^{2}$

  \item $2 \frac{d y}{d x}-\frac{1}{y}=\frac{2 x}{y}$

  \item $\frac{d y}{d x}=\frac{x y+3 x-y-3}{x y-2 x+4 y-8}$

  \item $\frac{d y}{d x}=\frac{x y+2 y-x-2}{x y-3 y+x-3}$

  \item $\frac{d y}{d x}=\sin x\left(\cos 2 y-\cos ^{2} y\right)$

  \item $\sec y \frac{d y}{d x}+\sin (x-y)=\sin (x+y)$

  \item $x \sqrt{1-y^{2}} d x=d y$

  \item $y\left(4-x^{2}\right)^{1 / 2} d y=\left(4+y^{2}\right)^{1 / 2} d x$

  \item $\left(e^{x}+e^{-x}\right) \frac{d y}{d x}=y^{2}$

  \item $(x+\sqrt{x}) \frac{d y}{d x}=y+\sqrt{y}$

\end{enumerate}

In Problems 41-48 solve the given differential equation subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item $\left(e^{-y}+1\right) \sin x d x=(1+\cos x) d y, \quad y(0)=0$

  \item $\left(1+x^{4}\right) d y+x\left(1+4 y^{2}\right) d x=0, \quad y(1)=0$

  \item $y d y=4 x\left(y^{2}+1\right)^{1 / 2} d x, \quad y(0)=1$

  \item $\frac{d y}{d t}+t y=y, \quad y(1)=3$

  \item $\frac{d x}{d y}=4\left(x^{2}+1\right), \quad x\left(\frac{\pi}{4}\right)=1$

  \item $\frac{d y}{d x}=\frac{y^{2}-1}{x^{2}-1}, \quad y(2)=2$

  \item $x^{2} y^{\prime}=y-x y, \quad y(-1)=-1$

  \item $y^{\prime}+2 y=1, \quad y(0)=\frac{5}{2}$

\end{enumerate}

In Problems 49 and 50 find a solution of the given differential equation that passes through the indicated points.\\
49. $\frac{d y}{d x}-y^{2}=-9$\\
(a) $(0,0)$\\
(b) $(0,3)$\\
(c) $\left(\frac{1}{3}, 1\right)$\\
50. $x \frac{d y}{d x}=y^{2}-y$\\
(a) $(0,1)$\\
(b) $(0,0)$\\
(c) $\left(\frac{1}{2}, \frac{1}{2}\right)$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item Find a singular solution for the equation in Problem 37.

  \item Find a singular solution for the equation in Problem 39.

\end{enumerate}

Often a radical change in the solution of a differential equation corresponds to a very small change in either the initial condition or the equation itself. In Problems 53-56 compare the solutions of the given initial-value problems.\\
53. $\frac{d y}{d x}=(y-1)^{2}, \quad y(0)=1$\\
54. $\frac{d y}{d x}=(y-1)^{2}, \quad y(0)=1.01$

\begin{enumerate}
  \setcounter{enumi}{54}
  \item $\frac{d y}{d x}=(y-1)^{2}+0.01, \quad y(0)=1 \quad$ 56. $\frac{d y}{d x}=(y-1)^{2}-0.01, y(0)=1$
\end{enumerate}

A differential equation of the form $d y / d x=f(a x+b y+c), b \neq 0$ can always be reduced to an equation with separable variables by means of the substitution $u=a x+b y+c$. Use this procedure to solve Problems 57-62.\\
57. $\frac{d y}{d x}=(x+y+1)^{2}$\\
58. $\frac{d y}{d x}=\frac{1-x-y}{x+y}$\\
59. $\frac{d y}{d x}=\tan ^{2}(x+y)$\\
60. $\frac{d y}{d x}=\sin (x+y)$\\
61. $\frac{d y}{d x}=2+\sqrt{y-2 x+3}$\\
62. $\frac{d y}{d x}=1+e^{y-x+5}$

\subsection*{2.3 HOMOGENEOUS EQUATIONS \\
 - Homogeneous function \\
 - Homogeneous equation}
Before considering the concept of a homogeneous first-order differential equation and its method of solution, we need to examine closely the nature of a homogeneous function. We begin with the definition of this concept.

DEFINITION 2.2 Homogeneous Function

If a function $f$ has the property that


\begin{equation*}
f(t x, t y)=t^{n} f(x, y) \tag{1}
\end{equation*}


for some real number $n$, then $f$ is said to be a homogeneous function of degree $n$.

EXAMPLE 1 Some Homogeneous Functions

(a) $f(x, y)=x^{2}-3 x y+5 y^{2}$

$$
\begin{aligned}
f(t x, t y) & =(t x)^{2}-3(t x)(t y)+5(t y)^{2} \\
& =t^{2} x^{2}-3 t^{2} x y+5 t^{2} y^{2} \\
& =t^{2}\left[x^{2}-3 x y+5 y^{2}\right]=t^{2} f(x, y)
\end{aligned}
$$

The function is homogeneous of degree two.

(b) $f(x, y)=\sqrt[3]{x^{2}+y^{2}}$

$$
f(t x, t y)=\sqrt[3]{t^{2} x^{2}+t^{2} y^{2}}=t^{2 / \beta} \sqrt[3]{x^{2}+y^{2}}=t^{2 / 3} f(x, y)
$$

The function is homogeneous of degree $\frac{2}{3}$.\\
(c) $f(x, y)=x^{3}+y^{3}+1$

$f(t x, t y)=t^{3} x^{3}+t^{3} y^{3}+1 \neq t^{3} f(x, y)$

since $t^{3} f(x, y)=t^{3} x^{3}+t^{3} y^{3}+t^{3}$. The function is not homogeneous.

(d) $f(x, y)=\frac{x}{2 y}+4$

$f(t x, t y)=\frac{t x}{2 t y}+4=\frac{x}{2 y}+4=t^{0} f(x, y)$

The function is homogeneous of degree zero.

As parts (c) and (d) of Example 1 show, a constant added to a function destroys homogeneity, unless the function is homogeneous of degree zero. Also, in many instances a homogeneous function can be recognized by examining the total degree of each term.

\section*{EXAMPLE 2 Examining the Degree of Each Term}
(a) $\left.f(x, y)=6 x y^{3}-x_{\text {degree } 2}^{\text {degree } 1} y_{\text {degree } 2}^{2}\right\}$ degree 4

The function is homogeneous of degree four.

(b) $f(x, y)=x^{2}-y$

The function is not homogeneous since the degrees of the two terms are different.

If $f(x, y)$ is a homogeneous function of degree $n$, notice that we can write


\begin{equation*}
f(x, y)=x^{n} f\left(1, \frac{y}{x}\right) \text { and } \quad f(x, y)=y^{n} f\left(\frac{x}{y}, 1\right) \tag{2}
\end{equation*}


where $f(1, y / x)$ and $f(x / y, 1)$ are both homogeneous of degree zero.

\section*{EXAMPLE 3 Special Forms of Homogeneous Functions}
We see that $f(x, y)=x^{2}+3 x y+y^{2}$ is homogeneous of degree two. Thus

$$
\begin{aligned}
& f(x, y)=x^{2}\left[1+3\left(\frac{y}{x}\right)+\left(\frac{y}{x}\right)^{2}\right]=x^{2} f\left(1, \frac{y}{x}\right) \\
& f(x, y)=y^{2}\left[\left(\frac{x}{y}\right)^{2}+3\left(\frac{x}{y}\right)+1\right]=y^{2} f\left(\frac{x}{y}, 1\right)
\end{aligned}
$$

A homogeneous first-order differential equation is defined in terms of homogeneous functions.

\section*{DEFINITION 2.3 Homogeneous Equation}
A differential equation of the form


\begin{equation*}
M(x, y) d x+N(x, y) d y=0 \tag{3}
\end{equation*}


is said to be homogeneous if both coefficients $M$ and $N$ are homogeneous functions of the same degree.

In other words, $M(x, y) d x+N(x, y) d y=0$ is homogeneous if

$$
M(t x, t y)=t^{n} M(x, y) \quad \text { and } \quad N(t x, t y)=t^{n} N(x, y)
$$

Method of Solution A homogeneous differential equation $M(x, y) d x+$ $N(x, y) d y=0$ can be solved by means of an algebraic substitution. Specifically, either substitution $y=u x$ or $x=v y$, where $u$ and $v$ are new dependent variables, will reduce the equation to a separable first-order differential equation. To see this, let us substitute $y=u x$ and its differential $d y=u d x+x d u$ into (3):

$$
M(x, u x) d x+N(x, u x)[u d x+x d u]=0
$$

Now, by the homogeneity property given in (2), we can write

or

$$
\begin{aligned}
x^{n} M(1, u) d x+x^{n} N(1, u)[u d x+x d u] & =0 \\
{[M(1, u)+u N(1, u)] d x+x N(1, u) d u } & =0 \\
\frac{d x}{x}+\frac{N(1, u) d u}{M(1, u)+u N(1, u)} & =0
\end{aligned}
$$

which gives

We hasten to point out that the preceding formula should not be memorized; rather, the procedure should be worked through each time. The proof that the substitution $x=v y$ in (3) also leads to a separable equation is left as an exercise. See Problem 45.

\section*{EXAMPLE 4 Solving a Homogeneous DE}
Solve $\left(x^{2}+y^{2}\right) d x+\left(x^{2}-x y\right) d y=0$.

Solution Both $M(x, y)$ and $N(x, y)$ are homogeneous of degree two. If we let $y=u x$, it follows that

$$
\begin{aligned}
\left(x^{2}+u^{2} x^{2}\right) d x+\left(x^{2}-u x^{2}\right)[u d x+x d u] & =0 \\
x^{2}(1+u) d x+x^{3}(1-u) d u & =0 \\
\frac{1-u}{1+u} d u+\frac{d x}{x} & =0 \\
{\left[-1+\frac{2}{1+u}\right] d u+\frac{d x}{x} } & =0 \leftarrow \text { division }
\end{aligned}
$$

After integration the last line gives

$$
-u+2 \ln |1+u|+\ln |x|=\ln |c| \quad \text { or } \quad-\frac{y}{x}+2 \ln \left|1+\frac{y}{x}\right|+\ln |x|=\ln |c| \text {. }
$$

Using the properties of logarithms, we can write the preceding solution as

$$
\ln \left|\frac{(x+y)^{2}}{c x}\right|=\frac{y}{x}
$$

The definition of a logarithm then yields

$$
(x+y)^{2}=c x e^{y / x}
$$

\section*{EXAMPLE 5 Solving a Homogeneous DE}
Solve $(2 \sqrt{x y}-y) d x-x d y=0$.

Solution The coefficients $M(x, y)$ and $N(x, y)$ are homogeneous of degree one. If $y=u x$, the differential equation becomes, after simplifying,

$$
\frac{d u}{2 u-2 u^{1 / 2}}+\frac{d x}{x}=0
$$

The integral of the first term can be evaluated by the further substitution $t=u^{1 / 2}$. The result is

$$
\frac{d t}{t-1}+\frac{d x}{x}=0
$$

Integrating yields

$$
\ln |t-1|+\ln |x|=\ln |c|
$$

$$
\begin{aligned}
& \ln \left|\sqrt{\frac{y}{x}}-1\right|+\ln |x|=\ln |c| \leftarrow t=u^{1 / 2} \quad \text { and } \quad u=y / x \\
& x\left(\sqrt{\frac{y}{x}}-1\right)=c \quad \text { or } \quad \sqrt{x y}-x=c
\end{aligned}
$$

By now you may be asking, When should the substitution $x=v y$ be used? Although it can be used for every homogeneous differential equation, in practice we try $x=v y$ whenever the function $M(x, y)$ is simpler than $N(x, y)$. In solving $\left(x^{2}+y^{2}\right) d x+\left(x^{2}-x y\right) d y=0$, for example, we know there is no appreciable difference between $M$ and $N$, so either $y=u x$ or $x=v y$ could be used. Also, it could happen that after using one substitution, we encounter integrals that are difficult or impossible to evaluate in closed form; switching substitutions may result in an easier problem.

\section*{EXAMPLE 6 Solving a Homogeneous DE}
Solve $2 x^{3} y d x+\left(x^{4}+y^{4}\right) d y=0$.

Solution Each coefficient is a homogeneous function of degree four. Since the coefficient of $d x$ is slightly simpler than the coefficient of $d y$, we try $x=v y$. After substituting, we simplify the equation

$$
2 v^{3} y^{4}[v d y+y d v]+\left(v^{4} y^{4}+y^{4}\right) d y=0 \quad \text { to } \quad \frac{2 v^{3} d v}{3 v^{4}+1}+\frac{d y}{y}=0
$$

Integration gives

$$
\frac{1}{6} \ln \left(3 v^{4}+1\right)+\ln |y|=\ln \left|c_{1}\right| \quad \text { or } \quad 3 x^{4} y^{2}+y^{6}=c
$$

where $c=c_{1}^{6}$. Now had the substitution $y=u x$ been used, then

$$
\frac{d x}{x}+\frac{u^{4}+1}{u^{5}+3 u} d u=0
$$

You are urged to reflect on how to evaluate the integral of the second term in the last equation.

A homogeneous differential equation can always be expressed in the alternative form

$$
\frac{d y}{d x}=F\left(\frac{y}{x}\right)
$$

To see this, suppose we write the equation $M(x, y) d x+N(x, y) d y=0$ as $d y / d x=f(x, y)$, where

$$
f(x, y)=-\frac{M(x, y)}{N(x, y)}
$$

The function $f(x, y)$ must necessarily be homogeneous of degree zero when $M$ and $N$ are homogeneous of degree $n$. From (2), it follows that

$$
f(x, y)=-\frac{x^{n} M\left(1, \frac{y}{x}\right)}{x^{n} N\left(1, \frac{y}{x}\right)}=-\frac{M\left(1, \frac{y}{x}\right)}{N\left(1, \frac{y}{x}\right)}
$$

The last ratio is recognized as a function of the form $F(y / x)$. We leave it as an exercise to demonstrate that a homogeneous differential equation can also be written as $d y / d x=G(x / y)$. See Problem 47 .

\section*{EXAMPLE 7 An Initial-Value Problem}
Solve the initial-value problem $x \frac{d y}{d x}=y+x e^{y / x}, y(1)=1$.

Solution

By writing the equation as

$$
\frac{d y}{d x}=\frac{y}{x}+e^{y / x}
$$

we see that the function to the right of the equality is homogeneous of degree zero. From the form of this function we are prompted to use $u=y / x$. After differentiating $y=u x$ by the product rule and substituting, we find

$$
u+x \frac{d u}{d x}=u+e^{u} \quad \text { or } \quad e^{-u} d u=\frac{d x}{x}
$$

Integrating and substituting $u=y / x$ gives

$$
-e^{-u}+c=\ln |x| \quad \text { or } \quad-e^{-y / x}+c=\ln |x| \text {. }
$$

Since $y=1$ when $x=1$, we get $-e^{-1}+c=0$ or $c=e^{-1}$. Therefore the solution to the initial-value problem is

$$
e^{-1}-e^{-y / x}=\ln |x|
$$

\section*{EXERCISES 2.3}
\section*{Answers to odd-numbered problems begin on page A-2.}
In Problems 1-10 determine whether the given function is homogeneous. If so, state the degree of homogeneity.

\begin{enumerate}
  \item $x^{3}+2 x y^{2}-y^{4} / x$
  \item $\sqrt{x+y}(4 x+3 y)$
  \item $\frac{x^{3} y-x^{2} y^{2}}{(x+8 y)^{2}}$
  \item $\frac{x}{y^{2}+\sqrt{x^{4}+y^{4}}}$
  \item $\cos \frac{x^{2}}{x+y}$
  \item $\sin \frac{x}{x+y}$
  \item $\ln x^{2}-2 \ln y$
  \item $\frac{\ln x^{3}}{\ln y^{3}}$
  \item $\left(x^{-1}+y^{-1}\right)^{2}$
  \item $(x+y+1)^{2}$
\end{enumerate}

In Problems 11-30 solve the given differential equation by using an appropriate substitution.\\
11. $(x-y) d x+x d y=0$\\
12. $(x+y) d x+x d y=0$\\
13. $x d x+(y-2 x) d y=0$\\
14. $y d x=2(x+y) d y$\\
15. $\left(y^{2}+y x\right) d x-x^{2} d y=0$\\
16. $\left(y^{2}+y x\right) d x+x^{2} d y=0$\\
17. $\frac{d y}{d x}=\frac{y-x}{y+x}$\\
18. $\frac{d y}{d x}=\frac{x+3 y}{3 x+y}$\\
19. $-y d x+(x+\sqrt{x y}) d y=0$\\
20. $x \frac{d y}{d x}-y=\sqrt{x^{2}+y^{2}}$\\
21. $2 x^{2} y d x=\left(3 x^{3}+y^{3}\right) d y$\\
22. $\left(x^{4}+y^{4}\right) d x-2 x^{3} y d y=0$\\
23. $\frac{d y}{d x}=\frac{y}{x}+\frac{x}{y}$\\
24. $\frac{d y}{d x}=\frac{y}{x}+\frac{x^{2}}{y^{2}}+1$\\
25. $y \frac{d x}{d y}=x+4 y e^{-2 x / y}$\\
26. $\left(x^{2} e^{-y / x}+y^{2}\right) d x=x y d y$\\
27. $\left(y+x \cot \frac{y}{x}\right) d x-x d y=0$\\
28. $\frac{d y}{d x}=\frac{y}{x} \ln \frac{y}{x}$\\
29. $\left(x^{2}+x y-y^{2}\right) d x+x y d y=0$\\
30. $\left(x^{2}+x y+3 y^{2}\right) d x-\left(x^{2}+2 x y\right) d y=0$

In Problems 31-44 solve the given differential equation subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $x y^{2} \frac{d y}{d x}=y^{3}-x^{3}, \quad y(1)=2$

  \item $\left(x^{2}+2 y^{2}\right) d x=x y d y, \quad y(-1)=1$

  \item $2 x^{2} \frac{d y}{d x}=3 x y+y^{2}, y(1)=-2$

  \item $x y d x-x^{2} d y=y \sqrt{x^{2}+y^{2}} d y, \quad y(0)=1$

  \item $\left(x+y e^{y / x}\right) d x-x e^{y / x} d y=0, \quad y(1)=0$

  \item $y d x+\left(y \cos \frac{x}{y}-x\right) d y=0, \quad y(0)=2$

  \item $\left(y^{2}+3 x y\right) d x=\left(4 x^{2}+x y\right) d y, \quad y(1)=1$

  \item $y^{3} d x=2 x^{3} d y-2 x^{2} y d x, \quad y(1)=\sqrt{2}$

  \item $(x+\sqrt{x y}) \frac{d y}{d x}+x-y=x^{-1 / 2} y^{3 / 2}, \quad y(1)=1$

  \item $y d x+x(\ln x-\ln y-1) d y=0, \quad y(1)=e$

  \item $y^{2} d x+\left(x^{2}+x y+y^{2}\right) d y=0, \quad y(0)=1$

  \item $(\sqrt{x}+\sqrt{y})^{2} d x=x d y, \quad y(1)=0$

  \item $\left(x+\sqrt{y^{2}-x y}\right) \frac{d y}{d x}=y, \quad y\left(\frac{1}{2}\right)=1$

  \item $\frac{d y}{d x}-\frac{y}{x}=\cosh \frac{y}{x}, \quad y(1)=0$

  \item Suppose $M(x, y) d x+N(x, y) d y=0$ is a homogeneous equation. Show that the substitution $x=v y$ reduces the equation to one with separable variables.

  \item Suppose $M(x, y) d x+N(x, y) d y=0$ is a homogeneous equation. Show that the substitutions $x=r \cos \theta, y=r \sin \theta$ reduce the equation to one with separable variables.

  \item Suppose $M(x, y) d x+N(x, y) d y=0$ is a homogeneous equation. Show that the equation has the alternative form $d y / d x=G(x / y)$

  \item If $f(x, y)$ is a homogeneous function of degree $n$, show that

\end{enumerate}

$$
x \frac{\partial f}{\partial x}+y \frac{\partial f}{\partial y}=n f
$$

\subsection*{2.4 EXACT EQUATIONS}
Although the simple equation

$$
y d x+x d y=0
$$

is both separable and homogeneous, we should recognize that it is also equivalent to the differential of the product of $x$ and $y$; that is,

$$
y d x+x d y=d(x y)=0
$$

By integrating we immediately obtain the implicit solution $x y=c$.

From calculus you might remember that if $z=f(x, y)$ is a function having\\
continuous first partial derivatives in a region $R$ of the $x y$-plane, then its total differential is


\begin{equation*}
d z=\frac{\partial f}{\partial x} d x+\frac{\partial f}{\partial y} d y \tag{1}
\end{equation*}


Now if $f(x, y)=c$, it follows from (1) that


\begin{equation*}
\frac{\partial f}{\partial x} d x+\frac{\partial f}{\partial y} d y=0 \tag{2}
\end{equation*}


In other words, given a family of curves $f(x, y)=c$, we can generate a first-order differential equation by computing the total differential.

EXAMPLE 1 Differential Yields a DE

$$
\begin{aligned}
& \text { If } x^{2}-5 x y+y^{3}=c \text {, then (2) gives } \\
& \qquad(2 x-5 y) d x+\left(-5 x+3 y^{2}\right) d y=0 \quad \text { or } \quad \frac{d y}{d x}=\frac{5 y-2 x}{-5 x+3 y^{2}}
\end{aligned}
$$

For our purposes, it is more important to turn the problem around; namely, given an equation such as


\begin{equation*}
\frac{d y}{d x}=\frac{5 y-2 x}{-5 x+3 y^{2}} \tag{3}
\end{equation*}


can we identify the equation as being equivalent to the statement

$$
d\left(x^{2}-5 x y+y^{3}\right)=0 ?
$$

Notice that equation (3) is neither separable nor homogeneous.

\section*{DEFINITION 2.4 Exact Equation}
A differential expression

$$
M(x, y) d x+N(x, y) d y
$$

is an exact differential in a region $R$ of the $x y$-plane if it corresponds to the total differential of some function $f(x, y)$.A differential equation of the form

$$
M(x, y) d x+N(x, y) d y=0
$$

is said to be an exact equation if the expression on the left side is an exact differential.

\section*{EXAMPLE 2 An Exact DE}
The equation $x^{2} y^{3} d x+x^{3} y^{2} d y=0$ is exact since it is recognized that

$$
d\left(\frac{1}{3} x^{3} y^{3}\right)=x^{2} y^{3} d x+x^{3} y^{2} d y
$$

The following theorem is a test for an exact differential.

\section*{THEOREM 2.2 Criterion for an Exact Differential}
Let $M(x, y)$ and $N(x, y)$ be continuous and have continuous first partial derivatives in a rectangular region $R$ defined by $a<x<b, c<y<d$. Then a necessary and sufficient condition that

$$
M(x, y) d x+N(x, y) d y
$$

be an exact differential is


\begin{equation*}
\frac{\partial M}{\partial y}=\frac{\partial N}{\partial x} \tag{4}
\end{equation*}


Proof of the Necessity For simplicity let us assume that $M(x, y)$ and $N(x, y)$ have continuous first partial derivatives for all $(x, y)$. Now if the expression $M(x, y) d x+N(x, y) d y$ is exact, there exists some function $f$ for which

$$
M(x, y) d x+N(x, y) d y=\frac{\partial f}{\partial x} d x+\frac{\partial f}{\partial y} d y
$$

for all $(x, y)$ in $R$. Therefore

and

$$
\begin{gathered}
M(x, y)=\frac{\partial f}{\partial x}, \quad N(x, y)=\frac{\partial f}{\partial y} \\
\frac{\partial M}{\partial y}=\frac{\partial}{\partial y}\left(\frac{\partial f}{\partial x}\right)=\frac{\partial^{2} f}{\partial y \partial x}=\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial y}\right)=\frac{\partial N}{\partial x}
\end{gathered}
$$

The equality of the mixed partials is a consequence of the continuity of the first partial derivatives of $M(x, y)$ and $N(x, y)$.

The sufficiency part of Theorem 2.2 consists of showing that there exists a function $f$ for which $\partial f / \partial x=M(x, y)$ and $\partial f / \partial y=N(x, y)$ whenever (4) holds. The construction of the function $f$ actually reflects a basic procedure for solving exact equations.

Method of Solution Given the equation

first show that


\begin{align*}
& M(x, y) d x+N(x, y) d y=0  \tag{5}\\
& \frac{\partial M}{\partial y}=\frac{\partial N}{\partial x} \\
& \frac{\partial f}{\partial x}=M(x, y)
\end{align*}


Then assume that

so we can find $f$ by integrating $M(x, y)$ with respect to $x$, while holding $y$ constant. We write


\begin{equation*}
f(x, y)=\int M(x, y) d x+g(y) \tag{6}
\end{equation*}


where the arbitrary function $g(y)$ is the "constant" of integration. Now differentiate (6) with respect to $y$ and assume $\partial f / \partial y=N(x, y)$ :

This gives


\begin{gather*}
\frac{\partial f}{\partial y}=\frac{\partial}{\partial y} \int M(x, y) d x+g^{\prime}(y)=N(x, y) \\
g^{\prime}(y)=N(x, y)-\frac{\partial}{\partial y} \int M(x, y) d x \tag{7}
\end{gather*}


Finally, integrate (7) with respect to $y$ and substitute the result in (6). The solution of the equation is $f(x, y)=c$.

Note Some observations are in order. First, it is important to realize that the expression $N(x, y)-(\partial / \partial y) \int M(x, y) d x$ in (7) is independent of $x$, since

$$
\begin{aligned}
\frac{\partial}{\partial x}\left[N(x, y)-\frac{\partial}{\partial y} \int M(x, y) d x\right] & =\frac{\partial N}{\partial x}-\frac{\partial}{\partial y}\left(\frac{\partial}{\partial x} \int M(x, y) d x\right) \\
& =\frac{\partial N}{\partial x}-\frac{\partial M}{\partial y}=0 .
\end{aligned}
$$

Second, we could just as well start the foregoing procedure with the assumption that $\partial f / \partial y=N(x, y)$. After integrating $N$ with respect to $y$ and then differentiating that result, we find the analogues of (6) and (7) would be, respectively,

$$
f(x, y)=\int N(x, y) d y+h(x) \quad \text { and } \quad h^{\prime}(x)=M(x, y)-\frac{\partial}{\partial x} \int N(x, y) d y
$$

In either case none of these formulas should be memorized. Also, when testing an equation for exactness, make sure it is of form (5). Often a differential equation is written $G(x, y) d x=H(x, y) d y$. In this case write the equation as $G(x, y) d x-H(x, y) d y=0$ and then identify $M(x, y)=G(x, y)$ and $N(x, y)=-H(x, y)$.

\section*{EXAMPLE 3 Solving an Exact DE}
Solve $2 x y d x+\left(x^{2}-1\right) d y=0$.

Solution With $M(x, y)=2 x y$ and $N(x, y)=x^{2}-1$, we have

$$
\frac{\partial M}{\partial y}=2 x=\frac{\partial N}{\partial x}
$$

Thus the equation is exact, and so, by Theorem 2.2, there exists a function $f(x, y)$ such that

$$
\frac{\partial f}{\partial x}=2 x y \quad \text { and } \quad \frac{\partial f}{\partial y}=x^{2}-1
$$

From the first of these equations we obtain, after integrating,

$$
f(x, y)=x^{2} y+g(y)
$$

Taking the partial derivative of the last expression with respect to $y$ and setting the result equal to $N(x, y)$ gives

$$
\frac{\partial f}{\partial y}=x^{2}+g^{\prime}(y)=x^{2}-1 . \quad \leftarrow N(x, y)
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-071}
\end{center}

Figure 2.8

It follows that $g^{\prime}(y)=-1$ and $g(y)=-y$.

The constant of integration need not be included in the preceding line since the solution is $f(x, y)=c$. Some of the family of curves $x^{2} y-y=c$ are given in Figure 2.8.

Note The solution of the equation is not $f(x, y)=x^{2} y-y$. Rather it is $f(x, y)=c$ or $f(x, y)=0$ if a constant is used in the integration of $g^{\prime}(y)$. Observe that the equation could also be solved by separation of variables.

\section*{EXAMPLE 4 Solving an Exact DE}
Solve $\left(e^{2 y}-y \cos x y\right) d x+\left(2 x e^{2 y}-x \cos x y+2 y\right) d y=0$.

Solution The equation is neither separable nor homogeneous but is exact since

$$
\frac{\partial M}{\partial y}=2 e^{2 y}+x y \sin x y-\cos x y=\frac{\partial N}{\partial x}
$$

Hence a function $f(x, y)$ exists for which

$$
M(x, y)=\frac{\partial f}{\partial x} \quad \text { and } \quad N(x, y)=\frac{\partial f}{\partial y} .
$$

Now for variety we shall start with the assumption that $\partial f / \partial y=N(x, y)$;

that is,

$$
\begin{gathered}
\frac{\partial f}{\partial y}=2 x e^{2 y}-x \cos x y+2 y \\
f(x, y)=2 x \int e^{2 y} d y-x \int \cos x y d y+2 \int y d y
\end{gathered}
$$

Remember, the reason $x$ can come out in front of the symbol $\int$ is that in the integration with respect to $y, x$ is treated as an ordinary constant. It follows that

so

$$
\begin{gathered}
f(x, y)=x e^{2 y}-\sin x y+y^{2}+h(x) \\
\frac{\partial f}{\partial x}=e^{2 y}-y \cos x y+h^{\prime}(x)=e^{2 y}-y \cos x y, \quad \leftarrow M(x, y) \\
h^{\prime}(x)=0 \quad \text { and } \quad h(x)=c
\end{gathered}
$$

Hence a one-parameter family of solutions is given by

$$
x e^{2 y}-\sin x y+y^{2}+c=0
$$

\section*{EXAMPLE 5 An Initial-Value Problem}
Solve the initial-value problem

$$
\left(\cos x \sin x-x y^{2}\right) d x+y\left(1-x^{2}\right) d y=0, \quad y(0)=2
$$

The equation is exact since

Now

$$
\begin{aligned}
\frac{\partial M}{\partial y} & =-2 x y=\frac{\partial N}{\partial x} \\
\frac{\partial f}{\partial y} & =y\left(1-x^{2}\right) \\
f(x, y) & =\frac{y^{2}}{2}\left(1-x^{2}\right)+h(x) \\
\frac{\partial f}{\partial x} & =-x y^{2}+h^{\prime}(x)=\cos x \sin x-x y^{2}
\end{aligned}
$$

The last equation implies

$$
h^{\prime}(x)=\cos x \sin x \quad \text { or } \quad h(x)=-\int(\cos x)(-\sin x d x)=-\frac{1}{2} \cos ^{2} x
$$

Thus

$$
\frac{y^{2}}{2}\left(1-x^{2}\right)-\frac{1}{2} \cos ^{2} x=c_{1} \quad \text { or } \quad y^{2}\left(1-x^{2}\right)-\cos ^{2} x=c
$$

where $2 c_{1}$ has been replaced by $c$. The initial condition $y=2$ when $x=0$ demands that $4(1)-\cos ^{2}(0)=c$ or that $c=3$. Thus a solution of the problem is

$$
y^{2}\left(1-x^{2}\right)-\cos ^{2} x=3
$$

Integrating Factor It is sometimes possible to convert a nonexact differential equation into an exact equation by multiplying it by a function $\mu(x, y)$ called an integrating factor. However, the resulting exact equation

$$
\mu M(x, y) d x+\mu N(x, y) d y=0
$$

may not be equivalent to the original equation in the sense that a solution of one is also a solution of the other. It is possible for a solution to be lost or gained as a result of the multiplication.

\section*{EXAMPLE 6 Using an Integrating Factor}
Solve $(x+y) d x+x \ln x d y=0$, using $\mu(x, y)=\frac{1}{x}$, on $(0, \infty)$.

Solution Let $M(x, y)=x+y$ and $N(x, y)=x \ln x$ so $\partial M / \partial y=1$ and $\partial N / \partial x=1+\ln x$. The given equation is not exact. However, if we multiply the equation by $\mu(x, y)=1 / x$, we obtain

$$
\left(1+\frac{y}{x}\right) d x+\ln x d y=0
$$

From this latter form we make the identifications:

$$
M(x, y)=1+\frac{y}{x}, \quad N(x, y)=\ln x, \quad \frac{\partial M}{\partial y}=\frac{1}{x}=\frac{\partial N}{\partial x}
$$

Therefore the second differential equation is exact. It follows that

and so

$$
\begin{aligned}
\frac{\partial f}{\partial x} & =1+\frac{y}{x}=M(x, y) \\
f(x, y) & =x+y \ln x+g(y) \\
\frac{\partial f}{\partial y} & =0+\ln x+g^{\prime}(y)=\ln x \\
g^{\prime}(y) & =0 \quad \text { and } \quad g(y)=c
\end{aligned}
$$

Hence $f(x, y)=x+y \ln x+c$. It is readily verified that

$$
x+y \ln x+c=0
$$

is a solution of both equations on $(0, \infty)$.

\section*{EXERCISES 2.4}
Answers to odd-numbered problems begin on page A-3.

In Problems 1-24 determine whether the given equation is exact. If it is exact, solve.

$\begin{array}{ll}\text { 1. }(2 x-1) d x+(3 y+7) d y=0 & \text { 2. }(2 x+y) d x-(x+6 y) d y=0\end{array}$\\
3. $(5 x+4 y) d x+\left(4 x-8 y^{3}\right) d y=0$\\
4. $(\sin y-y \sin x) d x+(\cos x+x \cos y-y) d y=0$\\
5. $\left(2 y^{2} x-3\right) d x+\left(2 y x^{2}+4\right) d y=0$\\
6. $\left(2 y-\frac{1}{x}+\cos 3 x\right) \frac{d y}{d x}+\frac{y}{x^{2}}-4 x^{3}+3 y \sin 3 x=0$\\
7. $(x+y)(x-y) d x+x(x-2 y) d y=0$\\
8. $\left(1+\ln x+\frac{y}{x}\right) d x=(1-\ln x) d y$\\
9. $\left(y^{3}-y^{2} \sin x-x\right) d x+\left(3 x y^{2}+2 y \cos x\right) d y=0$\\
10. $\left(x^{3}+y^{3}\right) d x+3 x y^{2} d y=0$\\
11. $\left(y \ln y-e^{-x y}\right) d x+\left(\frac{1}{y}+x \ln y\right) d y=0$\\
12. $\frac{2 x}{y} d x-\frac{x^{2}}{y^{2}} d y=0$\\
13. $x \frac{d y}{d x}=2 x e^{x}-y+6 x^{2}$\\
14. $\left(3 x^{2} y+e^{y}\right) d x+\left(x^{3}+x e^{y}-2 y\right) d y=0$\\
15. $\left(1-\frac{3}{x}+y\right) d x+\left(1-\frac{3}{y}+x\right) d y=0$\\
16. $\left(e^{y}+2 x y \cosh x\right) y^{\prime}+x y^{2} \sinh x+y^{2} \cosh x=0$\\
17. $\left(x^{2} y^{3}-\frac{1}{1+9 x^{2}}\right) \frac{d x}{d y}+x^{3} y^{2}=0$\\
18. $(5 y-2 x) y^{\prime}-2 y=0$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $(\tan x-\sin x \sin y) d x+\cos x \cos y d y=0$

  \item $(3 x \cos 3 x+\sin 3 x-3) d x+(2 y+5) d y=0$

  \item $\left(1-2 x^{2}-2 y\right) \frac{d y}{d x}=4 x^{3}+4 x y$

  \item $\left(2 y \sin x \cos x-y+2 y^{2} e^{x y^{2}}\right) d x=\left(x-\sin ^{2} x-4 x y e^{x y^{2}}\right) d y$

  \item $\left(4 x^{3} y-15 x^{2}-y\right) d x+\left(x^{4}+3 y^{2}-x\right) d y=0$

  \item $\left(\frac{1}{x}+\frac{1}{x^{2}}-\frac{y}{x^{2}+y^{2}}\right) d x+\left(y e^{y}+\frac{x}{x^{2}+y^{2}}\right) d y=0$

\end{enumerate}

In Problems 25-30 solve the given differential equation subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $(x+y)^{2} d x+\left(2 x y+x^{2}-1\right) d y=0, \quad y(1)=1$

  \item $\left(e^{x}+y\right) d x+\left(2+x+y e^{y}\right) d y=0, \quad y(0)=1$

  \item $(4 y+2 x-5) d x+(6 y+4 x-1) d y=0, \quad y(-1)=2$

  \item $\left(\frac{3 y^{2}-x^{2}}{y^{5}}\right) \frac{d y}{d x}+\frac{x}{2 y^{4}}=0, \quad y(1)=1$

  \item $\left(y^{2} \cos x-3 x^{2} y-2 x\right) d x+\left(2 y \sin x-x^{3}+\ln y\right) d y=0, \quad y(0)=e$

  \item $\left(\frac{1}{1+y^{2}}+\cos x-2 x y\right) \frac{d y}{d x}=y(y+\sin x), \quad y(0)=1$

\end{enumerate}

In Problems 31-34 find the value of $k$ so that the given differential equation is exact.

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $\left(y^{3}+k x y^{4}-2 x\right) d x+\left(3 x y^{2}+20 x^{2} y^{3}\right) d y=0$

  \item $\left(2 x-y \sin x y+k y^{4}\right) d x-\left(20 x y^{3}+x \sin x y\right) d y=0$

  \item $\left(2 x y^{2}+y e^{x}\right) d x+\left(2 x^{2} y+k e^{x}-1\right) d y=0$

  \item $\left(6 x y^{3}+\cos y\right) d x+\left(k x^{2} y^{2}-x \sin y\right) d y=0$

  \item Determine a function $M(x, y)$ so that the following differential equation is exact:

\end{enumerate}

$$
M(x, y) d x+\left(x e^{x y}+2 x y+\frac{1}{x}\right) d y=0
$$

\begin{enumerate}
  \setcounter{enumi}{35}
  \item Determine a function $N(x, y)$ so that the following differential equation is exact:
\end{enumerate}

$$
\left(y^{1 / 2} x^{-1 / 2}+\frac{x}{x^{2}+y}\right) d x+N(x, y) d y=0
$$

In Problems 37-42 solve the given differential equation by verifying that the indicated function $\mu(x, y)$ is an integrating factor.

\begin{enumerate}
  \setcounter{enumi}{36}
  \item $6 x y d x+\left(4 y+9 x^{2}\right) d y=0, \quad \mu(x, y)=y^{2}$

  \item $-y^{2} d x+\left(x^{2}+x y\right) d y=0, \quad \mu(x, y)=1 / x^{2} y$

  \item $(-x y \sin x+2 y \cos x) d x+2 x \cos x d y=0, \quad \mu(x, y)=x y$

  \item $y(x+y+1) d x+(x+2 y) d y=0, \quad \mu(x, y)=e^{x}$

  \item $\left(2 y^{2}+3 x\right) d x+2 x y d y=0, \quad \mu(x, y)=x$

  \item $\left(x^{2}+2 x y-y^{2}\right) d x+\left(y^{2}+2 x y-x^{2}\right) d y=0, \quad \mu(x, y)=(x+y)^{-2}$

  \item Show that any separable first-order differential equation in the form $h(y) d y-g(x) d x=0$ is also exact.

\end{enumerate}

\subsection*{2.5 LINEAR EQUATIONS \\
 - Linear equation}
In Chapter 1 we defined the general form of a linear differential equation of order $n$ to be

$$
a_{n}(x) \frac{d^{n} y}{d x^{n}}+a_{n-1}(x) \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x)
$$

We remind you that linearity means that all coefficients are functions of $x$ only and that $y$ and all its derivatives are raised to the first power. Now when $n=1$, we obtain a linear first-order equation.

\section*{DEFINITION 2.5 Linear Equation}
A differential equation of the form

$$
a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x)
$$

is said to be a linear equation.

Dividing by the lead coefficient $a_{1}(x)$ gives a more useful form, the standard form, of a linear equation:


\begin{equation*}
\frac{d y}{d x}+P(x) y=f(x) \tag{1}
\end{equation*}


We seek a solution of (1) on an interval $I$ for which the functions $P(x)$ and $f(x)$ are continuous. In the discussion that follows, we tacitly assume that (1) has a solution.

Integrating Factor Using differentials, we can rewrite equation (1) as


\begin{equation*}
d y+[P(x) y-f(x)] d x=0 \tag{2}
\end{equation*}


Linear equations possess the pleasant property that a function $\mu(x)$ can always be found such that the multiple of (2),


\begin{equation*}
\mu(x) d y+\mu(x)[P(x) y-f(x)] d x=0 \tag{3}
\end{equation*}


is an exact differential equation. By Theorem 2.2 we know that the left side of equation (3) is an exact differential if


\begin{align*}
\frac{\partial}{\partial x} \mu(x) & =\frac{\partial}{\partial y} \mu(x)[P(x) y-f(x)]  \tag{4}\\
\frac{d \mu}{d x} & =\mu P(x)
\end{align*}


This is a separable equation from which we can determine $\mu(x)$. We have


\begin{align*}
\frac{d \mu}{\mu} & =P(x) d x \\
\ln |\mu| & =\int P(x) d x  \tag{5}\\
\mu(x) & =e^{P(x) d x} \tag{6}
\end{align*}


The function $\mu(x)$ defined in (6) is an integrating factor for the linear equation. Note that we need not use a constant of integration in (5) since (3) is unaffected by a constant multiple. Also, $\mu(x) \neq 0$ for every $x$ in $I$ and is continuous and differentiable.

It is interesting to observe that equation (3) is still an exact differential equation even when $f(x)=0$. In fact, $f(x)$ plays no part in determining $\mu(x)$ since we see from (4) that $(\partial / \partial y) \mu(x) f(x)=0$. Thus both

$$
\begin{gathered}
e^{\int P(x) d x} d y+e^{\int P(x) d x}[P(x) y-f(x)] d x \\
e^{\int P(x) d x} d y+e^{\int P(x) d x} P(x) y d x
\end{gathered}
$$

and

are exact differentials. We now write (3) in the form

$$
e^{\int P(x) d x} d y+e^{\int P(x) d x} P(x) y d x=e^{\int P(x) d x} f(x) d x
$$

and recognize that we can write this equation as

$$
d\left[e^{\int P(x) d x} y\right]=e^{\int P(x) d x} f(x) d x
$$

Integrating the last equation gives

$$
e^{\int P(x) d x} y=\int e^{\int P(x) d x} f(x) d x+c
$$

or


\begin{equation*}
y=e^{-\int P(x) d x} \int e^{\int P(x) d x} f(x) d x+c e^{-\int P(x) d x} \tag{7}
\end{equation*}


In other words, if (1) has a solution, it must be of form (7). Conversely, it is a straightforward matter to verify that (7) constitutes a one-parameter family of solutions of equation (1).

Summary of the Method No attempt should be made to memorize the formula given in (7). The procedure should be followed each time, so for convenience we summarize the results.

\section*{SOLVING A LINEAR FIRST-ORDER EQUATION}
(i) To solve a linear first-order equation first put it into the form (1); that is, make the coefficient of $d y / d x$ unity.

(ii) Identify $P(x)$ and find the integrating factor

$$
e^{\int P(x) d x}
$$

(iii) Multiply the equation obtained in step (i) by the integrating factor:

$$
e^{\int P(x) d x} \frac{d y}{d x}+P(x) e^{\int P(x) d x} y=e^{\int P(x) d x} f(x)
$$

(iv) The left side of the equation in step (iii) is the derivative of the product of the integrating factor and the dependent variable $y$; that is,

$$
\frac{d}{d x}\left[e^{\int P(x) d x} y\right]=e^{\int P(x) d x} f(x)
$$

(v) Integrate both sides of the equation found in step (iv).

\section*{EXAMPLE 1 Solving a Linear DE}
Solve $x \frac{d y}{d x}-4 y=x^{6} e^{x}$.

Solution Write the equation as


\begin{equation*}
\frac{d y}{d x}-\frac{4}{x} y=x^{5} e^{x} \tag{8}
\end{equation*}


by dividing by $x$. Since $P(x)=-4 / x$, the integrating factor is

$$
e^{-4 \int d x / x}=e^{-4 \ln |x|}=e^{\ln x^{-4}}=x^{-4}
$$

Here we have used the basic identity $b^{\log _{b} N}=N, N>0$. Now if we multiply (8) by this term,

we obtain


\begin{gather*}
x^{-4} \frac{d y}{d x}-4 x^{-5} y=x e^{x}  \tag{9}\\
\frac{d}{d x}\left[x^{-4} y\right]=x e^{x} . * \tag{10}
\end{gather*}


It follows from integration by parts that

$$
x^{-4} y=x e^{x}-e^{x}+c \quad \text { or } \quad y=x^{5} e^{x}-x^{4} e^{x}+c x^{4}
$$

\section*{EXAMPLE 2 Solving a Linear DE}
$$
\text { Solve } \frac{d y}{d x}-3 y=0
$$

Solution The equation is already in form (1). Hence the integrating factor is

$$
\begin{aligned}
e^{\int(-3) d x} & =e^{-3 x} \\
e^{-3 x} \frac{d y}{d x}-3 e^{-3 x} y & =0 \\
\frac{d}{d x}\left[e^{-3 x} y\right] & =0
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item You should perform the indicated differentiations a few times in order to be convinced that all equations such as (8), (9), and (10) are formally equivalent.
\end{itemize}
}

Integrating, we have

$$
\begin{aligned}
e^{-3 x} y & =c \\
y & =c e^{3 x} .
\end{aligned}
$$

General Solution If it is assumed that $P(x)$ and $f(x)$ are continuous on an interval $I$ and $x_{0}$ is any point in the interval, then it follows from Theorem 2.1 that there exists only one solution of the initial-value problem


\begin{equation*}
\frac{d y}{d x}+P(x) y=f(x), \quad y\left(x_{0}\right)=y_{0} \tag{11}
\end{equation*}


But we saw earlier that (1) possesses a family of solutions and that every solution of the equation on the interval $I$ is of form (7). Thus, obtaining the solution of (11) is a simple matter of finding an appropriate value of $c$ in (7). Consequently, we are justified in calling (7) the general solution of the differential equation. In retrospect, you should recall that in several instances we found singular solutions of nonlinear equations. This cannot happen in the case of a linear equation when proper attention is paid to solving the equation over a common interval on which $P(x)$ and $f(x)$ are continuous.

\section*{EXAMPLE 3 General Solution}
Find the general solution of $\left(x^{2}+9\right) \frac{d y}{d x}+x y=0$.

Solution We write

$$
\frac{d y}{d x}+\frac{x}{x^{2}+9} y=0
$$

The function $P(x)=x /\left(x^{2}+9\right)$ is continuous on $(-\infty, \infty)$. Now the integrating factor for the equation is

$$
e^{\int x d x /\left(x^{2}+9\right)}=e^{\frac{1}{2} \int 2 x d x /\left(x^{2}+9\right)}=e^{\frac{1}{2} \ln \left(x^{2}+9\right)}=\sqrt{x^{2}+9}
$$

so

$$
\begin{aligned}
\sqrt{x^{2}+9} \frac{d y}{d x}+\frac{x}{\sqrt{x^{2}+9}} y & =0 \\
\frac{d}{d x}\left[\sqrt{x^{2}+9} y\right] & =0 \\
\sqrt{x^{2}+9} y & =c
\end{aligned}
$$

Hence the general solution on the interval is

$$
y=\frac{c}{\sqrt{x^{2}+9}}
$$

\section*{EXAMPLE 4 An Initial-Value Problem}
Solve the initial-value problem $\frac{d y}{d x}+2 x y=x, y(0)=-3$.

Solution The functions $P(x)=2 x$ and $f(x)=x$ are continuous on $(-\infty, \infty)$. The integrating factor is

$$
e^{2 \int x d x}=e^{x^{2}}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-079(1)}
\end{center}

Figure 2.9 so

$$
\begin{aligned}
e^{x^{2}} \frac{d y}{d x}+2 x e^{x^{2}} y & =x e^{x^{2}} \\
\frac{d}{d x}\left[e^{x^{2}} y\right] & =x e^{x^{2}} \\
e^{x^{2}} y & =\int x e^{x^{2}} d x=\frac{1}{2} e^{x^{2}}+c
\end{aligned}
$$

Thus the general solution of the differential equation is

$$
y=\frac{1}{2}+c e^{-x^{2}}
$$

The condition $y(0)=-3$ gives $c=-\frac{7}{2}$, and hence the solution of the initialvalue problem on the interval is

$$
y=\frac{1}{2}-\frac{7}{2} e^{-x^{2}}
$$

See Figure 2.9.

\section*{EXAMPLE 5 An Initial-Value Problem}
Solve the initial-value problem $x \frac{d y}{d x}+y=2 x, y(1)=0$.

Solution Write the given equation as

$$
\frac{d y}{d x}+\frac{1}{x} y=2
$$

and observe that $P(x)=1 / x$ is continuous on any interval not containing the origin. In view of the initial condition, we solve the problem on the interval $(0, \infty)$.

The integrating factor is

and so

$$
\begin{gathered}
e^{\int d x / x}=e^{\ln |x|}=x \\
\frac{d}{d x}[x y]=2 x \\
x y=x^{2}+c .
\end{gathered}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-079}
\end{center}

Figure 2.10

gives

But $y(1)=0$ implies $c=-1$. Hence we obtain


\begin{equation*}
y=x-\frac{1}{x}, \quad 0<x<\infty \tag{13}
\end{equation*}


Considered as a one-parameter family of curves, the graph of (12) is given in Figure 2.10. The solution (13) of the initial-value problem is indicated by the colored portion of the graph.

\section*{EXAMPLE 6 An Initial-Value Problem}
Solve the initial-value problem $\frac{d y}{d x}=\frac{1}{x+y^{2}}, y(-2)=0$.

Solution The given differential equation is not separable, homogeneous, exact, or linear in the variable $y$. However, if we take the reciprocal, then

$$
\frac{d x}{d y}=x+y^{2} \quad \text { or } \quad \frac{d x}{d y}-x=y^{2}
$$

This latter equation is linear in $x$, so the corresponding integrating factor is $e^{-\int d y}=e^{-y}$. Hence,

$$
\frac{d}{d y}\left[e^{-y} x\right]=y^{2} e^{-y} \quad \text { and } \quad e^{-y} x=\int y^{2} e^{-y} d y
$$

Integrating by parts twice then gives

$$
\begin{aligned}
e^{-y} x & =-y^{2} e^{-y}-2 y e^{-y}-2 e^{-y}+c \\
x & =-y^{2}-2 y-2+c e^{y}
\end{aligned}
$$

When $x=-2, y=0$, we find $c=0$ and so

$$
x=-y^{2}-2 y-2 \text {. }
$$

The next example illustrates a way of solving (1) when the function $f$ is discontinuous.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-080}
\end{center}

Figure 2.11

\section*{EXAMPLE 7 A Discontinuous $f(x)$}
Find a continuous solution satisfying

$$
\frac{d y}{d x}+y=f(x), \quad \text { where } \quad f(x)=\left\{\begin{array}{lr}
1, & 0 \leq x \leq 1 \\
0, & x>1
\end{array}\right.
$$

and the initial condition $y(0)=0$.

Solution From Figure 2.11 we see that $f$ is discontinuous at $x=1$. Consequently, we solve the problem in two parts. For $0 \leq x \leq 1$ we have

$$
\frac{d y}{d x}+y=1 \quad \text { or } \quad \frac{d}{d x}\left[e^{x} y\right]=e^{x}
$$

The last equation yields $y=1+c_{1} e^{-x}$. Since $y(0)=0$, we must have $c_{1}=-1$, and therefore

$$
y=1-e^{-x}, \quad 0 \leq x \leq 1
$$

For $x>1$ we then have

$$
\frac{d y}{d x}+y=0
$$

which leads to $y=c_{2} e^{-x}$. Hence we can write

$$
y=\left\{\begin{array}{lr}
1-e^{-x}, & 0 \leq x \leq 1 \\
c_{2} e^{-x}, & x>1
\end{array}\right.
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-081}
\end{center}

Figure 2.12\\
Now in order that $y$ be a continuous function, we certainly want $\lim _{x \rightarrow 1^{+}} y(x)=$ $y$ (1). This latter requirement is equivalent to $c_{2} e^{-1}=1-e^{-1}$ or $c_{2}=e-1$. As Figure 2.12 shows, the function

$$
y=\left\{\begin{array}{lr}
1-e^{-x}, & 0 \leq x \leq 1 \\
(e-1) e^{-x}, & x>1
\end{array}\right.
$$

is continuous but not differentiable at $x=1$.

Remarks Formula (7), representing the general solution of (1), actually consists of the sum of two solutions. We define


\begin{equation*}
y=y_{c}+y_{p} \tag{14}
\end{equation*}


where

$$
y_{c}=c e^{-\int P(x) d x} \text { and } y_{p}=e^{-\int P(x) d x} \int e^{\int P(x) d x} f(x) d x
$$

The function $y_{c}$ is readily shown to be the general solution of $y^{\prime}+P(x) y=0$, whereas $y_{p}$ is a particular solution of $y^{\prime}+P(x) y=f(x)$. As we shall see in Chapter 4, the additivity property of solutions (14) to form a general solution is an intrinsic property of linear equations of any order.

\section*{EXERCISES 2.5}
Answers to odd-numbered problems begin on page A-3.

In Problems 1-40 find the general solution of the given differential equation. State an interval on which the general solution is defined.

\begin{enumerate}
  \item $\frac{d y}{d x}=5 y$

  \item $\frac{d y}{d x}+2 y=0$

  \item $3 \frac{d y}{d x}+12 y=4$

  \item $x \frac{d y}{d x}+2 y=3$

  \item $\frac{d y}{d x}+y=e^{3 x}$

  \item $\frac{d y}{d x}=y+e^{x}$

  \item $y^{\prime}+3 x^{2} y=x^{2}$

  \item $y^{\prime}+2 x y=x^{3}$

  \item $x^{2} y^{\prime}+x y=1$

  \item $y^{\prime}=2 y+x^{2}+5$

  \item $\left(x+4 y^{2}\right) d y+2 y d x=0$

  \item $\frac{d x}{d y}=x+y$

  \item $x d y=(x \sin x-y) d x$

  \item $\left(1+x^{2}\right) d y+\left(x y+x^{3}+x\right) d x=0$

  \item $\left(1+e^{x}\right) \frac{d y}{d x}+e^{x} y=0$

  \item $\left(1-x^{3}\right) \frac{d y}{d x}=3 x^{2} y$

  \item $\cos x \frac{d y}{d x}+y \sin x=1$

  \item $\frac{d y}{d x}+y \cot x=2 \cos x$

  \item $x \frac{d y}{d x}+4 y=x^{3}-x$

  \item $(1+x) y^{\prime}-x y=x+x^{2}$

  \item $x^{2} y^{\prime}+x(x+2) y=e^{x}$

  \item $x y^{\prime}+(1+x) y=e^{-x} \sin 2 x$

  \item $\cos ^{2} x \sin x d y+\left(y \cos ^{3} x-1\right) d x=0$

  \item $(1-\cos x) d y+(2 y \sin x-\tan x) d x=0$

  \item $y d x+\left(x y+2 x-y e^{y}\right) d y=0$

  \item $\left(x^{2}+x\right) d y=\left(x^{5}+3 x y+3 y\right) d x$

  \item $x \frac{d y}{d x}+(3 x+1) y=e^{-3 x}$

  \item $(x+1) \frac{d y}{d x}+(x+2) y=2 x e^{-x}$

  \item $y d x-4\left(x+y^{6}\right) d y=0$

  \item $x y^{\prime}+2 y=e^{x}+\ln x$

  \item $\frac{d y}{d x}+y=\frac{1-e^{-2 x}}{e^{x}+e^{-x}}$

  \item $\frac{d y}{d x}-y=\sinh x$

  \item $y d x+\left(x+2 x y^{2}-2 y\right) d y=0$

  \item $y d x=\left(y e^{y}-2 x\right) d y$

  \item $\frac{d r}{d \theta}+r \sec \theta=\cos \theta$

  \item $\frac{d P}{d t}+2 t P=P+4 t-2$

  \item $(x+2)^{2} \frac{d y}{d x}=5-8 y-4 x y$

  \item $\left(x^{2}-1\right) \frac{d y}{d x}+2 y=(x+1)^{2}$

  \item $y^{\prime}=(10-y) \cosh x$

  \item $d x=\left(3 e^{y}-2 x\right) d y$

\end{enumerate}

In Problems 41-54 solve the given differential equation subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item $\frac{d y}{d x}+5 y=20, \quad y(0)=2$

  \item $y^{\prime}=2 y+x\left(e^{3 x}-e^{2 x}\right), \quad y(0)=2$

  \item $L \frac{d i}{d t}+R i=E ; \quad L, R$, and $E$ constants, $i(0)=i_{0}$

  \item $y \frac{d x}{d y}-x=2 y^{2}, \quad y(1)=5$

  \item $y^{\prime}+(\tan x) y=\cos ^{2} x, \quad y(0)=-1$

  \item $\frac{d Q}{d x}=5 x^{4} Q, \quad Q(0)=-7$

  \item $\frac{d T}{d t}=k(T-50) ; \quad k$ a constant, $T(0)=200$

  \item $x d y+\left(x y+2 y-2 e^{-x}\right) d x=0, \quad y(1)=0$

  \item $(x+1) \frac{d y}{d x}+y=\ln x, \quad y(1)=10$

  \item $x y^{\prime}+y=e^{x}, \quad y(1)=2$

  \item $x(x-2) y^{\prime}+2 y=0, \quad y(3)=6$

  \item $\sin x \frac{d y}{d x}+(\cos x) y=0, \quad y\left(-\frac{\pi}{2}\right)=1$

  \item $\frac{d y}{d x}=\frac{y}{y-x}, \quad y(5)=2$

  \item $\cos ^{2} x \frac{d y}{d x}+y=1, \quad y(0)=-3$

\end{enumerate}

In Problems $55-58$ find a continuous solution satisfying each differential equation and the given initial condition.\\
55. $\frac{d y}{d x}+2 y=f(x), \quad f(x)=\left\{\begin{array}{rr}1, & 0 \leq x \leq 3 \\ 0, & x>3\end{array}, \quad y(0)=0\right.$\\
56. $\frac{d y}{d x}+y=f(x), \quad f(x)=\left\{\begin{array}{rr}1, & 0 \leq x \leq 1 \\ -1, & x>1\end{array}, \quad y(0)=1\right.$\\
57. $\frac{d y}{d x}+2 x y=f(x), \quad f(x)=\left\{\begin{array}{rr}x, & 0 \leq x<1 \\ 0, & x \geq 1,\end{array} \quad y(0)=2\right.$\\
58. $\left(1+x^{2}\right) \frac{d y}{d x}+2 x y=f(x), \quad f(x)=\left\{\begin{array}{rr}x, & 0 \leq x<1 \\ -x, & x \geq 1\end{array} \quad \quad y(0)=0\right.$

\section*{2.6* EQUATIONS OF BERNOULLI, RICATTI, AND CLAIRAUT ${ }^{+}$ \\
 - Bernoulli's equation \\
 Ricatti's equation \\
 Clairaut's equation}
In this section we are not going to study any one particular type of differential equation. Rather, we are going to consider three classical equations that in some instances can be transformed into equations we have already studied.

Bernoulli's Equation The differential equation


\begin{equation*}
\frac{d y}{d x}+P(x) y=f(x) y^{n} \tag{1}
\end{equation*}


where $n$ is any real number, is called Bernoulli's equation. For $n=0$ and $n=1$, equation (1) is linear in $y$. Now for $y \neq 0$, (1) can be written as


\begin{equation*}
y^{-n} \frac{d y}{d x}+P(x) y^{1-n}=f(x) \tag{2}
\end{equation*}

\footnotetext{*This section is an optional section.

$\dagger$ JAKOB BERNOULLI (1654-I705) The Bernoullis were a Swiss family of scholars whose contributions to mathematics, physics, astronomy, and history spanned the sixteenth to the twentieth centuries. Jakob, the elder of the two sons of the patriarch Jacques Bernoulli, made many contributions to the then-new fields of calculus and probability. Originally the second of the two major divisions of calculus was called calculus summatorius. In 1696, at Jakob Bernoulli's suggestion, its name was changed to calculus integralis or, as we know it today, integral calculus.

JACOBO FRANCESCO RICATTI (I676-1754) An Italian count, Ricatti was also a mathematician and philosopher.

ALEXIS CLAUDE CLAIRAUT (1713-1765) Born in Paris in 1713, Clairaut was a child prodigy who wrote his first book on mathematics at the age of eleven. He was among the first to discover singular solutions of differential equations. Like many mathematicians of his era, Clairaut was also a physicist and astronomer.
}

If we let $w=y^{1-n}, n \neq 0, n \neq 1$, then

$$
\frac{d w}{d x}=(1-n) y^{-n} \frac{d y}{d x}
$$

With these substitutions, (2) can be simplified to the linear equation


\begin{equation*}
\frac{d w}{d x}+(1-n) P(x) w=(1-n) f(x) \tag{3}
\end{equation*}


Solving (3) for $w$ and using $y^{1-n}=w$ leads to a solution of (1).

\section*{EXAMPLE 1 Solving a Bernoulli DE}
Solve $\frac{d y}{d x}+\frac{1}{x} y=x y^{2}$.

Solution From (1) we identify $P(x)=1 / x, f(x)=x$, and $n=2$. Thus the substitution $w=y^{-1}$ gives

$$
\frac{d w}{d x}-\frac{1}{x} w=-x
$$

The integrating factor for this linear equation on, say, $(0, \infty)$ is

$$
e^{-\int d x / x}=e^{-\ln |x|}=e^{\ln |x|^{-1}}=x^{-1}
$$

Hence

$$
\frac{d}{d x}\left[x^{-1} w\right]=-1
$$

Integrating this latter form, we get

$$
x^{-1} w=-x+c \text { or } w=-x^{2}+c x \text {. }
$$

Since $w=y^{-1}$, we obtain $y=1 / w$ or

$$
y=\frac{1}{-x^{2}+c x}
$$

For $n>0$ note that the trivial solution $y=0$ is a solution of (1). In Example $1, y=0$ is a singular solution of the given equation.

Ricatti's Equation The nonlinear differential equation


\begin{equation*}
\frac{d y}{d x}=P(x)+Q(x) y+R(x) y^{2} \tag{4}
\end{equation*}


is called Ricatti's equation. If $y_{1}$ is a known particular solution of (4), then the substitutions

$$
y=y_{1}+u \text { and } \quad \frac{d y}{d x}=\frac{d y_{1}}{d x}+\frac{d u}{d x}
$$

in (4) lead to the following differential equation for $u$ :


\begin{equation*}
\frac{d u}{d x}-\left(Q+2 y_{1} R\right) u=R u^{2} \tag{5}
\end{equation*}


Since (5) is a Bernoulli equation with $n=2$, it can in turn be reduced to the linear equation


\begin{equation*}
\frac{d w}{d x}+\left(Q+2 y_{1} R\right) w=-R \tag{6}
\end{equation*}


by the substitution $w=u^{-1}$. See Problems 25 and 26 .

As Example 2 illustrates, in many cases a solution of a Ricatti equation cannot be expressed in terms of elementary functions.

\section*{EXAMPLE 2 Solving a Ricatti DE}
Solve $\frac{d y}{d x}=2-2 x y+y^{2}$.

Solution It is easily verified that a particular solution of this equation is $y_{1}=2 x$. From (4) we make the identifications $P(x)=2, Q(x)=-2 x$, and $R(x)=1$ and then solve the linear equation (6):

$$
\frac{d w}{d x}+(-2 x+4 x) w=-1 \quad \text { or } \quad \frac{d w}{d x}+2 x w=-1
$$

The integrating factor for the last equation is $e^{x^{2}}$, and so

$$
\frac{d}{d x}\left[e^{x^{2}} w\right]=-e^{x^{2}}
$$

Now the integral $\int_{x_{0}}^{x} e^{t^{2}} d t$ cannot be expressed in terms of elementary functions.* Thus we write

$$
\begin{gathered}
e^{x^{2}} w=-\int_{x_{0}}^{x} e^{t^{2}} d t+c \text { or } e^{x^{2}}\left(\frac{1}{u}\right)=-\int_{x_{0}}^{x} e^{t^{2}} d t+c, \\
u=\frac{e^{x^{2}}}{c-\int_{x_{0}}^{x} e^{t^{2}} d t}
\end{gathered}
$$

so

A solution of the equation is then $y=2 x+u$.

Clairaut's Equation It is left as an exercise to show that a solution of Clairaut's equation


\begin{equation*}
y=x y^{\prime}+f\left(y^{\prime}\right) \tag{7}
\end{equation*}


is the family of straight lines $y=c x+f(c)$, where $c$ is an arbitrary constant. See Problem 29. Furthermore (7) may also possess a solution in parametric form:


\begin{equation*}
x=-f^{\prime}(t), \quad y=f(t)-t f^{\prime}(t) \tag{8}
\end{equation*}

\footnotetext{\begin{itemize}
  \item When an integral $\int f(x) d x$ cannot be evaluated in terms of elementary functions, it is customary to write $\int_{x_{0}}^{x} f(t) d t$, where $x_{0}$ is a constant. When an initial condition is specified, it is imperative that this form be used.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-086(1)}
\end{center}

Figure 2.13

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-086}
\end{center}

Figure 2.14\\
This last solution is a singular solution since, if $f^{\prime \prime}(t) \neq 0$, it cannot be obtained from the family of solutions $y=c x+f(c)$.

\section*{EXAMPLE 3 Solving a Clairaut DE}
Solve $y=x y^{\prime}+\frac{1}{2}\left(y^{\prime}\right)^{2}$.

Solution We first make the identification $f\left(y^{\prime}\right)=\frac{1}{2}\left(y^{\prime}\right)^{2}$ so that $f(t)=\frac{1}{2} t^{2}$. It follows from the preceding discussion that a family of solutions is


\begin{equation*}
y=c x+\frac{1}{2} c^{2} \tag{9}
\end{equation*}


The graph of this family is given in Figure 2.13. Since $f^{\prime}(t)=t$, a singular solution is obtained from (8):

$$
x=-t, \quad y=\frac{1}{2} t^{2}-t \cdot t=-\frac{1}{2} t^{2}
$$

After eliminating the parameter, we find this latter solution is the same as $y=-\frac{1}{2} x^{2}$. One can readily see that this function is not part of the family (9). See Figure 2.14.

\section*{EXERCISES 2.6}
Answers to odd-numbered problems begin on page A-3.

In Problems 1-6 solve the given Bernoulli equation.

\begin{enumerate}
  \item $x \frac{d y}{d x}+y=\frac{1}{y^{2}}$
  \item $\frac{d y}{d x}-y=e^{x} y^{2}$
  \item $\frac{d y}{d x}=y\left(x y^{3}-1\right)$
  \item $x \frac{d y}{d x}-(1+x) y=x y^{2}$
  \item $x^{2} \frac{d y}{d x}+y^{2}=x y$
  \item $3\left(1+x^{2}\right) \frac{d y}{d x}=2 x y\left(y^{3}-1\right)$
\end{enumerate}

In Problems 7-10 solve the given differential equation subject to the indicated initial condition.\\
7. $x^{2} \frac{d y}{d x}-2 x y=3 y^{4}, \quad y(1)=\frac{1}{2}$\\
8. $y^{1 / 2} \frac{d y}{d x}+y^{3 / 2}=1, \quad y(0)=4$\\
9. $x y\left(1+x y^{2}\right) \frac{d y}{d x}=1, \quad y(1)=0$\\
10. $2 \frac{d y}{d x}=\frac{y}{x}-\frac{x}{y^{2}}, \quad y(1)=1$

In Problems 11-16 solve the given Ricatti equation; $y_{1}$ is a known solution of the equation.\\
11. $\frac{d y}{d x}=-2-y+y^{2}, \quad y_{1}=2$\\
12. $\frac{d y}{d x}=1-x-y+x y^{2}, \quad y_{1}=1$\\
13. $\frac{d y}{d x}=-\frac{4}{x^{2}}-\frac{1}{x} y+y^{2}, \quad y_{1}=\frac{2}{x}$\\
14. $\frac{d y}{d x}=2 x^{2}+\frac{1}{x} y-2 y^{2}, \quad y_{1}=x$\\
15. $\frac{d y}{d x}=e^{2 x}+\left(1+2 e^{x}\right) y+y^{2}, \quad y_{1}=-e^{x}$\\
16. $\frac{d y}{d x}=\sec ^{2} x-(\tan x) y+y^{2}, \quad y_{1}=\tan x$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Solve $\frac{d y}{d x}=6+5 y+y^{2}$.

  \item Solve $\frac{d y}{d x}=9+6 y+y^{2}$.

\end{enumerate}

In Problems 19-24 solve the given Clairaut equation. Obtain a singular solution.\\
19. $y=x y^{\prime}+1-\ln y^{\prime}$\\
20. $y=x y^{\prime}+\left(y^{\prime}\right)^{-2}$\\
21. $y=x \frac{d y}{d x}-\left(\frac{d y}{d x}\right)^{3}$\\
22. $y=(x+4) y^{\prime}+\left(y^{\prime}\right)^{2}$\\
23. $x y^{\prime}-y=e^{y}$\\
24. $y-x y^{\prime}=\ln y^{\prime}$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item Show that if $y_{1}$ is a solution of (4), then the substitution $y=y_{1}+u$ in (4) yields (5).

  \item Show that (5) can be reduced to (6) by means of the substitution $w=u^{-1}$.

  \item When $R(x)=-1$, the Ricatti equation can be written as $y^{\prime}+y^{2}-Q(x) y-P(x)=0$. Show that the substitution $y=w^{\prime} / w$ leads to the linear second-order equation $w^{\prime \prime}-Q(x) w^{\prime}-P(x) w=0$. (When $Q$ and $P$ are also constants, there is little difficulty in solving equations of this type.)

  \item An alternative definition of Clairaut's equation is any equation of the form $F\left(y-x y^{\prime}, y^{\prime}\right)=0$.

\end{enumerate}

(a) Show that a family of solutions of the latter equation is

$$
F(y-c x, c)=0
$$

(b) Use the result of part (a) to solve

$$
\left(x y^{\prime}-y\right)^{3}=\left(y^{\prime}\right)^{2}+5
$$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item Show that $y=c x+f(c)$, where $c$ is an arbitrary constant, is a solution of (7).

  \item Show that (8) is a solution of (7). [Hint: Differentiate both sides of (7) with respect to $x$ and consider two cases. Use parametric differentiation to show that

\end{enumerate}

$$
\frac{d y}{d x}=\frac{d y / d t}{d x / d t}=t, \quad f^{\prime \prime}(t) \neq 0
$$

Note that since the slope of $y=c x+f(c)$ is constant, the singular solution cannot be obtained from it.]

\section*{2.7* SUBSTITUTIONS}
In the preceding sections, we saw that sometimes a differential equation could be transformed by means of a substitution into a form that could then be solved by one of the standard methods. An equation may look different from any of those that we have just studied, but through a judicious change of variables perhaps an apparently difficult problem may be readily solved. Although we can give no firm rules on what, if any, substitution to use, a working axiom might be "Try something!" It sometimes pays to be clever.

\section*{EXAMPLE 1 DE Reduced to Separable Variables}
The differential equation

$$
y(1+2 x y) d x+x(1-2 x y) d y=0
$$

is not separable, homogeneous, exact, linear, or Bernoulli. However, if we stare at the equation long enough, we might be prompted to try the substitution

$$
u=2 x y \quad \text { or } \quad y=\frac{u}{2 x}
$$

Since

Since

$$
d y=\frac{x d u-u d x}{2 x^{2}}
$$

the equation becomes, after we simplify,

$$
2 u^{2} d x+(1-u) x d u=0
$$

We recognize the last equation as separable, and so from

$$
\begin{gathered}
2 \frac{d x}{x}+\frac{1-u}{u^{2}} d u=0 \\
2 \ln |x|-u^{-1}-\ln |u|=c \quad \text { or } \quad \ln \left|\frac{x}{2 y}\right|=c+\frac{1}{2 x y} \\
\frac{x}{2 y}=c_{1} e^{1 / 2 x y} \text { or } x=2 y c_{1} e^{1 / 2 x y}
\end{gathered}
$$

we obtain

where $e^{c}$ was replaced by $c_{1}$. We can also replace $2 c_{1}$ by $c_{2}$ if desired.

Notice that the differential equation in Example 1 possesses the trivial solution $y=0$ but that this function is not included in the one-parameter family of solutions.

\section*{EXAMPLE 2 DE Reduced to a Linear Equation}
Solve $2 x y \frac{d y}{d x}+2 y^{2}=3 x-6$.
\footnotetext{\begin{itemize}
  \item This section is an optional section.
\end{itemize}
}

Solution The presence of the term $2 y \frac{d y}{d x}$ prompts us to try $u=y^{2}$ since

$$
\frac{d u}{d x}=2 y \frac{d y}{d x}
$$

Now

$$
x \frac{d u}{d x}+2 u=3 x-6
$$

has the linear form

$$
\frac{d u}{d x}+\frac{2}{x} u=3-\frac{6}{x}
$$

so multiplication by the integrating factor $e^{\int(2 / x) d x}=e^{\ln x^{2}}=x^{2}$ gives

$$
\begin{gathered}
\frac{d}{d x}\left[x^{2} u\right]=3 x^{2}-6 x \\
x^{2} u=x^{3}-3 x^{2}+c \text { or } x^{2} y^{2}=x^{3}-3 x^{2}+c
\end{gathered}
$$

\section*{EXAMPLE 3 DE Reduced to Separable Variables}
Solve $x \frac{d y}{d x}-y=\frac{x^{3}}{y} e^{y / x}$.

Solution If we let $u=y / x$, the differential equation can be simplified to

$$
u e^{-u} d u=d x
$$

Integrating by parts and replacing $-c$ by $c_{1}$ then yields

$$
-u e^{-u}-e^{-u}=x+c \text { or } u+1=\left(c_{1}-x\right) e^{u}
$$

We then resubstitute $u=y / x$ and simplify:

$$
y+x=x\left(c_{1}-x\right) e^{y / x}
$$

Some higher-order differential equations can be reduced to first-order equations by a substitution.

\section*{EXAMPLE 4 Second-Order DE Reduced to a First-Order DE}
Solve $y^{\prime \prime}=2 x\left(y^{\prime}\right)^{2}$.

Solution If we let $u=y^{\prime}$ so that $d u / d x=y^{\prime \prime}$, the equation reduces to a separable form. We have

$$
\begin{array}{r}
\frac{d u}{d x}=2 x u^{2} \quad \text { or } \frac{d u}{u^{2}}=2 x d x \\
\int u^{-2} d u=\int 2 x d x \text { or }-u^{-1}=x^{2}+c_{1}^{2}
\end{array}
$$

The constant of integration is written as $c_{1}^{2}$ for convenience. The reason should be obvious in the next few steps. Since $u^{-1}=1 / y^{\prime}$, it follows that

$$
\begin{aligned}
& \frac{d y}{d x}=-\frac{1}{x^{2}+c_{1}^{2}} \quad \text { or } \quad d y=-\frac{d x}{x^{2}+c_{1}^{2}} \\
& \int d y=-\int \frac{d x}{x^{2}+c_{1}^{2}} \text { or } y+c_{2}=-\frac{1}{c_{1}} \tan ^{-1} \frac{x}{c_{1}} \text {. }
\end{aligned}
$$

\section*{EXERCISES 2.7}
Answers to odd-numbered problems begin on page A-3.

In Problems 1-26 solve the given differential equation by using an appropriate substitution.

$$
\begin{array}{ll}
\text { 1. } x e^{2 y} \frac{d y}{d x}+e^{2 y}=\frac{\ln x}{x} & \text { 2. } y^{\prime}+y \ln y=y e^{x}
\end{array}
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $y d x+\left(1+y e^{x}\right) d y=0$

  \item $\left(2+e^{-x / y}\right) d x+2\left(1-\frac{x}{y}\right) d y=0$

  \item $\frac{d y}{d x}-\frac{4}{x} y=2 x^{5} e^{y / x^{4}}$

  \item $\frac{d y}{d x}+x+y+1=(x+y)^{2} e^{3 x}$

  \item $2 y y^{\prime}+x^{2}+y^{2}+x=0$

  \item $y^{\prime}=y+x(y+1)^{2}+1$

  \item $2 x \csc 2 y \frac{d y}{d x}=2 x-\ln (\tan y)$

  \item $x^{2} \frac{d y}{d x}+2 x y=x^{4} y^{2}+1$

  \item $x^{4} y^{2} y^{\prime}+x^{3} y^{3}=2 x^{3}-3$

  \item $x e^{y} y^{\prime}-2 e^{y}=x^{2}$

  \item $y^{\prime}+1=e^{-(x+y)} \sin x$

  \item $\sin y \sinh x d x+\cos y \cosh x d y=0$

  \item $y \frac{d x}{d y}+2 x \ln x=x e^{y}$

  \item $x \sin y \frac{d y}{d x}+\cos y=-x^{2} e^{x}$

  \item $y^{\prime \prime}+\left(y^{\prime}\right)^{2}+1=0$

  \item $x y^{\prime \prime}=y^{\prime}+x\left(y^{\prime}\right)^{2}$

  \item $x y^{\prime \prime}=y^{\prime}+\left(y^{\prime}\right)^{3}$

  \item $x^{2} y^{\prime \prime}+\left(y^{\prime}\right)^{2}=0$

  \item $y^{\prime}-x y^{\prime \prime}-\left(y^{\prime \prime}\right)^{3}=1$

  \item $y^{\prime \prime}=1+\left(y^{\prime}\right)^{2}$

  \item $x y^{\prime \prime}-y^{\prime}=0$

  \item $y^{\prime \prime}+(\tan x) y^{\prime}=0$

  \item $y^{\prime \prime}+2 y\left(y^{\prime}\right)^{3}=0$

  \item $y^{2} y^{\prime \prime}=y^{\prime}$

\end{enumerate}

$$
\left[\text { Hint: Let } u=y^{\prime} \text { so that } y^{\prime \prime}=\frac{d u}{d x}=\frac{d u}{d y} \frac{d y}{d x}=\frac{d u}{d y} u\right. \text {.] }
$$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item In calculus the curvature of a curve whose equation is $y=f(x)$ is defined to be the number
\end{enumerate}

$$
\kappa=\frac{y^{\prime \prime}}{\left[1+\left(y^{\prime}\right)^{2}\right]^{3 / 2}}
$$

Determine a function for which $\kappa=1$. [Hint: For simplicity ignore constants of integration. Also consider a trigonometric substitution.]

\section*{2.8* PICARD'S METHOD}
The initial-value problem


\begin{equation*}
y^{\prime}=f(x, y), \quad y\left(x_{0}\right)=y_{0} \tag{1}
\end{equation*}


first considered in Section 2.1, can be written in an alternative manner. Let $f$ be continuous in a region containing the point $\left(x_{0}, y_{0}\right)$. By integrating both sides of the differential equation with respect to $x$, we get

$$
y(x)=c+\int_{x_{0}}^{x} f(t, y(t)) d t
$$

Now

$$
y\left(x_{0}\right)=c+\int_{x_{0}}^{x_{10}} f(t, y(t)) d t=c
$$

implies $c=y_{0}$. Thus


\begin{equation*}
y(x)=y_{0}+\int_{x_{0}}^{x} f(t, y(t)) d t \tag{2}
\end{equation*}


Conversely, if we start with (2), we can obtain (1). In other words, the integral equation (2) and the initial-value problem (1) are equivalent. We now try to solve (2) by a method of successive approximations.

Suppose $y_{0}(x)$ is an arbitrary continuous function that represents a guess or approximation to the solution of (2). Since $f\left(x, y_{0}(x)\right)$ is a known function depending solely on $x$, it can be integrated. With $y(t)$ replaced by $y_{0}(t)$, the righthand side of (2) defines another function, which we write as

$$
y_{1}(x)=y_{0}+\int_{x_{0}}^{x} f\left(t, y_{0}(t)\right) d t
$$

It is hoped that this new function is a better approximation to the solution. When we repeat the procedure, yet another function is given by

$$
y_{2}(x)=y_{0}+\int_{x_{0}}^{x} f\left(t, y_{1}(t)\right) d t
$$

In this manner we obtain a sequence of functions $y_{1}(x), y_{2}(x), y_{3}(x), \ldots$ whose $n$th term is defined by the relation


\begin{equation*}
y_{n}(x)=y_{0}+\int_{x_{0}}^{x} f\left(t, y_{n-1}(t)\right) d t, \quad n=1,2,3, \ldots \tag{3}
\end{equation*}


In the application of (3), it is common practice to choose the initial function as $y_{0}(x)=y_{0}$. The repetitive use of formula (3) is known as Picard's method of iteration.
\footnotetext{\begin{itemize}
  \item This section is an optional section.
\end{itemize}
}

\section*{EXAMPLE 1 Using Picard's Method}
Consider the problem $y^{\prime}=y-1, y(0)=2$. Use Picard's method to find the approximations $y_{1}, y_{2}, y_{3}, y_{4}$.

Solution If we identify $x_{0}=0, y_{0}(x)=2$, and $f\left(t, y_{n-1}(t)\right)=y_{n-1}(t)-1$, equation (3) becomes

$$
y_{n}(x)=2+\int_{0}^{x}\left(y_{n-1}(t)-1\right) d t, \quad n=1,2,3, \ldots
$$

Iterating this last expression then gives

$$
\begin{aligned}
y_{1}(x) & =2+\int_{0}^{x} 1 \cdot d t=2+x \\
y_{2}(x) & =2+\int_{0}^{x}(1+t) d t=2+x+\frac{x^{2}}{2} \\
y_{3}(x) & =2+\int_{0}^{x}\left(1+t+\frac{t^{2}}{2}\right) d t=2+x+\frac{x^{2}}{2}+\frac{x^{3}}{2 \cdot 3} \\
y_{4}(x) & =2+\int_{0}^{x}\left(1+t+\frac{t^{2}}{2}+\frac{t^{3}}{2 \cdot 3}\right) d t \\
& =2+x+\frac{x^{2}}{2}+\frac{x^{3}}{2 \cdot 3}+\frac{x^{4}}{2 \cdot 3 \cdot 4} .
\end{aligned}
$$

By induction it can be shown in Example 1 that the $n$th term of the sequence of approximations is

$$
y_{n}(x)=2+x+\frac{x^{2}}{2!}+\frac{x^{3}}{3!}+\cdots+\frac{x^{n}}{n!}=1+\sum_{k=0}^{n} \frac{x^{k}}{k!}
$$

From this latter form we recognize that the limit of $y_{n}(x)$ as $n \rightarrow \infty$ is $y(x)=1+e^{x}$. It should come as no surprise to note that the function is an exact solution of the given initial-value problem.

You should not be deceived by the relative ease with which the iterates $y_{n}(x)$ were obtained in the last example. In general, the integration involved in generating each $y_{n}(x)$ can become complicated very quickly. Nor, for that matter, is it always apparent that the sequence $\left\{y_{n}(x)\right\}$ converges to a nice explicit function. Thus it is fair to ask at this point: Is Picard's method a practical means of solving a first-order equation $y^{\prime}=f(x, y)$ subject to $y\left(x_{0}\right)=y_{0}$ ? In most cases the answer is no. One might ask further, in the spirit of a scientist/engineer: What is it good for? The answer is not bound to please: Picard's method of iteration is a theoretical tool used in the consideration of the existence and uniqueness of solutions of differential equations. Under certain conditions on $f(x, y)$ it can be shown that as $n \rightarrow \infty$, the sequence $\left\{y_{n}(x)\right\}$ defined by (3) converges to a function $y(x)$ that satisfies the integral equation (2) and hence the initial-value problem (1). Indeed, it is precisely Picard's method of successive approximations that is used in proving Picard's theorem of Section 2.1. However, the proof of Theorem 2.1 uses concepts from advanced calculus and is not presented here.

Our purpose in introducing this topic is twofold: for you to gain an appreciation for the potential of the procedure and obtain at least a nodding acquaintance with an iterative technique. In Chapter 9 we shall consider other methods for approximating solutions of differential equations that also utilize iteration.

\section*{EXERCISES 2.8}
\section*{Answers to odd-numbered problems begin on page A-4.}
In Problems 1-6 use Picard's method to find $y_{1}, y_{2}, y_{3}, y_{4}$. Determine the limit of the sequence $\left\{y_{n}(x)\right\}$ as $n \rightarrow \infty$.

\begin{enumerate}
  \item $y^{\prime}=-y, \quad y(0)=1$

  \item $y^{\prime}=x+y, \quad y(0)=1$

  \item $y^{\prime}=2 x y, \quad y(0)=1$

  \item $y^{\prime}+2 x y=x, \quad y(0)=0$

  \item $y^{\prime}+y^{2}=0, \quad y(0)=0$

  \item $y^{\prime}=2 e^{x}-y, \quad y(0)=1$

  \item (a) Use Picard's method to find $y_{1}, y_{2}, y_{3}$ for the problem

\end{enumerate}

$$
y^{\prime}=1+y^{2}, \quad y(0)=0
$$

(b) Solve the initial-value problem in part (a) by one of the methods of this chapter.

(c) Compare the results of parts (a) and (b).

\begin{enumerate}
  \setcounter{enumi}{7}
  \item In Picard's method the initial choice $y_{0}(x)=y_{0}$ is not necessary. Rework Problem 3 with (a) $y_{0}(x)=k$ a constant and $k \neq 1$ and (b) $y_{0}(x)=x$.
\end{enumerate}

\section*{CHAPTER 2 REVIEW}
An initial-value problem consists of finding a solution of

$$
\frac{d y}{d x}=f(x, y), \quad y\left(x_{0}\right)=y_{0}
$$

on an interval $I$ containing $x_{0}$. If $f(x, y)$ and $\partial f / \partial y$ are continuous in a rectangular region of the $x y$-plane with $\left(x_{0}, y_{0}\right)$ in its interior, then we are guaranteed that there exists an interval around $x_{0}$ on which the problem has a unique solution.

The method of solution for a first-order differential equation depends on an appropriate classification of the equation. We summarize five cases.

An equation is separable if it can be put into the form $h(y) d y=g(x) d x$. The solution results from integrating both sides of the equation.

If $M(x, y)$ and $N(x, y)$ are homogeneous functions of the same degree, then $M(x, y) d x+N(x, y) d y=0$ can be reduced to an equation with separable variables by either the substitution $y=u x$ or the substitution $x=v y$. The choice of substitution usually depends on which coefficient is simpler.

The differential equation $M(x, y) d x+N(x, y) d y=0$ is said to be exact if the form $M(x, y) d x+N(x, y) d y$ is an exact differential. When $M(x, y)$ and $N(x, y)$ are continuous and have continuous first partial derivatives, then $\partial M / \partial y$ $=\partial N / \partial x$ is a necessary and sufficient condition that $M(x, y) d x+N(x, y) d y$ be\\
exact. This means there exists some function $f(x, y)$ for which $M(x, y)=\partial f / \partial x$ and $N(x, y)=\partial f / \partial y$. The method of solution for an exact equation starts with integrating either of these latter expressions.

If a first-order equation can be put into the form $d y / d x+P(x) y=f(x)$, it is said to be linear in the variable $y$. We solve the equation by first finding the integrating factor $e^{\int P(x) d x}$, multiplying both sides of the equation by this factor, and then integrating both sides of

$$
\frac{d}{d x}\left[e^{\int P(x) d x} y\right]=e^{\int P(x) d x} f(x)
$$

Bernoulli's equation is $d y / d x+P(x) y=f(x) y^{n}$, where $n$ is any real number. When $n \neq 0$ and $n \neq 1$, Bernoulli's equation can be reduced to a linear equation by the substitution $w=y^{1-n}$.

In certain circumstances a differential equation can be reduced to one of the familiar forms by an appropriate substitution, or change, of variables. Of course we already know that this is the procedure when solving a homogeneous or a Bernoulli equation. In the general context, no rule on when to use a substitution can be given.

By converting an initial-value problem to an equivalent integral equation, Picard's method of iteration provides one way of obtaining an approximation to the solution of the problem.

\section*{CHAPTER 2 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-4.

Answer Problems 1-4 without referring back to the text. Fill in the blank or answer true or false.

\begin{enumerate}
  \item The differential equation $y^{\prime}=1 /\left(25-x^{2}-y^{2}\right)$ has a unique solution through any point $\left(x_{0}, y_{0}\right)$ in the region(s) defined by $\qquad$ .

  \item The initial-value problem $x y^{\prime}=3 y, y(0)=0$ has the solutions $y=x^{3}$ and $\qquad$ .

  \item The initial-value problem $y^{\prime}=y^{1 / 2}, y(0)=0$ has no solution since $\partial f / \partial y$ is discontinuous on the line $y=0$. $\qquad$

  \item There exists an interval centered at 2 on which the unique solution of the initial-value problem $y^{\prime}=(y-1)^{3}, y(2)=1$ is $y=1$. $\qquad$

  \item Without solving, classify each of the following equations as to whether it is separable, homogeneous, exact, linear, Bernoulli, Ricatti, or Clairaut.\\
(a) $\frac{d y}{d x}=\frac{1}{y-x}$\\
(b) $\frac{d y}{d x}=\frac{x-y}{x}$\\
(c) $\left(\frac{d y}{d x}\right)^{2}+2 y=2 x \frac{d y}{d x}$\\
(d) $\frac{d y}{d x}=\frac{1}{x(x-y)}$\\
(e) $\frac{d y}{d x}=\frac{y^{2}+y}{x^{2}+x}$\\
(f) $\frac{d y}{d x}=4+5 y+y^{2}$\\
(g) $y d x=\left(y-x y^{2}\right) d y$\\
(h) $x \frac{d y}{d x}=y e^{x / y}-x$\\
(i) $x y y^{\prime}+y^{2}=2 x$\\
(j) $2 x y y^{\prime}+y^{2}=2 x^{2}$\\
(k) $y d x+x d y=0$\\
(I) $\left(x^{2}+\frac{2 y}{x}\right) d x=\left(3-\ln x^{2}\right) d y$\\
(m) $\frac{d y}{d x}=\frac{x}{y}+\frac{y}{x}+1$\\
(n) $\frac{y}{x^{2}} \frac{d y}{d x}+e^{2 x^{3}+y^{2}}=0$\\
(o) $y=x y^{\prime}+\left(y^{\prime}-3\right)^{2}$\\
(p) $y^{\prime}+5 y^{2}=3 x^{4}-2 x y$

  \item Solve $\left(y^{2}+1\right) d x=y \sec ^{2} x d y$.

  \item Solve $\frac{y}{x} \frac{d y}{d x}=\frac{e^{x}}{\ln y}$ subject to $y(1)=1$.

  \item Solve $y(\ln x-\ln y) d x=(x \ln x-x \ln y-y) d y$.

  \item Solve $x y y^{\prime}=3 y^{2}+x^{2}$ subject to $y(-1)=2$.

  \item Solve $(6 x+1) y^{2} \frac{d y}{d x}+3 x^{2}+2 y^{3}=0$.

  \item Solve $y e^{x y} \frac{d x}{d y}+x e^{x y}=12 y^{2}$ subject to $y(0)=-1$.

  \item Solve $x d y+\left(x y+y-x^{2}-2 x\right) d x=0$.

  \item Solve $\left(x^{2}+4\right) \frac{d y}{d x}=2 x-8 x y$ subject to $y(0)=-1$.

  \item Solve $(2 x+y) y^{\prime}=1$.

  \item Solve $x \frac{d y}{d x}+4 y=x^{4} y^{2}$ subject to $y(1)=1$.

  \item Solve $-x y^{\prime}+y=\left(y^{\prime}+1\right)^{2}$ subject to $y(0)=0$.

\end{enumerate}

In Problems 17 and 18 solve the given differential equation by means of a substitution.\\
17. $\frac{d y}{d x}+x y^{3} \sec \frac{1}{y^{2}}=0$\\
18. $y^{\prime \prime}=x-y^{\prime}$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item Use the Picard method to find approximations $y_{\mathrm{I}}$ and $y_{2}$ for
\end{enumerate}

$$
y^{\prime}=x^{2}+y^{2}, \quad y(0)=1
$$

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Solve $y^{\prime}+2 y=4, y(0)=3$ by one of the usual methods. Solve the same problem by Picard's method and compare the results.
\end{enumerate}

\section*{APPLICATIONS OF FIRSTORDER DIFFERENTIAL EQUATIONS}
3.1 Orthogonal Trajectories

3.2 Applications of Linear Equations

3.3 Applications of Nonlinear Equations

Chapter 3 Review

Chapter 3 Review Exercises

In Section 1.2 we saw that a differential equation used to describe the behavior of some real-life system, whether physical, sociological, or even economic, is called a mathematical model. Mathematical models for phenomena, such as radioactive decay, population growth, chemical reactions, cooling of bodies, velocity of a falling body, rate of memorization, or current in a series circuit, are often first-order differential equations.

In this chapter we are concerned with solving some of the more commonly occurring linear and nonlinear first-order differential equations that arise in applications.

\section*{3. 1 ORTHOGONAL TRAJECTORIES \\
 - Differential equation of a family of curves \\
 - Orthogonal trajectories}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-097(1)}
\end{center}

Figure 3.1

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-097}
\end{center}

Figure 3.2\\
Differential Equation of a Family of Curves At the end of Section 1.1 we expressed the expectation or, better, the hope that an $n$ th-order ordinary differential will yield an $n$-parameter family of solutions. On the other hand, suppose we turn the problem around: Starting with an $n$-parameter family of curves, can we find an associated $n$ th-order differential equation that is entirely free of arbitrary parameters and represents the given family? In most cases the answer is yes.

In the discussion that follows we are interested in finding the differential equation $d y / d x=f(x, y)$ of a one-parameter family of curves.

\section*{EXAMPLE 1 DE of a Family of Curves}
Find the differential equation of the family $y=c_{1} x^{3}$.

Solution Differentiation gives

$$
\frac{d y}{d x}=3 c_{1} x^{2}
$$

We can eliminate the parameter $c_{1}$ from the equation by using $c_{1}=y / x^{3}$ obtained from the first equation:

$$
\frac{d y}{d x}=3\left(\frac{y}{x^{3}}\right) x^{2} \quad \text { or } \quad \frac{d y}{d x}=3 \frac{y}{x}
$$

Orthogonal Curves Recall from your study of analytic geometry that two lines $L_{1}$ and $L_{2}$, which are not parallel to the coordinate axes, are perpendicular if and only if their respective slopes satisfy the relationship $m_{1} m_{2}=-1$. For this reason, the graphs of $y=(-1 / 2) x+1$ and $y=2 x+4$ are obviously perpendicular. In general, two curves $\mathscr{C}_{1}$ and $\mathscr{C}_{2}$ are said to be orthogonal at a point if and only if their tangent lines $T_{1}$ and $T_{2}$ are perpendicular at the point of intersection. See Figure 3.1. Except for the case when $T_{1}$ and $T_{2}$ are parallel to the coordinate axes, this means the slopes of the tangents are negative reciprocals of each other.

\section*{EXAMPLE 2 Orthogonal Curves}
Show that the curves $\mathscr{C}_{1}$ and $\mathscr{C}_{2}$ defined by $y=x^{3}$ and $x^{2}+3 y^{2}=4$ are orthogonal at their point(s) of intersection.

Solution In Figure 3.2 it is seen that the points of intersection of the graphs are $(1,1)$ and $(-1,-1)$. Now the slope of the tangent line to $y=x^{3}$ at any point is $d y / d x=3 x^{2}$, so

$$
\left.\frac{d y}{d x}\right|_{x=1}=\left.\frac{d y}{d x}\right|_{x=-1}=3
$$

We use implicit differentiation to obtain $d y / d x$ for the second curve:

and therefore

$$
\begin{gathered}
2 x+6 y \frac{d y}{d x}=0 \quad \text { or } \quad \frac{d y}{d x}=-\frac{x}{3 y} \\
\left.\frac{d y}{d x}\right|_{(1,1)}=\left.\frac{d y}{d x}\right|_{(-1,-1)}=-\frac{1}{3}
\end{gathered}
$$

Thus, at either $(1,1)$ or $(-1,-1)$ we have

$$
\left(\frac{d y}{d x}\right)_{\mathscr{E}_{1}} \cdot\left(\frac{d y}{d x}\right)_{\mathscr{E}_{2}}=-1
$$

It is easy to show that any curve $\mathscr{C}_{1}$ in the family $y=c_{1} x^{3}, c_{1} \neq 0$ is orthogonal to each curve $\mathscr{C}_{2}$ in the family $x^{2}+3 y^{2}=c_{2}, c_{2}>0$. From Example 1 we know that the differential equation of the first family is

$$
\frac{d y}{d x}=3 \frac{y}{x}
$$

Implicit differentiation of $x^{2}+3 y^{2}=c_{2}$ leads to exactly the same differential equation as for $x^{2}+3 y^{2}=4$ in Example 2-namely,

$$
\frac{d y}{d x}=-\frac{x}{3 y}
$$

Hence, at the point $(x, y)$ on each curve,

$$
\left(\frac{d y}{d x}\right)_{\mathscr{Y}_{1}} \cdot\left(\frac{d y}{d x}\right)_{\mathscr{E}_{2}}=\left(\frac{3 y}{x}\right)\left(-\frac{x}{3 y}\right)=-1
$$

Since the slopes of the tangent lines are negative reciprocals, the curves $\mathscr{C}_{1}$ and $\mathscr{C}_{2}$ intersect each other in an orthogonal manner.

This discussion leads to the following definition.

\section*{DEFINITION 3.1 Orthogonal Trajectories}
When all the curves of one family of curves $G\left(x, y, c_{1}\right)=0$ intersect orthogonally all the curves of another family $H\left(x, y, c_{2}\right)=0$, then the families are said to be orthogonal trajectories of each other.

In other words, an orthogonal trajectory is any one curve that intersects every curve of another family at right angles.

\section*{EXAMPLE 3 Orthogonal Trajectories}
(a) The graph of $y=-\frac{1}{2} x+1$ is an orthogonal trajectory of $y=2 x+c_{1}$. The families $y=-\frac{1}{2} x+c_{2}$ and $y=2 x+c_{1}$ are orthogonal trajectories.

(b) The graph of $y=4 x^{3}$ is an orthogonal trajectory of $x^{2}+3 y^{2}=c_{2}$. The families $y=c_{1} x^{3}$ and $x^{2}+3 y^{2}=c_{2}$ are orthogonal trajectories.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-099(1)}
\end{center}

Figure 3.3

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-099}
\end{center}

Figure 3.4

(c) In Figure 3.3 it is seen that the family of straight lines $y=c_{1} x$ through the origin and the family $x^{2}+y^{2}=c_{2}$ of concentric circles with center at the origin are orthogonal trajectories.

Orthogonal trajectories occur naturally in the construction of meteorological maps and in the study of electricity and magnetism. For example, in an electric field around two bodies of opposite charge, the lines of force are perpendicular to the equipotential curves (that is, curves along which the potential is constant). The lines of force are indicated in Figure 3.4 by dashed lines.

General Method To find the orthogonal trajectories of a given family of curves we first find the differential equation

$$
\frac{d y}{d x}=f(x, y)
$$

that describes the family. The differential equation of the second, and orthogonal, family is then

$$
\frac{d y}{d x}=\frac{-1}{f(x, y)}
$$

\section*{EXAMPLE 4 Finding Orthogonal Trajectories}
Find the orthogonal trajectories of the family of rectangular hyperbolas

$$
y=\frac{c_{1}}{x}
$$

Solution The derivative of $y=c_{1} / x$ is

$$
\frac{d y}{d x}=\frac{-c_{1}}{x^{2}}
$$

Replacing $c_{1}$ by $c_{1}=x y$ yields the differential equation of the given family:

$$
\frac{d y}{d x}=-\frac{y}{x}
$$

The differential equation of the orthogonal family is then

$$
\frac{d y}{d x}=\frac{-1}{(-y / x)}=\frac{x}{y}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-099(2)}
\end{center}

Figure 3.5

We solve this last equation by separation of variables. From

$$
\begin{aligned}
y d y & =x d x \text { we get } \int y d y=\int x d x \\
\frac{y^{2}}{2} & =\frac{x^{2}}{2}+c_{2}^{\prime} \text { or } y^{2}-x^{2}=c_{2}
\end{aligned}
$$

where we replaced $2 c_{2}^{\prime}$ by $c_{2}$. We recognize that this solution represents another family of hyperbolas. The graphs of both families, for various values of $c_{1}$ and $c_{2}$, are given in Figure 3.5.

\section*{EXAMPLE 5 Finding Orthogonal Trajectories}
Find the orthogonal trajectories of $y=\frac{c_{1} x}{1+x}$.

Solution From the quotient rule we find

$$
\frac{d y}{d x}=\frac{c_{1}}{(1+x)^{2}} \quad \text { or } \quad \frac{d y}{d x}=\frac{y}{x(1+x)}
$$

since $c_{1}=y(1+x) / x$. The differential equation of the orthogonal trajectories is then

$$
\frac{d y}{d x}=-\frac{x(1+x)}{y}
$$

Again, by separating variables, we have

$$
\begin{aligned}
y d y & =-x(1+x) d x \quad \text { and } \int y d y=-\int\left(x+x^{2}\right) d x \\
\frac{y^{2}}{2} & =-\frac{x^{2}}{2}-\frac{x^{3}}{3}+c_{2}^{\prime} \quad \text { or } 3 y^{2}+3 x^{2}+2 x^{3}=c_{2}
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-100}
\end{center}

Figure 3.6

Polar Curves In calculus it is shown that for a graph of a polar equation $r=f(\theta)$,

$$
r \frac{d \theta}{d r}=\tan \psi
$$

where $\psi$ is the positive counterclockwise angle between the radial line and the tangent line. See Figure 3.6. It is left as an exercise to show that two polar curves $r=f_{1}(\theta)$ and $r=f_{2}(\theta)$ are orthogonal at a point of intersection if and only if


\begin{equation*}
\left(\tan \psi_{1}\right)_{\mathscr{ধ}_{1}}\left(\tan \psi_{2}\right)_{\mathscr{E}_{2}}=-1 \tag{1}
\end{equation*}


See Problem 42 .

\section*{EXAMPLE 6 Polar Orthogonal Trajectories}
Find the orthogonal trajectories of $r=c_{1}(1-\sin \theta)$.

Solution For the given curve we can write

so

$$
\begin{array}{r}
\frac{d r}{d \theta}=-c_{1} \cos \theta=\frac{-r \cos \theta}{1-\sin \theta} \\
r \frac{d \theta}{d r}=-\frac{1-\sin \theta}{\cos \theta}=\tan \psi_{1}
\end{array}
$$

Thus, by (1), the differential equation of the orthogonal trajectories is

$$
r \frac{d \theta}{d r}=\frac{\cos \theta}{1-\sin \theta}=\tan \psi_{2}
$$

Separating variables then gives

so

$$
\begin{aligned}
\frac{d r}{r} & =\frac{1-\sin \theta}{\cos \theta} d \theta=(\sec \theta-\tan \theta) d \theta \\
\ln |r| & =\ln |\sec \theta+\tan \theta|+\ln |\cos \theta|+\ln c_{2} \\
& =\ln \left|c_{2}(1+\sin \theta)\right| \\
r & =c_{2}(1+\sin \theta) .
\end{aligned}
$$

\section*{EXERCISES 3.1}
Answers to odd-numbered problems begin on page A-4.

In Problems 1-26 find the orthogonal trajectories of the given family of curves.

\begin{enumerate}
  \item $y=c_{1} x$

  \item $3 x+4 y=c_{1}$

  \item $y=c_{1} x^{2}$

  \item $y=\left(x-c_{1}\right)^{2}$

  \item $c_{1} x^{2}+y^{2}=1$

  \item $2 x^{2}+y^{2}=c_{1}^{2}$

  \item $y=c_{1} e^{-x}$

  \item $y=e^{c_{1} x}$

  \item $y^{2}=c_{1} x^{3}$

  \item $y^{a}=c_{1} x^{b}, \quad a$ and $b$ constants

  \item $y=\frac{x}{1+c_{1} x}$

  \item $y=\frac{1+c_{1} x}{1-c_{1} x}$

  \item $2 x^{2}+y^{2}=4 c_{1} x$

  \item $x^{2}+y^{2}=2 c_{1} x$

  \item $y^{3}+3 x^{2} y=c_{1}$

  \item $y^{2}-x^{2}=c_{1} x^{3}$

  \item $y=\frac{c_{1}}{1+x^{2}}$

  \item $y=\frac{1}{c_{1}+x}$

  \item $4 y+x^{2}+1+c_{1} e^{2 y}=0$

  \item $y=-x-1+c_{1} e^{x}$

  \item $y=\frac{1}{\ln c_{1} x}$

  \item $y=\ln \left(\tan x+c_{1}\right)$

  \item sinh $y=c_{1} x$

  \item $y=c_{1} \sin x$

  \item $x^{1 / 3}+y^{1 / 3}=c_{1}$

  \item $x^{a}+y^{a}=c_{1}, \quad a \neq 2$

  \item Find the member of the orthogonal trajectories for $x+y=c_{1} e^{y}$ that passes through $(0,5)$.

  \item Find the member of the orthogonal trajectories for $3 x y^{2}=2+3 c_{1} x$ that passes through $(0,10)$.

\end{enumerate}

In Problems 29-34 find the orthogonal trajectories of the given polar curves.\\
29. $r=2 c_{1} \cos \theta$\\
30. $r=c_{1}(1+\cos \theta)$\\
31. $r^{2}=c_{1} \sin 2 \theta$\\
32. $r=\frac{c_{1}}{1+\cos \theta}$\\
33. $r=c_{1} \sec \theta$\\
34. $r=c_{1} e^{\theta}$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item A family of curves that intersects a given family of curves at a specified constant angle $\alpha \neq \pi / 2$ is said to be an isogonal family. The two families are said to be isogonal trajectories of each other. If $d y / d x=f(x, y)$ is the differential equation of the given family, show that the differential equation of the isogonal family is
\end{enumerate}

$$
\frac{d y}{d x}=\frac{f(x, y) \pm \tan \alpha}{1 \mp f(x, y) \tan \alpha}
$$

In Problems 36-38 use the results of Problem 35 to find the isogonal family that intersects the one-parameter family of straight lines $y=c_{1} x$ at the given angle.\\
36. $\alpha=45^{\circ}$\\
37. $\alpha=60^{\circ}$\\
38. $\alpha=30^{\circ}$

A family of curves can be self-orthogonal in the sense that a member of the orthogonal trajectories is also a member of the original family. In Problems 39 and 40 show that the given family of curves is self-orthogonal.

\begin{enumerate}
  \setcounter{enumi}{38}
  \item parabolas $y^{2}=c_{1}\left(2 x+c_{1}\right)$

  \item confocal conics $\frac{x^{2}}{c_{1}+1}+\frac{y^{2}}{c_{1}}=1$

  \item Verify that the orthogonal trajectories of the family of curves given by the parametric equations $x=c_{1} e^{t} \cos t, y=c_{1} e^{t} \sin t$ are

\end{enumerate}

$$
x=c_{2} e^{-t} \cos t, \quad y=c_{2} e^{-t} \sin t
$$

[Hint: $d y / d x=(d y / d t) /(d x / d t)$.

\begin{enumerate}
  \setcounter{enumi}{41}
  \item Show that two polar curves $r=f_{1}(\theta)$ and $r=f_{2}(\theta)$ are orthogonal at a point of intersection if and only if
\end{enumerate}

$$
\left(\tan \psi_{1}\right)_{\mathscr{E}_{1}}\left(\tan \psi_{2}\right)_{\mathscr{G}_{2}}=-1
$$

\subsection*{3.2 APPLICATIONS OF LINEAR EQUATIONS \\
 - Exponcutial growth and decay - Half-life - Carbon dating $\cdot$ Response \\
 - Transient term - Steady-state term}
Growth and Decay The initial-value problem


\begin{equation*}
\frac{d x}{d t}=k x, \quad x\left(t_{0}\right)=x_{0} \tag{1}
\end{equation*}


where $k$ is a constant of proportionality, occurs in many physical theories involving either growth or decay. For example, in biology it is often observed that the rate at which certain bacteria grow is proportional to the number of bacteria present at time $t$. Over short intervals of time, the population of small animals, such as rodents, can be predicted fairly accurately by the solution of (1). In physics an initial-value problem such as (1) provides a model for approximating the remaining amount of a substance that is disintegrating, or decaying, through radioactivity. The differential equation in (1) could also determine the temperature of a cooling body. In chemistry the amount of a substance remaining during certain reactions is also described by (1).

The constant of proportionality $k$ in (1) is either positive or negative and can be determined from the solution of the problem using a subsequent measurement of $x$ at a time $t_{1}>t_{0}$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-103}
\end{center}

Figure 3.7

\section*{EXAMPLE 1 Bacterial Growth}
A culture initially has $N_{0}$ number of bacteria. At $t=1$ hour the number of bacteria is measured to be $\frac{3}{2} N_{0}$. If the rate of growth is proportional to the number of bacteria present, determine the time necessary for the number of bacteria to triple.

Solution We first solve the differential equation


\begin{equation*}
\frac{d N}{d t}=k N \tag{2}
\end{equation*}


subject to $N(0)=N_{0}$. Then we use the empirical condition $N(1)=\frac{3}{2} N_{0}$ to determine the constant of proportionality $k$.

Now (2) is both separable and linear. When it is put into the form

$$
\frac{d N}{d t}-k N=0
$$

we can see by inspection that the integrating factor is $e^{-k t}$. Multiplying both sides of the equation by this term gives immediately

$$
\frac{d}{d t}\left[e^{-k t} N\right]=0
$$

Integrating both sides of the last equation yields

$$
e^{-k t} N=c \quad \text { or } \quad N(t)=c e^{k t}
$$

At $t=0$ it follows that $N_{0}=c e^{0}=c$ and so $N(t)=N_{0} e^{k t}$. At $t=1$ we have

$$
\frac{3}{2} N_{0}=N_{0} e^{k} \quad \text { or } \quad e^{k}=\frac{3}{2}
$$

from which we get, to four decimal places, $k=\ln \frac{3}{2}=0.4055$. Thus

$$
N(t)=N_{0} e^{0.4055 t} .
$$

To find the time at which the bacteria have tripled we solve

$$
3 N_{0}=N_{0} e^{0.4055 t}
$$

for $t$. It follows from this equation that $0.4055 t=\ln 3$ and so

$$
t=\frac{\ln 3}{0.4055} \approx 2.71 \text { hours. }
$$

\section*{See Figure 3.7.}
Note We can write the function $N(t)$ obtained in Example 1 in an alternative form. From the laws of exponents,

$$
N(t)=N_{0}\left(e^{k}\right)^{t}=N_{0}\left(\frac{3}{2}\right)^{t}
$$

since $e^{k}=\frac{3}{2}$. This latter solution provides a convenient method for computing $N(t)$ for small positive integral values of $t$. It also clearly shows the influence of the subsequent experimental observation at $t=1$ on the solution for all time.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-104}
\end{center}

Figure 3.8

We notice, too, that the actual number of bacteria present at time $t=0$ is quite irrelevant in finding the time required to triple the number in the culture. The necessary time to triple, say, 100 or 10,000 bacteria is still approximately 2.71 hours.

As shown in Figure 3.8, the exponential function $e^{k t}$ increases as $t$ increases for $k>0$, and decreases as $t$ increases for $k<0$. Thus problems describing growth, such as population, bacteria, or even capital, are characterized by a positive value of $k$, whereas problems involving decay, as in radioactive disintegration, yield a negative $k$ value.

Half-Life In physics the half-life is a measure of the stability of a radioactive substance. The half-life is simply the time it takes for one-half of the atoms in an initial amount $A_{0}$ to disintegrate, or transmute, into the atoms of another element. The longer the half-life of a substance, the more stable it is. For example, the half-life of highly radioactive radium, Ra-226, is about 1700 years. In 1700 years one-half of a given quantity of Ra-226 is transmuted into radon, Rn222. The most commonly occurring uranium isotope, U-238, has a half-life of approximately $4,500,000,000$ years. In about 4.5 billion years, one-half of a quantity of $\mathrm{U}-238$ is transmuted into lead, $\mathrm{Pb}-206$.

\section*{EXAMPLE 2 Half-Life of a Radioactive Substance}
A breeder reactor converts the relatively stable uranium 238 into the isotope plutonium 239. After 15 years it is determined that $0.043 \%$ of the initial amount $A_{0}$ of the plutonium has disintegrated. Find the half-life of this isotope if the rate of disintegration is proportional to the amount remaining at time $t$.

Solution Let $A(t)$ denote the amount of plutonium remaining at time $t$. As in Example 1, the solution of the initial-value problem

$$
\frac{d A}{d t}=k A, \quad A(0)=A_{0}
$$

is $A(t)=A_{0} e^{k t}$. If $0.043 \%$ of the atoms of $A_{0}$ have disintegrated, then $99.957 \%$ of the substance remains. To find $k$ we use $0.99957 A_{0}=A(15)$; that is,

$$
0.99957 A_{0}=A_{0} e^{15 k}
$$

Solving for $k$ then gives $k=\frac{1}{15} \ln (0.99957)=-0.00002867$. Hence

$$
A(t)=A_{0} e^{-0.00002867 t}
$$

Now the half-life is the corresponding value of time for which $A(t)=\frac{1}{2} A_{0}$. Solving

$$
\frac{A_{0}}{2}=A_{0} e^{-0.00002867 t} \text { or } \frac{1}{2}=e^{-0.00002867 t}
$$

for $t$ gives $-0.00002867 t=\ln \frac{1}{2}=-\ln 2$ or

$$
t=\frac{\ln 2}{0.00002867} \approx 24,180 \text { years. }
$$

Carbon Dating About 1950 the chemist Willard Libby devised a method of using radioactive carbon as a means of determining the approximate ages of fossils. The theory of carbon dating is based on the fact that the isotope carbon 14 is produced in the atmosphere by the action of cosmic radiation on nitrogen. The ratio of the amount of C -14 to ordinary carbon in the atmosphere appears to be a constant, and as a consequence the proportionate amount of the isotope present in all living organisms is the same as that in the atmosphere. When an organism dies, the absorption of C-14, by either breathing or eating, ceases. Thus, by comparing the proportionate amount of C-14 present, say, in a fossil with the constant ratio found in the atmosphere, it is possible to obtain a reasonable estimation of its age. The method is based on the knowledge that the half-life of the radioactive C-14 is approximately 5600 years. For his work Libby won the Nobel Prize for chemistry in 1960. Libby's method has been used to date wooden furniture in Egyptian tombs and the woven flax wrappings of the Dead Sea scrolls.

\section*{EXAMPLE 3 Age of a Fossil}
A fossilized bone is found to contain $\frac{1}{1000}$ the original amount of C-14. Determine the age of the fossil.

Solution The starting point is again $A(t)=A_{0} e^{k t}$. To determine the value of $k$ we use the fact that $\frac{1}{2} A_{0}=A(5600)$ or $\frac{1}{2} A_{0}=A_{0} e^{5600 k}$. Hence we have $5600 k=\ln \frac{1}{2}$ or $k=\frac{-1}{5600} \ln 2=-0.00012378$. Therefore

$$
A(t)=A_{0} e^{-0.00012378 t}
$$

When $A(t)=\frac{1}{1000} A_{0}$, we have $\frac{1}{1000} A_{0}=A_{0} e^{-0.00012378 t}$. Solving the last equation for $t$ then yields

$$
t=\frac{\ln 1000}{0.00012378} \approx 55,800 \text { years }
$$

The date found in Example 3 is really at the border of accuracy for this method. The usual carbon 14 technique is limited to about 9 half-lives of the isotope, or about 50,000 years. One reason is that the chemical analysis needed to obtain an accurate measurement of the remaining $\mathrm{C}-14$ becomes somewhat formidable around the point of $A_{0} / 1000$. Also, this analysis demands the destruction of a rather large sample of the specimen. If this measurement is accomplished indirectly, based on the actual radioactivity of the specimen, then it is very difficult to distinguish between the radiation from the fossil and the normal background radiation. But in recent developments, the use of a particle accelerator has enabled scientists to separate the $\mathrm{C}-14$ from the stable $\mathrm{C}-12$ directly. By computing the precise value of the ratio of C-14 to C-12, the accuracy of this method can be extended to $70,000-100,000$ years. Other isotopic techniques such as using potassium 40 and argon 40 can give dates of several million years. Nonisotopic methods based on the use of amino acids are also sometimes possible.

Cooling Newton's law of cooling states that the rate at which the temperature $T(t)$ changes in a cooling body is proportional to the difference between the

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-106(1)}
\end{center}

(a)

\begin{center}
\begin{tabular}{cc}
\hline
$\boldsymbol{T}(\boldsymbol{t})$ & $\boldsymbol{t}$ (minutes) \\
\hline
$75^{\circ}$ & 20.1 \\
$74^{\circ}$ & 21.3 \\
$73^{\circ}$ & 22.8 \\
$72^{\circ}$ & 24.9 \\
$71^{\circ}$ & 28.6 \\
$70.5^{\circ}$ & 32.3 \\
\hline
\end{tabular}
\end{center}

(b)

Figure 3.9

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-106}
\end{center}

Figure 3.10 $L-R$ series circuit temperature in the body and the constant temperature $T_{\mathrm{m}}$ of the surrounding medium-that is,


\begin{equation*}
\frac{d T}{d t}=k\left(T-T_{\mathrm{m}}\right) \tag{3}
\end{equation*}


where $k$ is a constant of proportionality.

\section*{EXAMPLE 4 Newton's Law of Cooling}
When a cake is removed from a baking oven, its temperature is measured at $300^{\circ} \mathrm{F}$. Three minutes later its temperature is $200^{\circ} \mathrm{F}$. How long will it take to cool off to a room temperature of $70^{\circ} \mathrm{F}$ ?

Solution In (3) we make the identification $T_{\mathrm{m}}=70$. We must then solve the initial-value problem


\begin{equation*}
\frac{d T}{d t}=k(T-70), \quad T(0)=300 \tag{4}
\end{equation*}


and determine the value of $k$ so that $T(3)=200$.

Equation (4) is both linear and separable. Separating variables, we find that

$$
\begin{array}{lll}
\frac{d T}{T-70}=k d t & \text { yields } & \ln |T-70|=k t+c_{1} \\
T-70=c_{2} e^{k t} & \text { or } & T=70+c_{2} e^{k t}
\end{array}
$$

When $t=0, T=300$, so $300=70+c_{2}$ gives $c_{2}=230$ and therefore $T=70+230 e^{k t}$.

From $T(3)=200$ we find that $e^{3 k}=\frac{13}{23}$ or $k=\frac{1}{3} \ln \frac{13}{23}=-0.19018$. Thus


\begin{equation*}
T(t)=70+230 e^{-0.19018 t} \tag{5}
\end{equation*}


We note that (5) furnishes no finite solution to $T(t)=70$ since $\lim _{t \rightarrow \infty} T(t)=70$. Yet intuitively we expect the cake to reach the room temperature after a reasonably long period of time. How long is long? Of course, we should not be disturbed by the fact that the model (4) does not quite live up to our physical intuition. Parts (a) and (b) of Figure 3.9 clearly show that the cake will be approximately at room temperature in about one-half hour.

Series Circuits In a series circuit containing only a resistor and an inductor, Kirchhoff's second law states that the sum of the voltage drop across the inductor $(L(d i / d t))$ and the voltage drop across the resistor $(i R)$ is the same as the impressed voltage $(E(t))$ on the circuit. See Figure 3.10.

Thus we obtain the linear differential equation for the current $i(t)$,


\begin{equation*}
L \frac{d i}{d t}+R i=E(t) \tag{6}
\end{equation*}


where $L$ and $R$ are constants known as the inductance and the resistance, respectively. The current $i(t)$ is sometimes called the response of the system.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-107}
\end{center}

Figure 3.11 $R-C$ series circuit\\
The voltage drop across a capacitor with capacitance $C$ is given by $q(t) / C$, where $q$ is the charge on the capacitor. Hence, for the series circuit shown in Figure 3.11, Kirchhoff's second law gives


\begin{equation*}
R i+\frac{1}{C} q=E(t) \tag{7}
\end{equation*}


But current $i$ and charge $q$ are related by $i=d q / d t$, so (7) becomes the linear differential equation


\begin{equation*}
R \frac{d q}{d t}+\frac{1}{C} q=E(t) \tag{8}
\end{equation*}


\section*{EXAMPLE 5 Current in a Series Circuit}
A 12-volt battery is connected to a series circuit in which the inductance is $\frac{1}{2}$ henry and the resistance is 10 ohms. Determine the current $i$ if the initial current is zero.

Solution From (6) we see that we must solve

$$
\frac{1}{2} \frac{d i}{d t}+10 i=12
$$

subject to $i(0)=0$. First, we multiply the differential equation by 2 and read off the integrating factor $e^{20 t}$. We then obtain

$$
\begin{aligned}
\frac{d}{d t}\left[e^{20 t} i\right] & =24 e^{20 t} \\
e^{20 t} i & =\frac{24}{20} e^{20 t}+c \quad \text { or } \quad i=\frac{6}{5}+c e^{-20 t}
\end{aligned}
$$

Now $i(0)=0$ implies $0=\frac{6}{5}+c$ or $c=-\frac{6}{5}$. Therefore the response is

$$
i(t)=\frac{6}{5}-\frac{6}{5} e^{-20 t}
$$

From (7) of Section 2.5 we can write a general solution of (6):


\begin{equation*}
i(t)=\frac{e^{-(R / L) t}}{L} \int e^{(R / L) t} E(t) d t+c e^{-(R / L) t} \tag{9}
\end{equation*}


In particular, when $E(t)=E_{0}$ is a constant, (9) becomes


\begin{equation*}
i(t)=\frac{E_{0}}{R}+c e^{-(R / L) t} \tag{10}
\end{equation*}


Note that as $t \rightarrow \infty$, the second term in equation (10) approaches zero. Such a term is usually called a transient term; any remaining terms are called the steady-state part of the solution. In this case $E_{0} / R$ is also called the steadystate current; for large values of time it then appears that the current in the circuit is simply governed by Ohm's law $(E=i R)$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-108(1)}
\end{center}

Figure 3.12

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-108}
\end{center}

(a)

\begin{center}
\begin{tabular}{cc}
\hline
$\boldsymbol{t}$ (minutes) & $\boldsymbol{A}(\mathbf{l b})$ \\
\hline
50 & 266.41 \\
100 & 397.67 \\
150 & 477.27 \\
200 & 525.57 \\
300 & 572.62 \\
400 & 589.93 \\
\hline
\end{tabular}
\end{center}

(b)

Figure 3.13\\
Mixture Problem The mixing of two fluids sometimes gives rise to a linear first-order differential equation. In the next example we consider the mixture of two salt solutions with different concentrations.

\section*{BXAMPLE 6 Mixture of Two Salt Solutions}
Initially 50 pounds of salt is dissolved in a large tank holding 300 gallons of water. A brine solution is pumped into the tank at a rate of 3 gallons per minute, and the well-stirred solution is then pumped out at the same rate. See Figure 3.12. If the concentration of the solution entering is 2 pounds per gallon, determine the amount of salt in the tank at time $t$. How much salt is present after 50 minutes? after a long time?

Solution Let $A(t)$ be the amount of salt (in pounds) in the tank at any time. For problems of this sort, the net rate at which $A(t)$ changes is given by


\begin{equation*}
\frac{d A}{d t}=\binom{\text { rate of }}{\text { substance entering }}-\binom{\text { rate of }}{\text { substance leaving }}=R_{1}-R_{2} \tag{11}
\end{equation*}


Now the rate at which the salt enters the tank is, in pounds per minute,

$$
R_{1}=(3 \mathrm{gal} / \mathrm{min}) \cdot(2 \mathrm{lb} / \mathrm{gal})=6 \mathrm{lb} / \mathrm{min}
$$

whereas the rate at which salt is leaving is

$$
R_{2}=(3 \mathrm{gal} / \mathrm{min}) \cdot\left(\frac{A}{300} \mathrm{lb} / \mathrm{gal}\right)=\frac{A}{100} \mathrm{lb} / \mathrm{min}
$$

Thus equation (11) becomes


\begin{equation*}
\frac{d A}{d t}=6-\frac{A}{100} \tag{12}
\end{equation*}


which we solve subject to the initial condition $A(0)=50$.

Since the integrating factor is $e^{t / 100}$, we can write (12) as

$$
\frac{d}{d t}\left[e^{t / 100} A\right]=6 e^{t / 100}
$$

and therefore


\begin{equation*}
e^{t / 100} A=600 e^{t / 100}+c \quad \text { or } \quad A=600+c e^{-t / 100} \tag{13}
\end{equation*}


When $t=0, A=50$, so we find that $c=-550$. Finally, we obtain


\begin{equation*}
A(t)=600-550 e^{-t / 100} \tag{14}
\end{equation*}


At $t=50$ we find that $A(50)=266.41$ pounds. Also, as $t \rightarrow \infty$ it is seen from (14) and Figure 3.13 that $A \rightarrow 600$. Of course this is what we would expect; over a long period of time the number of pounds of salt in the solution must be

$$
(300 \mathrm{gal})(2 \mathrm{lb} / \mathrm{gal})=600 \mathrm{lb}
$$

In Example 6 we assumed that the rate at which the solution was pumped in was the same as the rate at which the solution was pumped out. However, this need not be the case; the mixed brine solution could be pumped out at a rate\\
faster or slower than the rate at which the other solution is pumped in. The resulting differential equation in this latter situation is linear with a variable coefficient.

\section*{EXAMPLE 7 Mixture of Two Salt Solutions}
If the well-stirred solution in Example 6 is pumped out at a slower rate of 2 gallons per minute, then the solution is accumulating at a rate of

$$
(3-2) \mathrm{gal} / \mathrm{min}=1 \mathrm{gal} / \mathrm{min}
$$

After $t$ minutes there are $300+t$ gallons of brine in the tank. The rate at which the salt is leaving is then

$$
R_{2}=(2 \mathrm{gal} / \mathrm{min}) \cdot\left(\frac{A}{300+t} \mathrm{lb} / \mathrm{gal}\right)=\frac{2 A}{300+t} \mathrm{lb} / \mathrm{min}
$$

Hence equation (11) becomes

$$
\frac{d A}{d t}=6-\frac{2 A}{300+t} \text { or } \frac{d A}{d t}+\frac{2 A}{300+t}=6
$$

Finding the integrating factor and solving the last equation, we get

$$
A(t)=2(300+t)+c(300+t)^{-2}
$$

The initial condition $A(0)=50$ yields $c=-4.95 \times 10^{7}$ and so

$$
A(t)=2(300+t)-\left(4.95 \times 10^{7}\right)(300+t)^{-2}
$$

Remarks Consider the differential equation in Example 1 that describes the growth of bacteria. The solution $N(t)=N_{0} e^{0.4055 t}$ of the initial-value problem $d N / d t=k N, N\left(t_{0}\right)=N_{0}$ is of course a continuous function. But in the example we are talking about a population of bacteria and so common sense dictates that $N$ take on only positive integer values. Moreover, the population does not necessarily grow continuously (that is, every second, every microsecond, and so on), as predicted by the function $N(t)=N_{0} e^{0.4055 t} ;$ there may be time intervals $\left[t_{1}, t_{2}\right]$ over which there is no growth at all. Perhaps, then, the graph shown in Figure 3.14(a) gives a more

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-109(2)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-109}
\end{center}

(b)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-109(1)}
\end{center}

(c)

Figure 3.14\\
realistic description of $N$ than that given by the graph of an exponential function. The point is that in many instances a mathematical model describes a system in only approximate terms. It is often more convenient than accurate to use a continuous function to describe a discrete phenomenon. However, for some purposes we may be satisfied if our model describes the system fairly accurately when viewed macroscopically in time as in Figures 3.14(b) and (c) rather than microscopically.

\section*{EXERCISES 3.2}
\section*{Answers to odd-numbered problems begin on page A-5.}
\begin{enumerate}
  \item The population of a certain community is known to increase at a rate proportional to the number of people present at time $t$. If the population has doubled in 5 years, how long will it take to triple? to quadruple?

  \item Suppose it is known that the population of the community in Problem 1 is 10,000 after 3 years. What was the initial population? What will be the population in 10 years?

  \item The population of a town grows at a rate proportional to the population at time $t$. Its initial population of 500 increases by $15 \%$ in 10 years. What will be the population in 30 years?

  \item The population of bacteria in a culture grows at a rate proportional to the number of bacteria present at time $t$. After 3 hours it is observed that there are 400 bacteria present. After 10 bours there are 2000 bacteria present. What is the initial number of bacteria?

  \item The radioactive isotope of lead, $\mathrm{Pb}-209$, decays at a rate proportional to the amount present at time $t$ and has a half-life of 3.3 hours. If 1 gram of lead is present initially, how long will it take for $90 \%$ of the lead to decay?

  \item Initially there were 100 milligrams of a radioactive substance present. After 6 hours the mass had decreased by $3 \%$. If the rate of decay is proportional to the amount of the substance present at time $t$, find the amount remaining after 24 hours.

  \item Determine the half-life of the radioactive substance described in Problem 6.

  \item Show that the half-life of a radioactive substance is, in general,

\end{enumerate}

$$
t=\frac{\left(t_{2}-t_{1}\right) \ln 2}{\ln \left(A_{1} / A_{2}\right)}
$$

where $A_{1}=A\left(t_{1}\right)$ and $A_{2}=A\left(t_{2}\right), t_{1}<t_{2}$.

\begin{enumerate}
  \setcounter{enumi}{8}
  \item When a vertical beam of light passes through a transparent substance, the rate at which its intensity $I$ decreases is proportional to $I(t)$, where $t$ represents the thickness of the medium (in feet). In clear seawater the intensity 3 feet below the surface is $25 \%$ of the initial intensity $I_{0}$ of the incident beam. What is the intensity of the beam 15 feet below the surface?

  \item When interest is compounded continuously, the amount of money $S$ increases at a rate proportional to the amount present at time $t: d S / d t=r S$, where $r$ is the annual rate of interest (see (26) of Section 1.2).\\
(a) Find the amount of money accrued at the end of 5 years when $\$ 5000$ is deposited in a savings account drawing $5 \frac{3}{4} \%$ annual interest compounded continuously.

\end{enumerate}

(b) In how many years will the initial sum deposited be doubled?

(c) Use a hand calculator to compare the number obtained in part (a) with the value

$$
S=5000\left(1+\frac{0.0575}{4}\right)^{5(4)}
$$

This value represents the amount accrued when interest is compounded quarterly.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item In a piece of burned wood, or charcoal, it was found that $85.5 \%$ of the C-14 had decayed. Use the information in Example 3 to determine the approximate age of the wood. (It is precisely these data that archaeologists used to date prehistoric paintings in a cave in Lascaux, France.)

  \item A thermometer is taken from an inside room to the outside where the air temperature is $5^{\circ} \mathrm{F}$. After 1 minute the thermometer reads $55^{\circ} \mathrm{F}$, and after 5 minutes the reading is $30^{\circ} \mathrm{F}$. What was the initial temperature of the room?

  \item A thermometer is removed from a room where the air temperature is $70^{\circ} \mathrm{F}$ to the outside where the temperature is $10^{\circ} \mathrm{F}$. After $\frac{1}{2}$ minute the thermometer reads $50^{\circ} \mathrm{F}$. What is the reading at $t=1$ minute? How long will it take for the thermometer to reach $15^{\circ} \mathrm{F}$ ?

  \item Formula (3) also holds when an object absorbs heat from the surrounding medium. If a small metal bar whose initial temperature is $20^{\circ} \mathrm{C}$ is dropped into a container of boiling water, how long will it take for the bar to reach $90^{\circ} \mathrm{C}$ if it is known that its temperature increased $2^{\circ}$ in 1 second? How long will it take the bar to reach $98^{\circ} \mathrm{C}$ ?

  \item A 30 -volt electromotive force is applied to an $L-R$ series circuit in which the inductance is 0.1 henry and the resistance is 50 ohms. Find the current $i(t)$ if $i(0)=0$. Determine the current as $t \rightarrow \infty$.

  \item Solve equation (6) under the assumption that $E(t)=E_{0} \sin \omega t$ and $i(0)=i_{0}$.

  \item A 100 -volt electromotive force is applied to an $R-C$ series circuit in which the resistance is 200 ohms and the capacitance is $10^{-4}$ farad. Find the charge $q(t)$ on the capacitor if $q(0)=0$. Find the current $i(t)$.

  \item A 200 -volt electromotive force is applied to an $R-C$ series circuit in which the resistance is 1000 ohms and the capacitance is $5 \times 10^{-6}$ farad. Find the charge $q(t)$ on the capacitor if $i(0)=0.4$. Determine the charge and current at $t=0.005$ second. Determine the charge as $t \rightarrow \infty$.

  \item An electromotive force

\end{enumerate}

$$
E(t)=\left\{\begin{array}{rr}
120, & 0 \leq t \leq 20 \\
0, & t>20
\end{array}\right.
$$

is applied to an $L-R$ series circuit in which the inductance is 20 henry and the resistance is 2 ohms. Find the current $i(t)$ if $i(0)=0$.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Suppose an $R$ - $C$ series circuit has a variable resistor. If the resistance at time $t$ is given by $R=k_{1}+k_{2} t$, where $k_{1}>0$ and $k_{2}>0$ are known constants, then (8) becomes
\end{enumerate}

$$
\left(k_{1}+k_{2} t\right) \frac{d q}{d t}+\frac{1}{C} q=E(t)
$$

Show that if $E(t)=E_{0}$ and $q(0)=q_{0}$, then

$$
q(t)=E_{0} C+\left(q_{0}-E_{0} C\right)\left(\frac{k_{1}}{k_{1}+k_{2} t}\right)^{1 / C k_{2}}
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item A tank contains 200 liters of fluid in which 30 g of salt is dissolved. Brine containing 1 g of salt per liter is then pumped into the tank at a rate of 4 liters per minute; the well-mixed solution is pumped out at the same rate. Find the number of grams of salt $A(t)$ in the tank at time $t$.

  \item Solve Problem 21 assuming pure water is pumped into the tank.

  \item A large tank is filled with 500 gallons of pure water. Brine containing 2 lb of salt per gallon is pumped into the tank at a rate of 5 gallons per minute. The well-mixed solution is pumped out at the same rate. Find the number of pounds of salt $A(t)$ in the tank at time $t$.

  \item Solve Problem 23 under the assumption that the solution is pumped out at a faster rate of 10 gallons per minute. When is the tank empty?

  \item A large tank is partially filled with 100 gallons of fluid in which 10 lb of salt is dissolved. Brine containing $\frac{1}{2} \mathrm{lb}$ of salt per gallon is pumped into the tank at a rate of 6 gallons per minute. The well-mixed solution is then pumped out at a slower rate of 4 gallons per minute. Find the number of pounds of salt in the tank after 30 minutes.

  \item Beer containing $6 \%$ alcohol per gallon is pumped into a vat that initially contains 400 gallons of beer at $3 \%$ alcohol. The rate at which the beer is pumped in is 3 gallons per minute, whereas the mixed liquid is pumped out at a rate of 4 gallons per minute. Find the number of gallons of alcohol $A(t)$ in the tank at time $t$. What is the percentage of alcohol in the tank after 60 minutes? When is the tank empty?

\end{enumerate}

\section*{Miscellaneous Applications}
\begin{enumerate}
  \setcounter{enumi}{26}
  \item The differential equation governing the velocity $v$ of a falling mass $m$ subjected to air resistance proportional to the instantaneous velocity is
\end{enumerate}

$$
m \frac{d v}{d t}=m g-k v
$$

where $k$ is a positive constant of proportionality.

(a) Solve the equation subject to the initial condition $v(0)=v_{0}$.

(b) Determine the limiting, or terminal, velocity of the weight.

(c) If distance $s$ is related to velocity $d s / d t=v$, find an explicit expression for $s$ if it is further known that $s(0)=s_{0}$.

\begin{enumerate}
  \setcounter{enumi}{27}
  \item The rate at which a drug disseminates into the bloodstream is governed by the differential equation
\end{enumerate}

$$
\frac{d X}{d t}=A-B X
$$

where $A$ and $B$ are positive constants. The function $X(t)$ describes the concentration of the drug in the bloodstream at time $t$. Find the limiting

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-113}
\end{center}

Figure 3.15

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-113(1)}
\end{center}

Figure 3.16

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-113(2)}
\end{center}

Figure 3.17 value of $X$ as $t \rightarrow \infty$. At what time is the concentration one-half this limiting value? Assume that $X(0)=0$.

\begin{enumerate}
  \setcounter{enumi}{28}
  \item A heart pacemaker, as shown in Figure 3.15, consists of a battery, a capacitor, and the heart as a resistor. When the switch $S$ is at $P$ the capacitor charges; when $S$ is at $Q$ the capacitor discharges, sending an electrical stimulus to the heart. During this time the voltage $E$ applied to the heart is given by
\end{enumerate}

$$
\frac{d E}{d t}=-\frac{1}{R C} E, \quad t_{1}<t<t_{2}
$$

where $R$ and $C$ are constants. Determine $E(t)$ if $E\left(t_{1}\right)=E_{0}$. (Of course, the opening and closing of the switch are periodic in time, to simulate the natural heartbeat.)

\begin{enumerate}
  \setcounter{enumi}{29}
  \item Suppose a cell is suspended in a solution containing a solute of constant concentration $C_{s}$. Suppose further that the cell has constant volume $V$ and that the area of its permeable membrane is the constant $A$. By Fick's law the rate of change of its mass $m$ is directly proportional to the area $A$ and the difference $C_{s}-C(t)$, where $C(t)$ is the concentration of the solute inside the cell at time $t$. Find $C(t)$ if $m=V C(t)$ and $C(0)=C_{0}$. See Figure 3.16.

  \item In one model of the changing population $P(t)$ of a community, it is assumed that

\end{enumerate}

$$
\frac{d P}{d t}=\frac{d B}{d t}-\frac{d D}{d t}
$$

where $d B / d t$ and $d D / d t$ are the birth and death rates, respectively.

(a) Solve for $P(t)$ if

$$
\frac{d B}{d t}=k_{1} P \quad \text { and } \quad \frac{d D}{d t}=k_{2} P \text {. }
$$

(b) Analyze the cases $k_{1}>k_{2}, k_{1}=k_{2}$, and $k_{1}<k_{2}$.

\begin{enumerate}
  \setcounter{enumi}{31}
  \item The differential equation
\end{enumerate}

$$
\frac{d P}{d t}=(k \cos t) P
$$

where $k$ is a positive constant, is often used as a model of a population that undergoes yearly seasonal fluctuations. Solve for $P(t)$ and graph the solution. Assume $P(0)=P_{0}$.

\begin{enumerate}
  \setcounter{enumi}{32}
  \item In polar coordinates the angular momentum of a moving body of mass $m$ is defined to be $L=m r^{2}(d \theta / d t)$. Assume that the coordinates of the body are $\left(r_{1}, \theta_{1}\right)$ and $\left(r_{2}, \theta_{2}\right)$ at times $t=a$ and $t=b, a<b$, respectively. If $L$ is constant, show that the area $A$ swept out by $r$ is $A=L(b-a) / 2 m$. When the sun is taken to be at the origin, this proves Kepler's second law of planetary motion: The radius vector joining the sun sweeps out equal areas in equal intervals of time. See Figure 3.17.

  \item When forgetfulness is taken into account, the rate of memorization of a subject is given by

\end{enumerate}

$$
\frac{d A}{d t}=k_{1}(M-A)-k_{2} A
$$

where $k_{1}>0, k_{2}>0, A(t)$ is the amount of material memorized in time $t, M$ is the total amount to be memorized, and $M-A$ is the amount remaining to be memorized. Solve for $A(t)$ and graph the solution. Assume $A(0)=0$. Find the limiting value of $A$ as $t \rightarrow \infty$ and interpret the result.

\subsection*{3.3 APPLICATIONS OF NONLINEAR EQUATIONS \\
 - Logistic equation - Chemical reactions - Escape velocity}
We have seen that if a population $P$ is described by


\begin{equation*}
\frac{d P}{d t}=k P, \quad k>0 \tag{1}
\end{equation*}


then $P(t)$ exhibits unbounded exponential growth. In many instances this differential equation provides an unrealistic model of the growth of a population; that is, what is actually observed differs substantially from what is predicted.

Around 1840 the Belgian mathematician-biologist P. F. Verhulst was concerned with mathematical formulations for predicting the human populations of various countries. One of the equations he studied was


\begin{equation*}
\frac{d l^{\prime}}{d!}=l^{\prime}\left(d \cdot b P^{\prime}\right), \tag{2}
\end{equation*}


where $a$ and $b$ are positive constants. Equation (2) came to be known as the logistic equation, and its solution is called the logistic function (the graph of which is naturally called a logistic curve).

Equation (1) does not provide a very accurate model for population growth when the population itself is very large. Overcrowded conditions with the resulting detrimental effects on the environment, such as pollution and excessive and competitive demands for food and fuel, can have an inhibitive effect on the population growth. If $a, a>0$ is a constant average birth rate, let us assume that the average death rate is proportional to the population $P(t)$ at time $t$. Thus, if $(1 / P)(d P / d t)$ is the rate of growth per individual in a population, then


\begin{equation*}
\frac{1}{P} \frac{d P}{d t}=\binom{\text { average }}{\text { birth rate }}-\binom{\text { average }}{\text { death rate }}=a-b P \tag{3}
\end{equation*}


where $b$ is a positive constant of proportionality. Cross multiplying (3) by $P$ immediately gives (2).

As we shall now see, the solution of (2) is bounded as $t \rightarrow \infty$. If we rewrite (2) as $d P / d t=a P-b P^{2}$, the term $-b P^{2}, b>0$ can be interpreted as an "inhibition" or "competition" term. Also, in most applications, the positive constant $a$ is much larger than the constant $b$.

Logistic curves have proved to be quite accurate in predicting the growth patterns, in a limited space, of certain types of bacteria, protozoa, water fleas (Daphnia), and fruit flies (Drosophila). We have already seen equation (2) in the form $d x / d t=k x(n+1-x), k>0$. This differential equation provides a reasonable model for describing the spread of an epidemic brought about by initially introducing an infected individual into a static population. The solution

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-115}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-115(1)}
\end{center}

(b)

$x(t)$ represents the number of individuals infected with the disease at time $t$ (see

Figure 3.18 Example 11, Section 1.2). Sociologists and even business analysts have borrowed this latter model to study the spread of information and the impact of advertising in certain centers of population.

Solution One method for solving equation (2) is separation of variables.* By using partial fractions, we can write

$$
\frac{d P}{P(a-b P)}=d t \quad \text { as } \quad\left(\frac{1 / a}{P}+\frac{b / a}{a-b P}\right) d P=d t
$$

Integrating, we get


\begin{gather*}
\frac{1}{a} \ln |P|-\frac{1}{a} \ln |a-b P|=t+c \quad \text { or } \quad \ln \left|\frac{P}{a-b P}\right|=a t+a c \\
\frac{P}{a-b P}=c_{1} e^{a t} . \tag{4}
\end{gather*}


It follows from the last equation that


\begin{equation*}
P(t)=\frac{a c_{1} e^{a t}}{1+b c_{1} e^{a t}}=\frac{a c_{1}}{b c_{1}+e^{-a t}} \tag{5}
\end{equation*}


Now if we are given the initial condition $P(0)=P_{0}, P_{0} \neq a / b,{ }^{\dagger}$ equation (4) implies $c_{1}=P_{0} /\left(a-b P_{0}\right)$. Substituting this value in (5) and simplifying then gives


\begin{equation*}
P(t)=\frac{a P_{0}}{b P_{0}+\left(a-b P_{0}\right) e^{-a t}} \tag{6}
\end{equation*}


Graphs of $P(t) \quad$ The basic shape of the graph of the logistic function $P(t)$ can be obtained without too much effort. Although the variable $t$ usually represents time and we are seldom concerned with applications in which $t<0$, it is nonetheless of some interest to include this interval when displaying the various graphs of $P$. From (6) we see that

$$
P(t) \rightarrow \frac{a P_{0}}{b P_{0}}=\frac{a}{b} \text { as } t \rightarrow \infty \quad \text { and } \quad P(t) \rightarrow 0 \text { as } t \rightarrow-\infty
$$

Now differentiating (2) by the product rule gives


\begin{align*}
\frac{d^{2} P}{d t^{2}} & =P\left(-b \frac{d P}{d t}\right)+(a-b P) \frac{d P}{d t} \\
& =\frac{d P}{d t}(a-2 b P) \\
& =P(a-b P)(a-2 b P) \\
& =2 b^{2} P\left(P-\frac{a}{b}\right)\left(P-\frac{a}{2 b}\right) \tag{7}
\end{align*}


From calculus recall that the points where $d^{2} P / d t^{2}=0$ are possible points of inflection, but $P=0$ and $P=a / b$ can obviously be ruled out. Hence $P=a / 2 b$
\footnotetext{\begin{itemize}
  \item In the form $d P / d t-a P=-b P^{2}$ you might recognize the logistic equation as a special case of Bernoulli's equation (see Section 2.6).
\end{itemize}

$\dagger$ Notice that $P=a / b$ is a singular solution of equation (2).
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-116}
\end{center}

Figure 3.19

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-116(1)}
\end{center}

(a)

\begin{center}
\begin{tabular}{cc}
\hline
(days) & $\boldsymbol{x}$ (number infected) \\
\hline
 &  \\
4 & 50 (observed) \\
5 & 124 \\
6 & 276 \\
7 & 507 \\
8 & 735 \\
9 & 882 \\
10 & 953 \\
\hline
\end{tabular}
\end{center}

(b)

Figure 3.20

is the only possible ordinate value at which the concavity of the graph can change. For $0<P<a / 2 b$ it follows from (7) that $P^{\prime \prime}>0$, and $a / 2 b<P<a / b$ implies $P^{\prime \prime}<0$. Thus, as we read from left to right, the graph changes from concave up to concave down at the point corresponding to $P=a / 2 b$. When the initial value satisfies $0<P_{0}<a / 2 b$, the graph of $P(t)$ assumes the shape of an S , as we see in Figure 3.18(a). For $a / 2 b<P_{0}<a / b$ the graph is still S-shaped but the point of inflection occurs at a negative value of $t$, as shown in Figure 3.18(b).

If $P_{0}>a / b$, equation (7) shows that $P^{\prime \prime}>0$ for all $t$ in the domain of $P(t)$ for which $P>0$. When $P<0$, equation (7) implies $P^{\prime \prime}<0$. However, $P=0$ is not a point of inflection since, whenever $a-b P_{0}<0$, an inspection of (6) reveals a vertical asymptote at

$$
t=-\frac{1}{a} \ln \left(\frac{b P_{0}}{b P_{0}-a}\right)
$$

The graph of $P(t)$ in this case is given in Figure 3.19.

\section*{EXAMPLE 1 Spread of a Flu Virus}
Suppose a student carrying a flu virus returns to an isolated college campus of 1000 students. If it is assumed that the rate at which the virus spreads is proportional not only to the number $x$ of infected students but also to the number of students not infected, determine the number of infected students after 6 days if it is further observed that after 4 days $x(4)=50$.

Solution Assuming that no one leaves the campus throughout the duration of the disease, we must solve the initial-value problem

$$
\frac{d x}{d t}=k x(1000-x), \quad x(0)=1
$$

By making the identifications $a=1000 k$ and $b=k$, we have immediately from (6) that


\begin{equation*}
x(t)=\frac{1000 k}{k+999 k e^{-1000 k t}}=\frac{1000}{1+999 e^{-1000 k t}} \tag{8}
\end{equation*}


Now, using the information $x(4)=50$, we determine $k$ from

$$
50=\frac{1000}{1+999 e^{-4000 k}}
$$

We find that $k=\frac{-1}{4000} \ln \frac{19}{999}=0.0009906$. Thus (8) becomes

$$
x(t)=\frac{1000}{1+999 e^{-0.9906 t}}
$$

Finally,

$$
x(6)=\frac{1000}{1+999 e^{-5.9436}}=276 \text { students. }
$$

Additional calculated values of $x(t)$ are given in the table in Figure 3.20.

Gompertz Curves A modification of the logistic equation is


\begin{equation*}
\frac{d P}{d t}=P(a-b \ln P) \tag{9}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-117}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-117(1)}
\end{center}

(b)

Figure 3.21

where $a$ and $b$ are constants. It is readily shown by separation of variables (see Problem 5) that a solution of (9) is


\begin{equation*}
P(t)=e^{a / b} e^{-c e^{-b t}} \tag{10}
\end{equation*}


where $c$ is an arbitrary constant. We note that when $b>0, P \rightarrow e^{a / b}$ as $t \rightarrow \infty$, whereas for $b<0, c>0, P \rightarrow 0$ as $t \rightarrow \infty$. The graph of the function (10), called a Gompertz curve, is quite similar to the graph of the logistic function. Figure 3.21 shows two possibilities for the graph of $P(t)$.

Functions such as (10) are encountered, for example, in studies of the growth or decline of certain populations, in the growth of solid tumors, in actuarial predictions, and in the study of growth of revenue in the sale of a commercial product.

Chemical Reactions The disintegration of a radioactive substance, governed by equation (1) of the preceding section, is said to be a first-order reaction. In chemistry a few reactions follow the same empirical law: If the molecules of a substance $A$ decompose into smaller molecules, it is a natural assumption that the rate at which this decomposition takes place is proportional to the amount of the first substance that has not undergone conversion; that is, if $X(t)$ is the amount of substance $A$ remaining at time $t$, then

$$
\frac{d X}{d t}=k X
$$

where $k$ is negative, since $X$ is decreasing. An example of a first-order chemical reaction is the conversion of $t$-butyl chloride into $t$-butyl alcohol:

$$
\left(\mathrm{CH}_{3}\right)_{3} \mathrm{CCl}+\mathrm{NaOH} \rightarrow\left(\mathrm{CH}_{3}\right)_{3} \mathrm{COH}+\mathrm{NaCl}
$$

Only the concentration of the $t$-butyl chloride controls the rate of reaction.

Now in the reaction

$$
\mathrm{CH}_{3} \mathrm{Cl}+\mathrm{NaOH} \rightarrow \mathrm{CH}_{3} \mathrm{OH}+\mathrm{NaCl}
$$

for every molecule of methyl chloride one molecule of sodium hydroxide is consumed, thus forming one molecule of methyl alcohol and one molecule of sodium chloride. In this case the rate at which the reaction proceeds is proportional to the product of the remaining concentrations of $\mathrm{CH}_{3} \mathrm{Cl}$ and of NaOH . If $X$ denotes the amount of $\mathrm{CH}_{3} \mathrm{OH}$ formed and $\alpha$ and $\beta$ are the given amounts of the first two chemicals $A$ and $B$, then the instantaneous amounts not converted to chemical $C$ are $\alpha-X$ and $\beta-X$, respectively. Hence the rate of formation of $C$ is given by


\begin{equation*}
\frac{d X}{d t}=k(\alpha-X)(\beta-X) \tag{11}
\end{equation*}


where $k$ is a constant of proportionality. A reaction described by equation (11) is said to be of second-order.

\section*{EXAMPLE 2 Second-Order Chemical Reaction}
A compound $C$ is formed when two chemicals $A$ and $B$ are combined. The resulting reaction between the two chemicals is such that for each gram of $A$, 4 grams of $B$ are used. It is observed that 30 grams of the compound $C$ are

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-118}
\end{center}

(a)

\begin{center}
\begin{tabular}{cl}
\hline
$\boldsymbol{t}$ (minutes) & \multicolumn{1}{c}{(grams)} \\
\hline
 &  \\
10 & 30 (measured) \\
15 & 34.78 \\
20 & 37.25 \\
25 & 38.54 \\
30 & 39.22 \\
35 & 39.59 \\
\hline
\end{tabular}
\end{center}

(b) formed in 10 minutes. Determine the amount of $C$ at any time if the rate of the reaction is proportional to the amounts of $A$ and $B$ remaining and if initially there are 50 grams of $A$ and 32 grams of $B$. How much of the compound $C$ is present at 15 minutes? Interpret the solution as $t \rightarrow \infty$.

Solution Let $X(t)$ denote the number of grams of the compound $C$ present at time $t$. Clearly $X(0)=0$ and $X(10)=30$.

Now for example, if there are 2 grams of compound $C$, we must have used, say, $a$ grams of $A$ and $b$ grams of $B$ so

$$
a+b=2 \text { and } \quad b=4 a
$$

Thus we must use $a=\frac{2}{5}=2 \frac{1}{5}$ grams of chemical $A$ and $b=\frac{8}{5}=2 \frac{4}{5}$ grams of $B$. In general, for $X$ grams of $C$ we must use

$$
\frac{X}{5} \text { grams of } A \text { and } \quad \frac{4}{5} X \text { grams of } B
$$

The amounts of $A$ and $B$ remaining at time $t$ are then

$$
50-\frac{X}{5} \text { and } \quad 32-\frac{4}{5} X
$$

respectively.

Now we know that the rate at which chemical $C$ is formed satisfies

$$
\frac{d X}{d t} \propto\left(50-\frac{X}{5}\right)\left(32-\frac{4}{5} X\right)
$$

To simplify the subsequent algebra, we factor $\frac{1}{5}$ from the first term and $\frac{4}{5}$ from the second, and then introduce the constant of proportionality:

$$
\frac{d X}{d t}=k(250-X)(40-X)
$$

By separation of variables and partial fractions, we can write


\begin{align*}
\frac{d X}{(250-X)(40-X)} & =k d t \\
-\frac{1 / 210}{250-X} d X+\frac{1 / 210}{40-X} d X & =k d t \\
\ln \left|\frac{250-X}{40-X}\right| & =210 k t+c_{1} \\
\frac{250-X}{40-X} & =c_{2} e^{210 k t} \tag{12}
\end{align*}


When $t=0, X=0$, so it follows at this point that $c_{2}=\frac{25}{4}$. Using $X=30$ at $t=10$, we find that $210 k=\frac{1}{10} \ln \frac{88}{25}=0.1258$. With this information we solve (12) for $X$ :


\begin{equation*}
X(t)=1000 \frac{1-e^{-0.1258 t}}{25-4 e^{-0.1258 t}} \tag{13}
\end{equation*}


The behavior of $X$ as a function of time is displayed in Figure 3.22. It is clear from the accompanying table and equation (13) that $X \rightarrow 40$ as $t \rightarrow \infty$. This means there are 40 grams of compound $C$ formed, leaving

$50-\frac{1}{5}(40)=42 \mathrm{~g}$ of chemical $A$ and $\quad 32-\frac{4}{5}(40)=0 \mathrm{~g}$ of chemical $B$.

Law of Mass Action The preceding example can be generalized in the following manner. Suppose that $a$ grams of substance $A$ are combined with $b$ grams of substance $B$. If there are $M$ parts of $A$ and $N$ parts of $B$ formed in the compound, then the amounts of substances $A$ and $B$ remaining at time $t$ are, respectively,

Thus


\begin{align*}
& a-\frac{M}{M+N} X \text { and } b-\frac{N}{M+N} X \\
& \frac{d X}{d t} \propto\left[a-\frac{M}{M+N} X\right]\left[b-\frac{N}{M+N} X\right] \tag{14}
\end{align*}


Proceeding as before, if we factor out $M /(M+N)$ from the first term and $N /(M+N)$ from the second term, the resulting differential equation is the same as (11):

where


\begin{gather*}
\frac{d X}{d t}=k(\alpha-X)(\beta-X)  \tag{15}\\
\alpha=\frac{a(M+N)}{M} \text { and } \beta=\frac{b(M+N)}{N}
\end{gather*}


Chemists refer to reactions described by equation (15) as the law of mass action.

When $\alpha \neq \beta$, it is readily shown (see Problem 9) that a solution of (15) is


\begin{equation*}
\frac{1}{\alpha-\beta} \ln \left|\frac{\alpha-X}{\beta-X}\right|=k t+c \tag{16}
\end{equation*}


When we assume the natural initial condition $X(0)=0$, equation (16) yields the explicit solution


\begin{equation*}
X(t)=\frac{\alpha \beta\left[1-e^{(\alpha-\beta) k t}\right]}{\beta-\alpha e^{(\alpha-\beta) k t}} \tag{17}
\end{equation*}


Without loss of generality we assume in (17) that $\beta>\alpha$ or $\alpha-\beta<0$. Since $X(t)$ is an increasing function, we expect $k>0$, and so it follows immediately from (17) that $X \rightarrow \alpha$ as $t \rightarrow \infty$.

Escape Velocity In Example 1 of Section 1.2 we saw that the differential equation of a free-falling object of mass $m$ near the surface of the earth is given by

$$
m \frac{d^{2} s}{d t^{2}}=-m g \quad \text { or simply } \quad \frac{d^{2} s}{d t^{2}}=-g
$$

where $s$ represents the distance from the surface of the earth to the object and the positive direction is considered to be upward. In other words, the underlying assumption here is that the distance $s$ to the object is small when compared with the radius $R$ of the earth; put yet another way, the distance $y$ from the center of the earth to the object is approximately the same as $R$. If, on the other hand, the distance $y$ to an object, such as a rocket or a space probe, is large compared to $R$, then we combine Newton's second law of motion and his universal law of gravitation to derive a differential equation in the variable $y$. The solution of this differential equation can be used to determine the minimum velocity, the so-called escape velocity, needed by a rocket to break free of the earth's gravitational attraction.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-120}
\end{center}

Figure 3.23

\section*{EXAMPLE 3 Velocity of a Rocket}
A rocket is shot vertically upward from the ground as shown in Figure 3.23. If the positive direction is upward and air resistance is ignored, then the differential equation of motion after fuel burnout is


\begin{equation*}
m \frac{d^{2} y}{d t^{2}}=-k \frac{m M}{y^{2}} \quad \text { or } \quad \frac{d^{2} y}{d t^{2}}=-k \frac{M}{y^{2}} \tag{18}
\end{equation*}


where $k$ is a constant of proportionality, $y$ is the distance from the center of the earth to the rocket, $M$ is the mass of the earth, and $m$ is the mass of the rocket. To determine the constant $k$, we use the fact that, when $y=R$,

$$
k \frac{m M}{R^{2}}=m g \quad \text { or } \quad k=\frac{g R^{2}}{M}
$$

Thus the last equation in (18) becomes


\begin{equation*}
\frac{d^{2} y}{d t^{2}}=-g \frac{R^{2}}{y^{2}} \tag{19}
\end{equation*}


Although this is not a first-order equation, if we write the acceleration as

$$
\frac{d^{2} y}{d t^{2}}=\frac{d v}{d t}=\frac{d v}{d y} \frac{d y}{d t}=v \frac{d v}{d y}
$$

then (19) becomes first-order in $v$; that is,

$$
v \frac{d v}{d y}=-g \frac{R^{2}}{y^{2}}
$$

This last equation can be solved by separation of variables. From


\begin{equation*}
\int v d v=-g R^{2} \int y^{-2} d y \quad \text { we get } \quad \frac{v^{2}}{2}=g \frac{R^{2}}{y}+c \tag{20}
\end{equation*}


If we assume that the velocity is $v=v_{0}$ at burnout and that $y \approx R$ at that instant, we can obtain the (approximate) value of $c$. From (20) we find $c=-g R+v_{0}^{2} / 2$. Substituting this value in (20) and multiplying the resulting equation by 2 yields


\begin{equation*}
v^{2}=2 g \frac{R^{2}}{y}-2 g R+v_{0}^{2} \tag{21}
\end{equation*}


You might object, correctly, that in Example 3 we have not really solved the original equation for $y$. Actually the solution (21) gives quite a bit of information. Now that we have done the hard part, we leave the actual determination of the escape velocity from the earth as an exercise. See Problem 11.

\section*{EXERCISES 3.3}
Answers to odd-numbered problems begin on page A-5.

\begin{enumerate}
  \item The number of supermarkets $C(t)$ throughout the country that are using a computerized checkout system is described by the initial-value problem
\end{enumerate}

$$
\frac{d C}{d t}=C(1-0.0005 C), \quad C(0)=1
$$

where $t>0$. How many supermarkets are using the computerized method when $t=10$ ? How many companies are estimated to adopt the new procedure over a long period of time?

\begin{enumerate}
  \setcounter{enumi}{1}
  \item The number of people $N(t)$ in a community who are exposed to a particular advertisement is governed by the logistic equation. Initially $N(0)=500$, and it is observed that $N(1)=1000$. If it is predicted that the limiting number of people in the community who will see the advertisement is 50,000 , determine $N(t)$ at time $t$.

  \item The population $P(t)$ at time $t$ in a suburb of a large city is governed by the initial-value problem

\end{enumerate}

$$
\frac{d P}{d t}=P\left(10^{-1}-10^{-7} P\right), \quad P(0)=5000
$$

where $t$ is measured in months. What is the limiting value of the population? At what time will the population be equal to one-half of this limiting value?

\begin{enumerate}
  \setcounter{enumi}{3}
  \item Find a solution of the modified logistic equation
\end{enumerate}

$$
\frac{d P}{d t}=P(a-b P)\left(1-c P^{-1}\right), \quad a, b, c>0
$$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item (a) Solve equation (9).
\end{enumerate}

(b) Determine the value of $c$ in equation (10) if $P(0)=P_{0}$.

\begin{enumerate}
  \setcounter{enumi}{5}
  \item Assuming $0<P_{0}<e^{a / b}$ and $a>0$, use equation (9) to find the ordinate of the point of inflection for a Gompertz curve.

  \item Two chemicals $A$ and $B$ are combined to form a chemical $C$. The rate or velocity of the reaction is proportional to the product of the instantaneous amounts of $A$ and $B$ not converted to chemical $C$. Initially there are 40 grams of $A$ and 50 grams of $B$, and for each gram of $B, 2$ grams of $A$ are used. It is observed that 10 grams of $C$ are formed in 5 minutes. How much is formed in 20 minutes? What is the limiting amount of $C$ after a long time? How much of chemicals $A$ and $B$ remains after a long time?

  \item Solve Problem 7 if 100 grams of chemical $A$ are present initially. At what time is chemical $C$ half-formed?

  \item Obtain a solution of the equation

\end{enumerate}

$$
\frac{d X}{d t}=k(\alpha-X)(\beta-X)
$$

governing second-order reactions in the two cases $\alpha \neq \beta$ and $\alpha=\beta$.

\begin{enumerate}
  \setcounter{enumi}{9}
  \item In a third-order chemical reaction the number of grams $X$ of a compound obtained by combining three chemicals is governed by
\end{enumerate}

$$
\frac{d X}{d t}=k(\alpha-X)(\beta-X)(\gamma-X)
$$

Solve the equation under the assumption $\alpha \neq \beta \neq \gamma$.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item (a) Use equation (21) to show that the escape velocity of the rocket is given by $v_{0}=\sqrt{2 g R}$. [Hint: Take $y \rightarrow \infty$ in (21) and assume $v>0$ for all times $t$.]\\
(b) The result in part (a) holds for any body in the solar system. Use the values $g=32 \mathrm{ft} / \mathrm{s}^{2}$ and $R=4000$ miles to show that the escape velocity from the earth is (approximately) $v_{0}=25,000 \mathrm{mi} / \mathrm{h}$.
\end{enumerate}

(c) Find the escape velocity from the moon if the acceleration of gravity is 0.165 g and $R=1080$ miles.

\section*{Miscellaneous Applications}
\begin{enumerate}
  \setcounter{enumi}{11}
  \item In Example 7 of Section 1.2 we saw that the differential equation describing the shape of a wire of constant linear density $w$ hanging under its own weight is
\end{enumerate}

$$
\frac{d^{2} y}{d x^{2}}=\frac{w}{T_{1}} \sqrt{1+\left(\frac{d y}{d x}\right)^{2}}
$$

where $T_{1}$ is the horizontal tension in the wire at its lowest point. Using the substitution $p=d y / d x$, solve this equation subject to the initial conditions $y(0)=1, y^{\prime}(0)=0$.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item An equation similar to that given in Problem 12 is
\end{enumerate}

$$
x \frac{d^{2} y}{d x^{2}}=\frac{v_{1}}{v_{2}} \sqrt{1+\left(\frac{d y}{d x}\right)^{2}}
$$

In this case the equation arises in the study of the shape of the path that a pursuer, traveling at a speed $v_{2}$, must take in order to intercept a prey traveling at speed $v_{1}$. Use the same substitution as in Problem 12 and the initial conditions $y(1)=0, y^{\prime}(1)=0$ to solve the equation. Consider the two cases $v_{1}=v_{2}$ and $v_{1} \neq v_{2}$.

\begin{enumerate}
  \setcounter{enumi}{13}
  \item According to Stefan's law of radiation, the rate of change of temperature from a body at absolute temperature $T$ is
\end{enumerate}

$$
\frac{d T}{d t}=k\left(T^{4}-T_{\mathrm{m}}^{4}\right)
$$

where $T_{\mathrm{m}}$ is the absolute temperature of the surrounding medium. Find a solution of this differential equation. It can be shown that when $T-T_{\mathrm{m}}$ is small compared to $T_{\mathrm{m}}$, this particular equation is closely approximated by Newton's law of cooling (Equation (3), Section 3.2).

\begin{enumerate}
  \setcounter{enumi}{14}
  \item The height $h$ of water that is flowing through an orifice at the bottom of a cylindrical tank is given by
\end{enumerate}

$$
\frac{d h}{d t}=-\frac{A_{\mathrm{o}}}{A_{\mathrm{w}}} \sqrt{2 g h}, \quad g=32 \mathrm{ft} / \mathrm{s}^{2}
$$

where $A_{\mathrm{w}}$ and $A_{\mathrm{o}}$ are the cross-sectional areas of the water and orifice, respectively (see Example 8, Section 1.2). Solve the equation if the initial height of the water is 20 ft and $A_{\mathrm{w}}=50 \mathrm{ft}^{2}$ and $A_{\mathrm{o}}=\frac{1}{4} \mathrm{ft}^{2}$. At what time is the tank empty?

\begin{enumerate}
  \setcounter{enumi}{15}
  \item The nonlinear differential equation
\end{enumerate}

$$
\left(\frac{d r}{d t}\right)^{2}=\frac{2 \mu}{r}+2 h
$$

where $\mu$ and $h$ are nonnegative constants, arises in the study of the twobody problem of celestial mechanics. Here the variable $r$ represents the distance between the two masses. Solve the equation in the two cases $h=0$ and $h>0$.

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Solve the differential equation of the tractrix
\end{enumerate}

$$
\frac{d y}{d x}=-\frac{y}{\sqrt{s^{2}-y^{2}}}
$$

(see Problem 19, Exercises 1.2). Assume that the initial point on the $y$-axis is $(0,10)$ and the length of rope is $s=10 \mathrm{ft}$.

\begin{enumerate}
  \setcounter{enumi}{17}
  \item A body of mass $m$ falling through a viscous medium encounters a resisting force proportional to the square of its instantaneous velocity. In this situation the differential equation for the velocity $v(t)$ at time $t$ is
\end{enumerate}

$$
m \frac{d v}{d t}=m g-k v^{2}
$$

where $k$ is a positive constant of proportionality. Solve the equation subject to $v(0)=v_{0}$. What is the limiting velocity of the falling body?

\begin{enumerate}
  \setcounter{enumi}{18}
  \item The differential equation
\end{enumerate}

$$
x\left(\frac{d x}{d y}\right)^{2}+2 y \frac{d x}{d y}=x
$$

where $x=x(y)$, occurs in the study of optics. The equation describes the type of plane curve that will reflect all incoming light rays to the same point (see Problem 15, Exercises 1.2). Show that the curve must be a parabola. [Hint: Use the substitution $w=x^{2}$ and then re-examine Section 2.6.]

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Solve the equation in Problem 19 with the aid of the quadratic formula.

  \item The equations of Lotka and Volterra*

\end{enumerate}

$$
\begin{aligned}
& \frac{d y}{d t}=y(\alpha-\beta x) \\
& \frac{d x}{d t}=x(-\gamma+\delta y)
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item A. J. LOTKA (1880-1949) Lotka, born in Austria, was an American biomathematician.
\end{itemize}

VITO VOLTERRA (1860-1940) Born in Ancona, Italy, Vito Volterra showed an early aptitude for mathematics. He studied calculus on his own initiative and investigated problems in gravitation at the age of twelve. Although his education was a constant financial struggle, Volterra quickly attained prominence as a scientist and mathematician. He was also an active politician and was appointed Senator of the Kingdom of Italy in 1905. Volterra became interested in the applications of mathematics to ecology in the mid-1920s and formulated this system of differential equations in an attempt to explain the variations in the fish population in the Mediterranean as a result of predator-prey interactions. (Lotka, working independently, arrived at the same system of equations and published the result in 1925 in his text Elements of Physical Biology.) Through his research into mathematical models of population, Volterra established the groundwork for a field of mathematics known as integral equations. A man of principle, Volterra refused to sign a loyalty oath to the fascist regime of Benito Mussolini and eventually resigned his chair of mathematics at the University of Rome and all his memberships in Italian scientific societies.
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-124}
\end{center}

Figure 3.24 where $\alpha, \beta, \gamma$, and $\delta$ are positive constants, occur in the analysis of the biological balance of two species of animals such as predators and prey (for example, foxes and rabbits). Here $x(t)$ and $y(t)$ denote the populations of the two species at time $t$. Although no explicit solutions of the system exist, solutions can be found relating the two populations at any time. Divide the first equation by the second and solve the resulting nonlinear first-order differential equation.

\begin{enumerate}
  \setcounter{enumi}{21}
  \item A classical problem in the calculus of variations is to find the shape of a curve $\mathscr{C}$ such that a bead, under the influence of gravity, will slide from $A(0,0)$ to $B\left(x_{1}, y_{1}\right)$ in the least time. See Figure 3.24. It can be shown that the differential equation for the shape of the path is $y\left[1+\left(y^{\prime}\right)^{2}\right]=k$, where $k$ is a constant. First solve for $d x$ in terms of $y$ and $d y$, and then use the substitution $y=k \sin ^{2} \theta$ to obtain the parametric form of the solution. The curve $\mathscr{C}$ turns out to be a cycloid.

  \item The initial-value problem describing the motion of a simple pendulum released from rest from an angle $\theta_{0}>0$ is

\end{enumerate}

$$
\frac{d^{2} \theta}{d t^{2}}+\frac{g}{l} \sin \theta=0, \quad \theta(0)=\theta_{0},\left.\quad \frac{d \theta}{d t}\right|_{t=0}=0
$$

(a) Obtain the first-order equation

$$
\left(\frac{d \theta}{d t}\right)^{2}=\frac{2 g}{l}\left(\cos \theta-\cos \theta_{0}\right)
$$

[Hint: Multiply the given equation by $2 d \theta / d t$.]

(b) Use the equation in part (a) to show that the period of motion is

$$
T=2 \sqrt{\frac{2 l}{g}} \int_{0}^{\theta_{0}} \frac{d \theta}{\sqrt{\cos \theta-\cos \theta_{0}}}
$$

\section*{CHAPTER 3 REVIEW}
If every curve in a one-parameter family of curves $G\left(x, y, c_{1}\right)=0$ is orthogonal to every curve in a second one-parameter family $H\left(x, y, c_{2}\right)=0$, we say that the two families are orthogonal trajectories. Two curves are orthogonal if their tangent lines are perpendicular at a point of intersection. When given a family, we find its differential equation $d y / d x=f(x, y)$ by differentiating the equation $G\left(x, y, c_{1}\right)=0$ and eliminating the parameter $c_{1}$. The differential equation of the second and orthogonal family is then $d y / d x=-1 / f(x, y)$. We solve this latter equation by the methods of Chapter 2 .

In the mathematical analysis of population growth, radioactive decay, or chemical mixtures, we often encounter linear differential equations such as

$$
\frac{d x}{d t}=k x \quad \text { and } \quad \frac{d x}{d t}=a+b x
$$

or nonlinear differential equations such as

$$
\frac{d x}{d t}=x(a-b x) \quad \text { and } \quad \frac{d x}{d t}=k(\alpha-x)(\beta-x)
$$

You should be able to solve these particular equations without hesitation. It is never a good idea simply to memorize solutions of differential equations.

\section*{CHAPTER 3 REVIEW EXERCISES}
\section*{Answers to odd-numbered problems begin on page A-6.}
\begin{enumerate}
  \item Find the orthogonal trajectories of the family of curves $y\left(x^{3}+c_{1}\right)=3$.

  \item Find the orthogonal trajectory to the family $y=4 x+1+c_{1} e^{4 x}$ passing through the point $(0,0)$.

  \item Find the orthogonal trajectories of the family of parabolas opening in the $y$ direction with vertex at $(1,2)$.

  \item Show that if a population expands at a rate proportional to the number of people present at any time, then the doubling time of the population is $T=(\ln 2) / k$, where $k$ is the positive growth rate. This is known as the Law of Malthus.

  \item In March 1976 the world population reached 4 billion. A popular news magazine has predicted that with an average yearly growth rate of $1.8 \%$, the world population will be 8 billion in 45 years. How does this value compare with that predicted by the model that says the rate of increase is proportional to the population at time $t$ ?

  \item Air containing $0.06 \%$ carbon dioxide is pumped into a room whose volume is $8000 \mathrm{ft}^{3}$. The rate at which the air is pumped in is $2000 \mathrm{ft}^{3} / \mathrm{min}$, and the circulated air is then pumped out at the same rate. If there is an initial concentration of $0.2 \%$ carbon dioxide, determine the subsequent amount in the room at any time. What is the concentration at 10 minutes? What is the steady-state or equilibrium concentration of carbon dioxide?

  \item The populations of two species of animals are described by the nonlinear system of first-order differential equations

\end{enumerate}

$$
\frac{d x}{d t}=k_{1} x(\alpha-x), \quad \frac{d y}{d t}=k_{2} x y
$$

Solve for $x$ and $y$ in terms of $t$.

\begin{enumerate}
  \setcounter{enumi}{7}
  \item A projectile is shot vertically into the air with an initial velocity of $v_{0} \mathrm{ft} / \mathrm{s}$. Assuming that air resistance is proportional to the square of the instantaneous velocity, the motion is described by this pair of differential equations:
\end{enumerate}

$$
m \frac{d v}{d t}=-m g-k v^{2}, \quad k>0
$$

positive $y$-axis up, origin at ground level so that $\nu=v_{0}$ at $y=0$, and

$$
m \frac{d v}{d t}=m g-k v^{2}, \quad k>0
$$

positive $y$-axis down, origin at the maximum height so that $v=0$ at $y=h$. The first and second equations describe the motion of the projectile when rising and falling, respectively.

(a) Determine the limiting, or terminal, velocity of the falling projectile. Compare this terminal velocity with that obtained in Problem 27 in Exercises 3.2 .

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-126}
\end{center}

Figure 3.25 (b) Prove that the impact velocity $v_{i}$ of the projectile is less than the initial velocity $v_{0}$. It can also be shown that the time $t_{1}$ needed to attain its maximum height $h$ is less than the time $t_{2}$ that it takes to fall from this height. See Figure 3.25.

\begin{enumerate}
  \setcounter{enumi}{8}
  \item Consider Newton's law of cooling $d T / d t=k\left(T-T_{\mathrm{m}}\right), k<0$, where the temperature of the surrounding medium $T_{\mathrm{m}}$ changes with time. Suppose the initial temperature of a body is $T_{1}$ and the initial temperature of the surrounding medium is $T_{2}$ and $T_{\mathrm{m}}=T_{2}+B\left(T_{1}-T\right)$, where $B>0$ is a constant.
\end{enumerate}

(a) Find the temperature of the body at any time $t$.

(b) What is the limiting value of the temperature as $t \rightarrow \infty$ ?

(c) What is the limiting value of $T_{\mathrm{m}}$ as $t \rightarrow \infty$ ?

\begin{enumerate}
  \setcounter{enumi}{9}
  \item An $L-R$ series circuit has a variable inductor with the inductance defined by
\end{enumerate}

$$
L=\left\{\begin{array}{lr}
1-\frac{t}{10}, & 0 \leq t<10 \\
0, & t \geq 10
\end{array}\right.
$$

Find the current $i(t)$ if the resistance is 0.2 ohm, the impressed voltage is $E(t)=4$, and $i(0)=0$. Graph $i(t)$.

\section*{by}
Michael Olinick

Department of Mathematics and Computer Sciences, Middlebury College

\section*{POPULATION DYNAMICS}
 DYNAMICSThe fact that ecology is essentially a mathematical subject is becoming ever more widely accepted," writes Evelyn C. Pielou [2]. "Ecologists everywhere are attempting to formulate and solve their problems by mathematical reasoning." Historically, the first and perhaps most important branch of mathematical ecology is the investigation of population dynamics: how populations grow and decline. First-order differential equations have been a critically important tool in these studies.

Many attempts to model population growth begin with the assumption that the rate of population growth is dependent on the size of the population. If $P$ represents the population at time $t$, then these models all have the form

$$
\frac{d P}{d t}=f(P)
$$

where $f$ is some function of the population level $P$. How should $f$ be selected?

The central figure in the history of population is the Reverend Thomas Robert Malthus (1766-1834). Malthus was an honors graduate in mathematics at Cambridge University, an ordained minister in the Church of England, and a professor of history and political economy. In a seminal work, AnEssay on the Principle of Population [3], Malthus argued that the appropriate form of $f(P)$, at least when the population is small, should be a constant multiple of $P$; that is,

$$
\frac{d P}{d t}=r P
$$

where $r$ is a constant.

As we have seen, this model yields exponential growth, since the solution of the differential equation is

$$
P(t)=P_{0} e^{r t}
$$

One characteristic of exponential growth is constant doubling time: It takes exactly the same amount of time, $(\ln 2) / r$, for the population to double in size\\
from $P_{0}$ to $2 P_{0}$ regardless of the size of $P_{0}$. Another way to examine exponential growth is to examine the population at successive time units:

$$
P(0), P(1), P(2), P(3), \ldots, P(k), P(k+1), \ldots
$$

Since $P(k)=P_{0} e^{r k}=P_{0}\left(e^{r}\right)^{k}$, these populations form a geometric sequence

$$
a, a c, a c^{2}, a c^{3}, a c^{4}, a c^{5}, \ldots
$$

with initial term $a=P_{0}$ and constant ratio $c=e^{r}$. Malthus, in fact, begins his famous essay with the observation "In taking a view of animated nature, we cannot fail to be struck with a prodigious power of increase in plants and animals whether they increase slowly or rapidly, their natural tendency must be to increase in a geometrical ratio, that is, by multiplication; and at whatever rate they are increasing during any one period, if no further obstacles be opposed to them, they must proceed in a geometrical progression." After carefully examining figures collected during the first censuses of the United States and looking at data from other countries, Malthus concluded that "the natural progress of population" was exponential in nature with a doubling time of about 25 years for humans.

Since this model asserts that there is no limit to the number of individuals in this population, it is clear that the exponential model is not a completely realistic picture. The exponential model may be a realistic one for the growth of some populations over relatively short time intervals. The population of the United States during the period from 1790 to 1860 grew at such an exponential pace, with an annual growth rate of about $3 \%$.

It's instructive to examine the actual U.S. census figures alongside those given by an exponential growth model. Table 3.1 shows the actual and predicted populations in millions. The "error" column displays the difference between the actual and predicted numbers. The final column, "\% error," is derived from the ratio of the error to the actual population. The "actual population" is that reported by the U.S. Census Bureau. The "predicted population" is generated from the equation

$$
P(t)=3.929 e^{0.029655 t}
$$

From the table we see that the exponential growth model fits the actual census data quite closely for the 70 -year period beginning in 1790; the largest error is less than $2 \%$. "Reality" and the model's predictions begin to diverge by 1870; the model

Table 3.I

\begin{center}
\begin{tabular}{rcccr}
\hline
Year & \begin{tabular}{l}
Actual \\
population \\
\end{tabular} & \begin{tabular}{l}
Predicted \\
population \\
\end{tabular} & Error & \begin{tabular}{c}
\% \\
Error \\
\end{tabular} \\
\hline
1790 & 3.929 & 3.929 & 0.000 & 0.00 \\
1800 & 5.308 & 5.285 & 0.023 & 0.43 \\
1810 & 7.24 & 7.110 & 0.130 & 1.80 \\
1820 & 9.638 & 9.564 & 0.074 & 0.76 \\
1830 & 12.866 & 12.866 & 0.000 & 0.00 \\
1840 & 17.069 & 17.307 & -0.238 & -1.40 \\
1850 & 23.192 & 23.282 & -0.090 & -0.39 \\
1860 & 31.433 & 31.319 & 0.114 & 0.36 \\
1870 & 38.558 & 42.131 & -3.573 & -9.27 \\
1880 & 50.156 & 56.675 & -6.519 & -13.00 \\
1890 & 62.948 & 76.240 & -13.292 & -21.12 \\
\hline
\end{tabular}
\end{center}

had no way of predicting the Civil War, which raged from 1861 to 1865 and during which more than half a million American young men lost their lives. We have cut off the table in 1890 . The disparity between the actual and predicted populations becomes enormously large in the twentieth century, reaching a staggering $495 \%$ error by 1990! One of the consequences we can draw from this model is that if the U.S. population had continued to grow at the same rate it had grown in the first half of the nineteenth century, we would have today a nation six times more populous than the one we do have. That's worth contemplating next time you're stuck in a traffic jam or waiting to check out at your local supermarket!

There are many generalizations of this model. In the logistic growth model, first developed by the Belgian mathematician Pierre-Francois Verhulst (1804-1849), we assume that $r$ is not a constant, but a variable that decreases in a simple linear fashion as the population increases. Thus we can represent $r$ as $a-b P$, where $a$ and $b$ are positive constants. This yields the model $d P / d t=(a-b P) P$, which has a solution of the form

$$
P(t)=\frac{K}{1+e^{d-a t}}
$$

Although Verhulst attempted to test his model on actual population data, he was frustrated by the inaccurate census information available in the early 1840s when he carried out his studies. Because the existing data on population were too inadequate to form any effective test of the logistic model at the time, Verhulst's work lay forgotten for nearly 80 years. It was rediscovered independently by two American scientists working at Johns Hopkins University, Raymond Pearl and Lowell J. Reed.

In 1920 Pearl and Reed [1] examined how closely the U.S. population growth curve followed a logistic curve. Using data from the censuses of 1790, 1850, and 1910 to find values for $K, d$, and $a$, they found that the logistic equation

$$
P(t)=\frac{197.274}{1+e^{3.896-0.031 t}}
$$

matched well the actual population figures for the 120 -year period beginning in 1790. In fact, the logistic model gives an excellent portrayal of the changes in the U.S. population from 1790 through 1950. Table 3.2 shows the comparison between the predictions of this logistic model and U.S. census data.

We have excellent agreement between the model's predictions and the observed population between 1790 and 1950. The largest error is about $3.5 \%$. While the model predicts a leveling off of U.S. inhabitants that should continue after mid-century, the actual data show the "baby boom" of the 1950s, which increased the population by almost 30 million in 10 years.

It is remarkable that a relatively simple model such as the logistic one can give such accurate results for a period of 160 years. The particular logistic curve calculated by Pearl and Reed could have been derived as early as 1911, when the results of the 1910 census were published. Their equation could have been used for 40 years to give accurate population projections that would have been useful for government planning.

How has the population of the United States grown in the last half of the twentieth century? Can a simple model explain the observed changes and give us a reasonable prediction for the near future? As populations become large, we often observe a slowing down of the rate of increase. Various reasons for this have been given, the principal one being competition for limited resources.

Table 3.2

\begin{center}
\begin{tabular}{rccrr}
\hline
Year & \begin{tabular}{l}
Predicted \\
population \\
\end{tabular} & \begin{tabular}{l}
Census \\
population \\
\end{tabular} & Error & \begin{tabular}{c}
\% \\
Error \\
\end{tabular} \\
\hline
1790 & 3.929 & 3.929 & 0.000 & 0.00 \\
1800 & 5.336 & 5.308 & 0.028 & 0.53 \\
1810 & 7.228 & 7.240 & -0.012 & -0.17 \\
1820 & 9.757 & 9.638 & 0.119 & 1.23 \\
1830 & 13.109 & 12.866 & 0.243 & 1.89 \\
1840 & 17.506 & 17.069 & 0.437 & 2.56 \\
1850 & 23.192 & 23.192 & 0.000 & 0.00 \\
1860 & 30.412 & 31.433 & -1.021 & -3.25 \\
1870 & 39.372 & 38.558 & 0.814 & 2.11 \\
1880 & 50.177 & 50.156 & 0.021 & 0.04 \\
1890 & 62.769 & 62.948 & -0.179 & -0.28 \\
1900 & 76.870 & 75.996 & 0.874 & 1.15 \\
1910 & 91.972 & 91.972 & 0.000 & 0.00 \\
1920 & 107.395 & 105.711 & 1.684 & 1.59 \\
1930 & 122.398 & 122.775 & -0.377 & -0.31 \\
1940 & 136.318 & 131.669 & 4.649 & 3.53 \\
1950 & 148.678 & 150.697 & -2.019 & -1.34 \\
1960 & 159.230 & 179.323 & -20.093 & -11.20 \\
1970 & 167.944 & 203.185 & -35.241 & -17.34 \\
1980 & 174.941 & 226.546 & -51.605 & -22.78 \\
1990 & 180.437 & 248.710 & -68.273 & -27.45 \\
\hline
\end{tabular}
\end{center}

Let's look at one of the simplest mathematical assumptions we can make: The growth rate is inversely proportional to the population. Our mathematical model looks like

$$
\frac{d P}{d t}=\frac{b}{P} \quad \text { with } \quad P(0)=P_{0}
$$

where $b$ is a positive constant.

The differential equation is easily solved by separating the variables and integrating. We obtain

$$
P(t)=\sqrt{2 b t+P_{0}^{2}}
$$

If $b$ is positive, this model predicts that the population will continue to increase without bound.

If the population at a later time $t_{1}$ is observed to be $P_{1}$, then we can determine the value of the parameter $b$ as

$$
b=\frac{P_{1}^{2}-P_{0}^{2}}{2 t_{1}}
$$

As a test of this simple model, we will look at the U.S. census figures. Taking $t=0$ to correspond with the 1950 figure of 150.697 million and $t=1$ for the 1960 census of 179.323 million, we obtain a value of 4723.58 for $b$. Thus our fitted model has the form

$$
P(t)=\sqrt{9447.16 t+(150.697)^{2}}
$$

where each unit increase in $t$ represents 10 years.

Table 3.3

\begin{center}
\begin{tabular}{llll}
\hline
Year & \begin{tabular}{l}
Actual \\
pop. \\
\end{tabular} & \begin{tabular}{l}
Pred. \\
pop. \\
\end{tabular} & \begin{tabular}{l}
\% \\
Error \\
\end{tabular} \\
\hline
1970 & 203.302 & 203.970 & 0.33 \\
1980 & 226.505 & 225.945 & 0.24 \\
1990 & 248.710 & 245.964 & 1.10 \\
\hline
\end{tabular}
\end{center}

With these values, in Table 3.3 we can compare the predictions of the model with the best estimates of the U.S. Census Bureau for the years 1970, 1980, and 1990. (Here both actual and predicted populations are given in millions; the percentage error is obtained by comparing the absolute value of the difference between actual and predicted values to the actual population level.)

We observe that this simple model yields surprisingly accurate results for a least one "real world" set of data. Our value of $t=0$ corresponds to the April 1,1950 , census date. The U.S. Census Bureau makes population projections for the first day of July. A recent projection for July 1, 2000, is 268.266 million. Using the corresponding value for $t$ of 5.025 , our model predicts a population of 264.918 million. The difference is about $1.25 \%$.

More accurate models of the growth of the U.S. population might be obtained by refining the logistic models in several different ways. The function $f(P)$ —chosen to be quadratic in the logistic model-might be taken to be a polynomial of higher degree so that higher-order effects of the size of the population on the growth rate could be included. Additional factors might be attached to the differential equation to incorporate the concept that the rate of change of population is a function not only of population but of time as well; that is, you could examine models of the form

$$
\frac{d P}{d t}=f(P, t)
$$

We should note that the Gompertz model can also be viewed as a generalization of the exponential model $d P / d t=r P$, with the constant $r$ replaced by a variable $r(t)$ which itself decreases at a constant percentage rate; that is,

$$
\frac{d r}{d t}=\alpha r
$$

where $\alpha$ is a negative constant. This gives $r$ as $r_{0} e^{\alpha t}$, so the Gompertz model takes the form

$$
\frac{d P}{d t}=r_{0} e^{\alpha t} P
$$

Generalizations of the Gompertz model include approaches where $r(t)$ is taken to be a polynomial in $t$ of a fixed degree.

Demographers are using increasingly complex and sophisticated mathematical models of both deterministic and probabilistic character to study changes in population growth in the past and to make projections about the future. Although there are many different approaches to the creation of such models, most of them are extensions or generalizations of a first-order nonlinear differential equation.

\section*{REFERENCES}
\begin{enumerate}
  \item Pearl, Raymond, and Lowell Reed. "On the Rate of Growth of the United States Population Since 1790 and Its Mathematical Representation." Proceedings of the National Academy of Sciences 6 (1920): 275-288.

  \item Pielou, E. C. An Introduction to Mathematical Ecology, second edition. New York: Wiley, 1977.

  \item Malthus, Thomas R. An Essay on the Principle of Population and a Summary View of the Principle of Population. Baltimore: Penguin, 1970.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-132}
\end{center}

\section*{LINEAR DIFFERENTIAL EQUATIONS OF HIGHER ORDER}
\subsection*{4.1 Preliminary Theory}
4.2 Constructing a Second Solution from a Known Solution

4.3 Homogeneous Linear Equations with Constant Coefficients

4.4 Undetermined Coefficients-Superposition Approach

4.5 Differential Operators

4.6 Undetermined Coefficients-Annihilator Approach

4.7 Variation of Parameters

Chapter 4 Review

Chapter 4 Review Exercises

We turn now to the solution of differential equations of order two or higher. Although we can solve some nonlinear first-order equations by the techniques considered in Chapter 2, nonlinear equations of higher order generally defy solution. This does not mean a nonlinear equation has no solution, but rather there are no rules or methods whereby its solution can be exhibited in terms of elementary or other kinds of functions. As a consequence, in attempting to solve higher-order equations, we shall confine our attention to linear equations.

We begin this chapter by first examining the underlying theory of linear equations. As we did in Section 2.5, we set conditions on the differential equation under which we can obtain its general solution. Recall that a general solution contains all solutions of the equation on some interval. For the remainder of the chapter we then develop methods for obtaining a general solution for a linear equation with constant coefficients. We shall see that our ability to solve an $n$ th-order linear differential equation with constant coefficients hinges on our ability to solve an $n$ th-degree polynomial equation. The method of solution of linear equations with nonconstant coefficients will be taken up in Chapter 6.

\section*{4. 1 PRELIMINARY THEORY}
\begin{itemize}
  \item Initial-value problem
  \item Initial conditions
  \item Boundary-value problem
  \item Boundary conditions
  \item Linear dependence
  \item Linear independence
  \item Wronskian
  \item Homogeneous equation
  \item Nonhomogeneous equation
  \item Superposition principle
  \item Fundamental set of solutions
  \item General solution
  \item Particular solution - Complementary function
\end{itemize}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-133}
\end{center}

Figure 4.I\\
We begin the discussion of higher-order differential equations, as we did that of first-order equations, with the notion of an initial-value problem. However, we confine our attention to linear differential equations.

\subsection*{4.1.1 Initial-Value and Boundary-Value Problems}
Initial-Value Problem For a linear $n$ th-order differential equation, the problem

Solve: $\quad a_{n}(x) \frac{d^{n} y}{d x^{n}}+a_{n-1}(x) \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x)$

Subject to: $\quad y\left(x_{0}\right)=y_{0}, \quad y^{\prime}\left(x_{0}\right)=y_{0}^{\prime}, \quad \ldots, \quad y^{(n-1)}\left(x_{0}\right)=y_{0}^{(n-1)}$,

where $y_{0}, y_{0}^{\prime}, \ldots, y_{0}^{(n-1)}$ are arbitrary constants, is called an initial-value problem (IVP). The specified values $y\left(x_{0}\right)=y_{0}, y^{\prime}\left(x_{0}\right)=y_{0}^{\prime}, \ldots, y^{(n-1)}\left(x_{0}\right)=y_{0}^{(n-1)}$ are called initial conditions. We seek a solution on some interval $I$ containing $x_{0}$.

In the case of a linear second-order equation, a solution of the initial-value problem

$$
a_{2}(x) \frac{d^{2} y}{d x^{2}}+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x), \quad y\left(x_{0}\right)=y_{0}, \quad y^{\prime}\left(x_{0}\right)=y_{0}^{\prime}
$$

is a function satisfying the differential equation on $I$ whose graph passes through $\left(x_{0}, y_{0}\right)$ such that the slope of the curve at the point is the number $y_{0}^{\prime}$. See Figure 4.1.

The next theorem gives sufficient conditions for the existence of a unique solution to (1).

\section*{THEOREM 4.1 Existence of a Unique Solution}
Let $a_{n}(x), a_{n-1}(x), \ldots, a_{1}(x), a_{0}(x)$, and $g(x)$ be continuous on an interval $I$ and let $a_{n}(x) \neq 0$ for every $x$ in this interval. If $x=x_{0}$ is any point in this interval, then a solution $y(x)$ of the initial-value problem (1) exists on the interval and is unique.

\section*{EXAMPLE 1 Solution of an IVP}
You should verify that the function $y=3 e^{2 x}+e^{-2 x}-3 x$ is a solution of the initial-value problem

$$
y^{\prime \prime}-4 y=12 x, \quad y(0)=4, \quad y^{\prime}(0)=1
$$

Now the differential equation is linear, the coefficients as well as $g(x)=12 x$ are continuous, and $a_{2}(x)=1 \neq 0$ on any interval containing $x=0$. We conclude from Theorem 4.1 that the given function is the unique solution.

\section*{EXAMPLE 2 Trivial Solution of an IVP}
The initial-value problem

$$
3 y^{\prime \prime \prime}+5 y^{\prime \prime}-y^{\prime}+7 y=0, \quad y(1)=0, \quad y^{\prime}(1)=0, \quad y^{\prime \prime}(1)=0
$$

possesses the trivial solution $y=0$. Since the third-order equation is linear with constant coefficients, it follows that all the conditions of Theorem 4.1 are fulfilled. Hence $y=0$ is the only solution on any interval containing $x=1$.

\section*{EXAMPLE 3 Solution of an IVP}
The function $y=\frac{1}{4} \sin 4 x$ is a solution of the initial-value problem

$$
y^{\prime \prime}+16 y=0, \quad y(0)=0, \quad y^{\prime}(0)=1
$$

It follows from Theorem 4.1 that on any interval containing $x=0$ the solution is unique.

The requirements in Theorem 4.1 that $a_{i}(x), i=0,1,2, \ldots, n$ be continuous and $a_{n}(x) \neq 0$ for every $x$ in $I$ are both important. Specifically, if $a_{n}(x)=0$ for some $x$ in the interval, then the solution of a linear initial-value problem may not be unique or even exist.

\section*{EXAMPLE 4 Family of Solutions of an IVP}
Verify that the function $y=c x^{2}+x+3$ is a solution of the initial-value problem

$$
x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y=6, \quad y(0)=3, \quad y^{\prime}(0)=1
$$

on the interval $(-\infty, \infty)$ for any choice of the parameter $c$.

Solution Since $y^{\prime}=2 c x+1$ and $y^{\prime \prime}=2 c$, it follows that

$$
\begin{aligned}
x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y & =x^{2}(2 c)-2 x(2 c x+1)+2\left(c x^{2}+x+3\right) \\
& =2 c x^{2}-4 c x^{2}-2 x+2 c x^{2}+2 x+6=6
\end{aligned}
$$

Also

$$
y(0)=c(0)^{2}+0+3=3 \quad \text { and } \quad y^{\prime}(0)=2 c(0)+1=1
$$

Although the differential equation in Example 4 is linear and the coefficients and $g(x)=6$ are continuous everywhere, the obvious difficulties are that $a_{2}(x)=x^{2}$ is zero at $x=0$ and that the initial conditions are also imposed at $x=0$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-135}
\end{center}

Figure 4.2\\
Boundary-Value Problem Another type of problem consists of solving a differential equation of order two or greater in which the dependent variable $y$ or its derivatives are specified at different points. A problem such as

$$
\begin{array}{ll}
\text { Solve: } & a_{2}(x) \frac{d^{2} y}{d x^{2}}+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x) \\
\text { Subject to: } & y(a)=y_{0}, \quad y(b)=y_{1}
\end{array}
$$

is called a two-point boundary-value problem or simply a boundary-value problem (BVP). The specified values $y(a)=y_{0}$ and $y(b)=y_{1}$ are called boundary conditions. A solution of the foregoing problem is a function satisfying the differential equation on some interval $I$, containing $a$ and $b$, whose graph passes through the two points $\left(a, y_{0}\right)$ and $\left(b, y_{1}\right)$. See Figure 4.2.

\section*{EXAMPLE 5 Solution of a BVP}
You should verify that on the interval $(0, \infty)$ the function $y=3 x^{2}-6 x+3$ satisfies both the differential equation and the boundary conditions of the two-point boundary-value problem

$$
x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y=6, \quad y(1)=0, \quad y(2)=3
$$

For a second-order differential equation, other pairs of boundary conditions could be

or

$$
\begin{aligned}
y^{\prime}(a)=y_{0}^{\prime}, & y(b)=y_{1} \\
y(a)=y_{0}, & y^{\prime}(b)=y_{1}^{\prime} \\
y^{\prime}(a)=y_{0}^{\prime}, & y^{\prime}(b)=y_{1}^{\prime}
\end{aligned}
$$

where $y_{0}, y_{0}^{\prime}, y_{1}$, and $y_{1}^{\prime}$ denote arbitrary constants. These three pairs of conditions are just special cases of the general boundary conditions

$$
\begin{aligned}
& \alpha_{1} y(a)+\beta_{1} y^{\prime}(a)=\gamma_{1} \\
& \alpha_{2} y(b)+\beta_{2} y^{\prime}(b)=\gamma_{2}
\end{aligned}
$$

The next examples show that even when the conditions of Theorem 4.1 are fulfilled, a boundary-value problem may have

(i) several solutions (as suggested in Figure 4.2),

(ii) a unique solution, or

(iii) no solution at all.

\section*{EXAMPLE 6 Family of Solutions of a BVP}
In Example 6 of Section 1.1, we saw that a two-parameter family of solutions for the differential equation $y^{\prime \prime}+16 y=0$ is

$$
y=c_{1} \cos 4 x+c_{2} \sin 4 x
$$

Suppose we now wish to determine that solution of the equation that further satisfies the boundary conditions

$$
y(0)=0, \quad y\left(\frac{\pi}{2}\right)=0
$$

Observe that the first condition

$$
0=c_{1} \cos 0+c_{2} \sin 0
$$

implies $c_{1}=0$, so $y=c_{2} \sin 4 x$. But when $x=\pi / 2$, we have

$$
0=c_{2} \sin 2 \pi
$$

Since $\sin 2 \pi=0$, this latter condition is satisfied for any choice of $c_{2}$, so it follows that a solution of the problem

$$
y^{\prime \prime}+16 y=0, \quad y(0)=0, \quad y\left(\frac{\pi}{2}\right)=0
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-136}
\end{center}

Figure 4.3

$$
y=c_{2} \sin 4 x
$$

As Figure 4.3 shows, there are an infinite number of functions satisfying the differential equation whose graphs pass through the two points $(0,0)$ and $(\pi / 2,0)$.

If the boundary conditions were $y(0)=0$ and $y(\pi / 8)=0$, then necessarily $c_{1}$ and $c_{2}$ would both equal zero. Thus $y=0$ would be a solution of this new boundary-value problem. In fact, as we shall see later on in this section, it is the only solution.

\section*{EXAMPLE 7 BVP with No Solution}
The boundary-value problem

$$
y^{\prime \prime}+16 y=0, \quad y(0)=0, \quad y\left(\frac{\pi}{2}\right)=1
$$

has no solution in the family $y=c_{1} \cos 4 x+c_{2} \sin 4 x$. As in Example 6, the condition $y(0)=0$ still implies that $c_{1}=0$. Thus $y=c_{2} \sin 4 x$, so when $x=\pi / 2$ we obtain the contradiction $1=c_{2} \cdot 0=0$.

Boundary-value problems are often encountered in the applications of partial differential equations.

\subsection*{4.1.2 LINEAR Dependence and LINEAR INDEPENDENCE}
The next two concepts are basic to the study of linear differential equations.

\section*{DEFINITION 4.1 Linear Dependence}
A set of functions $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ is said to be linearly dependent on an interval $I$ if there exist constants $c_{1}, c_{2}, \ldots, c_{n}$, not all zero, such that

$$
c_{1} f_{1}(x)+c_{2} f_{2}(x)+\cdots+c_{n} f_{n}(x)=0
$$

for every $x$ in the interval.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-137(1)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-137}
\end{center}

(b)

DEFINITION 4.2 Linear Independence

A set of functions $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ is said to be linearly independent on an interval $I$ if it is not linearly dependent on the interval.

In other words, a set of functions is linearly independent on an interval if the only constants for which

$$
c_{1} f_{1}(x)+c_{2} f_{2}(x)+\cdots+c_{n} f_{n}(x)=0
$$

for every $x$ in the interval are $c_{1}=c_{2}=\cdots=c_{n}=0$.

It is easy to understand these definitions in the case of a set of two functions $f_{1}(x)$ and $f_{2}(x)$. If the set of functions is linearly dependent on an interval, then there exist constants $c_{1}$ and $c_{2}$ that are not both zero such that for every $x$ in the interval,

$$
c_{1} f_{1}(x)+c_{2} f_{2}(x)=0
$$

Therefore, if we assume that $c_{1} \neq 0$, it follows that

$$
f_{1}(x)=-\frac{c_{2}}{c_{1}} f_{2}(x)
$$

that is, if a set of two functions is linearly dependent, then one is simply a constant multiple of the other. Conversely, if $f_{1}(x)=c_{2} f_{2}(x)$ for some constant $c_{2}$, then

$$
(-1) \cdot f_{1}(x)+c_{2} f_{2}(x)=0
$$

for every $x$ on some interval. Hence the functions are linearly dependent since at least one of the constants (namely, $c_{1}=-1$ ) is not zero. We conclude that $a$ set of two functions is linearly independent when neither is a constant multiple of the other on an interval.

\section*{EXAMPLE 8 Linearly Dependent Functions}
The set of functions $f_{1}(x)=\sin 2 x$ and $f_{2}(x)=\sin x \cos x$ is linearly dependent on the interval $(-\infty, \infty)$, since

$$
c_{1} \sin 2 x+c_{2} \sin x \cos x=0
$$

is satisfied for every real $x$ if we choose $c_{1}=\frac{1}{2}$ and $c_{2}=-1$. (Recall the trigonometric identity $\sin 2 x=2 \sin x \cos x$.)

\section*{EXAMPLE 9 Linearly Independent Functions}
The set of functions $f_{1}(x)=x$ and $f_{2}(x)=|x|$ is linearly independent on the interval $(-\infty, \infty)$. Inspection of Figure 4.4 should convince you that neither function is a constant multiple of the other. Thus in order to have $c_{1} f_{1}(x)+c_{2} f_{2}(x)=0$ for every real $x$, we must choose $c_{1}=0$ and $c_{2}=0$.

In the consideration of linear dependence or linear independence, the interval on which the functions are defined is important. The set of functions $f_{1}(x)=$ $x$ and $f_{2}(x)=|x|$ in Example 9 is linearly dependent on the interval $(0, \infty)$, since

$$
c_{1} x+c_{2}|x|=c_{1} x+c_{2} x=0
$$

is satisfied for any nonzero choice of $c_{1}$ and $c_{2}$ for which $c_{1}=-c_{2}$.

\section*{EXAMPLE 10 Linearly Dependent Functions}
The set of functions $f_{1}(x)=\cos ^{2} x, f_{2}(x)=\sin ^{2} x, f_{3}(x)=\sec ^{2} x, f_{4}(x)=\tan ^{2} x$ is linearly dependent on the interval $(-\pi / 2, \pi / 2)$, since

$$
c_{1} \cos ^{2} x+c_{2} \sin ^{2} x+c_{3} \sec ^{2} x+c_{4} \tan ^{2} x=0
$$

when $c_{1}=c_{2}=1, c_{3}=-1, c_{4}=1$. We note that $\cos ^{2} x+\sin ^{2} x=1$ and $1+\tan ^{2} x=\sec ^{2} x$.

A set of functions $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ is linearly dependent on an interval if at least one function can be expressed as a linear combination of the remaining functions.

\section*{EXAMPLE 11 Linearly Dependent Functions}
The set of functions $f_{1}(x)=\sqrt{x}+5, f_{2}(x)=\sqrt{x}+5 x, f_{3}(x)=x-1$, $f_{4}(x)=x^{2}$ is linearly dependent on the interval $(0, \infty)$, since $f_{2}$ can be written as a linear combination of $f_{1}, f_{3}$, and $f_{4}$. Observe that

$$
f_{2}(x)=1 \cdot f_{1}(x)+5 \cdot f_{3}(x)+0 \cdot f_{4}(x)
$$

for every $x$ in the interval $(0, \infty)$.

Wronskian The following theorem provides a sufficient condition for the linear independence of $n$ functions on an interval. Each function is assumed to be differentiable at least $n-1$ times.

\section*{THEOREM 4.2 Criterion for Linearly Independent Functions}
Suppose $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ possess at least $n-1$ derivatives. If the determinant

$$
\left|\begin{array}{cccc}
f_{1} & f_{2} & \ldots & f_{n} \\
f_{1}^{\prime} & f_{2}^{\prime} & \ldots & f_{n}^{\prime} \\
\vdots & & & \vdots \\
f_{1}^{(n-1)} & f_{2}^{(n-1)} & \ldots & f_{n}^{(n-1)}
\end{array}\right|
$$

is not zero for at least one point in the interval $I$, then the set of functions $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ is linearly independent on the interval.

The determinant in the preceding theorem is denoted by

$$
W\left(f_{1}(x), f_{2}(x), \ldots, f_{n}(x)\right)
$$

and is called the Wronskian ${ }^{*}$ of the functions.

Proof We prove Theorem 4.2 by contradiction for the case when $n=2$. Assume that $W\left(f_{1}\left(x_{0}\right), f_{2}\left(x_{0}\right)\right) \neq 0$ for a fixed $x_{0}$ in the interval $I$ and that $f_{1}(x)$ and $f_{2}(x)$ are linearly dependent on the interval. The fact that the set of functions is linearly dependent means there exist constants $c_{1}$ and $c_{2}$, not both zero, for which

$$
c_{1} f_{1}(x)+c_{2} f_{2}(x)=0
$$

for every $x$ in $I$. Differentiating this combination then gives

$$
c_{1} f_{1}^{\prime}(x)+c_{2} f_{2}^{\prime}(x)=0
$$

Thus we obtain the system of linear equations


\begin{align*}
& c_{1} f_{1}(x)+c_{2} f_{2}(x)=0 \\
& c_{1} f_{1}^{\prime}(x)+c_{2} f_{2}^{\prime}(x)=0 \tag{2}
\end{align*}


But the linear dependence of $f_{1}$ and $f_{2}$ implies that (2) possesses a nontrivial solution for each $x$ in the interval. Hence

$$
W\left(f_{1}(x), f_{2}(x)\right)=\left|\begin{array}{ll}
f_{1}(x) & f_{2}(x) \\
f_{1}^{\prime}(x) & f_{2}^{\prime}(x)
\end{array}\right|=0
$$

for every $x$ in $I^{\dagger}$ This contradicts the assumption that $W\left(f_{1}\left(x_{0}\right), f_{2}\left(x_{0}\right)\right) \neq 0$. We conclude that the set of functions $f_{1}$ and $f_{2}$ is linearly independent.

\section*{COROLLARY}
If $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ possess at least $n-1$ derivatives and are linearly dependent on $I$, then

$$
W\left(f_{1}(x), f_{2}(x), \ldots, f_{n}(x)\right)=0
$$

for every $x$ in the interval.

\section*{EXAMPLE 12 Zero Wronskian}
The set of functions $f_{1}(x)=\sin ^{2} x$ and $f_{2}(x)=1-\cos 2 x$ is linearly dependent on $(-\infty, \infty)$. (Why?) By the preceding corollary, $W\left(\sin ^{2} x, 1-\cos 2 x\right)=0$ for every real number. To see this, we observe
\footnotetext{\begin{itemize}
  \item JOSEF MARIA HOËNE WRONSKI (1778-1853) Born in Poland and educated in Germany, Wronski lived most of his life in France. More a philosopher than a mathematician, he believed that absolute truth could be attained through mathematics. Wronski's only noteworthy contribution to mathematics was the above determinant. Always an eccentric, he eventually went insane.
\end{itemize}
}
\footnotetext{\\
${ }^{+}$See Appendix III for a review of determinants.\\
}

$$
\begin{aligned}
W\left(\sin ^{2} x, 1-\cos 2 x\right)= & \left|\begin{array}{cc}
\sin ^{2} x & 1-\cos 2 x \\
2 \sin x \cos x & 2 \sin 2 x
\end{array}\right| \\
= & 2 \sin ^{2} x \sin 2 x-2 \sin x \cos x \\
& +2 \sin x \cos x \cos 2 x \\
= & \sin 2 x\left[2 \sin ^{2} x-1+\cos 2 x\right] \\
= & \sin 2 x\left[2 \sin ^{2} x-1+\cos ^{2} x-\sin ^{2} x\right] \\
= & \sin 2 x\left[\sin ^{2} x+\cos ^{2} x-1\right]=0 .
\end{aligned}
$$

Here we have used the trigonometric identities $\sin 2 x=2 \sin x \cos x, \cos 2 x=$ $\cos ^{2} x-\sin ^{2} x$, and $\sin ^{2} x+\cos ^{2} x=1$.

\section*{EXAMPLE IS}
\section*{Nonzero Wronskian}
For $f_{1}(x)=e^{m_{1} x}, f_{2}(x)=e^{m_{2} x}, m_{1} \neq m_{2}$,

$$
W\left(e^{m_{1} x}, e^{m_{2} x}\right)=\left|\begin{array}{cc}
e^{m_{1} x} & e^{m_{2} x} \\
m_{1} e^{m_{1} x} & m_{2} e^{m_{2} x}
\end{array}\right|=\left(m_{2}-m_{1}\right) e^{\left(m_{1}+m_{2}\right) x} \neq 0
$$

for every real value of $x$. Thus the set of functions $f_{1}$ and $f_{2}$ is linearly independent on any interval of the $x$-axis.

\section*{BXAMFLE IA Nonzero Wronskian}
If $\alpha$ and $\beta$ are real numbers, $\beta \neq 0$, then $y_{1}=e^{\alpha x} \cos \beta x$ and $y_{2}=e^{\alpha x} \sin \beta x$ are linearly independent on any interval of the $x$-axis, since

$$
\begin{aligned}
W\left(e^{\alpha x} \cos \beta x, e^{\alpha x} \sin \beta x\right) & =\left|\begin{array}{cc}
e^{\alpha x} \cos \beta x & e^{\alpha x} \sin \beta x \\
-\beta e^{\alpha x} \sin \beta x+\alpha e^{\alpha x} \cos \beta x & \beta e^{\alpha x} \cos \beta x+\alpha e^{\alpha x} \sin \beta x
\end{array}\right| \\
& =\beta e^{2 \alpha x}\left(\cos ^{2} \beta x+\sin ^{2} \beta x\right)=\beta e^{2 \alpha x} \neq 0
\end{aligned}
$$

Notice when $\alpha=0$ that $\cos \beta x$ and $\sin \beta x, \beta \neq 0$ are also linearly independent on any interval of the $x$-axis.

\section*{EXAMPLE 15 Nonzero Wronskian}
The set of functions $f_{1}(x)=e^{x}, f_{2}(x)=x e^{x}$, and $f_{3}(x)=x^{2} e^{x}$ is linearly independent on any interval of the $x$-axis, since

$$
W\left(e^{x}, x e^{x}, x^{2} e^{x}\right)=\left|\begin{array}{lll}
e^{x} & x e^{x} & x^{2} e^{x} \\
e^{x} & x e^{x}+e^{x} & x^{2} e^{x}+2 x e^{x} \\
e^{x} & x e^{x}+2 e^{x} & x^{2} e^{x}+4 x e^{x}+2 e^{x}
\end{array}\right|=2 e^{3 x}
$$

is not zero for any real value of $x$.

\section*{EXAMRLI: 16 Wronskian Cannot Be Used}
In Example 9 we saw that the set of functions $f_{1}(x)=x$ and $f_{2}(x)=|x|$ is linearly independent on $(-\infty, \infty)$; however, we cannot compute the Wronskian since $f_{2}$ is not differentiable at $x=0$.

We leave it as an exercise to show that a set of functions $f_{1}(x), f_{2}(x), \ldots, f_{n}(x)$ could be linearly independent on some interval and yet have a vanishing Wronskian. See Problem 30. In other words, if $W\left(f_{1}(x), f_{2}(x), \ldots, f_{n}(x)\right)=0$ for every $x$ in an interval, it does not necessarily mean that the functions are linearly dependent.

\subsection*{4.1.3 SolUtions of Linear Equations}
Homogeneous Equations A linear $n$ th-order differential equation of the form


\begin{equation*}
a_{n}(x) \frac{d^{n} y}{d x^{n}}+a_{n-1}(x) \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=0 \tag{3}
\end{equation*}


is said to be homogeneous, whereas


\begin{equation*}
a_{n}(x) \frac{d^{n} y}{d x^{n}}+a_{n-1}(x) \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1}(x) \frac{d y}{d x}+a_{0}(x) y=g(x) \tag{4}
\end{equation*}


$g(x)$ not identically zero, is said to be nonhomogeneous.

The word homogeneous in this context does not refer to coefficients that are homogeneous functions. See Section 2.3.

\section*{EXAMPLE 17 Homogeneous/Nonhomogeneous}
(a) The equation $2 y^{\prime \prime}+3 y^{\prime}-5 y=0$ is a homogeneous linear second-order ordinary differential equation.

(b) The equation $x^{3} y^{\prime \prime \prime}-2 x y^{\prime \prime}+5 y^{\prime}+6 y=e^{x}$ is a nonhomogeneous linear third-order ordinary differential equation.

We shall see in the latter part of this section, as well as in the subsequent sections of this chapter, that in order to solve a nonhomogeneous equation (4), we must first solve the associated homogeneous equation (3).

Note To avoid needless repetition throughout the remainder of this text, we shall, as a matter of course, make the following important assumptions when giving definitions and proving theorems about the linear equations (3) and (4). On some common interval $I$,

\begin{itemize}
  \item the coefficients $a_{i}(x), i=0,1, \ldots, n$ are continuous;
  \item the right-hand member $g(x)$ is continuous; and
  \item $a_{n}(x) \neq 0$ for every $x$ in the interval.
\end{itemize}

Superposition Principle In the next theorem we see that the sum, or superposition, of two or more solutions of a homogeneous linear differential equation is also a solution.

\section*{THEOREM 4.3 Superposition Principle-Homogeneous Equations}
Let $y_{1}, y_{2}, \ldots, y_{k}$ be solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$. Then the linear combination


\begin{equation*}
y=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{k} y_{k}(x) \tag{5}
\end{equation*}


where the $c_{i}, i=1,2, \ldots, k$ are arbitrary constants, is also a solution on the interval.

Proof We prove the case when $n=k=2$. Let $y_{1}(x)$ and $y_{2}(x)$ be solutions of

$$
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0
$$

If we define $y=c_{1} y_{1}(x)+c_{2} y_{2}(x)$, then

$$
\begin{aligned}
& a_{2}(x)\left[c_{1} y_{1}^{\prime \prime}+c_{2} y_{2}^{\prime \prime}\right]+a_{1}(x)\left[c_{1} y_{1}^{\prime}+c_{2} y_{2}^{\prime}\right]+a_{0}(x)\left[c_{1} y_{1}+c_{2} y_{2}\right] \\
& \quad=c_{1}[\underbrace{a_{2}(x) y_{1}^{\prime \prime}+a_{1}(x) y_{1}^{\prime}+a_{0}(x) y_{1}}_{\text {zero }}]+c_{2}[\underbrace{a_{2}(x) y_{2}^{\prime \prime}+a_{1}(x) y_{2}^{\prime}+a_{0}(x) y_{2}}_{\text {zero }}] \\
& \quad=c_{1} \cdot 0+c_{2} \cdot 0=0 .
\end{aligned}
$$

\section*{COROLLARIES TO THEOREM 4.3}
(A) A constant multiple $y=c_{1} y_{1}(x)$ of a solution $y_{1}(x)$ of a homogeneous linear differential equation is also a solution.

(B) A homogeneous linear differential equation always possesses the trivial solution $y=0$.

The superposition principle defined by (5) and its special case given in Corollary $(\mathrm{A})$ are properties that nonlinear differential equations, in general, do not possess. See Problems 31 and 32.

\section*{EXAMPLE 18 Superposition-Homogeneous DE}
The functions $y_{1}=x^{2}$ and $y_{2}=x^{2} \ln x$ are both solutions of the homogeneous third-order equation

$$
x^{3} y^{\prime \prime \prime}-2 x y^{\prime}+4 y=0
$$

on the interval $(0, \infty)$. By the superposition principle the linear combination

$$
y=c_{1} x^{2}+c_{2} x^{2} \ln x
$$

is also a solution of the equation on the interval.

\section*{EXAMPLE 19 Superposition-Homogeneous DE}
The functions $y_{1}=e^{x}, y_{2}=e^{2 x}$, and $y_{3}=e^{3 x}$ all satisfy the homogeneous equation

$$
\frac{d^{3} y}{d x^{3}}-6 \frac{d^{2} y}{d x^{2}}+11 \frac{d y}{d x}-6 y=0
$$

on $(-\infty, \infty)$. By Theorem 4.3 another solution is

$$
y=c_{1} e^{x}+c_{2} e^{2 x}+c_{3} e^{3 x}
$$

\section*{Constant Multiple Is a Solution}
The function $y=x^{2}$ is a solution of the homogeneous linear equation

$$
x^{2} y^{\prime \prime}-3 x y^{\prime}+4 y=0
$$

on $(0, \infty)$. Hence $y=c x^{2}$ is also a solution. For various values of $c$ we see that $y=3 x^{2}, y=e x^{2}, y=0, \ldots$ are all solutions of the equation on the interval.

Linearly Independent Solutions We are interested in determining when a set of $n$ solutions $y_{1}, y_{2}, \ldots, y_{n}$ of the homogeneous differential equation (3) is linearly independent. Surprisingly, the nonvanishing of the Wronskian of a set of $n$ such solutions on an interval $I$ is both necessary and sufficient for linear independence.

\section*{Criterion for Linearly Independent Solutions}
Let $y_{1}, y_{2}, \ldots, y_{n}$ be $n$ solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$. Then the set of solutions is linearly independent on $I$ if and only if

$$
W\left(y_{1}, y_{2}, \ldots, y_{n}\right) \neq 0
$$

for every $x$ in the interval.

Proof We prove Theorem 4.4 for the case when $n=2$. First, if $W\left(y_{1}, y_{2}\right) \neq 0$ for every $x$ in $I$, it follows immediately from Theorem 4.2 that $y_{1}$ and $y_{2}$ are linearly independent. Next, we must show that if $y_{1}$ and $y_{2}$ are linearly independent solutions of a homogeneous linear second-order differential equation, then $W\left(y_{1}, y_{2}\right) \neq 0$ for every $x$ in $I$. To show this, let us suppose $y_{1}$ and $y_{2}$ are linearly independent and there is some fixed $x_{0}$ in $I$ for which $W\left(y_{1}\left(x_{0}\right), y_{2}\left(x_{0}\right)\right)=0$. Hence there must exist $c_{1}$ and $c_{2}$, not both zero, such that


\begin{align*}
& c_{1} y_{1}\left(x_{0}\right)+c_{2} y_{2}\left(x_{0}\right)=0 \\
& c_{1} y_{1}^{\prime}\left(x_{0}\right)+c_{2} y_{2}^{\prime}\left(x_{0}\right)=0  \tag{6}\\
& y(x)=c_{1} y_{1}(x)+c_{2} y_{2}(x)
\end{align*}


If we define

then in view of (6), $y(x)$ must also satisfy


\begin{equation*}
y\left(x_{0}\right)=0, \quad y^{\prime}\left(x_{0}\right)=0 \tag{7}
\end{equation*}


But the identically zero function satisfies both the differential equation and the initial conditions (7), and thus by Theorem 4.1 it is the only solution. In other words, $y=0$ or $c_{1} y_{1}(x)+c_{2} y_{2}(x)=0$ for every $x$ in $I$. This contradicts the assumption that $y_{1}$ and $y_{2}$ are linearly independent on the interval.

From the foregoing discussion we conclude that when $y_{1}, y_{2}, \ldots, y_{n}$ are $n$ solutions of (3) on an interval $I$, the Wronskian either is identically zero or is never zero on the interval.

\section*{DEFINITION 4.3 Fundamental Set of Solutions}
Any linearly independent set $y_{1}, y_{2}, \ldots, y_{n}$ of $n$ solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$ is said to be a fundamental set of solutions on the interval.

\section*{THEOREM 4.5 Existence of Constants}
Let $y_{1}, y_{2}, \ldots, y_{n}$ be a fundamental set of solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$. Then for any solution $Y(x)$ of (3) on $I$, constants $C_{1}, C_{2}, \ldots, C_{n}$ can be found so that

$$
Y=C_{1} y_{1}(x)+C_{2} y_{2}(x)+\cdots+C_{n} y_{n}(x)
$$

Proof We prove the case when $n=2$. Let $Y$ be a solution, and let $y_{1}$ and $y_{2}$ be linearly independent solutions of

$$
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0
$$

on an interval $I$. Suppose $x=t$ is a point in this interval for which $W\left(y_{1}(t), y_{2}(t)\right) \neq 0$. Suppose also that the values of $Y(t)$ and $Y^{\prime}(t)$ are given by $Y(t)=k_{1}, Y^{\prime}(t)=k_{2}$. If we now examine the system of equations

$$
\begin{aligned}
C_{1} y_{1}(t)+C_{2} y_{2}(t) & =k_{1} \\
C_{1} y_{1}^{\prime}(t)+C_{2} y_{2}^{\prime}(t) & =k_{2}
\end{aligned}
$$

it follows that we can determine $C_{1}$ and $C_{2}$ uniquely provided the determinant of the coefficients satisfies

$$
\left|\begin{array}{ll}
y_{1}(t) & y_{2}(t) \\
y_{1}^{\prime}(t) & y_{2}^{\prime}(t)
\end{array}\right| \neq 0
$$

But this latter determinant is simply the Wronskian evaluated at $x=t$, and by assumption $W \neq 0$. If we now define the function

$$
G(x)=C_{1} y_{1}(x)+C_{2} y_{2}(x)
$$

we observe the following:

(i) $G(x)$ satisfies the differential equation since it is the superposition of two known solutions $y_{1}$ and $y_{2}$.

(ii) $G(x)$ satisfies the initial conditions

$$
G(t)=C_{1} y_{1}(t)+C_{2} y_{2}(t)=k_{1}, \quad G^{\prime}(t)=C_{1} y_{1}^{\prime}(t)+C_{2} y_{2}^{\prime}(t)=k_{2}
$$

(iii) $Y(x)$ satisfies the same linear equation and the same initial conditions.

Since the solution of this linear initial-value problem is unique (Theorem 4.1), we have $Y(x)=G(x)$ or

$$
Y(x)=C_{1} y_{1}(x)+C_{2} y_{2}(x)
$$

The basic question of whether a fundamental set of solutions exists for a linear equation is answered in the next theorem.

\section*{THEOREM 4.6 Existence of a Fundamental Set}
There exists a fundamental set of solutions for the homogeneous linear $n$ thorder differential equation (3) on an interval $I$.

The proof of this result follows from Theorem 4.1. The justification of Theorem 4.6 in the special case of second-order equations is left as an exercise.

Since we have shown that any solution of (3) is obtained from a linear combination of functions in a fundamental set of solutions, we are able to make the following definition.

\section*{DEFINITION 4.4 General Solution-Homogeneous Equations}
Let $y_{1}, y_{2}, \ldots, y_{n}$ be a fundamental set of solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$. The general solution of the equation on the interval is defined to be

$$
y=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{n} y_{n}(x)
$$

where the $c_{i}, i=1,2, \ldots, n$ are arbitrary constants.

Recall that the general solution as defined in Section 1.1 is also called the complete solution of the differential equation.

\section*{EXAMPLE 21 General Solution-Homogeneous DE}
The second-order equation $y^{\prime \prime}-9 y=0$ possesses two solutions

Since

$$
\begin{gathered}
y_{1}=e^{3 x} \text { and } y_{2}=e^{-3 x} \\
W\left(e^{3 x}, e^{-3 x}\right)=\left|\begin{array}{cc}
e^{3 x} & e^{-3 x} \\
3 e^{3 x} & -3 e^{-3 x}
\end{array}\right|=-6 \neq 0
\end{gathered}
$$

for every value of $x, y_{1}$ and $y_{2}$ form a fundamental set of solutions on $(-\infty, \infty)$. The general solution of the differential equation on the interval is

$$
y=c_{1} e^{3 x}+c_{2} e^{-3 x}
$$

\section*{EXAMPLE 22 Solution Obtained from General Solution}
You should verify that the function $y=4 \sinh 3 x-5 e^{-3 x}$ also satisfies the differential equation in Example 21. By choosing $c_{1}=2, c_{2}=-7$ in the general solution $y=c_{1} e^{3 x}+c_{2} e^{-3 x}$, we obtain

$$
\begin{aligned}
y & =2 e^{3 x}-7 e^{-3 x}=2 e^{3 x}-2 e^{-3 x}-5 e^{-3 x} \\
& =4\left(\frac{e^{3 x}-e^{-3 x}}{2}\right)-5 e^{-3 x} \\
& =4 \sinh 3 x-5 e^{-3 x}
\end{aligned}
$$

\section*{EXAMPLE 23 General Solution-Homogeneous DE}
The functions $y_{1}=e^{x}, y_{2}=e^{2 x}$, and $y_{3}=e^{3 x}$ satisfy the third-order equation

$$
\frac{d^{3} y}{d x^{3}}-6 \frac{d^{2} y}{d x^{2}}+11 \frac{d y}{d x}-6 y=0
$$

Since $\quad W\left(e^{x}, e^{2 x}, e^{3 x}\right)=\left|\begin{array}{ccc}e^{x} & e^{2 x} & e^{3 x} \\ e^{x} & 2 e^{2 x} & 3 e^{3 x} \\ e^{x} & 4 e^{2 x} & 9 e^{3 x}\end{array}\right|=2 e^{6 x} \neq 0$

for every real value of $x, y_{1}, y_{2}$, and $y_{3}$ form a fundamental set of solutions on $(-\infty, \infty)$. We conclude that

$$
y=c_{1} e^{x}+c_{2} e^{2 x}+c_{3} e^{3 x}
$$

is the general solution of the differential equation on the interval.

Nonhomogeneous Equations We now turn our attention to defining the general solution of a nonhomogeneous linear equation. Any function $y_{p}$, free of arbitrary parameters, that satisfies (4) is said to be a particular solution of the equation (sometimes also called a particular integral).

\section*{EXAMPLE 24 Particular Solutions of Nonhomogeneous DEs}
(a) A particular solution of

$$
y^{\prime \prime}+9 y=27
$$

is $y_{p}=3$, since $y_{p}^{\prime \prime}=0$ and $0+9 y_{p}=9(3)=27$.

(b) $y_{p}=x^{3}-x$ is a particular solution of

$$
x^{2} y^{\prime \prime}+2 x y^{\prime}-8 y=4 x^{3}+6 x
$$

since $y_{p}^{\prime}=3 x^{2}-1, y_{p}^{\prime \prime}=6 x$, and

$$
x^{2} y_{p}^{\prime \prime}+2 x y_{p}^{\prime}-8 y_{p}=x^{2}(6 x)+2 x\left(3 x^{2}-1\right)-8\left(x^{3}-x\right)=4 x^{3}+6 x
$$

\section*{THEOREM 4.7 A Solution of Equation (4)}
Let $y_{1}, y_{2}, \ldots, y_{k}$ be solutions of the homogeneous linear $n$ th-order differential equation (3) on an interval $I$, and let $y_{p}$ be any solution of the nonhomogeneous equation (4) on the same interval. Then

$$
y=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{k} y_{k}(x)+y_{p}(x)
$$

is also a solution of the nonhomogeneous equation on the interval for any constants $c_{1}, c_{2}, \ldots, c_{k}$.

We can now prove the following analogue of Theorem 4.5 for nonhomogeneous differential equations.

\section*{THEOREM 4.8 Existence of Constants}
Let $y_{p}$ be a given solution of the nonhomogeneous linear $n$ th-order differential equation (4) on an interval $I$, and let $y_{1}, y_{2}, \ldots, y_{n}$ be a fundamental set of solutions of the associated homogeneous equation (3) on the interval. Then for any solution $Y(x)$ of (4) on $I$, constants $C_{1}, C_{2}, \ldots, C_{n}$ can be found so that

$$
Y=C_{1} y_{1}(x)+C_{2} y_{2}(x)+\cdots+C_{n} y_{n}(x)+y_{p}(x)
$$

Proof We prove the case when $n=2$. Suppose $Y$ and $y_{p}$ are both solutions of $a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=g(x)$. If we define a function $u$ by $u(x)=Y(x)-$ $y_{p}(x)$, then

$$
\begin{aligned}
& a_{2}(x) u^{\prime \prime}+a_{1}(x) u^{\prime}+a_{0}(x) u \\
& \quad=a_{2}(x)\left[Y^{\prime \prime}-y_{p}^{\prime \prime}\right]+a_{1}(x)\left[Y^{\prime}-y_{p}^{\prime}\right]+a_{0}(x)\left[Y-y_{p}\right] \\
&=a_{2}(x) Y^{\prime \prime}+a_{1}(x) Y^{\prime}+a_{0}(x) Y-\left[a_{2}(x) y_{p}^{\prime \prime}+a_{1}(x) y_{p}^{\prime}+a_{0}(x) y_{p}\right] \\
&=g(x)-g(x)=0
\end{aligned}
$$

Therefore, in view of Definition 4.4 and Theorem 4.5 , we can write

or

$$
\begin{aligned}
u(x) & =C_{1} y_{1}(x)+C_{2} y_{2}(x) \\
Y(x)-y_{p}(x) & =C_{1} y_{1}(x)+C_{2} y_{2}(x) \\
Y(x) & =C_{1} y_{1}(x)+C_{2} y_{2}(x)+y_{p}(x)
\end{aligned}
$$

Thus we come to the last definition of this section.

\section*{DEFINITION 4.5 General Solution-Nonhomogeneous Equations}
Let $y_{p}$ be a given solution of the nonhomogeneous linear $n$ th-order differential equation (4) on an interval $I$, and let

$$
y_{c}=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{n} y_{n}(x)
$$

denote the general solution of the associated homogeneous equation (3) on the interval. The general solution of the nonhomogeneous equation on the interval is defined to be

$$
y=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{n} y_{n}(x)+y_{p}(x)=y_{c}(x)+y_{p}(x) .
$$

Complementary Function In Definition 4.5 the linear combination

$$
y_{c}(x)=c_{1} y_{1}(x)+c_{2} y_{2}(x)+\cdots+c_{n} y_{n}(x)
$$

which is the general solution of (3), is called the complementary function for equation (4). In other words, the general solution of a nonhomogeneous linear differential equation is

$$
y=\text { complementary function }+ \text { any particular solution. }
$$

\section*{EXAMPLE 25 General Solution-Nonhomogeneous DE}
By substitution, the function $y_{p}=-\frac{11}{12}-\frac{1}{2} x$ is readily shown to be a particular solution of the nonhomogeneous equation


\begin{equation*}
\frac{d^{3} y}{d x^{3}}-6 \frac{d^{2} y}{d x^{2}}+11 \frac{d y}{d x}-6 y=3 x \tag{8}
\end{equation*}


In order to write the general solution of (8), we must also be able to solve the associated homogeneous equation

$$
\frac{d^{3} y}{d x^{3}}-6 \frac{d^{2} y}{d x^{2}}+11 \frac{d y}{d x}-6 y=0
$$

But in Example 23 we saw that the general solution of this latter equation on the interval $(-\infty, \infty)$ was

$$
y_{c}=c_{1} e^{x}+c_{2} e^{2 x}+c_{3} e^{3 x}
$$

Hence the general solution of (8) on the interval is

$$
y=y_{c}+y_{p}=c_{1} e^{x}+c_{2} e^{2 x}+c_{3} e^{3 x}-\frac{11}{12}-\frac{1}{2} x
$$

Another Superposition Principle The last theorem of this discussion will be useful in Section 4.4 when we consider a method for finding particular solutions of nonhomogeneous equations.

\section*{THEOREM 4.9 Superposition Principle-Nonhomogeneous Equations}
Let $y_{p_{1}}, y_{p_{2}}, \ldots, y_{p_{k}}$ be $k$ particular solutions of the linear $n$ th-order differential equation (4) on an interval $I$ corresponding, in turn, to $k$ distinct functions $g_{1}, g_{2}, \ldots, g_{k}$. That is, suppose $y_{p_{i}}$ denotes a particular solution of the corresponding differential equation

$$
a_{n}(x) y^{(n)}+a_{n-1}(x) y^{(n-1)}+\cdots+a_{1}(x) y^{\prime}+a_{0}(x) y=g_{i}(x)
$$

where $i=1,2, \ldots, k$. Then

$$
y_{p}=y_{p_{1}}(x)+y_{p_{2}}(x)+\cdots+y_{p_{k}}(x)
$$

is a particular solution of

$$
\begin{aligned}
& a_{n}(x) y^{(n)}+a_{n-1}(x) y^{(n-1)}+\cdots+a_{1}(x) y^{\prime}+a_{0}(x) y \\
& \quad=g_{1}(x)+g_{2}(x)+\cdots+g_{k}(x)
\end{aligned}
$$

We leave the proof of this result when $k=2$ as an exercise. See Problem 50 .

\section*{EXAMPLE 26 Superposition-Nonhomogeneous DE}
You should verify that

$y_{p_{1}}=-4 x^{2}$ is a particular solution of $y^{\prime \prime}-3 y^{\prime}+4 y=-16 x^{2}+24 x-8$,

$y_{p_{2}}=e^{2 x}$ is a particular solution of $y^{\prime \prime}-3 y^{\prime}+4 y=2 e^{2 x}$,

$y_{p_{3}}=x e^{x}$ is a particular solution of $y^{\prime \prime}-3 y^{\prime}+4 y=2 x e^{x}-e^{x}$.

It follows from Theorem 4.9 that the superposition of $y_{p_{1}}, y_{p_{2}}$, and $y_{p_{3}}$,

$$
y=y_{p_{1}}+y_{p_{2}}+y_{p_{3}}=-4 x^{2}+e^{2 x}+x e^{x}
$$

is a solution of

$$
y^{\prime \prime}-3 y^{\prime}+4 y=\underbrace{-16 x^{2}+24 x-8}_{g_{1}(x)}+\underbrace{2 e^{2 x}}_{g_{2}(x)}+\underbrace{2 x e^{x}-e^{x}}_{g_{3}(x)}
$$

Before we actually start solving homogeneous and nonhomogeneous linear differential equations, we need the one additional bit of theory presented in the next section.

Remarks A physical system that changes with time and whose mathematical model is a linear differential equation

$$
a_{n}(t) y^{(n)}+a_{n-1}(t) y^{(n-1)}+\cdots+a_{1}(t) y^{\prime}+a_{0}(t) y=g(t)
$$

is said to be a linear system. The values of the variables $y(t), y^{\prime}(t), \ldots$., $y^{(n-1)}(t)$ at a specific time $t_{0}$ describe the state of the system. The function\\
$g$ is variously called the input function, forcing function, or excitation function. A solution $y(t)$ of the differential equation is said to be the output or response of the system. The dependence of the output on the input is illustrated in Figure 4.5.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-150}
\end{center}

Figure 4.5

In order for a physical system to be a linear system, it is necessary that the superposition principle (Theorem 4.9) hold in the system; that is, the response of the system to a superposition of inputs is a superposition of outputs.

\section*{EXERCISES 4.1}
\section*{Answers to odd-numbered problems begin on page A-6.}
\section*{4.I.I Initial-Value and Boundary-Value Problems}
\begin{enumerate}
  \item Given that $y=c_{1} e^{x}+c_{2} e^{-x}$ is a two-parameter family of solutions of $y^{\prime \prime}-y=0$ on the interval $(-\infty, \infty)$, find a member of the family satisfying the initial conditions $y(0)=0, y^{\prime}(0)=1$.

  \item Find a solution of the differential equation in Problem 1 satisfying the boundary conditions $y(0)=0, y(1)=1$.

  \item Given that $y=c_{1} e^{4 x}+c_{2} e^{-x}$ is a two-parameter family of solutions of $y^{\prime \prime}-3 y^{\prime}-4 y=0$ on the interval $(-\infty, \infty)$, find a member of the family satisfying the initial conditions $y(0)=1, y^{\prime}(0)=2$.

  \item Given that $y=c_{1}+c_{2} \cos x+c_{3} \sin x$ is a three-parameter family of solutions of $y^{\prime \prime \prime}+y^{\prime}=0$ on the interval $(-\infty, \infty)$, find a member of the family satisfying the initial conditions $y(\pi)=0, y^{\prime}(\pi)=2$, $y^{\prime \prime}(\pi)=-1$.

  \item Given that $y=c_{1} x+c_{2} x \ln x$ is a two-parameter family of solutions of $x^{2} y^{\prime \prime}-x y^{\prime}+y=0$ on the interval $(-\infty, \infty)$, find a member of the family satisfying the initial conditions $y(1)=3, y^{\prime}(1)=-1$.

  \item Given that $y=c_{1}+c_{2} x^{2}$ is a two-parameter family of solutions of $x y^{\prime \prime}-y^{\prime}=0$ on the interval $(-\infty, \infty)$, show that constants $c_{1}$ and $c_{2}$ cannot be found so that a member of the family satisfies the initial conditions $y(0)=0, y^{\prime}(0)=1$. Explain why this does not violate Theorem 4.1.

  \item Find two members of the family of solutions of $x y^{\prime \prime}-y^{\prime}=0$ given in Problem 6 satisfying the initial conditions $y(0)=0, y^{\prime}(0)=0$.

  \item Find a member of the family of solutions of $x y^{\prime \prime}-y^{\prime}=0$ given in Prob-\\
lem 6 satisfying the boundary conditions $y(0)=1, y^{\prime}(1)=6$. Does Theorem 4.1 guarantee that this solution is unique?

  \item Given that $y=c_{1} e^{x} \cos x+c_{2} e^{x} \sin x$ is a two-parameter family of solutions of $y^{\prime \prime}-2 y^{\prime}+2 y=0$ on the interval $(-\infty, \infty)$, determine whether a member of the family can be found that satisfies the conditions\\
(a) $y(0)=1, \quad y^{\prime}(0)=0$\\
(b) $y(0)=1, \quad y(\pi)=-1$\\
(c) $y(0)=1, \quad y(\pi / 2)=1$\\
(d) $y(0)=0, \quad y(\pi)=0$

  \item Given that $y=c_{1} x^{2}+c_{2} x^{4}+3$ is a two-parameter family of solutions of $x^{2} y^{\prime \prime}-5 x y^{\prime}+8 y=24$ on the interval $(-\infty, \infty)$, determine whether a member of the family can be found that satisfies the conditions\\
(a) $y(-1)=0, \quad y(1)=4$\\
(b) $y(0)=1, \quad y(1)=2$\\
(c) $y(0)=3, \quad y(1)=0$\\
(d) $y(1)=3, \quad y(2)=15$

\end{enumerate}

In Problems 11 and 12 find an interval around $x=0$ for which the given initial-value problem has a unique solution.\\
11. $(x-2) y^{\prime \prime}+3 y=x ; \quad y(0)=0, y^{\prime}(0)=1$\\
12. $y^{\prime \prime}+(\tan x) y=e^{x} ; \quad y(0)=1, y^{\prime}(0)=0$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Given that $y=c_{1} \cos \lambda x+c_{2} \sin \lambda x$ is a family of solutions of the differential equation $y^{\prime \prime}+\lambda^{2} y=0$, determine the values of the parameter $\lambda$ for which the boundary-value problem
\end{enumerate}

$$
y^{\prime \prime}+\lambda^{2} y=0, \quad y(0)=0, \quad y(\pi)=0
$$

has nontrivial solutions.

\begin{enumerate}
  \setcounter{enumi}{13}
  \item Determine the values of the parameter $\lambda$ for which the boundary-value problem
\end{enumerate}

$$
y^{\prime \prime}+\lambda^{2} y=0, \quad y(0)=0, \quad y(5)=0
$$

has nontrivial solutions. See Problem 13.

\subsection*{4.1.2 Linear Dependence and Linear Independence}
In Problems 15-22 determine whether the given functions are linearly independent or dependent on $(-\infty, \infty)$.\\
15. $f_{1}(x)=x, \quad f_{2}(x)=x^{2}, \quad f_{3}(x)=4 x-3 x^{2}$\\
16. $f_{1}(x)=0, \quad f_{2}(x)=x, \quad f_{3}(x)=e^{x}$\\
17. $f_{1}(x)=5, \quad f_{2}(x)=\cos ^{2} x, \quad f_{3}(x)=\sin ^{2} x$\\
18. $f_{1}(x)=\cos 2 x, \quad f_{2}(x)=1, \quad f_{3}(x)=\cos ^{2} x$\\
19. $f_{1}(x)=x, \quad f_{2}(x)=x-1, \quad f_{3}(x)=x+3$\\
20. $f_{1}(x)=2+x, \quad f_{2}(x)=2+|x|$\\
21. $f_{1}(x)=1+x, \quad f_{2}(x)=x, \quad f_{3}(x)=x^{2}$\\
22. $f_{1}(x)=e^{x}, \quad f_{2}(x)=e^{-x}, \quad f_{3}(x)=\sinh x$

In Problems 23-28 show by computing the Wronskian that the given functions are linearly independent on the indicated interval.\\
23. $x^{1 / 2}, x^{2} ;(0, \infty)$\\
24. $1+x, x^{3} ; \quad(-\infty, \infty)$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $\sin x, \csc x ; \quad(0, \pi) \quad$ 26. $\tan x, \cot x ;(0, \pi / 2)$

  \item $e^{x}, e^{-x}, e^{4 x} ; \quad(-\infty, \infty)$

  \item $x, x \ln x, x^{2} \ln x ; \quad(0, \infty)$

  \item Observe that for the functions $f_{1}(x)=2$ and $f_{2}(x)=e^{x}$,

\end{enumerate}

$$
1 \cdot f_{1}(0)-2 \cdot f_{2}(0)=0
$$

Does this imply that $f_{1}$ and $f_{2}$ are linearly dependent on any interval containing $x=0$ ?

\begin{enumerate}
  \setcounter{enumi}{29}
  \item (a) Show graphically that $f_{1}(x)=x^{2}$ and $f_{2}(x)=x|x|$ are linearly independent on $(-\infty, \infty)$.
\end{enumerate}

(b) Show that $W\left(f_{1}(x), f_{2}(x)\right)=0$ for every real number.

\section*{4.I.3 Solutions of Linear Equations}
\begin{enumerate}
  \setcounter{enumi}{30}
  \item (a) Verify that $y=1 / x$ is a solution of the nonlinear differential equation $y^{\prime \prime}=2 y^{3}$ on the interval $(0, \infty)$.
\end{enumerate}

(b) Show that the constant multiple $y=c / x$ is not a solution of the equation when $c \neq 0, \pm 1$.

\begin{enumerate}
  \setcounter{enumi}{31}
  \item (a) Verify that $y_{1}=1$ and $y_{2}=\ln x$ are solutions of the nonlinear differential equation $y^{\prime \prime}+\left(y^{\prime}\right)^{2}=0$ on the interval $(0, \infty)$.
\end{enumerate}

(b) Is $y_{1}+y_{2}$ a solution of the equation? Is $c_{1} y_{1}+c_{2} y_{2}, c_{1}$ and $c_{2}$ arbitrary, a solution of the equation?

In Problems 33-40 verify that the given functions form a fundamental set of solutions of the differential equation on the indicated interval. Form the general solution.

\begin{enumerate}
  \setcounter{enumi}{32}
  \item $y^{\prime \prime}-y^{\prime}-12 y=0 ; \quad e^{-3 x}, e^{4 x},(-\infty, \infty)$

  \item $y^{\prime \prime}-4 y=0 ; \quad \cosh 2 x, \sinh 2 x,(-\infty, \infty)$

  \item $y^{\prime \prime}-2 y^{\prime}+5 y=0 ; \quad e^{x} \cos 2 x, e^{x} \sin 2 x,(-\infty, \infty)$

  \item $4 y^{\prime \prime}-4 y^{\prime}+y=0 ; \quad e^{x / 2}, x e^{x / 2},(-\infty, \infty)$

  \item $x^{2} y^{\prime \prime}-6 x y^{\prime}+12 y=0 ; \quad x^{3}, x^{4},(0, \infty)$

  \item $x^{2} y^{\prime \prime}+x y^{\prime}+y=0 ; \quad \cos (\ln x), \sin (\ln x),(0, \infty)$

  \item $x^{3} y^{\prime \prime \prime}+6 x^{2} y^{\prime \prime}+4 x y^{\prime}-4 y=0 ; \quad x, x^{-2}, x^{-2} \ln x,(0, \infty)$

  \item $y^{(4)}+y^{\prime \prime}=0 ; \quad 1, x, \cos x, \sin x,(-\infty, \infty)$

\end{enumerate}

In Problems 41-44 verify that the given two-parameter family of functions is the general solution of the nonhomogeneous differential equation on the indicated interval.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item $y^{\prime \prime}-7 y^{\prime}+10 y=24 e^{x}$
\end{enumerate}

$$
y=c_{1} e^{2 x}+c_{2} e^{5 x}+6 e^{x},(-\infty, \infty)
$$

\begin{enumerate}
  \setcounter{enumi}{41}
  \item $y^{\prime \prime}+y=\sec x$
\end{enumerate}

$$
y=c_{1} \cos x+c_{2} \sin x+x \sin x+(\cos x) \ln (\cos x),(-\pi / 2, \pi / 2)
$$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item $y^{\prime \prime}-4 y^{\prime}+4 y=2 e^{2 x}+4 x-12$
\end{enumerate}

$y=c_{1} e^{2 x}+c_{2} x e^{2 x}+x^{2} e^{2 x}+x-2,(-\infty, \infty)$

\begin{enumerate}
  \setcounter{enumi}{43}
  \item $2 x^{2} y^{\prime \prime}+5 x y^{\prime}+y=x^{2}-x$
\end{enumerate}

$$
y=c_{1} x^{-1 / 2}+c_{2} x^{-1}+\frac{1}{15} x^{2}-\frac{1}{6} x,(0, \infty)
$$

\begin{enumerate}
  \setcounter{enumi}{44}
  \item (a) Verify that $y_{1}=x^{3}$ and $y_{2}=|x|^{3}$ are linearly independent solutions of the differential equation $x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=0$ on $(-\infty, \infty)$.
\end{enumerate}

(b) Show that $W\left(y_{1}, y_{2}\right)=0$ for every real number.

(c) Does the result of part (b) violate Theorem 4.4?

(d) Verify that $Y_{1}=x^{3}$ and $Y_{2}=x^{2}$ are also linearly independent solutions of the differential equation on the interval $(-\infty, \infty)$.

(e) Find a solution of the equation satisfying $y(0)=0, y^{\prime}(0)=0$.

(f) By the superposition principle both linear combinations

$$
y=c_{1} y_{1}+c_{2} y_{2} \quad \text { and } \quad y=c_{1} Y_{1}+c_{2} Y_{2}
$$

are solutions of the differential equation. Is one, both, or neither the general solution of the differential equation on $(-\infty, \infty)$ ?

\begin{enumerate}
  \setcounter{enumi}{45}
  \item Consider the second-order differential equation
\end{enumerate}


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0 \tag{9}
\end{equation*}


where $a_{2}(x), a_{1}(x)$, and $a_{0}(x)$ are continuous on an interval $I$ and $a_{2}(x) \neq 0$ for every $x$ in the interval. From Theorem 4.1 there exists only one solution $y_{1}$ of the equation satisfying $y\left(x_{0}\right)=1$ and $y^{\prime}\left(x_{0}\right)=0$, where $x_{0}$ is a point in $I$. Similarly there exists a unique solution $y_{2}$ of the equation satisfying $y\left(x_{0}\right)=0$ and $y^{\prime}\left(x_{0}\right)=1$. Show that $y_{1}$ and $y_{2}$ form a fundamental set of solutions of the differential equation on the interval $I$.

\begin{enumerate}
  \setcounter{enumi}{46}
  \item Let $y_{1}$ and $y_{2}$ be two solutions of (9).
\end{enumerate}

(a) If $W\left(y_{1}, y_{2}\right)$ is the Wronskian of $y_{1}$ and $y_{2}$, show that

$$
a_{2}(x) \frac{d W}{d x}+a_{1}(x) W=0
$$

(b) Derive Abel's formula, ${ }^{*}$

$$
W=c e^{-\left\{\left[a_{1}(x) / a_{2}(x)\right] d x\right.}
$$

where $c$ is a constant.

(c) Using an alternative form of Abel's formula,

$$
W=c e^{\left.-\int_{x_{0}}^{x}\left[a_{1}(t)\right) a_{2}(t)\right] d t},
$$

for $x_{0}$ in $I$, show that

$$
W\left(y_{1}, y_{2}\right)=W\left(x_{0}\right) e^{\left.-\int_{x_{0}}^{x}\left[a_{1}(t)\right) u_{2}(t)\right] d t}
$$
\footnotetext{\begin{itemize}
  \item NIELS HENRIK ABEL (I802-I829) Abel was a brilliant Norwegian mathematician whose tragic death at age 26 due to tuberculosis was an inestimable loss for mathematics. His greatest achievement was the solution of a problem that baffled mathematicians for centuries: he showed that a general fifth-degree polynomial equation cannot be solved algebraicallythat is, in terms of radicals. Abel's contemporary, the Frenchman Evariste Galois, then proved that it was impossible to solve any general polynomial equation of degree greater than four in an algebraic manner. Galois is another tragic figure in the history of mathematics; a political activist, he was killed in a duel at the age of 22 .
\end{itemize}
}
(d) Show that if $W\left(x_{0}\right)=0$, then $W=0$ for every $x$ in $I$, whereas if $W\left(x_{0}\right) \neq 0$, then $W \neq 0$ for every $x$ in the interval.

In Problems 48 and 49 use the results of Problem 47.

\begin{enumerate}
  \setcounter{enumi}{47}
  \item If $y_{1}$ and $y_{2}$ are two solutions of
\end{enumerate}

$$
\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+n(n+1) y=0
$$

on $(-1,1)$, show that $W\left(y_{1}, y_{2}\right)=c /\left(1-x^{2}\right)$, where $c$ is a constant.

\begin{enumerate}
  \setcounter{enumi}{48}
  \item In Chapter 6 we shall see that the solutions $y_{1}$ and $y_{2}$ of $x y^{\prime \prime}+y^{\prime}+x y=0$, $0<x<\infty$ are infinite series. Suppose we consider initial conditions
\end{enumerate}

$$
y_{1}\left(x_{0}\right)=k_{1}, \quad y_{1}^{\prime}\left(x_{0}\right)=k_{2}
$$

and

$$
y_{2}\left(x_{0}\right)=k_{3}, \quad y_{2}^{\prime}\left(x_{0}\right)=k_{4}
$$

for $x_{0}>0$. Show that

$$
W\left(y_{1}, y_{2}\right)=\frac{\left(k_{1} k_{4}-k_{2} k_{3}\right) x_{0}}{x}
$$

\begin{enumerate}
  \setcounter{enumi}{49}
  \item Suppose the mathematical model of a linear system is given by
\end{enumerate}

$$
a_{2}(t) \frac{d^{2} y}{d t^{2}}+a_{1}(t) \frac{d y}{d t}+a_{0}(t) y=E(t)
$$

If $y_{1}$ is a response of the system to an input $E_{1}(t)$ and $y_{2}$ is a response of the same system to an input $E_{2}(t)$, show that $y_{1}+y_{2}$ is a response of the system to the input $E_{1}(t)+E_{2}(t)$.

\subsection*{4.2 CONSTRUCTING A SECOND SOLUTION FROM A KNOWN SOLUTION}
\begin{itemize}
  \item Reduction of order
\end{itemize}

Reduction of Order It is one of the more interesting as well as important facts in the study of linear second-order differential equations that we can construct a second solution from a known solution. Suppose $y_{1}(x)$ is a nonzero solution of the equation


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0 \tag{1}
\end{equation*}


We assume, as we did in the preceding section, that the coefficients in (1) are continuous and $a_{2}(x) \neq 0$ for every $x$ in some interval $I$. The process we use to find a second solution $y_{2}(x)$ consists of reducing the order of equation (1) to a first-order equation. For example, it is easily verified that $y_{1}=e^{x}$ satisfies the differential equation $y^{\prime \prime}-y=0$. If we try to determine a solution of the form $y=u(x) e^{x}$, then

$$
y^{\prime}=u e^{x}+e^{x} u^{\prime}, \quad y^{\prime \prime}=u e^{x}+2 e^{x} u^{\prime}+e^{x} u^{\prime \prime}
$$

and so

Since $e^{x} \neq 0$, this last equation requires that $u^{\prime \prime}+2 u^{\prime}=0$.

If we let $w=u^{\prime}$, then the latter equation is recognized as a linear first-order equation $w^{\prime}+2 w=0$. Using the integrating factor $e^{2 x}$, we can write

$$
\begin{gathered}
\frac{d}{d x}\left[e^{2 x} w\right]=0 \\
w=c_{1} e^{-2 x} \text { or } u^{\prime}=c_{1} e^{-2 x}
\end{gathered}
$$

Thus

$$
u=-\frac{c_{1}}{2} e^{-2 x}+c_{2} \quad \text { and } \quad y=u(x) e^{x}=-\frac{c_{1}}{2} e^{-x}+c_{2} e^{x}
$$

By picking $c_{2}=0$ and $c_{1}=-2$, we obtain the second solution $y_{2}=e^{-x}$. Since $W\left(e^{x}, e^{-x}\right) \neq 0$ for every $x$, the solutions are linearly independent on $(-\infty, \infty)$ and thus the expression for $y$ is actually the general solution of the given equation.

\section*{EXAMPLE 1 A Second Solution by Reduction of Order}
Given that $y_{1}=x^{3}$ is a solution of $x^{2} y^{\prime \prime}-6 y=0$, use reduction of order to find a second solution on the interval $(0, \infty)$.

Solution Define $y=u(x) x^{3}$ so that

$$
y^{\prime}=3 x^{2} u+x^{3} u^{\prime}, \quad y^{\prime \prime}=x^{3} u^{\prime \prime}+6 x^{2} u^{\prime}+6 x u
$$

and

$$
\begin{aligned}
x^{2} y^{\prime \prime}-6 y & =x^{2}\left(x^{3} u^{\prime \prime}+6 x^{2} u^{\prime}+6 x u\right)-6 u x^{3} \\
& =x^{5} u^{\prime \prime}+6 x^{4} u^{\prime}=0
\end{aligned}
$$

provided $u(x)$ is a solution of

$$
x^{5} u^{\prime \prime}+6 x^{4} u^{\prime}=0 \quad \text { or } \quad u^{\prime \prime}+\frac{6}{x} u^{\prime}=0
$$

If $w=u^{\prime}$, we obtain the linear first-order equation

$$
w^{\prime}+\frac{6}{x} w=0
$$

which possesses the integrating factor $e^{6 \int d x / x}=e^{6 \ln x}=x^{6}$. Now

$$
\frac{d}{d x}\left[x^{6} w\right]=0 \quad \text { gives } \quad x^{6} w=c_{1}
$$

Therefore $w=u^{\prime}=\frac{c_{1}}{x^{6}}$, and thus

$$
u=-\frac{c_{1}}{5 x^{5}}+c_{2} \text { and } \quad y=u(x) x^{3}=-\frac{c_{1}}{5 x^{2}}+c_{2} x^{3}
$$

Choosing $c_{2}=0$ and $c_{1}=-5$ yields the second solution $y_{2}=1 / x^{2}$.

General Case Suppose we divide by $a_{2}(x)$ in order to put equation (1) in the standard form


\begin{equation*}
y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=0 \tag{2}
\end{equation*}


where $P(x)$ and $Q(x)$ are continuous on some interval $I$. Let us suppose further that $y_{1}(x)$ is a known solution of (2) on $I$ and that $y_{1}(x) \neq 0$ for every $x$ in the interval. If we define $y=u(x) y_{1}(x)$, it follows that

$$
\begin{gathered}
y^{\prime}=u y_{1}^{\prime}+y_{1} u^{\prime}, \quad y^{\prime \prime}=u y_{1}^{\prime \prime}+2 y_{1}^{\prime} u^{\prime}+y_{1} u^{\prime \prime} \\
y^{\prime \prime}+P y^{\prime}+Q y=u[\underbrace{y_{1}^{\prime \prime}+P y_{1}^{\prime}+Q y_{1}}_{\text {zero }}]+y_{1} u^{\prime \prime}+\left(2 y_{1}^{\prime}+P y_{1}\right) u^{\prime}=0 .
\end{gathered}
$$

This implies that we must have


\begin{equation*}
y_{1} u^{\prime \prime}+\left(2 y_{1}^{\prime}+P y_{1}\right) u^{\prime}=0 \quad \text { or } \quad y_{1} w^{\prime}+\left(2 y_{1}^{\prime}+P y_{1}\right) w^{\prime}=0 \tag{3}
\end{equation*}


where we have let $w=u^{\prime}$. Observe that equation (3) is both linear and separable. Applying the latter technique, we obtain

$$
\begin{gathered}
\frac{d w}{w}+2 \frac{y_{1}^{\prime}}{y_{1}} d x+P d x=0 \\
\ln |w|+2 \ln \left|y_{1}\right|=-\int P d x+c \text { or } \ln \left|w y_{1}^{2}\right|=-\int P d x+c \\
w y_{1}^{2}=c_{1} e^{-\int P d x} \text { or } w=u^{\prime}=c_{1} \frac{e^{-\int P d x}}{y_{1}^{2}} .
\end{gathered}
$$

Integrating again gives $u=c_{1} \int \frac{e^{-\int P d x}}{y_{1}^{2}} d x+c_{2}$ and therefore

$$
y=u(x) y_{1}(x)=c_{1} y_{1}(x) \int \frac{e^{-\int P(x) d x}}{y_{1}^{2}(x)} d x+c_{2} y_{1}(x)
$$

By choosing $c_{2}=0$ and $c_{1}=1$, we find that a second solution of equation (2) is


\begin{equation*}
y_{2}=y_{1}(x) \int \frac{e^{-\int P(x) d x}}{y_{1}^{2}(x)} d x \tag{4}
\end{equation*}


It makes a good review exercise in differentiation to start with formula (4) and actually verify that equation (2) is satisfied.

Now $y_{1}(x)$ and $y_{2}(x)$ are linearly independent, since

$$
W\left(y_{1}(x), y_{2}(x)\right)=\left|\begin{array}{cc}
y_{1} & y_{1} \int \frac{e^{-\int P d x}}{y_{1}^{2}} d x \\
y_{1}^{\prime} & \frac{e^{-\int P d x}}{y_{1}} d x+y_{1}^{\prime} \int \frac{e^{-\int P d x}}{y_{1}^{2}} d x
\end{array}\right|=e^{-\int P d x}
$$

is not zero on any interval on which $y_{1}(x)$ is not zero.*

\section*{EXAMPLE 2 A Second Solution by Formula (4)}
The function $y_{1}=x^{2}$ is a solution of $x^{2} y^{\prime \prime}-3 x y^{\prime}+4 y=0$. Find the general solution on the interval $(0, \infty)$.
\footnotetext{\begin{itemize}
  \item Alternatively, if $y_{2}=u(x) y_{1}$, then $W\left(y_{1}, y_{2}\right)=u^{\prime}\left(y_{1}\right)^{2} \neq 0$, since $y_{1} \neq 0$ for every $x$ on some interval. If $u^{\prime}=0$, then $u=$ constant.
\end{itemize}
}

Solution Since the equation has the alternative form

we find from (4)

$$
\begin{aligned}
y^{\prime \prime} & -\frac{3}{x} y^{\prime}+\frac{4}{x^{2}} y=0 \\
y_{2} & =x^{2} \int \frac{e^{3 \int d x / x}}{x^{4}} d x \quad \leftarrow e^{3 d d x x}=e^{\ln x^{3}}=x^{3} \\
& =x^{2} \int \frac{d x}{x}=x^{2} \ln x
\end{aligned}
$$

The general solution on $(0, \infty)$ is given by $y=c_{1} y_{1}+c_{2} y_{2}$; that is,

$$
y=c_{1} x^{2}+c_{2} x^{2} \ln x
$$

\section*{EXAMPLE 3 A Second Solution by Formula (4)}
It can be verified that $y_{1}=\frac{\sin x}{\sqrt{x}}$ is a solution of $x^{2} y^{\prime \prime}-x y^{\prime}+\left(x^{2}-\frac{1}{4}\right) y=0$ on $(0, \pi)$. Find a second solution.

Solution First put the equation into the form

$$
y^{\prime \prime}+\frac{1}{x} y^{\prime}+\left(1-\frac{1}{4 x^{2}}\right) y=0
$$

Then from (4) we have

$$
\begin{aligned}
y_{2} & =\frac{\sin x}{\sqrt{x}} \int \frac{e^{-\int d x / x}}{\left(\frac{\sin x}{\sqrt{x}}\right)^{2}} d x \quad \leftarrow e^{-\int d d x}=e^{\ln x^{-1}}=x^{-1} \\
& =\frac{\sin x}{\sqrt{x}} \int \csc ^{2} x d x \\
& =\frac{\sin x}{\sqrt{x}}(-\cot x)=-\frac{\cos x}{\sqrt{x}}
\end{aligned}
$$

Since the differential equation is homogeneous, we can disregard the negative sign and take the second solution to be $y_{2}=(\cos x) / \sqrt{x}$.

Observe that $y_{1}(x)$ and $y_{2}(x)$ of Example 3 are linearly independent solutions of the given differential equation on the larger interval $(0, \infty)$.

Remarks We have derived and illustrated how to use (4) because you will see this formula again in the next section and in Section 6.1. We use (4) simply to save time in obtaining a desired result. Your instructor will tell you whether you should memorize (4) or whether you should know the first principles of reduction of order.

Answers to odd-numbered problems begin on page A-7.

In Problems 1-30 find a second solution of each differential equation. Use reduction of order or formula (4) as instructed. Assume an appropriate interval of validity.

\begin{enumerate}
  \item $y^{\prime \prime}+5 y^{\prime}=0 ; \quad y_{1}=1$
  \item $y^{\prime \prime}-y^{\prime}=0 ; \quad y_{1}=1$
  \item $y^{\prime \prime}-4 y^{\prime}+4 y=0 ; \quad y_{1}=e^{2 x}$
  \item $y^{\prime \prime}+2 y^{\prime}+y=0 ; \quad y_{1}=x e^{-x}$
  \item $y^{\prime \prime}+16 y=0 ; \quad y_{1}=\cos 4 x$
  \item $y^{\prime \prime}+9 y=0 ; \quad y_{1}=\sin 3 x$
  \item $y^{\prime \prime}-y=0 ; \quad y_{1}=\cosh x$
  \item $y^{\prime \prime}-25 y=0 ; \quad y_{1}=e^{5 x}$
  \item $9 y^{\prime \prime}-12 y^{\prime}+4 y=0 ; \quad y_{1}=e^{2 x / 3}$
  \item $6 y^{\prime \prime}+y^{\prime}-y=0 ; \quad y_{1}=e^{x / 3}$
  \item $x^{2} y^{\prime \prime}-7 x y^{\prime}+16 y=0 ; \quad y_{1}=x^{4}$
  \item $x^{2} y^{\prime \prime}+2 x y^{\prime}-6 y=0 ; \quad y_{1}=x^{2}$
  \item $x y^{\prime \prime}+y^{\prime}=0 ; \quad y_{1}=\ln x$
  \item $4 x^{2} y^{\prime \prime}+y=0 ; \quad y_{1}=x^{1 / 2} \ln x$
  \item $\left(1-2 x-x^{2}\right) y^{\prime \prime}+2(1+x) y^{\prime}-2 y=0 ; \quad y_{1}=x+1$
  \item $\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}=0 ; \quad y_{1}=1$
  \item $x^{2} y^{\prime \prime}-x y^{\prime}+2 y=0 ; \quad y_{1}=x \sin (\ln x)$
  \item $x^{2} y^{\prime \prime}-3 x y^{\prime}+5 y=0 ; \quad y_{1}=x^{2} \cos (\ln x)$
  \item $(1+2 x) y^{\prime \prime}+4 x y^{\prime}-4 y=0 ; \quad y_{1}=e^{-2 x}$
  \item $(1+x) y^{\prime \prime}+x y^{\prime}-y=0 ; \quad y_{1}=x$
  \item $x^{2} y^{\prime \prime}-x y^{\prime}+y=0 ; \quad y_{1}=x$
  \item $x^{2} y^{\prime \prime}-20 y=0 ; \quad y_{1}=x^{-4}$
  \item $x^{2} y^{\prime \prime}-5 x y^{\prime}+9 y=0 ; \quad y_{1}=x^{3} \ln x$
  \item $x^{2} y^{\prime \prime}+x y^{\prime}+y=0 ; \quad y_{1}=\cos (\ln x)$
  \item $x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=0 ; \quad y_{1}=x^{2}+x^{3}$
  \item $x^{2} y^{\prime \prime}-7 x y^{\prime}-20 y=0 ; \quad y_{1}=x^{10}$
  \item $(3 x+1) y^{\prime \prime}-(9 x+6) y^{\prime}+9 y=0 ; \quad y_{1}=e^{3 x}$
  \item $x y^{\prime \prime}-(x+1) y^{\prime}+y=0 ; \quad y_{1}=e^{x}$
  \item $y^{\prime \prime}-3(\tan x) y^{\prime}=0 ; \quad y_{1}=1$
  \item $x y^{\prime \prime}-(2+x) y^{\prime}=0 ; \quad y_{1}=1$
\end{enumerate}

In Problems 31-34 use the method of reduction of order to find a solution of the given nonhomogeneous equation. The indicated function $y_{1}(x)$ is a solution of the associated homogeneous equation. Determine a second solution of the homogeneous equation and a particular solution of the nonhomogeneous equation.\\
31. $y^{\prime \prime}-4 y=2 ; \quad y_{1}=e^{-2 x}$\\
32. $y^{\prime \prime}+y^{\prime}=1 ; \quad y_{1}=1$\\
33. $y^{\prime \prime}-3 y^{\prime}+2 y=5 e^{3 x} ; \quad y_{1}=e^{x}$\\
34. $y^{\prime \prime}-4 y^{\prime}+3 y=x ; \quad y_{1}=e^{x}$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item Verify by direct substitution that formula (4) satisfies equation (2).
\end{enumerate}

\subsection*{4.3 HOMOGENEOUS LINEAR EQUATIONS WITH CONSTANT COEFFICIENTS \\
 - Auxiliary equation \\
 - Second-order equations \\
 - Euler's formula \\
 - Higher-order equations}
We have seen that the linear first-order equation $d y / d x+a y=0$, where $a$ is a constant, has the exponential solution $y=c_{1} e^{-a x}$ on $(-\infty, \infty)$. Therefore, it is natural to seek to determine whether exponential solutions exist on $(-\infty, \infty)$ for higher-order equations such as


\begin{equation*}
a_{n} y^{(n)}+a_{n-1} y^{(n-1)}+\cdots+a_{2} y^{\prime \prime}+a_{1} y^{\prime}+a_{0} y=0 \tag{1}
\end{equation*}


where the $a_{i}, i=0,1, \ldots, n$ are constants. The surprising fact is that all solutions of (1) are exponential functions or constructed out of exponential functions. We begin by considering the special case of the second-order equation

Auxiliary Equation If we try a solution of the form $y=e^{m x}$, then $y^{\prime}=m e^{m x}$ and $y^{\prime \prime}=m^{2} e^{m x}$, so equation (2) becomes

$$
a m^{2} e^{m x}+b m e^{m x}+c e^{m x}=0 \text { or } \quad e^{m x}\left(a m^{2}+b m+c\right)=0
$$

Because $e^{m x}$ is never zero for real values of $x$, it is apparent that the only way that this exponential function can satisfy the differential equation is if we choose $m$ so that it is a root of the quadratic equation

This latter equation is called the auxiliary equation, or characteristic equation, of the differential equation (2). We consider three cases-namely, the solutions of the auxiliary equation corresponding to distinct real roots, real but equal roots, and a conjugate pair of complex roots.

Case I: Distinct Real Roots Under the assumption that the auxiliary equation (3) has two unequal real roots $m_{1}$ and $m_{2}$, we find two solutions $y_{1}=e^{m_{1} x}$ and $y_{2}=e^{m_{2} x}$. We have seen that these functions are linearly independent on $(-\infty, \infty)$ (see Example 13, Section 4.1) and hence form a fundamental set. It follows that the general solution of (2) on this interval is

Case I: Repeated Real Roots When $m_{1}=m_{2}$, we necessarily obtain only one exponential solution $y_{1}=e^{m_{1} x}$. However, it follows immediately from the discussion of Section 4.2 that a second solution is


\begin{equation*}
y_{2}=e^{m_{1} x} \int \frac{e^{-(b / a) x}}{e^{2 m_{1} x}} d x \tag{5}
\end{equation*}


But from the quadratic formula, we have $m_{1}=-b / 2 a$ since the only way to have $m_{1}=m_{2}$ is to have $b^{2}-4 a c=0$. In view of the fact that $2 m_{1}=-b / a$, (5) becomes

$$
y_{2}=e^{m_{1} x} \int \frac{e^{2 m_{1} x}}{e^{2 m_{1} x}} d x=e^{m_{1} x} \int d x=x e^{m_{1} x}
$$

The general solution of (2) is then


\begin{equation*}
y=c_{1} e^{m_{1} x}+c_{2} x e^{m_{1} x} \tag{6}
\end{equation*}


Case III: Conjugate Complex Roots If $m_{1}$ and $m_{2}$ are complex, then we can write

$$
m_{1}=\alpha+i \beta \text { and } m_{2}=\alpha-i \beta
$$

where $\alpha$ and $\beta>0$ are real and $i^{2}=-1$. Formally there is no difference between this case and Case I , and hence

$$
y=C_{1} e^{(\alpha+i \beta) x}+C_{2} e^{(\alpha-i \beta) x}
$$

However, in practice we prefer to work with real functions instead of complex exponentials. To this end we use Euler's formula:*

$$
e^{i \theta}=\cos \theta+i \sin \theta,
$$

where $\theta$ is any real number. It follows from this formula that


\begin{equation*}
e^{i \beta x}=\cos \beta x+i \sin \beta x \text { and } \quad e^{-i \beta x}=\cos \beta x-i \sin \beta x \tag{array}
\end{equation*}


where we have used $\cos (-\beta x)=\cos \beta x$ and $\sin (-\beta x)=-\sin \beta x$. Note that by first adding and then subtracting the two equations in (7), we obtain, respectively,

$$
e^{i \beta x}+e^{-i \beta x}=2 \cos \beta x \text { and } \quad e^{i \beta x}-e^{-i \beta x}=2 i \sin \beta x
$$

Since $y=C_{1} e^{(\alpha+i \beta) x}+C_{2} e^{(\alpha-i \beta) x}$ is a solution of (2) for any choice of the constants $C_{1}$ and $C_{2}$, the choices $C_{1}=C_{2}=1$ and $C_{1}=1, C_{2}=-1$ give, in turn, two solutions:

$$
y_{1}=e^{(\alpha+i \beta) x}+e^{(\alpha-i \beta) x} \text { and } y_{2}=e^{(\alpha+i \beta) x}-e^{(\alpha-i \beta) x}
$$
\footnotetext{\begin{itemize}
  \item LEONHARD EULER (1707-1783) A man with a prodigious memory and phenomenal powers of concentration, Euler had almost universal interests; he was a theologian, physicist, astronomer, linguist, physiologist, classical scholar, and, primarily, mathematician. Euler is considered to be a true genius of the era. In mathematics, he made lasting contributions to algebra, trigonometry, analytic geometry, calculus, calculus of variations, differential equations, complex variables, number theory, and topology. The volume of his mathematical output did not seem to be affected by the distractions of thirteen children or the fact that he was totally blind for the last seventeen years of his life. Euler wrote over 700 papers and 32 books on mathematics and was responsible for introducing many of the symbols (such as $e, \pi$, and $i=\sqrt{-1}$ ) and notations (such as $f(x), \Sigma, \sin x$, and $\cos x$ ) that are still used. Euler was born in Basel, Switzerland, on April 15, 1707, and died of a stroke in St. Petersburg on September 18, 1783, while serving in the court of the Russian empress Catherine the Great. mula.
\end{itemize}

See Appendix IV for a review of complex numbers and a derivation of Euler's for-
}

But

$$
y_{1}=e^{\alpha x}\left(e^{i \beta x}+e^{-i \beta x}\right)=2 e^{\alpha x} \cos \beta x
$$

and

$$
y_{2}=e^{\alpha x}\left(e^{i \beta x}-e^{-i \beta x}\right)=2 i e^{\alpha x} \sin \beta x
$$

Hence, from Corollary (A) of Theorem 4.3 the last two results show that the real functions $e^{\alpha x} \cos \beta x$ and $e^{\alpha x} \sin \beta x$ are solutions of (2). Moreover, from Example 14 of Section 4.1 we have $W\left(e^{\alpha x} \cos \beta x, e^{\alpha x} \sin \beta x\right)=$ $\beta e^{2 \alpha x} \neq 0, \beta>0$, and so we can conclude that $e^{\alpha x} \cos \beta x$ and $e^{\alpha x} \sin \beta x$ themselves form a fundamental set of solutions of the differential equation on $(-\infty, \infty)$. By the superposition principle, the general solution is


\begin{equation*}
y=c_{1} e^{\alpha x} \cos \beta x+c_{2} e^{\alpha x} \sin \beta x=e^{\alpha x}\left(c_{1} \cos \beta x+c_{2} \sin \beta x\right) \tag{8}
\end{equation*}


\section*{EXAMPLE 1 Second-Order DEs}
Solve the following differential equations:\\
(a) $2 y^{\prime \prime}-5 y^{\prime}-3 y=0$\\
(b) $y^{\prime \prime}-10 y^{\prime}+25 y=0$\\
(c) $y^{\prime \prime}+y^{\prime}+y=0$

\section*{Solution}
(a) $2 m^{2}-5 m-3=(2 m+1)(m-3)=0, m_{1}=-\frac{1}{2}, m_{2}=3$,

$$
y=c_{1} e^{-x / 2}+c_{2} e^{3 x}
$$

(b) $m^{2}-10 m+25=(m-5)^{2}=0, m_{1}=m_{2}=5$,

$$
y=c_{1} e^{5 x}+c_{2} x e^{5 x}
$$

(c) $m^{2}+m+1=0, m_{1}=-\frac{1}{2}+\frac{\sqrt{3}}{2} i, m_{2}=-\frac{1}{2}-\frac{\sqrt{3}}{2} i$,

$$
y=e^{-x / 2}\left(c_{1} \cos \frac{\sqrt{3}}{2} x+c_{2} \sin \frac{\sqrt{3}}{2} x\right)
$$

\section*{EXAMPLE 2 An Initial-Value Problem}
Solve the initial-value problem $y^{\prime \prime}-4 y^{\prime}+13 y=0, y(0)=-1, y^{\prime}(0)=2$.

Solution The roots of the auxiliary equation $m^{2}-4 m+13=0$ are $m_{1}=2+3 i$ and $m_{2}=2-3 i$, so

$$
y=e^{2 x}\left(c_{1} \cos 3 x+c_{2} \sin 3 x\right)
$$

The condition $y(0)=-1$ implies

$$
-1=e^{0}\left(c_{1} \cos 0+c_{2} \sin 0\right)=c_{1}
$$

from which we can write

$$
y=e^{2 x}\left(-\cos 3 x+c_{2} \sin 3 x\right)
$$

Differentiating this latter expression yields

$$
y^{\prime}=e^{2 x}\left(3 \sin 3 x+3 c_{2} \cos 3 x\right)+2 e^{2 x}\left(-\cos 3 x+c_{2} \sin 3 x\right)
$$

and using $y^{\prime}(0)=2$ gives $3 c_{2}-2=2$, and so $c_{2}=\frac{4}{3}$. Hence

$$
y=e^{2 x}\left(-\cos 3 x+\frac{4}{3} \sin 3 x\right)
$$

\section*{EXAMPLE 3 Two Second-Order DEs Worth Knowing}
The two equations


\begin{align*}
& y^{\prime \prime}+k^{2} y=0  \tag{array}\\
& y^{\prime \prime}-k^{2} y=0 \tag{10}
\end{align*}


are frequently encountered in the study of applied mathematics. For the former differential equation, the auxiliary equation $m^{2}+k^{2}=0$ has the roots $m_{1}=k i$ and $m_{2}=-k i$. It follows from (8) that the general solution of (9) is


\begin{equation*}
y=c_{1} \cos k x+c_{2} \sin k x \tag{11}
\end{equation*}


The differential equation (10) has the auxiliary equation $m^{2}-k^{2}=0$, with real roots $m_{1}=k$ and $m_{2}=-k$, so its general solution is


\begin{equation*}
y=c_{1} e^{k x}+c_{2} e^{-k x} \tag{12}
\end{equation*}


Notice that if we choose $c_{1}=c_{2}=\frac{1}{2}$ in (12), then

$$
y=\frac{e^{k x}+e^{-k x}}{2}=\cosh k x
$$

is also a solution of (10). Furthermore, if $c_{1}=\frac{1}{2}, c_{2}=-\frac{1}{2}$, then (12) becomes

$$
y=\frac{e^{k x}-e^{-k x}}{2}=\sinh k x
$$

Since cosh $k x$ and $\sinh k x$ are linearly independent on any interval of the $x$-axis, they form a fundamental set. Thus an alternative form for the general solution of (10) is


\begin{equation*}
y=c_{1} \cosh k x+c_{2} \sinh k x \tag{13}
\end{equation*}


Higher-Order Equations In general, to solve an $n$ th-order differential equation


\begin{equation*}
a_{n} y^{(n)}+a_{n-1} y^{(n-1)}+\cdots+a_{2} y^{\prime \prime}+a_{1} y^{\prime}+a_{0} y=0 \tag{14}
\end{equation*}


where the $a_{i}, i=0,1, \ldots, n$ are real constants, we must solve an $n$ th-degree polynominal equation


\begin{equation*}
a_{n} m^{n}+a_{n-1} m^{n-1}+\cdots+a_{2} m^{2}+a_{1} m+a_{0}=0 \tag{array}
\end{equation*}


If all the roots of (15) are real and distinct, then the general solution of (14) is


\begin{equation*}
y=c_{1} e^{m_{1} x}+c_{2} e^{m_{2} x}+\cdots+c_{n} e^{m_{2 x} x} \tag{16}
\end{equation*}


It is somewhat harder to summarize the analogues of Cases II and III because the roots of an auxiliary equation of degree greater than two can occur in many combinations. For example, a fifth-degree equation could have five distinct real roots, or three distinct real and two complex roots, or one real and four complex\\
roots, or five real but equal roots, or five real roots but two of them equal, and so on. When $m_{1}$ is a root of multiplicity $k$ of an $n$ th-degree auxiliary equation (that is, $k$ roots are equal to $m_{1}$ ), it can be shown that the linearly independent solutions are

$$
e^{m_{1} x}, x e^{m_{1} x}, x^{2} e^{m_{1} x}, \ldots, x^{k-1} e^{m_{1} x}
$$

and the general solution must contain the linear combination

$$
c_{1} e^{m_{1} x}+c_{2} x e^{m_{1} x}+c_{3} x^{2} e^{m_{1} x}+\cdots+c_{k} x^{k-1} e^{m_{1} x}
$$

Lastly, it should be remembered that when the coefficients are real, complex roots of an auxiliary equation always appear in conjugate pairs. Thus, for example, a cubic polynomial equation can have at most two complex roots.

\section*{EXAMPLE 4 Third-Order DE}
Solve $y^{\prime \prime \prime}+3 y^{\prime \prime}-4 y=0$.

Solution It should be apparent from inspection of

$$
m^{3}+3 m^{2}-4=0
$$

that one root is $m_{1}=1$. Now if we divide $m^{3}+3 m^{2}-4$ by $m-1$, we find that

$$
m^{3}+3 m^{2}-4=(m-1)\left(m^{2}+4 m+4\right)=(m-1)(m+2)^{2}
$$

and so the other roots are $m_{2}=m_{3}=-2$. Thus the general solution is

$$
y=c_{1} e^{x}+c_{2} e^{-2 x}+c_{3} x e^{-2 x}
$$

Of course, the most difficult aspect of solving constant-coefficient equations is finding the roots of auxiliary equations of degree greater than two. As illustrated in Example 4, one way to solve an equation is to guess a root $m_{1}$. If we have found one root $m_{1}$, we then know from the factor theorem that $m-m_{1}$ is a factor of the polynomial. By dividing the polynomial by $m-m_{1}$, we obtain the factorization $\left(m-m_{1}\right) Q(m)$. We then try to find the roots of the quotient $Q(\mathrm{~m})$. The algebraic technique of synthetic division is also very helpful in finding rational roots of polynomial equations. Specifically, if $m_{1}=p / q$ is a rational real root ( $p$ and $q$ integers, $p / q$ in lowest terms) of an auxiliary equation

$$
a_{n} m^{n}+\cdots+a_{1} m+a_{0}=0
$$

with integer coefficients, then $p$ is a factor of $a_{0}$ and $q$ is a factor of $a_{n}$. Thus to determine whether a polynomial equation has rational roots we need only examine all ratios of each factor of $a_{0}$ to each factor of $a_{n}$. In this manner we construct a list of all the possible rational roots of the equation. We test each of these numbers by synthetic division. If the remainder is zero, the number $m_{1}$ being tested is a root of the equation and thus $m-m_{1}$ is a factor of the polynomial.

The next example illustrates this method.

\section*{EXAMPLE 5 Using Synthetic Division}
Solve $3 y^{\prime \prime \prime}+5 y^{\prime \prime}+10 y^{\prime}-4 y=0$.

Solution The auxiliary equation is

$$
3 m^{3}+5 m^{2}+10 m-4=0
$$

All the factors of $a_{0}=-4$ and $a_{n}=3$ are

$$
p: \pm 1, \pm 2, \pm 4 \quad \text { and } \quad q: \pm 1, \pm 3
$$

respectively. Therefore the possible rational roots of the auxiliary equation are

$$
\frac{p}{q}:-1,1,-2,2,-4,4,-\frac{1}{3}, \frac{1}{3},-\frac{2}{3}, \frac{2}{3},-\frac{4}{3}, \frac{4}{3}
$$

Testing each of these numbers in turn by synthetic division, we eventually find

coefficients of auxiliary equation

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-164}
\end{center}

Consequently $m_{1}=\frac{1}{3}$ is a root. Furthermore, you should verify that it is the only rational root. The numbers highlighted in the preceding division are the coefficients of the quotient. Thus the auxiliary equation can be written as

$$
\left(m-\frac{1}{3}\right)\left(3 m^{2}+6 m+12\right)=0 \quad \text { or } \quad(3 m-1)\left(m^{2}+2 m+4\right)=0
$$

Solving $m^{2}+2 m+4=0$ by the quadratic formula leads to the complex roots $m_{2}=-1+\sqrt{3} i$ and $m_{3}=-1-\sqrt{3} i$. Thus the general solution of the differential equation is

$$
y=c_{1} e^{x / 3}+e^{-x}\left(c_{2} \cos \sqrt{3} x+c_{3} \sin \sqrt{3} x\right)
$$

\section*{EXAMPLE 6 Fourth-Order DE}
Solve $\frac{d^{4} y}{d x^{4}}+2 \frac{d^{2} y}{d x^{2}}+y=0$.

Solution The auxiliary equation

$$
m^{4}+2 m^{2}+1=\left(m^{2}+1\right)^{2}=0
$$

has roots $m_{1}=m_{3}=i$ and $m_{2}=m_{4}=-i$. Thus from Case II the solution is

$$
y=C_{1} e^{i x}+C_{2} e^{-i x}+C_{3} x e^{i x}+C_{4} x e^{-i x}
$$

By Euler's formula the grouping $C_{1} e^{i x}+C_{2} e^{-i x}$ can be rewritten as

$$
c_{1} \cos x+c_{2} \sin x
$$

after a relabeling of constants. Similarly, $x\left(C_{3} e^{i x}+C_{4} e^{-i x}\right)$ can be expressed as $x\left(c_{3} \cos x+c_{4} \sin x\right)$. Hence the general solution is

$$
y=c_{1} \cos x+c_{2} \sin x+c_{3} x \cos x+c_{4} x \sin x
$$

Example 6 illustrates a special case when the auxiliary equation has repeated complex roots. In general, if $m_{1}=\alpha+i \beta, \beta>0$ is a complex root of multiplicity $k$ of an auxiliary equation with real coefficients, then its conjugate $m_{2}=\alpha-i \beta$ is also a root of multiplicity $k$. From the $2 k$ complex-valued solutions

$$
\begin{aligned}
& e^{(\alpha+i \beta) x}, \quad x e^{(\alpha+i \beta) x}, \quad x^{2} e^{(\alpha+i \beta) x}, \ldots, \quad x^{k-1} e^{(\alpha+i \beta) x} \\
& e^{(\alpha-i \beta) x}, \quad x e^{(\alpha-i \beta) x}, \quad x^{2} e^{(\alpha-i \beta) x}, \ldots, \quad x^{k-1} e^{(\alpha-i \beta) x}
\end{aligned}
$$

we conclude, with the aid of Euler's formula, that the general solution of the corresponding differential equation must then contain a linear combination of the $2 k$ real linearly independent solutions

$$
\begin{array}{rrrrr}
e^{\alpha x} \cos \beta x, & x e^{\alpha x} \cos \beta x, & x^{2} e^{\alpha x} \cos \beta x, & \ldots, & x^{k-1} e^{\alpha x} \cos \beta x \\
e^{\alpha x} \sin \beta x, & x e^{\alpha x} \sin \beta x, & x^{2} e^{\alpha x} \sin \beta x, & \ldots, & x^{k-1} e^{\alpha x} \sin \beta x
\end{array}
$$

In Example 6 we identify $k=2, \alpha=0$, and $\beta=1$.

\section*{EXERCISES 4.3}
Answers to odd-numbered problems begin on page A-8.

In Problems 1-36 find the general solution of the given differential equation.

\begin{enumerate}
  \item $4 y^{\prime \prime}+y^{\prime}=0$
  \item $2 y^{\prime \prime}-5 y^{\prime}=0$
  \item $y^{\prime \prime}-36 y=0$
  \item $y^{\prime \prime}-8 y=0$
  \item $y^{\prime \prime}+9 y=0$
  \item $3 y^{\prime \prime}+y=0$
  \item $y^{\prime \prime}-y^{\prime}-6 y=0$
  \item $y^{\prime \prime}-3 y^{\prime}+2 y=0$
  \item $\frac{d^{2} y}{d x^{2}}+8 \frac{d y}{d x}+16 y=0$
  \item $\frac{d^{2} y}{d x^{2}}-10 \frac{d y}{d x}+25 y=0$
  \item $y^{\prime \prime}+3 y^{\prime}-5 y=0$
  \item $y^{\prime \prime}+4 y^{\prime}-y=0$
  \item $12 y^{\prime \prime}-5 y^{\prime}-2 y=0$
  \item $8 y^{\prime \prime}+2 y^{\prime}-y=0$
  \item $y^{\prime \prime}-4 y^{\prime}+5 y=0$
  \item $2 y^{\prime \prime}-3 y^{\prime}+4 y=0$
  \item $3 y^{\prime \prime}+2 y^{\prime}+y=0$
  \item $2 y^{\prime \prime}+2 y^{\prime}+y=0$
  \item $y^{\prime \prime \prime}-4 y^{\prime \prime}-5 y^{\prime}=0$
  \item $4 y^{\prime \prime \prime}+4 y^{\prime \prime}+y^{\prime}=0$
  \item $y^{\prime \prime \prime}-y=0$
  \item $y^{\prime \prime \prime}+5 y^{\prime \prime}=0$
  \item $y^{\prime \prime \prime}-5 y^{\prime \prime}+3 y^{\prime}+9 y=0$
  \item $y^{\prime \prime \prime}+3 y^{\prime \prime}-4 y^{\prime}-12 y=0$
  \item $y^{\prime \prime \prime}+y^{\prime \prime}-2 y=0$
  \item $y^{\prime \prime \prime}-y^{\prime \prime}-4 y=0$
  \item $y^{\prime \prime \prime}+3 y^{\prime \prime}+3 y^{\prime}+y=0$
  \item $y^{\prime \prime \prime}-6 y^{\prime \prime}+12 y^{\prime}-8 y=0$
  \item $\frac{d^{4} y}{d x^{4}}+\frac{d^{3} y}{d x^{3}}+\frac{d^{2} y}{d x^{2}}=0$
  \item $\frac{d^{4} y}{d x^{4}}-2 \frac{d^{2} y}{d x^{2}}+y=0$
  \item $16 \frac{d^{4} y}{d x^{4}}+24 \frac{d^{2} y}{d x^{2}}+9 y=0$
  \item $\frac{d^{4} y}{d x^{4}}-7 \frac{d^{2} y}{d x^{2}}-18 y=0$
  \item $\frac{d^{5} y}{d x^{5}}-16 \frac{d y}{d x}=0$
  \item $\frac{d^{5} y}{d x^{5}}-2 \frac{d^{4} y}{d x^{4}}+17 \frac{d^{3} y}{d x^{3}}=0$
  \item $\frac{d^{5} y}{d x^{5}}+5 \frac{d^{4} y}{d x^{4}}-2 \frac{d^{3} y}{d x^{3}}-10 \frac{d^{2} y}{d x^{2}}+\frac{d y}{d x}+5 y=0$
  \item $2 \frac{d^{5} y}{d x^{5}}-7 \frac{d^{4} y}{d x^{4}}+12 \frac{d^{3} y}{d x^{3}}+8 \frac{d^{2} y}{d x^{2}}=0$
\end{enumerate}

In Problems 37-52 solve the given differential equation subject to the indicated initial conditions.\\
37. $y^{\prime \prime}+16 y=0, \quad y(0)=2, y^{\prime}(0)=-2$\\
38. $y^{\prime \prime}-y=0, \quad y(0)=y^{\prime}(0)=1$\\
39. $y^{\prime \prime}+6 y^{\prime}+5 y=0, \quad y(0)=0, y^{\prime}(0)=3$\\
40. $y^{\prime \prime}-8 y^{\prime}+17 y=0, \quad y(0)=4, y^{\prime}(0)=-1$\\
41. $2 y^{\prime \prime}-2 y^{\prime}+y=0, \quad y(0)=-1, y^{\prime}(0)=0$\\
42. $y^{\prime \prime}-2 y^{\prime}+y=0, \quad y(0)=5, y^{\prime}(0)=10$\\
43. $y^{\prime \prime}+y^{\prime}+2 y=0, \quad y(0)=y^{\prime}(0)=0$\\
44. $4 y^{\prime \prime}-4 y^{\prime}-3 y=0, \quad y(0)=1, y^{\prime}(0)=5$\\
45. $y^{\prime \prime}-3 y^{\prime}+2 y=0, \quad y(1)=0, y^{\prime}(1)=1$\\
46. $y^{\prime \prime}+y=0, \quad y\left(\frac{\pi}{3}\right)=0, y^{\prime}\left(\frac{\pi}{3}\right)=2$\\
47. $y^{\prime \prime \prime}+12 y^{\prime \prime}+36 y^{\prime}=0, \quad y(0)=0, y^{\prime}(0)=1, y^{\prime \prime}(0)=-7$\\
48. $y^{\prime \prime \prime}+2 y^{\prime \prime}-5 y^{\prime}-6 y=0, \quad y(0)=y^{\prime}(0)=0, y^{\prime \prime}(0)=1$\\
49. $y^{\prime \prime \prime}-8 y=0, \quad y(0)=0, y^{\prime}(0)=-1, y^{\prime \prime}(0)=0$\\
50. $\frac{d^{4} y}{d x^{4}}=0, \quad y(0)=2, y^{\prime}(0)=3, y^{\prime \prime}(0)=4, y^{\prime \prime \prime}(0)=5$\\
51. $\frac{d^{4} y}{d x^{4}}-3 \frac{d^{3} y}{d x^{3}}+3 \frac{d^{2} y}{d x^{2}}-\frac{d y}{d x}=0, \quad y(0)=y^{\prime}(0)=0, y^{\prime \prime}(0)=y^{\prime \prime \prime}(0)=1$\\
52. $\frac{d^{4} y}{d x^{4}}-y=0, \quad y(0)=y^{\prime}(0)=y^{\prime \prime}(0)=0, y^{\prime \prime \prime}(0)=1$

In Problems 53-56 solve the given differential equation subject to the indicated boundary conditions.\\
53. $y^{\prime \prime}-10 y^{\prime}+25 y=0, \quad y(0)=1, y(1)=0$\\
54. $y^{\prime \prime}+4 y=0, \quad y(0)=0, y(\pi)=0$\\
55. $y^{\prime \prime}+y=0, \quad y^{\prime}(0)=0, y^{\prime}\left(\frac{\pi}{2}\right)=2$\\
56. $y^{\prime \prime}-y=0, \quad y(0)=1, y^{\prime}(1)=0$

\begin{enumerate}
  \setcounter{enumi}{56}
  \item The roots of an auxiliary equation are $m_{1}=4, m_{2}=m_{3}=-5$. What is the corresponding differential equation?

  \item The roots of an auxiliary equation are $m_{1}=-\frac{1}{2}, m_{2}=3+i$, $m_{3}=3-i$. What is the corresponding differential equation?

\end{enumerate}

In Problems 59 and 60 find the general solution of the given equation if it is known that $y_{1}$ is a solution.\\
59. $y^{\prime \prime \prime}-9 y^{\prime \prime}+25 y^{\prime}-17 y=0 ; \quad y_{1}=e^{x}$\\
60. $y^{\prime \prime \prime}+6 y^{\prime \prime}+y^{\prime}-34 y=0 ; \quad y_{1}=e^{-4 x} \cos x$

In Problems 61-64 determine a homogeneous linear differential equation with constant coefficients having the given solutions.\\
61. $4 e^{6 x}, 3 e^{-3 x}$\\
62. $10 \cos 4 x,-5 \sin 4 x$\\
63. $3,2 x,-e^{7 x}$\\
64. $8 \sinh 3 x, 12 \cosh 3 x$

\begin{enumerate}
  \setcounter{enumi}{64}
  \item Use the facts
\end{enumerate}

$$
i=\left(\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2} i\right)^{2} \text { and }-i=\left(\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2} i\right)^{2}
$$

to solve the differential equation

$$
\frac{d^{4} y}{d x^{4}}+y=0
$$

[Hint: Write the auxiliary equation $m^{4}+1=0$ as $\left(m^{2}+1\right)^{2}-2 m^{2}=0$. See what happens when you factor.]

\subsection*{4.4 UNDETERMINED COEFFICIENTS SUPERPOSITION APPROACH \\
 - Undetermined coefficients}
Note to the lustructor In this section the method of undetermined coefficients is developed from the viewpoint of the superposition principle for nonhomogeneous differential equations (Theorem 4.9). In Section 4.6 an entirely different approach to this method will be presented, one utilizing the concept of differential annihilator operators. Take your pick.

To obtain the general solution of a nonhomogeneous linear differential equation we must do two things:

(i) Find the complementary function $y_{c}$.

(ii) Find any particular solution $y_{p}$ of the nonhomogeneous equation.

Recall from the discussion of Section 4.1 that a particular solution is any function, free of arbitrary constants, that satisfies the differential equation identically. The general solution of a nonhomogeneous equation on an interval is then $y=y_{c}+y_{p}$.

As in the Section 4.3 we begin with second-order equations, but in this case nonhomogeneous equations of the form


\begin{equation*}
a y^{\prime \prime}+b y^{\prime}+c y=g(x) \tag{1}
\end{equation*}


where $a, b$, and $c$ are constants. Although the method of undetermined coefficients presented in this section is not limited to second-order equations, it is limited to nonhomogeneous linear equations in which

\begin{itemize}
  \item coefficients are constant and
  \item $g(x)$ is a constant $k$, a polynomial function, an exponential function $e^{\alpha x}, \sin \beta x, \cos \beta x$, or finite sums and products of these functions.
\end{itemize}

Note Strictly speaking, $g(x)=k$ (a constant) is a polynomial function. Since a constant function is probably not the first thing that comes to mind when you think of polynomial functions, for emphasis we continue to use the redundancy "constant functions, polynomials, . . . ."

The following are some examples of the types of input functions $g(x)$ that are appropriate for this discussion:

$$
\begin{gathered}
g(x)=10, \quad g(x)=x^{2}-5 x, \quad g(x)=15 x-6+8 e^{-4 x} \\
g(x)=\sin 3 x-5 x \cos 2 x, \quad g(x)=e^{x} \cos x-\left(3 x^{2}-1\right) e^{-x}
\end{gathered}
$$

and so on. That is, $g(x)$ is a linear combination of functions of the type

$$
k \text { (constant), } \quad x^{n}, \quad x^{n} e^{\alpha x}, \quad x^{n} e^{\alpha x} \cos \beta x, \text { and } x^{n} e^{\alpha x} \sin \beta x \text {, }
$$

where $n$ is a nonnegative integer and $\alpha$ and $\beta$ are real numbers. The method of undetermined coefficients is not applicable to equations of form (1) when

$$
g(x)=\ln x, \quad g(x)=\frac{1}{x}, \quad g(x)=\tan x, \quad g(x)=\sin ^{-1} x
$$

and so on. Differential equations with this latter kind of input function will be considered in Section 4.7.

The set of functions that consists of constants, polynomials, exponentials $e^{\alpha x}$, sines, and cosines has the remarkable property that derivatives of their sums and products are again sums and products of constants, polynomials, exponentials $e^{\alpha x}$, sines, and cosines. Since the linear combination of derivatives $a y_{p}^{\prime \prime}+b y_{p}^{\prime}+c y_{p}$ must be identically equal to $g(x)$, it seems reasonable to assume then that $y_{p}$ has the same form as $g(x)$. This assumption could be better characterized as an educated conjecture or guess. The next two examples illustrate the basic method.

\section*{EXAMPLE 1 General Solution}
Solve $y^{\prime \prime}+4 y^{\prime}-2 y=2 x^{2}-3 x+6$.

Solution Step 1. We first solve the associated homogeneous equation $y^{\prime \prime}+4 y^{\prime}-2 y=0$. From the quadratic formula we find that the roots of the auxiliary equation $m^{2}+4 m-2=0$ are $m_{1}=-2-\sqrt{6}$ and $m_{2}=-2+$ $\sqrt{6}$. Hence the complementary function is

$$
y_{c}=c_{1} e^{-(2+\sqrt{6}) x}+c_{2} e^{(-2+\sqrt{6}) x}
$$

Step 2. Now since the input function $g(x)$ is a quadratic polynomial, let us assume a particular solution that is also in the form of a quadratic polynomial:

$$
y_{p}=A x^{2}+B x+C
$$

We seek to determine specific coefficients $A, B$, and $C$ for which $y_{p}$ is a solution of (2). Substituting $y_{p}$ and the derivatives

$$
y_{p}^{\prime}=2 A x+B \quad \text { and } \quad y_{p}^{\prime \prime}=2 A
$$

into the given differential equation (2), we get

$y_{p}^{\prime \prime}+4 y_{p}^{\prime}-2 y_{p}=2 A+8 A x+4 B-2 A x^{2}-2 B x-2 C=2 x^{2}-3 x+6$.

Since the last equation is supposed to be an identity, the coefficients of like powers of $x$ must be equal:

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-169(1)}
\end{center}

That is,

$$
-2 A=2, \quad 8 A-2 B=-3, \quad 2 A+4 B-2 C=6
$$

Solving this system of equations leads to the values $A=-1, B=-\frac{5}{2}$, and $C=-9$. Thus a particular solution is

$$
y_{p}=-x^{2}-\frac{5}{2} x-9
$$

Step 3. The general solution of the given equation is

$$
y=y_{c}+y_{p}=c_{1} e^{-(2+\sqrt{6}) x}+c_{2} e^{(-2+\sqrt{6}) x}-x^{2}-\frac{5}{2} x-9
$$

\section*{EXAMPLE 2 Particular Solution}
Find a particular solution of $y^{\prime \prime}-y^{\prime}+y=2 \sin 3 x$.

Solution A natural first guess for a particular solution would be $A \sin 3 x$. But since successive differentiations of $\sin 3 x$ produce $\sin 3 x$ and $\cos 3 x$, we are prompted instead to assume a particular solution that includes both of these terms:

$$
y_{p}=A \cos 3 x+B \sin 3 x
$$

Differentiating $y_{p}$ and substituting the results into the differential equation gives, after regrouping,

$$
y_{p}^{\prime \prime}-y_{p}^{\prime}+y_{p}=(-8 A-3 B) \cos 3 x+(3 A-8 B) \sin 3 x=2 \sin 3 x
$$

or

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-169}
\end{center}

From the resulting system of equations

$$
-8 A-3 B=0, \quad 3 A-8 B=2
$$

we get $A=\frac{6}{73}$ and $B=-\frac{16}{73}$. A particular solution of the equation is

$$
y_{p}=\frac{6}{73} \cos 3 x-\frac{16}{73} \sin 3 x
$$

As we mentioned, the form that we assume for the particular solution $y_{p}$ is an educated guess; it is not a blind guess. This educated guess must take into consideration not only the types of functions that make up $g(x)$ but also, as we shall see in Example 4, the functions that make up the complementary function $y_{c}$.

\section*{EXAMPLE 3 Forming $y_{p}$ by Superposition}
Solve


\begin{equation*}
y^{\prime \prime}-2 y^{\prime}-3 y=4 x-5+6 x e^{2 x} \tag{3}
\end{equation*}


Solution Step 1. First, the solution of the associated homogeneous equation $y^{\prime \prime}-2 y^{\prime}-3 y=0$ is found to be $y_{c}=c_{1} e^{-x}+c_{2} e^{3 x}$.

Step 2. Next, the presence of $4 x-5$ in $g(x)$ suggests that the particular solution includes a linear polynomial. Furthermore, since the derivative of the product $x e^{2 x}$ produces $2 x e^{2 x}$ and $e^{2 x}$, we also assume that the particular solution includes both $x e^{2 x}$ and $e^{2 x}$. In other words, $g$ is the sum of two basic kinds of functions:

$$
g(x)=g_{1}(x)+g_{2}(x)=\text { polynomial }+ \text { exponentials }
$$

Correspondingly, the superposition principle for nonhomogeneous equations (Theorem 4.9) suggests that we seek a particular solution

$$
y_{p}=y_{p_{1}}+y_{p_{2}}
$$

where $y_{p_{1}}=A x+B$ and $y_{p_{2}}=C x e^{2 x}+D e^{2 x}$. Substituting

$$
y_{p}=A x+B+C x e^{2 x}+D e^{2 x}
$$

into the given equation (3) and grouping like terms gives


\begin{equation*}
y_{p}^{\prime \prime}-2 y_{p}^{\prime}-3 y_{p}=-3 A x-2 A-3 B-3 C x e^{2 x}+(2 C-3 D) e^{2 x}=4 x-5+6 x e^{2 x} \tag{4}
\end{equation*}


From this identity we obtain the system of four equations in four unknowns:

$$
-3 A=4, \quad-2 A-3 B=-5, \quad-3 C=6, \quad 2 C-3 D=0
$$

The last equation in this system results from the interpretation that the coefficient of $e^{2 x}$ in the right member of (4) is zero. Solving, we find $A=-\frac{4}{3}$, $B=-\frac{23}{9}, C=-2$, and $D=-\frac{4}{3}$. Consequently,

$$
y_{p}=-\frac{4}{3} x+\frac{23}{9}-2 x e^{2 x}-\frac{4}{3} e^{2 x}
$$

Step 3. The general solution of the equation is

$$
y=c_{1} e^{-x}+c_{2} e^{3 x}-\frac{4}{3} x+\frac{23}{9}-\left(2 x+\frac{4}{3}\right) e^{2 x}
$$

In light of the superposition principle (Theorem 4.9) we can also approach Example 3 from the viewpoint of solving two simpler problems. You should verify that substituting

and

$$
\begin{array}{ll}
y_{p_{1}}=A x+B & \text { into } \quad y^{\prime \prime}-2 y^{\prime}-3 y=4 x-5 \\
y_{p_{2}}=C x e^{2 x}+D e^{2 x} & \text { into } \quad y^{\prime \prime}-2 y^{\prime}-3 y=6 x e^{2 x}
\end{array}
$$

yields in turn $y_{p_{1}}=-\frac{4}{3} x+\frac{23}{9}$ and $y_{p_{2}}=-\left(2 x+\frac{4}{3}\right) e^{2 x}$. A particular solution of (3) is then $y_{p}=y_{p_{1}}+y_{p_{2}}$.

The next example illustrates that sometimes the "obvious" assumption for the form of $y_{p}$ is not a correct assumption.

\section*{EXAMPLE 4 A Glitch in the Method}
Find a particular solution of $y^{\prime \prime}-5 y^{\prime}+4 y=8 e^{x}$.

Solution Differentiation of $e^{x}$ produces no new functions. Thus, proceeding as we did in the earlier examples, we can reasonably assume a particular solution of the form

$$
y_{p}=A e^{x}
$$

But in this case substitution of this expression into the differential equation yields the contradictory statement

$$
0=8 e^{x}
$$

and so we have clearly made the wrong guess for $y_{p}$.

The difficulty here is apparent upon examining the complementary function $y_{c}=c_{1} e^{x}+c_{2} e^{4 x}$. Observe that our assumption $A e^{x}$ is already present in $y_{c}$. This means that $e^{x}$ is a solution of the associated homogeneous differential equation, and a constant multiple $A e^{x}$ when substituted into the differential equation necessarily produces zero.

What then should be the form of $y_{p}$ ? Inspired by Case II of Section 4.3, let's see whether we can find a particular solution of the form

$$
y_{p}=A x e^{x}
$$

Using $y_{p}^{\prime}=A x e^{x}+A e^{x}$ and $y_{p}^{\prime \prime}=A x e^{x}+2 A e^{x}$, we obtain

$$
\begin{gathered}
y_{p}^{\prime \prime}-5 y_{p}^{\prime}+4 y_{p}=A x e^{x}+2 A e^{x}-5 A x e^{x}-5 A e^{x}+4 A x e^{x}=8 e^{x} \\
-3 A e^{x}=8 e^{x}
\end{gathered}
$$

or

From this last equation we see that the value of $A$ is now determined as $A=-\frac{8}{3}$. Therefore

$$
y_{p}=-\frac{8}{3} x e^{x}
$$

must be a particular solution of the given equation.

The difference in the procedures used in Examples 1-3 and in Example 4 suggests that we consider two cases. The first case reflects the situation in Examples $1-3$.

Case I No function in the assumed particular solution is a solution of the associated homogeneous differential equation.

Table 4.1 illustrates some specific examples of $g(x)$ in (1) along with the corresponding form of the particular solution. We are, of course, taking for granted that no function in the assumed particular solution $y_{p}$ is duplicated by a function in the complementary function $y_{c}$.

Table 4.1 Trial Particular Solutions

\begin{center}
\begin{tabular}{|c|c|}
\hline
$g(x)$ & Form of $y_{p}$ \\
\hline
1. 1 (any constant) & $A$ \\
\hline
2. $5 x+7$ & $A x+B$ \\
\hline
3. $3 x^{2}-2$ & $A x^{2}+B x+C$ \\
\hline
4. $x^{3}-x+1$ & $A x^{3}+B x^{2}+C x+D$ \\
\hline
5. $\sin 4 x$ & $A \cos 4 x+B \sin 4 x$ \\
\hline
6. $\cos 4 x$ & $A \cos 4 x+B \sin 4 x$ \\
\hline
7. $e^{5 x}$ & $A e^{5 x}$ \\
\hline
8. $(9 x-2) e^{5 x}$ & $(A x+B) e^{5 x}$ \\
\hline
9. $x^{2} e^{5 x}$ & $\left(A x^{2}+B x+C\right) e^{5 x}$ \\
\hline
10. $e^{3 x} \sin 4 x$ & $A e^{3 x} \cos 4 x+B e^{3 x} \sin 4 x$ \\
\hline
\begin{tabular}{l}
11. $5 x^{2} \sin 4 x$ \\
12. $x e^{3 x} \cos 4 x$ \\
\end{tabular} & \begin{tabular}{l}
$\left(A x^{2}+B x+C\right) \cos 4 x+\left(D x^{2}+E x+F\right) \sin 4 x$ \\
$(A x+B) e^{3 x} \cos 4 x+(C x+D) e^{3 x} \sin 4 x$ \\
\end{tabular} \\
\hline
\end{tabular}
\end{center}

\section*{EXAMPLE 5 Forms of Particular Solutions-Case I}
Determine the form of a particular solution of

(a) $y^{\prime \prime}-8 y^{\prime}+25 y=5 x^{3} e^{-x}-7 e^{-x}$ and (b) $y^{\prime \prime}+4 y=x \cos x$.

\section*{Solution}
(a) We can write

$$
g(x)=\left(5 x^{3}-7\right) e^{-x}
$$

Using entry 9 in the table as a model, we assume a particular solution of the form

$$
y_{p}=\left(A x^{3}+B x^{2}+C x+D\right) e^{-x}
$$

Note that there is no duplication between the terms in $y_{p}$ and the terms in the complementary function $y_{c}=e^{4 x}\left(c_{1} \cos 3 x+c_{2} \sin 3 x\right)$.

(b) The function $g(x)=x \cos x$ is similar to entry 11 in the table, except of course we use a linear rather than a quadratic polynomial and $\cos x$ and $\sin x$ instead of $\cos 4 x$ and $\sin 4 x$ in the form of $y_{p}$ :

$$
y_{p}=(A x+B) \cos x+(C x+D) \sin x \text {. }
$$

Again observe that there is no duplication of terms between $y_{p}$ and $y_{c}=c_{1} \cos 2 x+c_{2} \sin 2 x$.

If $g(x)$ consists of a sum of, say, $m$ terms of the kind listed in the table, then (as in Example 3) the assumption for a particular solution $y_{p}$ consists of the sum of the trial forms $y_{p_{1}}, y_{p_{2}}, \ldots, y_{p_{m}}$ corresponding to these terms:

$$
y_{p}=y_{p_{1}}+y_{p_{2}}+\cdots+y_{p_{m}}
$$

Put another way:

The form of $y_{p}$ is a linear combination of all linearly independent functions that are generated by repeated differentiations of $g(x)$.

\section*{EXAMPLE 6 Forming $y_{p}$ by Superposition-Case I}
Determine the form of a particular solution of

$$
y^{\prime \prime}-9 y^{\prime}+14 y=3 x^{2}-5 \sin 2 x+7 x e^{6 x}
$$

\section*{Solution}
$$
\begin{array}{ll}
\text { Corresponding to } 3 x^{2} \text {, we assume } & y_{p_{1}}=A x^{2}+B x+C . \\
\text { Corresponding to }-5 \sin 2 x \text {, we assume } & y_{p_{2}}=D \cos 2 x+E \sin 2 x \text {. } \\
\text { Corresponding to } 7 x e^{6 x} \text {, we assume } & y_{p_{3}}=(F x+G) e^{6 x} .
\end{array}
$$

The assumption for the particular solution is then

$$
y_{p}=y_{p_{1}}+y_{p_{2}}+y_{p_{3}}=A x^{2}+B x+C+D \cos 2 x+E \sin 2 x+(F x+G) e^{6 x}
$$

No term in this assumption duplicates a term in $y_{c}=c_{1} e^{2 x}+c_{2} e^{7 x}$.

Case II A function in the assumed particular solution is also a solution of the associated homogeneous differential equation.

The next example is similar to Example 4.

\section*{EXAMPLE 7 Particular Solution-Case II}
Find a particular solution of $y^{\prime \prime}-2 y^{\prime}+y=e^{x}$.

Solution The complementary function is $y_{c}=c_{1} e^{x}+c_{2} x e^{x}$. As in Example 4, the assumption $y_{p}=A e^{x}$ will fail since it is apparent from $y_{c}$ that $e^{x}$ is a solution of the associated homogeneous equation $y^{\prime \prime}-2 y^{\prime}+y=0$. Moreover, we will not be able to find a particular solution of the form $y_{p}=A x e^{x}$ since the term $x e^{x}$ is also duplicated in $y_{c}$. We next try

$$
y_{p}=A x^{2} e^{x}
$$

Substituting into the given differential equation yields

$$
2 A e^{x}=e^{x} \quad \text { and so } \quad A=\frac{1}{2}
$$

Thus a particular solution is $y_{p}=\frac{1}{2} x^{2} e^{x}$.

Suppose again that $g(x)$ consists of $m$ terms of the kind given in the table and suppose further that the usual assumption for a particular solution is

$$
y_{p}=y_{p_{1}}+y_{p_{2}}+\cdots+y_{p_{m}}
$$

where the $y_{p_{i}}, i=1,2, \ldots, m$ are the trial particular solution forms corresponding to these terms. Under the circumstance described in Case II, we can make up the following general rule:

If any $y_{p_{i}}$ contains terms that duplicate terms in $y_{c}$, then that $y_{p_{i}}$ must be multiplied by $x^{n}$, where $n$ is the smallest positive integer that eliminates that duplication.

\section*{EXAMPLE 8 An Initial-Value Problem}
Solve the initial-value problem $y^{\prime \prime}+y=4 x+10 \sin x, y(\pi)=0, y^{\prime}(\pi)=2$.

Solution The solution of the associated homogeneous equation $y^{\prime \prime}+y=0$ is

$$
y_{c}=c_{1} \cos x+c_{2} \sin x
$$

Now since $g(x)$ is the sum of a linear polynomial and a sine function, our normal assumption for $y_{p}$ from entries 2 and 5 of the trial solutions table would be the sum of $y_{p_{1}}=A x+B$ and $y_{p_{2}}=C \cos x+D \sin x$ :


\begin{equation*}
y_{p}=A x+B+C \cos x+D \sin x \tag{5}
\end{equation*}


But there is an obvious duplication of the terms $\cos x$ and $\sin x$ in this assumed form and two terms in the complementary function. This duplication can be eliminated by simply multiplying $y_{p_{2}}$ by $x$. Instead of (5) we now use


\begin{equation*}
y_{p}=A x+B+C x \cos x+D x \sin x \tag{6}
\end{equation*}


Differentiating this expression and substituting the results into the differential equation gives

$$
y_{p}^{\prime \prime}+y_{p}=A x+B-2 C \sin x+2 D \cos x=4 x+10 \sin x
$$

and so

$$
A=4, \quad B=0, \quad-2 C=10, \quad 2 D=0
$$

The solutions of the system are immediate: $A=4, B=0, C=-5$, and $D=0$. Therefore from (6) we obtain

$$
y_{p}=4 x-5 x \cos x
$$

The general solution of the given equation is

$$
y=y_{c}+y_{p}=c_{1} \cos x+c_{2} \sin x+4 x-5 x \cos x
$$

We now apply the prescribed initial conditions to the general solution of the equation. First, $y(\pi)=c_{1} \cos \pi+c_{2} \sin \pi+4 \pi-5 \pi \cos \pi=0$ yields $c_{1}=9 \pi$, since $\cos \pi=-1$ and $\sin \pi=0$. Next, from the derivative

$$
y^{\prime}=-9 \pi \sin x+c_{2} \cos x+4+5 x \sin x-5 \cos x
$$

and

$$
y^{\prime}(\pi)=-9 \pi \sin \pi+c_{2} \cos \pi+4+5 \pi \sin \pi-5 \cos \pi=2
$$

we find $c_{2}=7$. The solution of the initial-value problem is then

$$
y=9 \pi \cos x+7 \sin x+4 x-5 x \cos x
$$

\section*{EXAMPLE 9 Particular Solution-Case II}
Solve $y^{\prime \prime}-6 y^{\prime}+9 y=6 x^{2}+2-12 e^{3 x}$.

Solution The complementary function is

$$
y_{c}=c_{1} e^{3 x}+c_{2} x e^{3 x}
$$

and based on entries 3 and 7 of the table, the usual assumption for a particular solution would be

$$
y_{p}=\underbrace{A x^{2}+B x+C}_{y_{p_{1}}}+\underbrace{D e^{3 x}}_{y_{y_{2}}} .
$$

Inspection of these functions shows that the one term in $y_{p_{2}}$ is duplicated in $y_{c}$. If we multiply $y_{p_{2}}$ by $x$, we note that the term $x e^{3 x}$ is still part of $y_{c}$. But multiplying $y_{p_{2}}$ by $x^{2}$ eliminates all duplications. Thus the operative form of a particular solution is

$$
y_{p}=A x^{2}+B x+C+D x^{2} e^{3 x}
$$

Differentiating this last form, substituting into the differential equation, and collecting like terms gives

$$
y_{p}^{\prime \prime}-6 y_{p}^{\prime}+9 y_{p}=9 A x^{2}+(-12 A+9 B) x+2 A-6 B+9 C+2 D e^{3 x}=6 x^{2}+2-12 e^{3 x} .
$$

It follows from this identity that $A=\frac{2}{3}, B=\frac{8}{9}, C=\frac{2}{3}$, and $D=-6$. Hence the general solution $y=y_{c}+y_{p}$ is

$$
y=c_{1} e^{3 x}+c_{2} x e^{3 x}+\frac{2}{3} x^{2}+\frac{8}{9} x+\frac{2}{3}-6 x^{2} e^{3 x}
$$

Higher-Order Equations The method of undetermined coefficients given here is not restricted to second-order equations but can be used as well with higher-order equations

$$
a_{n} y^{(n)}+a_{n-1} y^{(n-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=g(x)
$$

with constant coefficients. It is only necessary that $g(x)$ consist of the proper kinds of functions discussed above.

\section*{EXAMPLE 10 Third-Order DE}
Solve $y^{\prime \prime \prime}+y^{\prime \prime}=e^{x} \cos x$.

Solution From the characteristic equation $m^{3}+m^{2}=0$ we find $m_{1}=m_{2}=0$ and $m_{3}=-1$. Hence the complementary solution of the equation is $y_{c}=c_{1}+c_{2} x+c_{3} e^{-x}$. With $g(x)=e^{x} \cos x$ we see from entry 10 of the table of trial particular solutions that we should assume

$$
y_{p}=A e^{x} \cos x+B e^{x} \sin x
$$

Since there are no functions in $y_{p}$ that duplicate functions in the complementary solution, we proceed in the usual manner. From

$$
y_{p}^{\prime \prime \prime}+y_{p}^{\prime \prime}=(-2 A+4 B) e^{x} \cos x+(-4 A-2 B) e^{x} \sin x=e^{x} \cos x
$$

we get

$$
-2 A+4 B=1, \quad-4 A-2 B=0
$$

This system gives $A=-\frac{1}{10}$ and $B=\frac{1}{5}$, so a particular solution is

$$
y_{p}=-\frac{1}{10} e^{x} \cos x+\frac{1}{5} e^{x} \sin x
$$

The general solution of the equation is

$$
y=y_{c}+y_{p}=c_{1}+c_{2} x+c_{3} e^{-x}-\frac{1}{10} e^{x} \cos x+\frac{1}{5} e^{x} \sin x
$$

\section*{EXAMPLE 11 Fourth-Order DE}
Determine the form of a particular solution of $y^{(4)}+y^{\prime \prime \prime}=1-e^{-x}$.

Solution Comparing the complementary function

$$
y_{c}=c_{1}+c_{2} x+c_{3} x^{2}+c_{4} e^{-x}
$$

with our normal assumption for a particular solution

$$
y_{p}=\underbrace{A}_{y_{p_{1}}}+\underbrace{B e^{-x}}_{y_{p_{2}}},
$$

we see that the duplications between $y_{c}$ and $y_{p}$ are eliminated when $y_{p_{1}}$ is multiplied by $x^{3}$ and $y_{p_{2}}$ is multiplied by $x$. Thus the correct assumption for a particular solution is

$$
y_{p}=A x^{3}+B x e^{-x}
$$

\section*{EXERCISES 4.4}
Answers to odd-numbered problems begin on page A-8.

In Problems 1-26 solve the given differential equation by the method of undetermined coefficients.

\begin{enumerate}
  \item $y^{\prime \prime}+3 y^{\prime}+2 y=6$
  \item $4 y^{\prime \prime}+9 y=15$
  \item $y^{\prime \prime}-10 y^{\prime}+25 y=30 x+3$
  \item $y^{\prime \prime}+y^{\prime}-6 y=2 x$
  \item $\frac{1}{4} y^{\prime \prime}+y^{\prime}+y=x^{2}-2 x$
  \item $y^{\prime \prime}-8 y^{\prime}+20 y=100 x^{2}-26 x e^{x}$
  \item $y^{\prime \prime}+3 y=-48 x^{2} e^{3 x}$
  \item $4 y^{\prime \prime}-4 y^{\prime}-3 y=\cos 2 x$
  \item $y^{\prime \prime}-y^{\prime}=-3$
  \item $y^{\prime \prime}+2 y^{\prime}=2 x+5-e^{-2 x}$
  \item $y^{\prime \prime}-y^{\prime}+\frac{1}{4} y=3+e^{x / 2}$
  \item $y^{\prime \prime}-16 y=2 e^{4 x}$
  \item $y^{\prime \prime}+4 y=3 \sin 2 x$
  \item $y^{\prime \prime}+4 y=\left(x^{2}-3\right) \sin 2 x$
  \item $y^{\prime \prime}+y=2 x \sin x$
  \item $y^{\prime \prime}-5 y^{\prime}=2 x^{3}-4 x^{2}-x+6$
  \item $y^{\prime \prime}-2 y^{\prime}+5 y=e^{x} \cos 2 x$
  \item $y^{\prime \prime}-2 y^{\prime}+2 y=e^{2 x}(\cos x-3 \sin x)$
  \item $y^{\prime \prime}+2 y^{\prime}+y=\sin x+3 \cos 2 x$
  \item $y^{\prime \prime}+2 y^{\prime}-24 y=16-(x+2) e^{4 x}$
  \item $y^{\prime \prime \prime}-6 y^{\prime \prime}=3-\cos x$
  \item $y^{\prime \prime \prime}-2 y^{\prime \prime}-4 y^{\prime}+8 y=6 x e^{2 x}$
  \item $y^{\prime \prime \prime}-3 y^{\prime \prime}+3 y^{\prime}-y=x-4 e^{x}$
  \item $y^{\prime \prime \prime}-y^{\prime \prime}-4 y^{\prime}+4 y=5-e^{x}+e^{2 x}$
  \item $y^{(4)}+2 y^{\prime \prime}+y=(x-1)^{2}$
  \item $y^{(4)}-y^{\prime \prime}=4 x+2 x e^{-x}$
\end{enumerate}

In Problems 27 and 28 use a trigonometric identity as an aid in finding a particular solution of the given differential equation.\\
27. $y^{\prime \prime}+y=8 \sin ^{2} x$\\
28. $y^{\prime \prime}+y=\sin x \cos 2 x$

In Problems 29-40 solve the given differential equation subject to the indicated initial conditions.\\
29. $y^{\prime \prime}+4 y=-2, y\left(\frac{\pi}{8}\right)=\frac{1}{2}, y^{\prime}\left(\frac{\pi}{8}\right)=2$\\
30. $2 y^{\prime \prime}+3 y^{\prime}-2 y=14 x^{2}-4 x-11, y(0)=0, y^{\prime}(0)=0$\\
31. $5 y^{\prime \prime}+y^{\prime}=-6 x, y(0)=0, y^{\prime}(0)=-10$\\
32. $y^{\prime \prime}+4 y^{\prime}+4 y=(3+x) e^{-2 x}, y(0)=2, y^{\prime}(0)=5$\\
33. $y^{\prime \prime}+4 y^{\prime}+5 y=35 e^{-4 x}, y(0)=-3, y^{\prime}(0)=1$\\
34. $y^{\prime \prime}-y=\cosh x, y(0)=2, y^{\prime}(0)=12$\\
35. $\frac{d^{2} x}{d t^{2}}+\omega^{2} x=F_{0} \sin \omega t, x(0)=0, x^{\prime}(0)=0$\\
36. $\frac{d^{2} x}{d t^{2}}+\omega^{2} x=F_{0} \cos \gamma t, x(0)=0, x^{\prime}(0)=0$\\
37. $y^{\prime \prime}+y=\cos x-\sin 2 x, y\left(\frac{\pi}{2}\right)=0, y^{\prime}\left(\frac{\pi}{2}\right)=0$\\
38. $y^{\prime \prime}-2 y^{\prime}-3 y=2 \cos ^{2} x, y(0)=-\frac{1}{3}, y^{\prime}(0)=0$\\
39. $y^{\prime \prime \prime}-2 y^{\prime \prime}+y^{\prime}=2-24 e^{x}+40 e^{5 x}, y(0)=\frac{1}{2}, y^{\prime}(0)=\frac{5}{2}, y^{\prime \prime}(0)=-\frac{9}{2}$\\
40. $y^{\prime \prime \prime}+8 y=2 x-5+8 e^{-2 x}, y(0)=-5, y^{\prime}(0)=3, y^{\prime \prime}(0)=-4$

In Problems 41 and 42 solve the given differential equation subject to the indicated boundary conditions.\\
41. $y^{\prime \prime}+y=x^{2}+1, y(0)=5, y(1)=0$\\
42. $y^{\prime \prime}-2 y^{\prime}+2 y=2 x-2, y(0)=0, y(\pi)=\pi$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item In applications the input function $g(x)$ is often discontinuous. Solve the initial-value problem $y^{\prime \prime}+4 y=g(x), y(0)=1, y^{\prime}(0)=2$, where
\end{enumerate}

$$
g(x)=\left\{\begin{array}{lr}
\sin x, & 0 \leq x \leq \pi / 2 \\
0, & x>\pi / 2
\end{array}\right.
$$

[Hint: Solve the problem on the two intervals and then find a solution so that $y$ and $y^{\prime}$ are continuous at $x=\pi / 2$.]

\subsection*{4.5 DIFFERENTIAL OPERATORS}
In calculus, differentiation is often denoted by the capital letter $D$; that is,

$$
\frac{d y}{d x}=D y
$$

The symbol $D$ is called a differential operator, and it transforms a differentiable function into another function; for example,

$$
D\left(e^{4 x}\right)=4 e^{4 x}, \quad D\left(5 x^{3}-6 x^{2}\right)=15 x^{2}-12 x, \quad D(\cos 2 x)=-2 \sin 2 x
$$

The differential operator $D$ also possesses a linearity property; $D$ operating on a linear combination of two differentiable functions is the same as the linear combination of $D$ operating on the individual functions. In symbols, this means


\begin{equation*}
D\{a f(x)+b g(x)\}=a D f(x)+b D g(x) \tag{1}
\end{equation*}


where $a$ and $b$ are constants. Because of (1) we say that $D$ is a linear differential operator.

Higher-Order Derivatives Higher-order derivatives can be expressed in terms of $D$ in a natural manner:

$$
\frac{d}{d x}\left(\frac{d y}{d x}\right)=\frac{d^{2} y}{d x^{2}}=D(D y)=D^{2} y \quad \text { and in general } \quad \frac{d^{n} y}{d x^{n}}=D^{n} y
$$

where $y$ represents a sufficiently differentiable function. Polynomial expressions involving $D$ such as

$$
D+3, \quad D^{2}+3 D-4, \text { and } 5 D^{3}-6 D^{2}+4 D+9
$$

are also linear differential operators.

Differential Equations Any linear differential equation can be expressed in terms of the $D$ notation. For example, a second-order differential equation with constant coefficients $a y^{\prime \prime}+b y^{\prime}+c y=g(x)$ can be written as

$$
a D^{2} y+b D y+c y=g(x) \text { or } \quad\left(a D^{2}+b D+c\right) y=g(x)
$$

If we further define $L=a D^{2}+b D+c$, then the last equation can be written compactly as

$$
L(y)=g(x)
$$

The operator $L=a D^{2}+b D+c$ is said to be a second-order linear differential operator with constant coefficients.

\section*{EXAMPLE 1 Second-Order Differential Operator}
The differential equation $y^{\prime \prime}+y^{\prime}+2 y=5 x-3$ can be written as

$$
\left(D^{2}+D+2\right) y=5 x-3
$$

\section*{An $\boldsymbol{n}$ th-order linear differential operator}
$$
L=a_{n} D^{n}+a_{n-1} D^{n-1}+\cdots+a_{1} D+a_{0}
$$

with constant coefficients can be factored whenever the characteristic polynomial $a_{n} m^{n}+a_{n-1} m^{n-1}+\cdots+a_{1} m+a_{0}$ factors.* For example, if we treat $D$ as an algebraic quantity, then $D^{2}+5 D+6$ can be factored as $(D+2)(D+3)$ or as $(D+3)(D+2)$. In other words, for a function $y=f(x)$ possessing a second derivative

$$
\left(D^{2}+5 D+6\right) y=(D+2)(D+3) y=(D+3)(D+2) y
$$

To see why this is so, let $w=(D+3) y=y^{\prime}+3 y$. Then

$$
(D+2) w=D w+2 w=(\underbrace{y^{\prime \prime}+3 y^{\prime}}_{D w})+(\underbrace{2 y^{\prime}+6 y}_{2 w})=y^{\prime \prime}+5 y^{\prime}+6 y .
$$

Similarly, if we let $w=(D+2) y=y^{\prime}+2 y$, then

$$
(D+3) w=D w+3 w=(\underbrace{y^{\prime \prime}+2 y^{\prime}}_{D w})+(\underbrace{3 y^{\prime}+6 y}_{3 w})=y^{\prime \prime}+5 y^{\prime}+6 y .
$$

This illustrates a general property:

Factors of a linear differential operator with constant coefficients commute.

\section*{EXAMPLE 2 Factoring a Differential Operator}
(a) The operator $D^{2}-1$ can be written as

$$
(D+1)(D-1) \text { or }(D-1)(D+1)
$$

(b) The operator $D^{2}+D+2$ in Example 1 does not factor with real numbers.

\section*{EXAMPLE 8 Factoring a Differential Operator}
The differential equation $y^{\prime \prime}+4 y^{\prime}+4 y=0$ is written as

$$
\left(D^{2}+4 D+4\right) y=0 \quad \text { or } \quad(D+2)(D+2) y=0 \quad \text { or } \quad(D+2)^{2} y=0 \text {. }
$$

Annihilator Operator If $L$ is a linear differential operator with constant coefficients and $y=f(x)$ is a sufficiently differentiable function such that

$$
L(y)=0
$$

then $L$ is said to be an annihilator of the function. For example, if $y=k$ (a constant), then $D k=0$. Also, $D^{2} x=0, D^{3} x^{2}=0$, and so on.
\footnotetext{\begin{itemize}
  \item If one is willing to use complex numbers, then a differential operator with constant coefficients can always be factored. We are, however, primarily concerned with writing differential equations in operator form with real coefficients.
\end{itemize}
}

The differential operator $D^{n}$ annihilates each of the functions

$$
1, x, x^{2}, \ldots, x^{n-1}
$$

As an immediate consequence of (2) and the fact that differentiation can be done term by term, a polynomial

$$
c_{0}+c_{1} x+\cdots+c_{n-1} x^{n-1}
$$

can be annihilated by finding an operator that annihilates the highest power of $x$.

\section*{EXAMPLE 4 Annihilator Operator}
Find a differential operator that annihilates $1-5 x^{2}+8 x^{3}$.

Solution From (2) we know that $D^{4} x^{3}=0$, and so it follows that

$$
D^{4}\left(1-5 x^{2}+8 x^{3}\right)=0
$$

Note The functions that are annihilated by an $n$ th-order linear differential operator $L$ are simply those functions that can be obtained from the general solution of the homogeneous differential equation $L(y)=0$.

The differential operator $(D-\alpha)^{n}$ annihilates each of the functions


\begin{equation*}
e^{\alpha x}, x e^{\alpha x}, x^{2} e^{\alpha x}, \ldots, x^{n-1} e^{\alpha x} \tag{3}
\end{equation*}


To see this, note that the auxiliary equation of the homogeneous equation $(D-\alpha)^{n} y=0$ is $(m-\alpha)^{n}=0$. Since $\alpha$ is a root of multiplicity $n$, the general solution is


\begin{equation*}
y=c_{1} e^{\alpha x}+c_{2} x e^{\alpha x}+\cdots+c_{n} x^{n-1} e^{\alpha x} \tag{4}
\end{equation*}


\section*{EXAMPLE 5 Annihilator Operator}
Find an annihilator operator for (a) $e^{5 x}$ and (b) $4 e^{2 x}-6 x e^{2 x}$.

\section*{Solution}
(a) From (3) with $\alpha=5$ and $n=1$, we see that

$$
(D-5) e^{5 x}=0
$$

(b) From (3) and (4) with $\alpha=2$ and $n=2$, we have

$$
(D-2)^{2}\left(4 e^{2 x}-6 x e^{2 x}\right)=0
$$

When $\alpha$ and $\beta$ are real numbers, the quadratic formula reveals that $\left[m^{2}-2 \alpha m+\left(\alpha^{2}+\beta^{2}\right)\right]^{n}=0$ has complex roots $\alpha+i \beta, \alpha-i \beta$, both of multiplicity $n$. From the discussion at the end of Section 4.3 , we have the next result.

The differential operator $\left[D^{2}-2 \alpha D+\left(\alpha^{2}+\beta^{2}\right)\right]^{n}$ annihilates each of the functions


\begin{align*}
& e^{\alpha x} \cos \beta x, x e^{\alpha x} \cos \beta x, x^{2} e^{\alpha x} \cos \beta x, \ldots, x^{n-1} e^{\alpha x} \cos \beta x  \tag{5}\\
& e^{\alpha x} \sin \beta x, x e^{\alpha x} \sin \beta x, x^{2} e^{\alpha x} \sin \beta x, \ldots, x^{n-1} e^{\alpha x} \sin \beta x
\end{align*}


\section*{EXAMPLE 6 Using (5)}
From (5), with $\alpha=-1, \beta=2$, and $n=1$, we see that

$$
\left(D^{2}+2 D+5\right) e^{-x} \cos 2 x=0 \quad \text { and } \quad\left(D^{2}+2 D+5\right) e^{-x} \sin 2 x=0
$$

Since $y_{1}(x)=e^{-x} \cos 2 x$ and $y_{2}(x)=e^{-x} \sin 2 x$ are the two linearly independent functions in the general solution of $\left(D^{2}+2 D+5\right) y=0$, the linear operator $D^{2}+2 D+5$ also annihilates any linear combination of these functions, such as $5 e^{-x} \cos 2 x-9 e^{-x} \sin 2 x$.

\section*{EXAMPLE 7 Using (5)}
From (5), with $\alpha=0, \beta=1$, and $n=2$, it is seen that the differential operator $\left(D^{2}+1\right)^{2}$ or $D^{4}+2 D^{2}+1$ annihilates $\cos x, x \cos x, \sin x$, and $x \sin x$. Moreover, $\left(D^{2}+1\right)^{2}$ annihilates any linear combination of these functions.

When $\alpha=0$ and $n=1$, a special case of (5) is

\[
\left(D^{2}+\beta^{2}\right)\left\{\begin{array}{l}
\cos \beta x  \tag{6}\\
\sin \beta x
\end{array}=0\right.
\]

We are often interested in annihilating the sum of two or more functions. As seen in Examples $4-7$, if $L$ is a linear differential operator such that $L\left(y_{1}\right)=0$ and $L\left(y_{2}\right)=0$, then $L$ annihilates the linear combination $c_{1} y_{1}(x)+c_{2} y_{2}(x)$. This is a direct consequence of Theorem 4.3. Let us now suppose that $L_{1}$ and $L_{2}$ are linear differential operators with constant coefficients such that $L_{1}$ annihilates $y_{1}(x)$ and $L_{2}$ annihilates $y_{2}(x)$ but $L_{1}\left(y_{2}\right) \neq 0$ and $L_{2}\left(y_{1}\right) \neq 0$. Then the product of differential operators $L_{1} L_{2}$ annihilates the sum $c_{1} y_{1}(x)+c_{2} y_{2}(x)$. We can easily demonstrate this using linearity and the fact that $L_{1} L_{2}=L_{2} L_{1}$ :


\begin{align*}
L_{1} L_{2}\left(y_{1}+y_{2}\right) & =L_{1} L_{2}\left(y_{1}\right)+L_{1} L_{2}\left(y_{2}\right) \\
& =L_{2} L_{1}\left(y_{1}\right)+L_{1} L_{2}\left(y_{2}\right)  \tag{7}\\
& =L_{2}[\underbrace{L_{1}\left(y_{1}\right)}_{\text {zero }}]+L_{1}[\underbrace{L_{2}\left(y_{2}\right)}_{\text {zero }}]=0 .
\end{align*}


\section*{EXAMPLE 8 Using (2) and (6)}
Find a differential operator that annihilates $7-x+6 \sin 3 x$.

Solution From (2) and (6) we have, respectively,

$$
D^{2}(7-x)=0 \quad \text { and } \quad\left(D^{2}+9\right) \sin 3 x=0
$$

It follows from (7) that the operator $D^{2}\left(D^{2}+9\right)$ annihilates the given linear combination.

\section*{EXAMPLE 9 Using (3)}
Find a differential operator that annihilates $e^{-3 x}+x e^{x}$.

Solution From (3),

$$
(D+3) e^{-3 x}=0 \quad \text { and } \quad(D-1)^{2} x e^{x}=0
$$

Hence the product of the two operations $(D+3)(D-1)^{2}$ annihilates the given linear combination.

Remarks The differential operator that annihilates a function is not unique. For example, we know that $D-5$ annihilates $e^{5 x}$, but so do differential operators of higher order such as $(D-5)(D+1)$ and $(D-5) D^{2}$. (Verify this.) When we seek a differential annihilator for a function $y=f(x)$, we want the operator of lowest possible order that does the job.

\section*{EXERCISES 4.5}
Answers to odd-numbered problems begin on page A-8.

In Problems 1-6 write the given differential equation in the form $L(y)=g(x)$, where $L$ is a differential operator with constant coefficients.

\begin{enumerate}
  \item $\frac{d y}{d x}+5 y=9 \sin x$
  \item $4 \frac{d y}{d x}+8 y=x+3$
  \item $3 y^{\prime \prime}-5 y^{\prime}+y=e^{x}$
  \item $y^{\prime \prime \prime}-2 y^{\prime \prime}+7 y^{\prime}-6 y=1-\sin x$
  \item $y^{\prime \prime \prime}-4 y^{\prime \prime}+5 y^{\prime}=4 x$
  \item $y^{(4)}-2 y^{\prime \prime}+y=e^{-3 x}+e^{2 x}$
\end{enumerate}

In Problems 7-16, if possible, factor the given differential operator.\\
7. $9 D^{2}-4$\\
8. $D^{2}-5$\\
9. $D^{2}-4 D-12$\\
10. $2 D^{2}-3 D-2$\\
11. $D^{3}+10 D^{2}+25 D$\\
12. $D^{3}+4 D$\\
13. $D^{3}+2 D^{2}-13 D+10$\\
14. $D^{3}+4 D^{2}+3 D$\\
15. $D^{4}+8 D$\\
16. $D^{4}-8 D^{2}+16$

In Problems $17-20$ verify that the given differential operator annihilates the indicated function.\\
17. $D^{4} ; y=10 x^{3}-2 x \quad$ 18. $2 D-1 ; y=4 e^{x / 2}$\\
19. $(D-2)(D+5) ; \quad y=4 e^{2 x}$\\
20. $D^{2}+64 ; \quad y=2 \cos 8 x-5 \sin 8 x$

In Problems 21-32 find a differential operator that annihilates the given function.\\
21. $1+6 x-2 x^{3}$\\
22. $x^{3}(1-5 x)$\\
23. $1+7 e^{2 x}$\\
24. $x+3 x e^{6 x}$\\
25. $\cos 2 x$\\
26. $1+\sin x$\\
27. $13 x+9 x^{2}-\sin 4 x$\\
28. $8 x-\sin x+10 \cos 5 x$\\
29. $e^{-x}+2 x e^{x}-x^{2} e^{x}$\\
30. $\left(2-e^{x}\right)^{2}$\\
31. $3+e^{x} \cos 2 x$\\
32. $e^{-x} \sin x-e^{2 x} \cos x$

In Problems 33-40 find linearly independent functions that are annihilated by the given differential operator.\\
33. $D^{5}$\\
34. $D^{2}+4 D$\\
35. $(D-6)(2 D+3)$\\
36. $D^{2}-9 D-36$\\
37. $D^{2}+5$\\
38. $D^{2}-6 D+10$\\
39. $D^{3}-10 D^{2}+25 D$\\
40. $D^{2}(D-5)(D-7)$

\subsection*{4.6 UNDETERMINED COEFFICIENTS ANNIHILATOR APPROACH}
\begin{itemize}
  \item Method of undetermined coefficients
  \item Particular solution
\end{itemize}

To obtain the general solution of a nonhomogeneous linear differential equation we must do two things:

(i) Find the complementary function $y_{c}$.

(ii) Find any particular solution $y_{p}$ of the nonhomogeneous equation.

Recall from the discussion of Section 4.1 that a particular solution is any function, free of arbitrary constants, that satisfies the differential equation identically. The general solution of a nonhomogeneous equation on an interval is then $y=y_{c}+y_{p}$.

If $L$ denotes a linear differential operator of the form $a_{n} D^{n}+$ $a_{n-1} D^{n-1}+\cdots+a_{1} D+a_{0}$, then a nonhomogeneous linear differential equation can be written simply as


\begin{equation*}
L(y)=g(x) \tag{1}
\end{equation*}


The method of undetermined coefficients presented in this section is limited to nonhomogeneous linear equations in which

\begin{itemize}
  \item coefficients are constant and
  \item $g(x)$ is a constant $k$, a polynomial function, an exponential function $e^{\alpha x}, \sin \beta x, \cos \beta x$, or finite sums and products of these functions.
\end{itemize}

Note Strictly speaking, $g(x)=k$ (a constant) is a polynomial function. Since a constant function is probably not the first thing that comes to mind when you think of polynomial functions, for emphasis we continue to use the redundancy "constant functions, polynomials, . . .."

The following are some examples of the types of input functions $g(x)$ that are appropriate for this discussion:

$$
\begin{gathered}
g(x)=10, \quad g(x)=x^{2}-5 x, \quad g(x)=15 x-6+8 e^{4 x} \\
g(x)=\sin 3 x-5 x \cos 2 x, \quad g(x)=e^{x} \cos x-\left(3 x^{2}-1\right) e^{-x}
\end{gathered}
$$

and so on. In other words, $g(x)$ is a linear combination of functions of the form

$$
k \text { (constant), } \quad x^{m}, \quad x^{m} e^{\alpha x}, \quad x^{m} e^{\alpha x} \cos \beta x, \quad \text { and } \quad x^{m} e^{\alpha x} \sin \beta x
$$

where $m$ is a nonnegative integer and $\alpha$ and $\beta$ are real numbers. The method of undetermined coefficients is not applicable to equations of the form (1) when

$$
g(x)=\ln x, \quad g(x)=\frac{1}{x}, \quad g(x)=\tan x, \quad g(x)=\sin ^{-1} x
$$

and so on. Differential equations with this latter kind of input function will be considered in Section 4.7.

As we saw in Section 4.5, a linear combination of functions of the type $k, x^{m}, x^{m} e^{\alpha x}, x^{m} e^{\alpha x} \cos \beta x$, and $x^{m} e^{\alpha x} \sin \beta x$ is precisely that kind of function that can be annihilated by an operator $L_{1}$ (of lowest order) consisting of a product of operators such as $D^{n},(D-\alpha)^{n}$, and $\left(D^{2}-2 \alpha D+\alpha^{2}+\beta^{2}\right)^{n}$. Applying $L_{1}$ to both members of (1) yields


\begin{equation*}
L_{1} L(y)=L_{1}(g(x))=0 \tag{2}
\end{equation*}


By solving the homogeneous higher-order equation $L_{1} L(y)=0$, we can discover the form of a particular solution $y_{p}$ for the original nonhomogeneous equation $L(y)=g(x)$.

The next several examples illustrate the method. The general solution of each equation is defined on the interval $(-\infty, \infty)$.

\section*{EXAMPLE I Using (2) of Section 4.5}
Solve


\begin{equation*}
\frac{d^{2} y}{d x^{2}}+3 \frac{d y}{d x}+2 y=4 x^{2} \tag{3}
\end{equation*}


Solution Step 1. We first solve the homogeneous equation

$$
\frac{d^{2} y}{d x^{2}}+3 \frac{d y}{d x}+2 y=0
$$

From the auxiliary equation $m^{2}+3 m+2=(m+1)(m+2)=0$, we find $m_{1}=-1, m_{2}=-2$, and so the complementary function is

$$
y_{c}=c_{1} e^{-x}+c_{2} e^{-2 x}
$$

Step 2. In view of (2) of Section 4.5, (3) can be rendered homogeneous by taking three derivatives of each side of the equation. In other words,


\begin{equation*}
D^{3}\left(D^{2}+3 D+2\right) y=4 D^{3} x^{2}=0 \tag{4}
\end{equation*}


since $D^{3} x^{2}=0$. The auxiliary equation of (4),

$$
m^{3}\left(m^{2}+3 m+2\right)=0 \quad \text { or } \quad m^{3}(m+1)(m+2)=0
$$

has roots $0,0,0,-1$, and -2 . Thus its general solution must be


\begin{equation*}
y=c_{1}+c_{2} x+c_{3} x^{2}+c_{4} e^{-x}+c_{5} e^{-2 x} \tag{5}
\end{equation*}


The terms in the box in (5) constitute the complementary function of the original equation (3). We can then argue that a particular solution $y_{p}$ of (3) should also satisfy equation (4). This means that the terms remaining in (5) must be the basic structure of $y_{p}$ :


\begin{equation*}
y_{p}=A+B x+C x^{2} \tag{6}
\end{equation*}


where, for convenience, we have replaced $c_{1}, c_{2}$, and $c_{3}$ by $A, B$, and $C$, respectively. For (6) to be a particular solution of (3), it is necessary to find specific coefficients $A, B$, and $C$. Differentiating (6), we have

$$
y_{p}^{\prime}=B+2 C x, \quad y_{p}^{\prime \prime}=2 C
$$

and substitution into (3) then gives

$$
y_{p}^{\prime \prime}+3 y_{p}^{\prime}+2 y_{p}=2 C+3 B+6 C x+2 A+2 B x+2 C x^{2}=4 x^{2}
$$

Since the last equation is supposed to be an identity, the coefficients of like powers of $x$ must be equal:

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-185}
\end{center}

That is,


\begin{equation*}
2 C=4, \quad 2 B+6 C=0, \quad 2 A+3 B+2 C=0 \tag{7}
\end{equation*}


Solving (7) gives $A=7, B=-6$, and $C=2$. Thus $y_{p}=7-6 x+2 x^{2}$.

Step 3. The general solution of (3) is $y=y_{c}+y_{p}$ or

$$
y=c_{1} e^{-x}+c_{2} e^{-2 x}+7-6 x+2 x^{2}
$$

\section*{EXAMPLE 2 Using (3) and (6) of Section 4.5}
Solve


\begin{equation*}
y^{\prime \prime}-3 y^{\prime}=8 e^{3 x}+4 \sin x \tag{8}
\end{equation*}


Solution Step 1. The auxiliary equation for the homogeneous equation $y^{\prime \prime}-3 y^{\prime}=0$ is $m(m-3)=0$, and so

$$
y_{c}=c_{1}+c_{2} e^{3 x}
$$

Step 2. Now since $(D-3) e^{3 x}=0$ and $\left(D^{2}+1\right) \sin x=0$, we apply the differential operator $(D-3)\left(D^{2}+1\right)$ to both sides of (8):


\begin{equation*}
(D-3)\left(D^{2}+1\right)\left(D^{2}-3 D\right) y=0 \tag{9}
\end{equation*}


The auxiliary equation of $(9)$ is


\begin{gather*}
(m-3)\left(m^{2}+1\right)\left(m^{2}-3 m\right)=0 \quad \text { or } \quad m(m-3)^{2}\left(m^{2}+1\right)=0 \\
y=c_{1}+c_{2} e^{3 x}+c_{3} x e^{3 x}+c_{4} \cos x+c_{5} \sin x \tag{10}
\end{gather*}


Thus

After excluding the linear combination of terms in the box that corresponds to $y_{c}$, we arrive at the form of $y_{p}$ :

$$
y_{p}=A x e^{3 x}+B \cos x+C \sin x
$$

Substituting $y_{p}$ in (8) and simplifying yields

$$
\begin{aligned}
y_{p}^{\prime \prime}-3 y_{p}^{\prime} & =3 A e^{3 x}+(-B-3 C) \cos x+(3 B-C) \sin x \\
& =8 e^{3 x}+4 \sin x
\end{aligned}
$$

Equating coefficients gives

$$
3 A=8, \quad-B-3 C=0, \quad 3 B-C=4 .
$$

We find $A=\frac{8}{3}, B=\frac{6}{5}, C=-\frac{2}{5}$, and consequently

$$
y_{p}=\frac{8}{3} x e^{3 x}+\frac{6}{5} \cos x-\frac{2}{5} \sin x
$$

Step 3. The general solution of (8) is then

$$
y=c_{1}+c_{2} e^{3 x}+\frac{8}{3} x e^{3 x}+\frac{6}{5} \cos x-\frac{2}{5} \sin x
$$

\section*{EXAMPLE 3 Using (2) and (3) of Section 4.5}
Solve


\begin{equation*}
y^{\prime \prime}+8 y=5 x+2 e^{-x} \tag{11}
\end{equation*}


Solution From (2) and (3) of Section 4.5 we know that $D^{2} x=0$ and $(D+1) e^{-x}=0$, respectively. Hence we apply $D^{2}(D+1)$ to (11):

$$
D^{2}(D+1)\left(D^{2}+8\right) y=0
$$

It is seen that

$$
\begin{gathered}
y=c_{1} \cos 2 \sqrt{2} x+c_{2} \sin 2 \sqrt{2} x+c_{3}+c_{4} x+c_{5} e^{-x} \\
\text { and so } \quad y_{p}=A+B x+C e^{-x} .
\end{gathered}
$$

Substituting $y_{p}$ into (11) yields

$$
y_{p}^{\prime \prime}+8 y_{p}=8 A+8 B x+9 C e^{-x}=5 x+2 e^{-x}
$$

This implies $A=0, B=\frac{5}{8}$, and $C=\frac{2}{9}$, so the general solution of (1) is

$$
y=c_{1} \cos 2 \sqrt{2} x+c_{2} \sin 2 \sqrt{2} x+\frac{5}{8} x+\frac{2}{9} e^{-x}
$$

\section*{EXAMPLE 4 Using (5) of Section 4.5}
Solve


\begin{equation*}
y^{\prime \prime}+y=x \cos x-\cos x \tag{12}
\end{equation*}


Solution In Example 7 of Section 4.5 we saw that $x \cos x$ and $\cos x$ are annihilated by the operator $\left(D^{2}+1\right)^{2}$. Thus

$$
\left(D^{2}+1\right)^{2}\left(D^{2}+1\right) y=0 \quad \text { or } \quad\left(D^{2}+1\right)^{3} y=0
$$

Since $i$ and $-i$ are both complex roots of multiplicity 3 of the auxiliary equation of the last differential equation, we conclude

$$
y=c_{1} \cos x+c_{2} \sin x+c_{3} x \cos x+c_{4} x \sin x+c_{5} x^{2} \cos x+c_{6} x^{2} \sin x
$$

We substitute

$$
y_{p}=A x \cos x+B x \sin x+C x^{2} \cos x+E x^{2} \sin x
$$

into (12) and simplify:

$$
\begin{aligned}
y_{p}^{\prime \prime}+y_{p} & =4 E x \cos x-4 C x \sin x+(2 B+2 C) \cos x+(-2 A+2 E) \sin x \\
& =x \cos x-\cos x
\end{aligned}
$$

Equating coefficients gives the equations

$$
4 E=1, \quad-4 C=0, \quad 2 B+2 C=-1, \quad-2 A+2 E=0
$$

from which we find $E=\frac{1}{4}, C=0, B=-\frac{1}{2}$, and $A=\frac{1}{4}$. Hence the general solution of (12) is

$$
y=c_{1} \cos x+c_{2} \sin x+\frac{1}{4} x \cos x-\frac{1}{2} x \sin x+\frac{1}{4} x^{2} \sin x
$$

\section*{EXAMPLE 5 Form of a Particular Solution}
Determine the form of a particular solution for


\begin{equation*}
y^{\prime \prime}-2 y^{\prime}+y=10 e^{-2 x} \cos x \tag{13}
\end{equation*}


Solution The complementary function for the given equation is $y_{c}=c_{1} e^{x}+c_{2} x e^{x}$.

Now from (5) of Section 4.5 , with $\alpha=-2, \beta=1$, and $n=1$, we know that

$$
\left(D^{2}+4 D+5\right) e^{-2 x} \cos x=0
$$

Applying the operator $D^{2}+4 D+5$ to (13) gives


\begin{equation*}
\left(D^{2}+4 D+5\right)\left(D^{2}-2 D+1\right) y=0 \tag{14}
\end{equation*}


Since the roots of the auxiliary equation of (14) are $-2-i,-2+i, 1$, and 1 ,

$$
y=c_{1} e^{x}+c_{2} x e^{x}+c_{3} e^{-2 x} \cos x+c_{4} e^{-2 x} \sin x
$$

Hence a particular solution of (13) can be found with the form

$$
y_{p}=A e^{-2 x} \cos x+B e^{-2 x} \sin x
$$

\section*{EXAMPLE 6 Form of a Particular Solution}
Determine the form of a particular solution for


\begin{equation*}
y^{\prime \prime \prime}-4 y^{\prime \prime}+4 y^{\prime}=5 x^{2}-6 x+4 x^{2} e^{2 x}+3 e^{5 x} \tag{15}
\end{equation*}


Solution Observe that

$$
D^{3}\left(5 x^{2}-6 x\right)=0, \quad(D-2)^{3} x^{2} e^{2 x}=0, \quad \text { and } \quad(D-5) e^{5 x}=0
$$

Therefore $D^{3}(D-2)^{3}(D-5)$ applied to (15) gives

$$
\begin{array}{r}
D^{3}(D-2)^{3}(D-5)\left(D^{3}-4 D^{2}+4 D\right) y=0 \\
D^{4}(D-2)^{5}(D-5) y=0
\end{array}
$$

or

The roots of the auxiliary equation for the last differential equation are easily seen to be $0,0,0,0,2,2,2,2,2$, and 5 . Hence


\begin{equation*}
y=c_{1}+c_{2} x+c_{3} x^{2}+c_{4} x^{3}+c_{5} e^{2 x}+c_{6} x e^{2 x}+c_{7} x^{2} e^{2 x}+c_{8} x^{3} e^{2 x}+c_{9} x^{4} e^{2 x}+c_{10} e^{5 x} . \tag{16}
\end{equation*}


Since the linear combination $c_{1}+c_{5} e^{2 x}+c_{6} x e^{2 x}$ can be taken as the complementary function of (15), the remaining terms in (16) give the form of a particular solution of the differential equation:

$$
y_{p}=A x+B x^{2}+C x^{3}+E x^{2} e^{2 x}+F x^{3} e^{2 x}+G x^{4} e^{2 x}+H e^{5 x} \text {. }
$$

Summary of the Method For your convenience the method of undetermined coefficients is summarized here.

\section*{UNDETERMINED COEFFICIENTS-ANNIHILATOR APPROACH}
The differential equation $L(y)=g(x)$ has constant coefficients and the function $g(x)$ consists of finite sums and products of constants, polynomials, exponential functions $e^{\alpha x}$, sines, and cosines.

(i) Find the complementary solution $y_{c}$ for the homogeneous equation $L(y)=0$.

(ii) Operate on both sides of the nonhomogeneous equation $L(y)=g(x)$ with a differential operator $L_{1}$ that annihilates the function $g(x)$.

(iii) Find the general solution of the higher-order homogeneous differential equation $L_{1} L(y)=0$.

(iv) Delete all those terms from the solution in step (iii) that are duplicated in the complementary solution $y_{c}$ found in step (i). Form a linear combination $y_{p}$ of the terms that remain. This is the form of a particular solution of $L(y)=g(x)$.

(v) Substitute $y_{p}$ found in step (iv) into $L(y)=g(x)$. Match coefficients of the various functions on each side of the equality and solve the resulting system of equations for the unknown coefficients in $y_{p}$.

(vi) With the particular solution found in step ( $v$ ), form the general solution $y=y_{c}+y_{p}$ of the given differential equation.

\section*{EXERCISES 4.6}
Answers to odd-numbered problems begin on page A-8.

In Problems 1-32 solve the given differential equation by the method of undetermined coefficients.

$$
\begin{array}{ll}
\text { 1. } y^{\prime \prime}-9 y=54 & \text { 2. } 2 y^{\prime \prime}-7 y^{\prime}+5 y=-29
\end{array}
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $y^{\prime \prime}+y^{\prime}=3$
  \item $y^{\prime \prime \prime}+2 y^{\prime \prime}+y^{\prime}=10$
  \item $y^{\prime \prime}+4 y^{\prime}+4 y=2 x+6$
  \item $y^{\prime \prime}+3 y^{\prime}=4 x-5$
  \item $y^{\prime \prime \prime}+y^{\prime \prime}=8 x^{2}$
  \item $y^{\prime \prime}-2 y^{\prime}+y=x^{3}+4 x$
  \item $y^{\prime \prime}-y^{\prime}-12 y=e^{4 x}$
  \item $y^{\prime \prime}+2 y^{\prime}+2 y=5 e^{6 x}$
  \item $y^{\prime \prime}-2 y^{\prime}-3 y=4 e^{x}-9$
  \item $y^{\prime \prime}+6 y^{\prime}+8 y=3 e^{-2 x}+2 x$
  \item $y^{\prime \prime}+25 y=6 \sin x$
  \item $y^{\prime \prime}+4 y=4 \cos x+3 \sin x-8$
  \item $y^{\prime \prime}+6 y^{\prime}+9 y=-x e^{4 x}$
  \item $y^{\prime \prime}+3 y^{\prime}-10 y=x\left(e^{x}+1\right)$
  \item $y^{\prime \prime}-y=x^{2} e^{x}+5$
  \item $y^{\prime \prime}+2 y^{\prime}+y=x^{2} e^{-x}$
  \item $y^{\prime \prime}-2 y^{\prime}+5 y=e^{x} \sin x$
  \item $y^{\prime \prime}+y^{\prime}+\frac{1}{4} y=e^{x}(\sin 3 x-\cos 3 x)$
  \item $y^{\prime \prime}+25 y=20 \sin 5 x$
  \item $y^{\prime \prime}+y=4 \cos x-\sin x$
  \item $y^{\prime \prime}+y^{\prime}+y=x \sin x$
  \item $y^{\prime \prime}+4 y=\cos ^{2} x$
  \item $y^{\prime \prime \prime}+8 y^{\prime \prime}=-6 x^{2}+9 x+2$
  \item $y^{\prime \prime \prime}-y^{\prime \prime}+y^{\prime}-y=x e^{x}-e^{-x}+7$
  \item $y^{\prime \prime \prime}-3 y^{\prime \prime}+3 y^{\prime}-y=e^{x}-x+16$
  \item $2 y^{\prime \prime \prime}-3 y^{\prime \prime}-3 y^{\prime}+2 y=\left(e^{x}+e^{-x}\right)^{2}$
  \item $y^{(4)}-2 y^{\prime \prime \prime}+y^{\prime \prime}=e^{x}+1$
  \item $y^{(4)}-4 y^{\prime \prime}=5 x^{2}-e^{2 x}$
  \item $16 y^{(4)}-y=e^{x / 2}$
  \item $y^{(4)}-5 y^{\prime \prime}+4 y=2 \cosh x-6$
\end{enumerate}

In Problems 33-40 solve the given differential equation subject to the indicated initial conditions.\\
33. $y^{\prime \prime}-64 y=16, \quad y(0)=1, y^{\prime}(0)=0$\\
34. $y^{\prime \prime}+y^{\prime}=x, \quad y(0)=1, y^{\prime}(0)=0$\\
35. $y^{\prime \prime}-5 y^{\prime}=x-2, \quad y(0)=0, y^{\prime}(0)=2$\\
36. $y^{\prime \prime}+5 y^{\prime}-6 y=10 e^{2 x}, \quad y(0)=1, y^{\prime}(0)=1$\\
37. $y^{\prime \prime}+y=8 \cos 2 x-4 \sin x, \quad y(\pi / 2)=-1, y^{\prime}(\pi / 2)=0$\\
38. $y^{\prime \prime \prime}-2 y^{\prime \prime}+y^{\prime}=x e^{x}+5, \quad y(0)=2, y^{\prime}(0)=2, y^{\prime \prime}(0)=-1$\\
39. $y^{\prime \prime}-4 y^{\prime}+8 y=x^{3}, \quad y(0)=2, y^{\prime}(0)=4$\\
40. $y^{(4)}-y^{\prime \prime \prime}=x+e^{x}, \quad y(0)=0, y^{\prime}(0)=0, y^{\prime \prime}(0)=0, y^{\prime \prime \prime}(0)=0$

In Problems 41 and 42 determine the form of a particular solution for the given differential equation.\\
41. $y^{\prime \prime}-y=e^{x}(2+3 x \cos 2 x) \quad$ 42. $y^{\prime \prime}+y^{\prime}=9-e^{-x}+x^{2} \sin x$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item Show that the operator $(x D-1)(D+4)$ is not the same as the operator $(D+4)(x D-1)$.

  \item Prove that the differential equation

\end{enumerate}

$$
a_{n} y^{(n)}+a_{n-1} y^{(n-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=k
$$

$k$ a constant, $a_{0} \neq 0$, has the particular solution $y_{p}=k / a_{0}$.

\subsection*{4.7 VARIATION OF PARAMETERS \\
 - Variation of parameters \\
 - Particular solution}
Linear First-Order Equation Revisited In Chapter 2 we saw that the general solution of the linear first-order differential equation


\begin{equation*}
\frac{d y}{d x}+P(x) y=f(x) \tag{1}
\end{equation*}


where $P(x)$ and $f(x)$ are continuous on an interval $I$, is


\begin{equation*}
y=e^{-\int P(x) d x} \int e^{\int P(x) d x} f(x) d x+c_{1} e^{-\int P(x) d x} \tag{2}
\end{equation*}


Now (2) has the form $y=y_{c}+y_{p}$, where $y_{c}=c_{1} e^{-\int P(x) d x}$ is a solution of


\begin{equation*}
\frac{d y}{d x}+P(x) y=0 \tag{3}
\end{equation*}


and


\begin{equation*}
y_{p}=e^{-\int P(x) d x} \int e^{\int P(x) d x} f(x) d x \tag{4}
\end{equation*}


is a particular solution of (1). As a means of motivating an additional method for solving nonhomogeneous linear equations of higher order, we rederive (4) by a method known as variation of parameters. The basic procedure is essentially that used in Section 4.2.

Suppose $y_{1}$ is a known solution of (3); that is,

$$
\frac{d y_{1}}{d x}+P(x) y_{1}=0
$$

We proved in Section 2.5 that $y_{1}=e^{-\int P(x) d x}$ is a solution, and since the differential equation is linear, its general solution is $y=c_{1} y_{1}(x)$. Variation of parameters consists of finding a function $u_{1}$ such that

$$
y_{p}=u_{1}(x) y_{1}(x)
$$

is a particular solution of (1). In other words, we replace the parameter $c_{1}$ by a variable $u_{1}$.

Substituting $y_{p}=u_{1} y_{1}$ into (1) gives

$$
\begin{array}{r}
\frac{d}{d x}\left[u_{1} y_{1}\right]+P(x) u_{1} y_{1}=f(x) \\
u_{1} \frac{d y_{1}}{d x}+y_{1} \frac{d u_{1}}{d x}+P(x) u_{1} y_{1}=f(x) \\
u_{1} \underbrace{\left.\frac{d y_{1}}{d x}+P(x) y_{1}\right]}_{\text {zero }}+y_{1} \frac{d u_{1}}{d x}=f(x),
\end{array}
$$

$$
y_{1} \frac{d u_{1}}{d x}=f(x)
$$

By separating variables, we find that

$$
d u_{1}=\frac{f(x)}{y_{1}(x)} d x \quad \text { and } \quad u_{1}=\int \frac{f(x)}{y_{1}(x)} d x
$$

from which it follows that

$$
y=u_{1} y_{1}=y_{1} \int \frac{f(x)}{y_{1}(x)} d x
$$

From the definition of $y_{1}$ we see that the last result is identical to (4).

Second-Order Equations To adapt the foregoing procedure to a linear second-order differential equation


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=g(x) \tag{5}
\end{equation*}


we put (5) in the standard form


\begin{equation*}
y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=f(x) \tag{6}
\end{equation*}


by dividing through by $a_{2}(x)$. Here we assume that $P(x), Q(x)$, and $f(x)$ are continuous on some interval $I$. Equation (6) is the analogue of (1). As we know, when $P(x)$ and $Q(x)$ are constants, we have absolutely no difficulty in writing $y_{c}$.

Suppose $y_{1}$ and $y_{2}$ form a fundamental set of solutions on $I$ of the associated homogeneous form of (6); that is,

$$
y_{1}^{\prime \prime}+P(x) y_{1}^{\prime}+Q(x) y_{1}=0 \quad \text { and } \quad y_{2}^{\prime \prime}+P(x) y_{2}^{\prime}+Q(x) y_{2}=0
$$

Now we ask: Can two functions $u_{1}$ and $u_{2}$ be found so that

is a particular solution of (6)? Notice that our assumption for $y_{p}$ is the same as $y_{c}=c_{1} y_{1}+c_{2} y_{2}$, but we have replaced $c_{1}$ and $c_{2}$ by the "variable parameters" $u_{1}$ and $u_{2}$. Because we seek to determine two unknown functions, reason dictates that we need two equations. As in the introductory discussion leading to the discovery of (4), one of these equations results from substituting $y_{p}=u_{1} y_{1}+u_{2} y_{2}$ into the given differential equation (6). The other equation that we impose is


\begin{equation*}
y_{1} u_{1}^{\prime}+y_{2} u_{2}^{\prime}=0 \tag{7}
\end{equation*}


This equation is an assumption that is made to simplify the first derivative and, thereby, the second derivative of $y_{p}$. Using the product rule to differentiate $y_{p}$, we get


\begin{equation*}
y_{p}^{\prime}=u_{1} y_{1}^{\prime}+y_{1} u_{1}^{\prime}+u_{2} y_{2}^{\prime}+y_{2} u_{2}^{\prime}=u_{1} y_{1}^{\prime}+u_{2} y_{2}^{\prime}+\cdots \tag{8}
\end{equation*}


and so $y_{p}^{\prime}=u_{1} y_{1}^{\prime}+u_{2} y_{2}^{\prime}$

Continuing, we find

$$
y_{p}^{\prime \prime}=u_{1} y_{1}^{\prime \prime}+y_{1}^{\prime} u_{1}^{\prime}+u_{2} y_{2}^{\prime \prime}+y_{2}^{\prime} u_{2}^{\prime}
$$

Substitution of these results in (6) yields

$$
\begin{aligned}
& y_{p}^{\prime \prime}+P y_{p}^{\prime}+Q y_{p}=u_{1} y_{1}^{\prime \prime}+y_{1}^{\prime} u_{1}^{\prime}+u_{2} y_{2}^{\prime \prime}+y_{2}^{\prime} u_{2}^{\prime}+P u_{1} y_{1}^{\prime}+P u_{2} y_{2}^{\prime}+Q u_{1} y_{1}+Q u_{2} y_{2} \\
& =u_{1}[y_{1}^{\prime \prime}+\underbrace{\left.P y_{1}^{\prime}+Q y_{1}\right]}+u_{2}[y_{2}^{\prime \prime}+\underbrace{\left.P y_{2}^{\prime}+Q y_{2}\right]}+y_{1}^{\prime} u_{1}^{\prime}+y_{2}^{\prime} u_{2}^{\prime}=f(x)
\end{aligned}
$$

In other words, $u_{1}$ and $u_{2}$ must be functions that also satisfy the condition


\begin{equation*}
y_{1}^{\prime} u_{1}^{\prime}+y_{2}^{\prime} u_{2}^{\prime}=f(x) \tag{9}
\end{equation*}


Equations (7) and (9) constitute a linear system of equations for determining the derivatives $u_{1}^{\prime}$ and $u_{2}^{\prime}$. By Cramer's rule,* the solution of

$$
\begin{aligned}
& y_{1} u_{1}^{\prime}+y_{2} u_{2}^{\prime}=0 \\
& y_{1}^{\prime} u_{1}^{\prime}+y_{2}^{\prime} u_{2}^{\prime}=f(x)
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item See Appendix III for a review of Cramer's rule.
\end{itemize}
}
can be expressed in terms of determinants:


\begin{equation*}
u_{1}^{\prime}=\frac{W_{1}}{W} \text { and } \quad u_{2}^{\prime}=\frac{W_{2}}{W} \tag{10}
\end{equation*}


where

\[
W=\left|\begin{array}{ll}
y_{1} & y_{2}  \tag{11}\\
y_{1}^{\prime} & y_{2}^{\prime}
\end{array}\right|, \quad W_{1}=\left|\begin{array}{cc}
0 & y_{2} \\
f(x) & y_{2}^{\prime}
\end{array}\right|, \quad \text { and } \quad W_{2}=\left|\begin{array}{cc}
y_{1} & 0 \\
y_{1}^{\prime} & f(x)
\end{array}\right|
\]

The determinant $W$ is recognized as the Wronskian of $y_{1}$ and $y_{2}$. By linear independence of $y_{1}$ and $y_{2}$ on $I$, we know that $W\left(y_{1}(x), y_{2}(x)\right) \neq 0$ for every $x$ in the interval.

Summary of the Method Usually it is not a good idea to memorize formulas in lieu of understanding a procedure. However, the foregoing procedure is too long and complicated to use each time we wish to solve a differential equation. In this case it is more efficient to simply use the formulas in (10). Thus, to solve $a_{2} y^{\prime \prime}+a_{1} y^{\prime}+a_{0} y=g(x)$, first find the complementary function $y_{c}=c_{1} y_{1}+$ $c_{2} y_{2}$ and then compute the Wronskian

$$
W=\left|\begin{array}{ll}
y_{1} & y_{2} \\
y_{1}^{\prime} & y_{2}^{\prime}
\end{array}\right|
$$

By dividing by $a_{2}$, we put the equation into the form $y^{\prime \prime}+P y^{\prime}+Q y=f(x)$ to determine $f(x)$. We find $u_{1}$ and $u_{2}$ by integrating $u_{1}^{\prime}=W_{1} / W$ and $u_{2}^{\prime}=W_{2} / W$, where $W_{1}$ and $W_{2}$ are defined in (11). A particular solution is $y_{p}=u_{1} y_{1}+u_{2} y_{2}$. The general solution of the equation is then $y=y_{c}+y_{p}$.

\section*{EXAMPLE I General Solution}
Solve $y^{\prime \prime}-4 y^{\prime}+4 y=(x+1) e^{2 x}$.

Solution Since the auxiliary equation is $m^{2}-4 m+4=(m-2)^{2}=0$, we have $y_{c}=c_{1} e^{2 x}+c_{2} x e^{2 x}$. Identifying $y_{1}=e^{2 x}$ and $y_{2}=x e^{2 x}$, we next compute the Wronskian

$$
W\left(e^{2 x}, x e^{2 x}\right)=\left|\begin{array}{cc}
e^{2 x} & x e^{2 x} \\
2 e^{2 x} & 2 x e^{2 x}+e^{2 x}
\end{array}\right|=e^{4 x}
$$

Since the given differential equation is already in form (6) (that is, the coefficient of $y^{\prime \prime}$ is 1 ), we identify $f(x)=(x+1) e^{2 x}$. From (11) we obtain

$$
\begin{gathered}
W_{1}=\left|\begin{array}{cc}
0 & x e^{2 x} \\
(x+1) e^{2 x} & 2 x e^{2 x}+e^{2 x}
\end{array}\right|=-(x+1) x e^{4 x} \\
W_{2}=\left|\begin{array}{cc}
e^{2 x} & 0 \\
2 e^{2 x} & (x+1) e^{2 x}
\end{array}\right|=(x+1) e^{4 x}
\end{gathered}
$$

and so, from (10),

$$
u_{1}^{\prime}=-\frac{(x+1) x e^{4 x}}{e^{4 x}}=-x^{2}-x, \quad u_{2}^{\prime}=\frac{(x+1) e^{4 x}}{e^{4 x}}=x+1
$$

It follows that

$$
u_{1}=-\frac{x^{3}}{3}-\frac{x^{2}}{2} \quad \text { and } \quad u_{2}=\frac{x^{2}}{2}+x
$$

Therefore

$$
\begin{aligned}
y_{p} & =\left(-\frac{x^{3}}{3}-\frac{x^{2}}{2}\right) e^{2 x}+\left(\frac{x^{2}}{2}+x\right) x e^{2 x} \\
& =\left(\frac{x^{3}}{6}+\frac{x^{2}}{2}\right) e^{2 x} \\
y & =y_{c}+y_{p}=c_{1} e^{2 x}+c_{2} x e^{2 x}+\left(\frac{x^{3}}{6}+\frac{x^{2}}{2}\right) e^{2 x}
\end{aligned}
$$

Hence

\section*{General Solution}
Solve $4 y^{\prime \prime}+36 y=\csc 3 x$.

Solution We first put the equation in the standard form (6) by dividing by 4 :

$$
y^{\prime \prime}+9 y=\frac{1}{4} \csc 3 x
$$

Since the roots of the auxiliary equation $m^{2}+9=0$ are $m_{1}=3 i$ and $m_{2}=-3 i$, the complementary function is $y_{c}=c_{1} \cos 3 x+c_{2} \sin 3 x$. Using $y_{1}=\cos 3 x, y_{2}=\sin 3 x$, and $f(x)=\frac{1}{4} \csc 3 x$, we find

$$
\begin{aligned}
W(\cos 3 x, \sin 3 x) & =\left|\begin{array}{cc}
\cos 3 x & \sin 3 x \\
-3 \sin 3 x & 3 \cos 3 x
\end{array}\right|=3 \\
W_{1} & =\left|\begin{array}{cc}
0 & \sin 3 x \\
\frac{1}{4} \csc 3 x & 3 \cos 3 \mathrm{x}
\end{array}\right|=-\frac{1}{4} \leftarrow \csc 3 x=\frac{1}{\sin 3 x} \\
W_{2} & =\left|\begin{array}{cc}
\cos 3 x & 0 \\
-3 \sin 3 x & \frac{1}{4} \csc 3 x
\end{array}\right|=\frac{1}{4} \frac{\cos 3 x}{\sin 3 x} .
\end{aligned}
$$

Integrating

$$
\begin{aligned}
& u_{1}^{\prime}=\frac{W_{1}}{W}=-\frac{1}{12} \quad \text { and } \quad u_{2}^{\prime}=\frac{W_{2}}{W}=\frac{1}{12} \frac{\cos 3 x}{\sin 3 x} \\
& u_{1}=-\frac{1}{12} x \quad \text { and } \quad u_{2}=\frac{1}{36} \ln |\sin 3 x|
\end{aligned}
$$

Thus a particular solution is

$$
y_{p}=-\frac{1}{12} x \cos 3 x+\frac{1}{36}(\sin 3 x) \ln |\sin 3 x| \text {. }
$$

The general solution of the equation is


\begin{equation*}
y=y_{c}+y_{p}=c_{1} \cos 3 x+c_{2} \sin 3 x-\frac{1}{12} x \cos 3 x+\frac{1}{36}(\sin 3 x) \ln |\sin 3 x| \tag{12}
\end{equation*}


Equation (12) represents the general solution of the differential equation on, say, the interval $(0, \pi / 6)$.

Constants of Integration When computing the indefinite integrals of $u_{1}^{\prime}$ and $u_{2}^{\prime}$, we need not introduce any constants. This is because

$$
\begin{aligned}
y=y_{c}+y_{p} & =c_{1} y_{1}+c_{2} y_{2}+\left(u_{1}+a_{1}\right) y_{1}+\left(u_{2}+b_{1}\right) y_{2} \\
& =\left(c_{1}+a_{1}\right) y_{1}+\left(c_{2}+b_{1}\right) y_{2}+u_{1} y_{1}+u_{2} y_{2} \\
& =C_{1} y_{1}+C_{2} y_{2}+u_{1} y_{1}+u_{2} y_{2} .
\end{aligned}
$$

\section*{EXAMPLE 3 Using Nonelementary Integrals}
Solve $y^{\prime \prime}-y=\frac{1}{x}$.

Solution The auxiliary equation $m^{2}-1=0$ yields $m_{1}=-1$ and $m_{2}=1$. Therefore $y_{c}=c_{1} e^{x}+c_{2} e^{-x}$ and

$$
\begin{gathered}
W\left(e^{x}, e^{-x}\right)=\left|\begin{array}{cc}
e^{x} & e^{-x} \\
e^{x} & -e^{-x}
\end{array}\right|=-2 \\
u_{1}^{\prime}=-\frac{e^{-x}(1 / x)}{-2}, \quad u_{1}=\frac{1}{2} \int_{x_{0}}^{x} \frac{e^{-t}}{t} d t \\
u_{2}^{\prime}=\frac{e^{x}(1 / x)}{-2}, \quad u_{2}=-\frac{1}{2} \int_{x_{0}}^{x} \frac{e^{t}}{t} d t .
\end{gathered}
$$

It is well known that the integrals defining $u_{1}$ and $u_{2}$ cannot be expressed in terms of elementary functions. Hence we write

$$
y_{p}=\frac{1}{2} e^{x} \int_{x_{0}}^{x} \frac{e^{-t}}{t} d t-\frac{1}{2} e^{-x} \int_{x_{0}}^{x} \frac{e^{t}}{t} d t
$$

and so

$$
y=y_{c}+y_{p}=c_{1} e^{x}+c_{2} e^{-x}+\frac{1}{2} e^{x} \int_{x_{0}}^{x} \frac{e^{-t}}{t} d t-\frac{1}{2} e^{-x} \int_{x_{0}}^{x} \frac{e^{t}}{t} d t
$$

In Example 3 we can integrate on any interval $x_{0} \leq t \leq x$ not containing the origin.

Higher-Order Equations The method we have just examined for nonhomogeneous second-order differential equations can be generalized to $n$ th-order linear equations that have been put into the form


\begin{equation*}
y^{(n)}+P_{n-1}(x) y^{(n-1)}+\cdots+P_{1}(x) y^{\prime}+P_{0}(x) y=f(x) \tag{13}
\end{equation*}


If $y=c_{1} y_{1}+c_{2} y_{2}+\cdots+c_{n} y_{n}$ is the complementary function for (13), then a particular solution is

$$
y_{p}=u_{1}(x) y_{1}(x)+u_{2}(x) y_{2}(x)+\cdots+u_{n}(x) y_{n}(x),
$$

where the $u_{k}^{\prime}, k=1,2, \ldots, n$ are determined by the $n$ equations

$$
\begin{gathered}
y_{1} u_{1}^{\prime}+y_{2} u_{2}^{\prime}+\cdots+y_{n} u_{n}^{\prime}=0 \\
y_{1}^{\prime} u_{1}^{\prime}+y_{2}^{\prime} u_{2}^{\prime}+\cdots+y_{n}^{\prime} u_{n}^{\prime}=0 \\
\vdots \\
y_{1}^{(n-1)} u_{1}^{\prime}+y_{2}^{(n-1)} u_{2}^{\prime}+\cdots+y_{n}^{(n-1)} u_{n}^{\prime}=f(x) .
\end{gathered}
$$

The first $n-1$ equations in this system, like (7), are assumptions made to simplify the first $n-1$ derivatives of $y_{p}$. The last equation of the system results\\
from substituting the $n$th derivative of $y_{p}$ and the simplified lower derivatives into (13). In this case, Cramer's rule gives

$$
u_{k}^{\prime}=\frac{W_{k}}{W}, \quad k=1,2, \ldots, n
$$

where $W$ is the Wronskian of $y_{1}, y_{2}, \ldots, y_{n}$, and $W_{k}$ is the determinant obtained by replacing the $k$ th column of the Wronskian by the column whose entries are $0,0, \ldots, 0, f(x)$. When $n=2$, we get (10) and (11).

Remarks (i) Variation of parameters has a distinct advantage over the method of undetermined coefficients in that it will always yield a particular solution $y_{p}$, provided the related homogeneous equation can be solved. The present method is not limited to a function $f(x)$, which is a combination of the four types of functions listed on page 146. Also, variation of parameters, unlike undetermined coefficients, is applicable to differential equations with variable coefficients.

In the problems that follow do not hesitate to simplify the form of $y_{p}$. Depending on how the antiderivatives of $u_{1}^{\prime}$ and $u_{2}^{\prime}$ are found, you may not obtain the same $y_{p}$ as given in the answer section. For example, in Problem 3, both $y_{p}=\frac{1}{2} \sin x-\frac{1}{2} x \cos x$ and $y_{p}=\frac{1}{4} \sin x-\frac{1}{2} x \cos x$ are valid answers. In either case, the general solution $y=y_{c}+y_{p}$ simplifies to $y=c_{1} \cos x+c_{2} \sin x-\frac{1}{2} x \cos x$. Why?

(ii) In Problems 25-28 you are asked to solve initial-value problems. Be sure to apply the initial conditions to the general solution $y=y_{c}+y_{p}$. Students often make the mistake of applying the initial conditions to only the complementary function $y_{c}$ since it is that part of the solution that contains the constants. Review Example 8 in Section 4.4 for the correct procedure.

\section*{EXERCISES 4.7}
\section*{Answers to odd-numbered problems begin on page A-9.}
In Problems 1-24 solve each differential equation by variation of parameters. State an interval on which the general solution is defined.

\begin{enumerate}
  \item $y^{\prime \prime}+y=\sec x$
  \item $y^{\prime \prime}+y=\tan x$
  \item $y^{\prime \prime}+y=\sin x$
  \item $y^{\prime \prime}+y=\sec x \tan x$
  \item $y^{\prime \prime}+y=\cos ^{2} x$
  \item $y^{\prime \prime}+y=\sec ^{2} x$
  \item $y^{\prime \prime}-y=\cosh x$
  \item $y^{\prime \prime}-y=\sinh 2 x$
  \item $y^{\prime \prime}-4 y=e^{2 x} / x$
  \item $y^{\prime \prime}-9 y=9 x / e^{3 x}$
  \item $y^{\prime \prime}+3 y^{\prime}+2 y=1 /\left(1+e^{x}\right)$
  \item $y^{\prime \prime}-3 y^{\prime}+2 y=e^{3 x} /\left(1+e^{x}\right)$
  \item $y^{\prime \prime}+3 y^{\prime}+2 y=\sin e^{x}$
  \item $y^{\prime \prime}-2 y^{\prime}+y=e^{x} \arctan x$
  \item $y^{\prime \prime}-2 y^{\prime}+y=e^{x} /\left(1+x^{2}\right)$
  \item $y^{\prime \prime}-2 y^{\prime}+2 y=e^{x} \sec x$
  \item $y^{\prime \prime}+2 y^{\prime}+y=e^{-x} \ln x$
  \item $y^{\prime \prime}+10 y^{\prime}+25 y=e^{-10 x} / x^{2}$
  \item $3 y^{\prime \prime}-6 y^{\prime}+30 y=e^{x} \tan 3 x$
  \item $4 y^{\prime \prime}-4 y^{\prime}+y=e^{x / 2} \sqrt{1-x^{2}}$
  \item $y^{\prime \prime \prime}+y^{\prime}=\tan x$
  \item $y^{\prime \prime \prime}+4 y^{\prime}=\sec 2 x$
  \item $y^{\prime \prime \prime}-2 y^{\prime \prime}-y^{\prime}+2 y=e^{3 x}$
  \item $2 y^{\prime \prime \prime}-6 y^{\prime \prime}=x^{2}$
\end{enumerate}

In Problems 25-28 solve each differential equation by variation of parameters subject to the initial conditions $y(0)=1, y^{\prime}(0)=0$.\\
25. $4 y^{\prime \prime}-y=x e^{x / 2}$\\
26. $2 y^{\prime \prime}+y^{\prime}-y=x+1$\\
27. $y^{\prime \prime}+2 y^{\prime}-8 y=2 e^{-2 x}-e^{-x}$\\
28. $y^{\prime \prime}-4 y^{\prime}+4 y=\left(12 x^{2}-6 x\right) e^{2 x}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item Given that $y_{1}=x$ and $y_{2}=x \ln x$, form a fundamental set of solutions of $x^{2} y^{\prime \prime}-x y^{\prime}+y=0$ on $(0, \infty)$. Find the general solution of
\end{enumerate}

$$
x^{2} y^{\prime \prime}-x y^{\prime}+y=4 x \ln x
$$

\begin{enumerate}
  \setcounter{enumi}{29}
  \item Given that $y_{1}=x^{2}$ and $y_{2}=x^{3}$, form a fundamental set of solutions of $x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=0$ on $(0, \infty)$. Find the general solution of
\end{enumerate}

$$
x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=\frac{1}{x}
$$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item Given that $y_{1}=x^{-1 / 2} \cos x$ and $y_{2}=x^{-1 / 2} \sin x$, form a fundamental set of solutions of $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{1}{4}\right) y=0$ on $(0, \infty)$. Find the general solution of
\end{enumerate}

$$
x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{1}{4}\right) y=x^{3 / 2}
$$

\begin{enumerate}
  \setcounter{enumi}{31}
  \item Given that $y_{1}=\cos (\ln x)$ and $y_{2}=\sin (\ln x)$ are known linearly independent solutions of $x^{2} y^{\prime \prime}+x y^{\prime}+y=0$ on $(0, \infty)$ :
\end{enumerate}

(a) Find a particular solution of

$$
x^{2} y^{\prime \prime}+x y^{\prime}+y=\sec (\ln x)
$$

(b) Give the general solution of the equation and state an interval of validity. [Hint: It is not $(0, \infty)$. Why?]

\begin{enumerate}
  \setcounter{enumi}{32}
  \item (a) Use undetermined coefficients to find a particular solution of
\end{enumerate}

$$
y^{\prime \prime}+2 y^{\prime}+y=4 x^{2}-3
$$

(b) Use variation of parameters to find a particular solution of

$$
y^{\prime \prime}+2 y^{\prime}+y=\frac{e^{-x}}{x}
$$

(c) Use the superposition principle (Theorem 4.9) to find a particular solution of

$$
y^{\prime \prime}+2 y^{\prime}+y=4 x^{2}-3+\frac{e^{-x}}{x}
$$

\begin{enumerate}
  \setcounter{enumi}{33}
  \item Use the method outlined in Problem 33 to find a particular solution of
\end{enumerate}

$$
y^{\prime \prime}+y=2 x-e^{3 x}+\cot x
$$

\section*{CHAPTER 4 REVIEW}
We summarize the important results of this chapter for linear second-order differential equations.

The equation


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0 \tag{1}
\end{equation*}


is said to be homogeneous, whereas


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=g(x) \tag{2}
\end{equation*}


$g(x)$ not identically zero, is nonhomogeneous. In the consideration of the linear equations (1) and (2), we assume that $a_{2}(x), a_{1}(x), a_{0}(x)$, and $g(x)$ are continuous on an interval $I$ and that $a_{2}(x) \neq 0$ for every $x$ in the interval. Under these assumptions there exists a unique solution of (2) satisfying the initial conditions $y\left(x_{0}\right)=y_{0}, y^{\prime}\left(x_{0}\right)=y_{0}^{\prime}$, where $x_{0}$ is a point in $I$.

The Wronskian of two differentiable functions $f_{1}(x)$ and $f_{2}(x)$ is the determinant

$$
W\left(f_{1}(x), f_{2}(x)\right)=\left|\begin{array}{ll}
f_{1}(x) & f_{2}(x) \\
f_{1}^{\prime}(x) & f_{2}^{\prime}(x)
\end{array}\right|
$$

When $W \neq 0$ for at least one point in an interval, the set of functions is linearly independent on the interval. If the set of functions is linearly dependent on the interval, then $W=0$ for every $x$ in the interval.

In solving the homogeneous equation (1), we want linearly independent solutions. A necessary and sufficient condition that two solutions $y_{1}$ and $y_{2}$ are linearly independent on $I$ is that $W\left(y_{1}, y_{2}\right) \neq 0$ for every $x$ in $I$. We say $y_{1}$ and $y_{2}$ form a fundamental set on $I$ when they are linearly independent solutions of (1) on the interval. For any two solutions $y_{1}$ and $y_{2}$, the superposition principle states that the linear combination $c_{1} y_{1}+c_{2} y_{2}$ is also a solution of (1). When $y_{1}$ and $y_{2}$ form a fundamental set, the function $y=c_{1} y_{1}+c_{2} y_{2}$ is called the general solution of (1). The general solution of (2) is $y=y_{c}+y_{p}$, where $y_{c}$ is the complementary function, or general solution, of (1) and $y_{p}$ is any particular solution of (2).

To solve (1) in the case $a y^{\prime \prime}+b y^{\prime}+c y=0, a, b$, and $c$ constants, we first solve the auxiliary equation $a m^{2}+b m+c=0$. There are three forms of the general solution depending on the three possible ways in which the roots of the auxiliary equation can occur (see Table 4.2).

Table 4.2

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-197}
\end{center}

To solve a nonhomogeneous differential equation we use either the method of undetermined coefficients or variation of parameters to find a particular solution $y_{p}$. The former procedure is limited to differential equations $a y^{\prime \prime}+b y^{\prime}+c y=g(x)$, where $a, b$, and $c$ are constants and $g(x)$ is a constant, a polynomial, $e^{\alpha x}, \cos \beta x, \sin \beta x$, or finite sums and products of these functions.

\section*{CHAPTER 4 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-9.

Answer Problems 1-10 without referring back to the text. Fill in the blank or answer true or false. In some cases there can be more than one correct answer.

\begin{enumerate}
  \item The only solution of $y^{\prime \prime}+x^{2} y=0, y(0)=0, y^{\prime}(0)=0$ is $\qquad$ .

  \item If two differentiable functions $f_{1}(x)$ and $f_{2}(x)$ are linearly independent on an interval, then $W\left(f_{1}(x), f_{2}(x)\right) \neq 0$ for at least one point in the interval. $\qquad$

  \item Two functions $f_{1}(x)$ and $f_{2}(x)$ are linearly independent on an interval if one is not a constant multiple of the other. $\qquad$

  \item The functions $f_{1}(x)=x^{2}, f_{2}(x)=1-x^{2}$, and $f_{3}(x)=2+x^{2}$ are linearly $\qquad$ on the interval $(-\infty, \infty)$.

  \item The functions $f_{1}(x)=x^{2}$ and $f_{2}(x)=x|x|$ are linearly independent on the interval $\qquad$ , whereas they are linearly dependent on the interval $\qquad$ .

  \item Two solutions $y_{1}$ and $y_{2}$ of $y^{\prime \prime}+y^{\prime}+y=0$ are linearly dependent if $W\left(y_{1}, y_{2}\right)=0$ for every real value of $x$. $\qquad$ .

  \item A constant multiple of a solution of a differential equation is also a solution. $\qquad$

  \item A fundamental set of two solutions of $(x-2) y^{\prime \prime}+y=0$ exists on any interval not containing the point $\qquad$ .

  \item For the method of undetermined coefficients, the assumed form of the particular solution $y_{p}$ for $y^{\prime \prime}-y=1+e^{x}$ is $\qquad$ .

  \item A differential operator that annihilates $e^{2 x}(x+\sin x)$ is $\qquad$ .

\end{enumerate}

In Problems 11 and 12 find a second solution for the differential equation given that $y_{1}(x)$ is a known solution.\\
11. $y^{\prime \prime}+4 y=0, \quad y_{1}=\cos 2 x$\\
12. $x y^{\prime \prime}-2(x+1) y^{\prime}+(x+2) y=0, \quad y_{1}=e^{x}$

In Problems 13-18 find the general solution of each differential equation.\\
13. $y^{\prime \prime}-2 y^{\prime}-2 y=0$\\
14. $2 y^{\prime \prime}+2 y^{\prime}+3 y=0$\\
15. $y^{\prime \prime \prime}+10 y^{\prime \prime}+25 y^{\prime}=0$\\
16. $2 y^{\prime \prime \prime}+9 y^{\prime \prime}+12 y^{\prime}+5 y=0$\\
17. $3 y^{\prime \prime \prime}+10 y^{\prime \prime}+15 y^{\prime}+4 y=0$\\
18. $2 \frac{d^{4} y}{d x^{4}}+3 \frac{d^{3} y}{d x^{3}}+2 \frac{d^{2} y}{d x^{2}}+6 \frac{d y}{d x}-4 y=0$

In Problems 19-22 solve each differential equation by the method of undetermined coefficients.\\
19. $y^{\prime \prime}-3 y^{\prime}+5 y=4 x^{3}-2 x$\\
20. $y^{\prime \prime}-2 y^{\prime}+y=x^{2} e^{x}$\\
21. $y^{\prime \prime \prime}-5 y^{\prime \prime}+6 y^{\prime}=2 \sin x+8$\\
22. $y^{\prime \prime \prime}-y^{\prime \prime}=6$

In Problems 23 and 24 solve the given differential equation subject to the indicated conditions.\\
23. $y^{\prime \prime}-2 y^{\prime}+2 y=0, \quad y(\pi / 2)=0, y(\pi)=-1$\\
24. $y^{\prime \prime}-y=x+\sin x, \quad y(0)=2, y^{\prime}(0)=3$

In Problems 25 and 26 solve each differential equation by the method of variation of parameters.\\
25. $y^{\prime \prime}-2 y^{\prime}+2 y=e^{x} \tan x$\\
26. $y^{\prime \prime}-y=2 e^{x} /\left(e^{x}+e^{-x}\right)$

In Problems 27 and 28 solve the given differential equation subject to the indicated conditions.\\
27. $\left(2 D^{3}-13 D^{2}+24 D-9\right) y=36, \quad y(0)=-4, y^{\prime}(0)=0, y^{\prime \prime}(0)=\frac{5}{2}$\\
28. $y^{\prime \prime}+y=\sec ^{3} x, \quad y(0)=1, y^{\prime}(0)=\frac{1}{2}$

\section*{CHAOS}
Afamous science fiction story tells of a politician who, soon after winning an election, takes a trip in a time travel machine back to the days of the dinosaurs. While there, and though much admonished not to disturb anything, he bends a blade of grass. When he returns to his real present, he finds that in this modified world he has lost the election.

This is what mathematicians mean when they say that a system exhibits chaos: Tiny changes in the initial state of a system can decisively affect the outcome. One speaks of the butterfly effect. Can the fluttering of the wings of a butterfly in Japan have a decisive effect on the weather in the United States a month later?

Most people would probably dismiss the suggestion as preposterous without a second thought. But I think it is true, at least if the time span of one month is increased to six months, and I propose here to give some quantitative reasons for my conclusions.

It is not obvious how you would go about justifying the reality of the butterfly effect. We do not have a time machine available; we cannot go back six weeks, catch a butterfly (while disturbing nothing else, whatever that means), and then come back and observe the consequences. We need to take a more devious tack.

To help you follow the argument, I will describe a "toy model" that clearly exhibits "butterfly behavior," and within which the notions that I will introduce can be understood.

Consider the (purely mathematical) system in which, at each tick of the clock, an angle is doubled. A state of the system is an angle, and it evolves by doubling again and again. In symbols, you could describe the system as a sequence of angles,

$$
\theta_{0}, \theta_{1}, \ldots
$$

where $\theta_{0}$ is the initial state of the system and $\theta_{n+1}=2 \theta_{n}$.

This system exhibits butterfly behavior. If $\theta_{0}$ is perturbed by one-billionth of a turn, then the state after 30 ticks of the clock is completely unknown. In-\\
deed, the uncertainty in our knowledge of the state of the system doubles at each tick; after 30 ticks, our uncertainty has grown to

$$
\frac{2^{30}}{1,000,000,000}
$$

which is slightly greater than 1 . Our uncertainty is now more than a turn; we don't know anything anymore.

The example above brings in a key notion in all descriptions of chaos entropy. This is essentially the rate at which information dissipates. There are many ways of describing this rate with precision, and they go by various names (for example, Lyapunov exponents), but for the purposes of this article, I will stick with the doubling time: the amount of time it takes for a small uncertainty to double.

How would we estimate this time for the system formed by the weather? Of course, we cannot "choose two initial states for the weather an epsilon apart and measure how fast they diverge," but we can do something like it. We can go back over history and find times when the weather was very similar. Then we can see how long it took for the weather pattern to diverge. This has been done and leads to a doubling time of about $2 \frac{1}{2}$ days.

You can also go to the meteorology department of a big research institution (in practice, the Institut de Météorologie de l'université de Paris-VI) and ask what the doubling time is for their best computer models. You get much the same figure.

The next question that must be faced is this: What corresponds to the number one-billionth above? What proportion of the size of the system (the atmosphere) is our disturbance (one butterfly)? One (perhaps contestable) way of estimating this is simply to measure the ratio of the masses. We might guess that a butterfly weighs 1 gram (rather a heavy butterfly), and it turns out that the atmosphere has a mass of about $5 \times 10^{21}$ grams.

The atmospheric pressure is very nearly $1 \mathrm{~kg} / \mathrm{cm}^{2}$, meaning that there is 1 kg of air above every square centimeter of the earth. The area of a sphere of radius $r$ is $4 \pi r^{2}$, and the radius of the earth is about 6000 km . Thus the mass of the atmosphere is about

$$
1000 \times 4 \times \pi \times\left(6 \times 10^{8}\right)^{2} \text { grams. }
$$

So a butterfly isn't one-billionth the size of the system; it is more nearly a thousand-billion-billionth.

Since $5 \times 10^{21}$ is approximately $2^{72}$, it should take about 72 doubling periods for the effects of an individual butterfly to induce perturbations on a global scale.

One consequence of this analysis is that long-term weather prediction should be completely impossible. It is inconceivable that anyone could ever know the state of the atmosphere to within the effect of one butterfly, or even on a scale a thousand billion times larger. Perturbations on that scale decisively affect the global weather within a month.

Physicists, chemists, astronomers, and mathematicians have now shown that a vast collection of systems appear to display "chaos," in the sense that they are expanding and have a doubling time for errors.

One example is due to the meteorologist E. Lorenz, whose discovery may be credited with starting this entire line of thought. In 1961 he was running a simulation of the weather. The computers of the time were primitive, so the data had to be drastically simplified for any computation to be possible. He observed various behaviors from his model, apparently quite satisfactory, until one day he decided to examine something he had already computed over a longer time. He typed in what he thought were the original initial conditions, went off to get a cup of coffee, and when he came back he found that his new "weather" was unrelated to the previous run of his model.

He eventually realized that the difference was due to the fact that he had entered the initial conditions with fewer decimals than in the initial run. After further simplification of his model, Lorenz found that the following set of three coupled differential equations exhibits the same sort of chaotic behavior:

$$
\begin{aligned}
& x^{\prime}=10(y-x) \\
& y^{\prime}=28 x-y-x z \\
& z^{\prime}=\frac{8}{3} z+x y
\end{aligned}
$$

Much further work on these equations and others in $R^{3}$ have shown that chaotic behavior and fractal attractors are common.

The presence of chaos plays havoc with predictions, but it is sometimes useful; sometimes chaos can be translated into control.

NASA is not able to build rockets with enough fuel to give the speeds required to go huge distances. So they delicately bounced the spacecraft off Venus, stealing a bit of Venus's potential energy to give the spacecraft the fantastic speeds required. Only because the tiny variations in the trajectory due to the guidance rockets can be amplified to enormous variations in speed and trajectory is such a scheme feasible. But imagine how difficult this makes the longterm predictions about the orbits of comets.

The presence of chaos also has philosophical consequences, for instance, about the conflict of determinism and free will. How can humans have free will if the universe is completely governed by deterministic laws?

Well, if the equations exhibit chaos, then it follows that you cannot know that they are deterministic, however long you observe the system. If you were to observe a sequence of "doubled angles," each with 15 decimal places, you could never know whether you are observing a sequence of exact doubles of some angle or the same system perturbed at a scale smaller than $10^{-15}$ (such as round-off error).

Similarly, if the brain were not following exactly the laws of physics but were perturbed (by spiritual forces, free will, god) at a scale unmeasurable without drastically affecting the system (I doubt anyone reacts the same way with electrodes in his brain), then you could never know it, but over a time scale of perhaps 4 seconds, you could decisively alter all decisions. Making precise sense of the above would require knowing something about the doubling time of the brain. Introspection tells me this should be perhaps 0.1 second, the time of an elementary realization. Perhaps some day neurology will give a more credible estimate. If this is roughly accurate, then 4 seconds is 40 doubling times later, and $2^{40} \approx 10^{12}$ is approximately the number of neurons in the brain.

Personally, I do not think that there is a god tinkering with the laws of physics in my brain, but this is not knowable. Chaos prevents us from knowing such things.

More generally, although I am as firm a scientist as you could hope to find, I think that the world is essentially incomprehensible, with all sorts of tiny events having enormous consequences that no one can hope to foresee or understand.

If you find preposterous the idea that your smallest actions probably influence the entire world after a short time, consider the following. The time span used is much longer, about 1200 years, but I think the implications are much the same. Who were your ancestors in the year 800 A.D.? You have two parents, four grandparents, and so on. The number of ancestors should be $2^{n}$ in the $n$th generation. The year 800 is $50-60$ generations ago, leading to $2^{50} \approx 10^{15}$ ancestors at that time. Of course this is a million times larger than the population of the world today, and a much larger multiple of the population at that time. This shows among other things that there must have been a lot of inbreeding.

Now think about it from the point of view of a woman in the year 800. In order for the population to be sustained, and even grow, she had to have at least an average of 2 children, 4 grandchildren, and so on. Of course, her line might become extinct, but if that were to happen, then it must happen soon, after fewer than three generations. The probability of having no descendants can be evaluated over the short term and might be $\frac{1}{3}$ or $\frac{1}{2}$. And once the descendance has become large, it tends to become the entire population quite rapidly (although the influence of inbreeding slows this down considerably).

If you put these two points of view together, you will see that essentially everyone of European ancestry is descended from every person alive in Europe in the year 800 who has any descendants at all. For instance, we are all descended from Charlemagne, but also from about half of the peasants alive at the time. If just one of those couples had had one child fewer, everyone would be genetically different.

Of course, this doesn't make sense; long ago the paths of history would have diverged so that no detailed comparisons are possible. But certainly the smallest variation in the sexual behavior of anyone at that time would certainly have affected the world in incalculable ways.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-204}
\end{center}

\section*{APPLICATIONS OF SECOND-ORDER DIFFERENTIAL EQUATIONS: VIBRATIONAL MODELS }
A single differential equation can serve as a mathematical model for many different phenomena. Forms of the linear second-order differential equation $a y^{\prime \prime}+b y^{\prime}+c y=f(t)$ appear in the analysis of problems in physics, engineering, chemistry, and biology.

In this chapter our primary focus is on one application: the motion of a mass attached to a spring. We shall see what the individual terms $a y^{\prime \prime}, b y^{\prime}, c y$, and $f(t)$ of the differential equation $a y^{\prime \prime}+b y^{\prime}+c y=f(t)$ mean in the context of this vibrational system. We shall also see that, except for terminology and physical interpretation of the terms $a y^{\prime \prime}, b y^{\prime}, c y$, and $f(t)$, the mathematics of a series circuit is identical to that of a vibrating spring-mass system. Our goal, of course, is not to study all possible applications but to acquaint you with the mathematical procedures that are common to these problems.

\subsection*{5.1 SIMPLE HARMONIC MOTION \\
 - Free motion \\
 - Simple harmonic motio \\
 - Free undamped motion \\
 - Period \\
 - Frequency \\
 - Equation of motion \\
 - Amplitude \\
 - Phase angle}
Hooke's Law Suppose, as in Figure 5.1(b), a mass $m_{1}$ is attached to a flexible spring suspended from a rigid support. When $m_{1}$ is replaced with a different mass $m_{2}$, the amount of stretch, or elongation, of the spring will of course be different.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-205}
\end{center}

Figure 5.I

By Hooke's law,* the spring itself exerts a restoring force $F$ opposite to the direction of elongation and proportional to the amount of elongation $s$. Simply stated, $F=k s$, where $k$ is a constant of proportionality. Although masses with different weights stretch a spring by different amounts, the spring is essentially characterized by the number $k$. For example, if a mass weighing 10 lb stretches a spring by $\frac{1}{2} \mathrm{ft}$, then $10=k\left(\frac{1}{2}\right)$ implies $k=20 \mathrm{lb} / \mathrm{ft}$. Necessarily then a mass weighing 8 lb stretches the same spring $\frac{2}{5} \mathrm{ft}$.

Newton's Second Law After a mass $m$ is attached to a spring, it stretches the spring by an amount $s$ and attains a position of equilibrium at which its weight
\footnotetext{\begin{itemize}
  \item ROBERT HOOKE (I635-1703) An English physicist and inventor, Hooke published this law in I658. The idea of attaching a spring to a balance wheel, causing oscillatory motion that enabled a clock to mark units of time, is usually attributed to Hooke. The concept of the balance spring led to the invention of the pocket watch by Christian Huygens in 1674. Hooke accused Huygens of stealing his invention. Irascible and contentious, Hooke charged many of his colleagues, notably Isaac Newton, with plagiarism.
\end{itemize}
}
$W$ is balanced by the restoring force $k s$. Recall from Section 1.2 that weight is defined by $W=m g$, where the mass is measured in slugs, kilograms, or grams and $g=32 \mathrm{ft} / \mathrm{s}^{2}, 9.8 \mathrm{~m} / \mathrm{s}^{2}$, or $980 \mathrm{~cm} / \mathrm{s}^{2}$, respectively. As indicated in Figure 5.2(b), the condition of equilibrium is $m g=k s$ or $m g-k s=0$. If the mass is now displaced by an amount $x$ from its equilibrium position and released, the net force $F$ in this dynamic case is given by Newton's second law of motion $F=m a$, where $a$ is the acceleration $d^{2} x / d t^{2}$. Assuming that there are no retarding forces acting on the system and assuming that the mass vibrates free of other external influencing forces-free motion-we can equate $F$ to the resultant force of the weight and the restoring force:


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k(s+x)+m g=-k x+\underbrace{m g-k s}_{\text {zero }}=-k x \tag{1}
\end{equation*}


The negative sign in (1) indicates that the restoring force of the spring acts opposite to the direction of motion. Furthermore, we shall adopt the convention that displacements measured below the equilibrium position are positive. See Figure 5.3.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-206}
\end{center}

(a)

(b)

(c)

Figure 5.2

Figure 5.3

Differential Equation of Free Undamped Motion By dividing (1) by the mass $m$, we obtain the second-order differential equation

or


\begin{align*}
& \frac{d^{2} x}{d t^{2}}+\frac{k}{m} x=0  \tag{2}\\
& \frac{d^{2} x}{d t^{2}}+\omega^{2} x=0 \tag{3}
\end{align*}


where $\omega^{2}=k / m$. Equation (3) is said to describe simple harmonic motion, or free undamped motion. There are two obvious initial conditions associated with (3):


\begin{equation*}
x(0)=\alpha, \quad x^{\prime}(0)=\beta \tag{4}
\end{equation*}


representing the amount of initial displacement and the initial velocity, respectively. For example, if $\alpha>0, \beta<0$, the mass starts from a point below the equilibrium position with an imparted upward velocity. If $\alpha<0, \beta=0$, the

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-207(1)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-207}
\end{center}

(b)

Figure 5.4 mass is released from rest from a point $|\alpha|$ units above the equilibrium position, and so on.

Solution and Equation of Motion To solve equation (3) we note that the solutions of the auxiliary equation $m^{2}+\omega^{2}=0$ are the complex numbers $m_{1}=\omega i, m_{2}=-\omega i$. Thus from (8) of Section 4.3, we find the general solution of (3) to be


\begin{equation*}
x(t)=c_{1} \cos \omega t+c_{2} \sin \omega t \tag{5}
\end{equation*}


The period of free vibrations described by (5) is $T=2 \pi / \omega$, and the frequency is $f=1 / T=\omega / 2 \pi$. For example, for $x(t)=2 \cos 3 t-4 \sin 3 t$, the period is $2 \pi / 3$ and the frequency is $3 / 2 \pi$. The former number means that the graph of $x(t)$ repeats every $2 \pi / 3$ units; the latter number means that there are 3 cycles of the graph every $2 \pi$ units or, equivalently, the mass undergoes $3 / 2 \pi$ complete vibrations per unit time. In addition, it can be shown that the period $2 \pi / \omega$ is the time interval between two successive maxima of $x(t)$. Keep in mind that a maximum of $x(t)$ is a positive displacement corresponding to the mass attaining a maximum distance below the equilibrium position, whereas a minimum of $x(t)$ is a negative displacement corresponding to the mass attaining a maximum height above the equilibrium position. We shall refer to either case as an extreme displacement of the mass. Finally, when the initial conditions (4) are used to determine the constants $c_{1}$ and $c_{2}$ in (5), we say that the resulting particular solution is the equation of motion.

\section*{EXAMPLLE1 Interpretation of an IVP}
Solve and interpret the initial-value problem

$$
\frac{d^{2} x}{d t^{2}}+16 x=0, \quad x(0)=10, \quad x^{\prime}(0)=0
$$

Solution The problem is equivalent to pulling a mass on a spring down 10 units below the equilibrium position, holding it until $t=0$, and then releasing it from rest. Applying the initial conditions to the solution

$$
x(t)=c_{1} \cos 4 t+c_{2} \sin 4 t
$$

gives $x(0)=10=c_{1} \cdot 1+c_{2} \cdot 0$, so $c_{1}=10$ and hence

$$
\begin{gathered}
x(t)=10 \cos 4 t+c_{2} \sin 4 t \\
\frac{d x}{d t}=-40 \sin 4 t+4 c_{2} \cos 4 t
\end{gathered}
$$

Now $x^{\prime}(0)=0=4 c_{2} \cdot 1$ implies that $c_{2}=0$; therefore, the equation of motion is $x(t)=10 \cos 4 t$.

The solution clearly shows that once the system is set in motion, it stays in motion with the mass bouncing back and forth 10 units on either side of the
\footnotetext{\begin{itemize}
  \item Sometimes the number $\omega$ is called the circular frequency of vibrations. For free undamped motion the numbers $2 \pi / \omega$ and $\omega / 2 \pi$ are also referred to as the natural period and natural frequency, respectively.
\end{itemize}
}
equilibrium position $x=0$. As shown in Figure 5.4(b), the period of oscillation is $2 \pi / 4=\pi / 2$ seconds.

\section*{EXAMPLE 2 Free Undamped Motion}
A mass weighing 2 lb stretches a spring 6 inches. At $t=0$ the mass is released from a point 8 inches below the equilibrium position with an upward velocity of $\frac{4}{3} \mathrm{ft} / \mathrm{s}$. Determine the function $x(t)$ that describes the subsequent free motion.

Solution Since we are using the engineering system of units, the measurements given in terms of inches must be converted to feet: 6 inches $=\frac{1}{2}$ foot; 8 inches $=\frac{2}{3}$ foot. In addition we must convert the units of weight given in pounds to units of mass. From $m=W / g$ we have $m=\frac{2}{32}=\frac{1}{16}$ slug. Also, from Hooke's law, $2=k\left(\frac{1}{2}\right)$ implies $k=4 \mathrm{lb} / \mathrm{ft}$. Hence the analogues of (1) and (2) are, respectively,

$$
\frac{1}{16} \frac{d^{2} x}{d t^{2}}=-4 x \quad \text { and } \quad \frac{d^{2} x}{d t^{2}}+64 x=0
$$

The initial displacement and initial velocity are given by

$$
x(0)=\frac{2}{3}, \quad x^{\prime}(0)=-\frac{4}{3}
$$

where the negative sign in the last condition is a consequence of the fact that the mass is given an initial velocity in the negative or upward direction.

Now $\omega^{2}=64$ or $\omega=8$, so the general solution of the differential equation is


\begin{equation*}
x(t)=c_{1} \cos 8 t+c_{2} \sin 8 t \tag{6}
\end{equation*}


Applying the initial condition $x(0)=\frac{2}{3}$ to (6), we first find $\frac{2}{3}=c_{1} \cdot 1+c_{2} \cdot 0$, so $c_{1}=\frac{2}{3}$. Then applying $x^{\prime}(0)=-\frac{4}{3}$ to

$$
x^{\prime}(t)=-\frac{16}{3} \sin 8 t+8 c_{2} \cos 8 t
$$

gives $-\frac{4}{3}=-\frac{16}{3} \cdot 0+8 c_{2} \cdot 1$ and $c_{2}=-\frac{1}{6}$. Thus the equation of motion is


\begin{equation*}
x(t)=\frac{2}{3} \cos 8 t-\frac{1}{6} \sin 8 t \tag{7}
\end{equation*}


Note The distinction between weight and mass is often blurred. Thus one often speaks of both the motion of a mass on a spring and the motion of a weight on a spring.

Alternative Form of $\boldsymbol{x}(\boldsymbol{t})$ When $c_{1} \neq 0$ and $c_{2} \neq 0$, the actual amplitude $A$ of free vibrations is not obvious from inspection of equation (5). For example, although the mass in Example 2 is initially displaced $\frac{2}{3} \mathrm{ft}$ beyond the equilibrium position, the amplitude of vibrations is a number larger than $\frac{2}{3}$. Hence it is often convenient to convert a solution of form (5) to the simpler form


\begin{equation*}
x(t)=A \sin (\omega t+\phi) \tag{8}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-209}
\end{center}

Figure 5.5 where $A=\sqrt{c_{1}^{2}+c_{2}^{2}}$ and $\phi$ is a phase angle defined by

\[
\left.\begin{array}{l}
\sin \phi=\frac{c_{1}}{A}  \tag{9}\\
\cos \phi=\frac{c_{2}}{A}
\end{array}\right\} \tan \phi=\frac{c_{1}}{c_{2}}
\]

To verify this we expand (8) by the addition formula for the sine function:

$A \sin \omega t \cos \phi+A \cos \omega t \sin \phi=(A \sin \phi) \cos \omega t+(A \cos \phi) \sin \omega t$.

It follows from Figure 5.5 that if $\phi$ is defined by

$$
\sin \phi=\frac{c_{1}}{\sqrt{c_{1}^{2}+c_{2}^{2}}}=\frac{c_{1}}{A}, \quad \cos \phi=\frac{c_{2}}{\sqrt{c_{1}^{2}+c_{2}^{2}}}=\frac{c_{2}}{A},
$$

then (10) becomes

$$
A \frac{c_{1}}{A} \cos \omega t+A \frac{c_{2}}{A} \sin \omega t=c_{1} \cos \omega t+c_{2} \sin \omega t=x(t)
$$

\section*{EXAMPLE 3 Writing Solution (7) in Form (8)}
In view of the foregoing discussion, we can write the solution (7) in Example 2,

$$
x(t)=\frac{2}{3} \cos 8 t-\frac{1}{6} \sin 8 t, \quad \text { alternatively as } \quad x(t)=A \sin (8 t+\phi)
$$

The amplitude is given by

$$
A=\sqrt{\left(\frac{2}{3}\right)^{2}+\left(-\frac{1}{6}\right)^{2}}=\frac{\sqrt{17}}{6} \approx 0.69 \mathrm{ft}
$$

One should exercise some care when finding the phase angle $\phi$ defined by (9). In this case

$$
\tan \phi=\frac{\frac{2}{3}}{-\frac{1}{6}}=-4
$$

and a scientific hand calculator would give

$$
\tan ^{-1}(-4)=-1.326 \text { radians. } *
$$

But this angle is located in the fourth quadrant and therefore contradicts the fact that $\sin \phi>0$ and $\cos \phi<0$ (recall that $c_{1}>0$ and $c_{2}<0$ ). Hence we must take $\phi$ to be the second-quadrant angle


\begin{gather*}
\phi=\pi+(-1.326)=1.816 \text { radians. } \\
x(t)=\frac{\sqrt{17}}{6} \sin (8 t+1.816) \tag{11}
\end{gather*}

\footnotetext{\begin{itemize}
  \item The range of the inverse tangent is $-\pi / 2<\tan ^{-1} x<\pi / 2$.
\end{itemize}
}

Form (8) is very useful since it is easy to find the values of time for which the graph of $x(t)$ crosses the positive $t$-axis (the line $x=0$ ). We observe that $\sin (\omega t+\phi)=0$ when $\omega t+\phi=n \pi$, where $n$ is a nonnegative integer.

\section*{EXAMPLE 4 Times at the Equilibrium Position}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-210}
\end{center}

Figure 5.6\\
For motion described by $x(t)=(\sqrt{17} / 6) \sin (8 t+1.816)$, find the first value of time for which the mass passes through the equilibrium position heading downward.

Solution The values $t_{1}, t_{2}, t_{3}, \ldots$ for which $\sin (8 t+1.816)=0$ are determined from

$$
8 t_{1}+1.816=\pi, \quad 8 t_{2}+1.816=2 \pi, \quad 8 t_{3}+1.816=3 \pi, \quad \ldots .
$$

We find $t_{1}=0.166, t_{2}=0.558, t_{3}=0.951, \ldots$, respectively.

Figure 5.6 shows that the mass passes through $x=0$ heading downward (namely, toward $x>0$ ) the first time at $t_{2}=0.558$ second.

\section*{EXERCISES 5.1}
\section*{Answers to odd-numbered problems begin on page A-9.}
In Problems 1 and 2 state in words a possible physical interpretation of the given initial-value problem.

$$
\begin{array}{ll}
\frac{4}{32} x^{\prime \prime}+3 x=0 & \text { 2. } \frac{1}{16} x^{\prime \prime}+4 x=0 \\
x(0)=-3, x^{\prime}(0)=-2 & x(0)=0.7, x^{\prime}(0)=0
\end{array}
$$

In Problems 3-8 write the solution of the given initial-value problem in form (8).\\
3. $x^{\prime \prime}+25 x=0$\\
4. $\frac{1}{2} x^{\prime \prime}+8 x=0$\\
$x(0)=-2, x^{\prime}(0)=10$\\
$x(0)=1, x^{\prime}(0)=-2$\\
5. $x^{\prime \prime}+2 x=0$\\
6. $\frac{1}{4} x^{\prime \prime}+16 x=0$\\
$x(0)=-1, x^{\prime}(0)=-2 \sqrt{2}$\\
$x(0)=4, x^{\prime}(0)=16$\\
7. $0.1 x^{\prime \prime}+10 x=0$\\
8. $x^{\prime \prime}+x=0$\\
$x(0)=1, x^{\prime}(0)=1$\\
$x(0)=-4, x^{\prime}(0)=3$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item The period of free undamped oscillations of a mass on a spring is $\pi / 4$ second. If the spring constant is $16 \mathrm{lb} / \mathrm{ft}$, what is the numerical value of the weight?

  \item A spring is suspended from a ceiling. When a mass weighing 60 lb is attached, the spring is stretched $\frac{1}{2} \mathrm{ft}$. The mass is removed and a person grabs the end of the spring and proceeds to bounce up and down with a period of 1 second. How much does the person weigh?

  \item A 4-lb weight is attached to a spring whose spring constant is $16 \mathrm{lb} / \mathrm{ft}$. What is the period of simple harmonic motion?

  \item A $20-\mathrm{kg}$ mass is attached to a spring. If the frequency of simple harmonic motion is $2 / \pi$ vibrations/second, what is the spring constant $k$ ? What is the frequency of simple harmonic motion if the original mass is replaced with an 80 -kg mass?

  \item A 24-1b weight, attached to the end of a spring, stretches it 4 in. Find the equation of motion if the weight is released from rest from a point 3 in . above the equilibrium position.

  \item Determine the equation of motion if the weight in Problem 13 is released from the equilibrium position with an initial downward velocity of $2 \mathrm{ft} / \mathrm{s}$.

  \item A $20-\mathrm{lb}$ weight stretches a spring 6 in . The weight is released from rest 6 in. below the equilibrium position.

\end{enumerate}

(a) Find the position of the weight at $t=\pi / 12, \pi / 8, \pi / 6, \pi / 4,9 \pi / 32$ seconds.

(b) What is the velocity of the weight when $t=3 \pi / 16$ second? In which direction is the weight heading at this instant?

(c) At what times does the weight pass through the equilibrium position?

\begin{enumerate}
  \setcounter{enumi}{15}
  \item A force of 400 newtons stretches a spring 2 m . A mass of 50 kg is attached to the end of the spring and released from the equilibrium position with an upward velocity of $10 \mathrm{~m} / \mathrm{s}$. Find the equation of motion.

  \item Another spring whose constant is $20 \mathrm{~N} / \mathrm{m}$ is suspended from the same rigid support but parallel to the spring-mass system in Problem 16. A mass of 20 kg is attached to the second spring and both masses are released from the equilibrium position with an upward velocity of $10 \mathrm{~m} / \mathrm{s}$.

\end{enumerate}

(a) Which mass exhibits the greater amplitude of motion?

(b) Which mass is moving faster at $t=\pi / 4$ second? at $\pi / 2$ seconds?

(c) At what times are the two masses in the same position? Where are the masses at these times? In which directions are they moving?

\begin{enumerate}
  \setcounter{enumi}{17}
  \item A $32-\mathrm{lb}$ weight stretches a spring 2 ft . Determine the amplitude and period of motion if the weight is released 1 ft above the equilibrium position with an initial upward velocity of $2 \mathrm{ft} / \mathrm{s}$. How many complete vibrations will the weight have completed at the end of $4 \pi$ seconds?

  \item An $8-\mathrm{lb}$ weight attached to a spring exhibits simple harmonic motion. Determine the equation of motion if the spring constant is $1 \mathrm{lb} / \mathrm{ft}$ and if the weight is released 6 in. below the equilibrium position with a downward velocity of $\frac{3}{2} \mathrm{ft} / \mathrm{s}$. Express the solution in form (8).

  \item A mass weighing 10 lb stretches a spring $\frac{1}{4} \mathrm{ft}$. This mass is removed and replaced with a mass of 1.6 slugs, which is released $\frac{1}{3} \mathrm{ft}$ above the equilibrium position with a downward velocity of $\frac{5}{4} \mathrm{ft} / \mathrm{s}$. Express the solution in form (8). At what times does the mass attain a displacement below the equilibrium position numerically equal to one-half the amplitude?

  \item A $64-\mathrm{lb}$ weight attached to the end of a spring stretches it 0.32 ft . From a position 8 in. above the equilibrium position the weight is given a downward velocity of $5 \mathrm{ft} / \mathrm{s}$.

\end{enumerate}

(a) Find the equation of motion.

(b) What are the amplitude and period of motion?

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-212}
\end{center}

Figure 5.7

(c) How many complete vibrations will the weight have completed at the end of $3 \pi$ seconds?

(d) At what time does the weight pass through the equilibrium position heading downward for the second time?

(e) At what time does the weight attain its extreme displacement on either side of the equilibrium position?

(f) What is the position of the weight at $t=3$ seconds?

(g) What is the instantaneous velocity at $t=3$ seconds?

(h) What is the acceleration at $t=3$ seconds?

(i) What is the instantaneous velocity at the times when the weight passes through the equilibrium position?

(j) At what times is the weight 5 in. below the equilibrium position?

(k) At what times is the weight 5 in. below the equilibrium position heading in the upward direction?

\begin{enumerate}
  \setcounter{enumi}{21}
  \item A mass of 1 slug is suspended from a spring whose characteristic spring constant is $9 \mathrm{lb} / \mathrm{ft}$. Initially the mass starts from a point 1 ft above the equilibrium position with an upward velocity of $\sqrt{3} \mathrm{ft} / \mathrm{s}$. Find the times for which the mass is heading downward at velocity of $3 \mathrm{ft} / \mathrm{s}$.

  \item Under some circumstances when two parallel springs, with constants $k_{1}$ and $k_{2}$, support a single weight $W$, the effective spring constant of the system is given by $k=4 k_{1} k_{2} /\left(k_{1}+k_{2}\right)$.*A 20-lb weight stretches one spring 6 in. and another spring 2 in . The springs are attached to a common rigid support and then to a metal plate. As shown in Figure 5.7, the 20-lb weight is attached to the center of the plate in the double spring arrangement. Determine the effective spring constant of this system. Find the equation of motion if the weight is released from the equilibrium position with a downward velocity of $2 \mathrm{ft} / \mathrm{s}$.

  \item A certain weight stretches one spring $\frac{1}{3} \mathrm{ft}$ and another spring $\frac{1}{2} \mathrm{ft}$. The two springs are attached to a common rigid support in a manner indicated in Problem 23 and Figure 5.7. The first weight is set aside, and an $8-\mathrm{lb}$ weight is attached to the double spring arrangement and the system is set in motion. If the period of motion is $\pi / 15$ second, determine the numerical value of the first weight.

  \item If $x_{0}$ and $v_{0}$ are the initial position and velocity, respectively, of a weight exhibiting simple harmonic motion, show that the amplitude of vibrations is

\end{enumerate}

$$
A=\sqrt{x_{0}^{2}+\left(\frac{v_{0}}{\omega}\right)^{2}}
$$

\begin{enumerate}
  \setcounter{enumi}{25}
  \item Show that any linear combination $x(t)=c_{1} \cos \omega t+c_{2} \sin \omega t$ can also be written in the form
\end{enumerate}

$$
x(t)=A \cos (\omega t+\phi)
$$

where

$$
A=\sqrt{c_{1}^{2}+c_{2}^{2}}, \quad \sin \phi=-\frac{c_{2}}{A}, \quad \cos \phi=\frac{c_{1}}{A} .
$$
\footnotetext{\begin{itemize}
  \item If the two springs have the same natural length and if the plate is guided either by rails or by an external force so that the extensions of both springs are always the same, then the effective spring constant is simply $k=k_{1}+k_{2}$.
\end{itemize}
}

\begin{enumerate}
  \setcounter{enumi}{26}
  \item Express the solution of Problem 3 in the form of the cosine function given in Problem 26.

  \item Show that when a weight attached to a spring exhibits simple harmonic motion, the maximum value of the speed (that is, $|v(t)|)$ occurs when the weight is passing through the equilibrium position.

  \item A weight attached to a spring exhibits simple harmonic motion. Show that the maximum acceleration of the weight occurs at an extreme displacement and has the magnitude $4 \pi^{2} A / T^{2}$, where $A$ is the amplitude and $T$ is the period of free vibrations.

  \item Use (8) to prove that the time interval between two successive maxima of $x(t)$ is $2 \pi / \omega$.

\end{enumerate}

\subsection*{5.2 DAMPED MOTION}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-213(1)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-213}
\end{center}

(b)

Figure 5.8\\
The discussion of free harmonic motion is somewhat unrealistic since the motion described by equation (2) of Section 5.1 assumes that no retarding forces are acting on the moving mass. Unless the mass is suspended in a perfect vacuum, there will be at least a resisting force due to the surrounding medium. For example, as Figure 5.8 shows, the mass $m$ could be suspended in a viscous medium or connected to a dashpot damping device.

Differential Equation of Motion with Damping In the study of mechanics, damping forces acting on a body are considered to be proportional to a power of the instantaneous velocity. In particular, we shall assume throughout the subsequent discussion that this force is given by a constant multiple of $d x / d t$.* When no other external forces are impressed on the system, it follows from Newton's second law that


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k x-\beta \frac{d x}{d t} \tag{1}
\end{equation*}


where $\beta$ is a positive damping constant and the negative sign is a consequence of the fact that the damping force acts in a direction opposite to the motion.

Dividing (1) by the mass $m$, we find the differential equation of free damped motion is


\begin{align*}
& \frac{d^{2} x}{d t^{2}}+\frac{\beta}{m} \frac{d x}{d t}+\frac{k}{m} x=0  \tag{2}\\
& \frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=0 \tag{3}
\end{align*}

\footnotetext{\begin{itemize}
  \item In many instances, such as problems in hydrodynamics, the damping force is proportional to $(d x / d t)^{2}$.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-214(3)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-214(4)}
\end{center}

(b)

Figure 5.9

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-214(1)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-214(2)}
\end{center}

(b)

Figure $\mathbf{5 . 1 0}$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-214}
\end{center}

Figure 5.11\\
In equation (3) we make the identifications


\begin{equation*}
2 \lambda=\frac{\beta}{m}, \quad \omega^{2}=\frac{k}{m} \tag{4}
\end{equation*}


The symbol $2 \lambda$ is used only for algebraic convenience since the auxiliary equation is $m^{2}+2 \lambda m+\omega^{2}=0$ and the corresponding roots are then

$$
m_{1}=-\lambda+\sqrt{\lambda^{2}-\omega^{2}}, \quad m_{2}=-\lambda-\sqrt{\lambda^{2}-\omega^{2}}
$$

We can now distinguish three possible cases depending on the algebraic sign of $\lambda^{2}-\omega^{2}$. Since each solution contains the damping factor $e^{-\lambda t}, \lambda>0$, the displacements of the mass become negligible for large time.

Case I $\lambda^{2}-\omega^{2}>0$. In this situation the system is said to be overdamped, since the damping coefficient $\beta$ is large when compared to the spring constant $k$. The corresponding solution of (3) is

or


\begin{gather*}
x(t)=c_{1} e^{m_{1} t}+c_{2} e^{m_{2} t} \\
x(t)=e^{-\lambda t}\left(c_{1} e^{\sqrt{\lambda^{2}-\omega^{2} t}}+c_{2} e^{-\sqrt{\lambda^{2}-\omega^{2} t}}\right) \tag{5}
\end{gather*}


This equation represents a smooth and nonoscillatory motion. Figure 5.9 shows two possible graphs of $x(t)$.

Case II $\lambda^{2}-\omega^{2}=0$. The system is said to be critically damped, since any slight decrease in the damping force would result in oscillatory motion. The general solution of (3) is

or


\begin{align*}
& x(t)=c_{1} e^{m_{1} t}+c_{2} t e^{m_{1} t} \\
& x(t)=e^{-\lambda t}\left(c_{1}+c_{2} t\right) \tag{6}
\end{align*}


Some graphs of typical motion are given in Figure 5.10. Notice that the motion is quite similar to that of an overdamped system. It is also apparent from (6) that the mass can pass through the equilibrium position at most one time.*

Case III $\lambda^{2}-\omega^{2}<0$. In this case the system is said to be underdamped, since the damping coefficient is small compared to the spring constant. The roots $m_{1}$ and $m_{2}$ are now complex:

$$
m_{1}=-\lambda+\sqrt{\omega^{2}-\lambda^{2}} i, \quad m_{2}=-\lambda-\sqrt{\omega^{2}-\lambda^{2}} i
$$

and so the general solution of equation (3) is


\begin{equation*}
x(t)=e^{-\lambda t}\left(c_{1} \cos \sqrt{\omega^{2}-\lambda^{2}} t+c_{2} \sin \sqrt{\omega^{2}-\lambda^{2} t}\right) \tag{7}
\end{equation*}


As indicated in Figure 5.11, the motion described by (7) is oscillatory; but because of the coefficient $e^{-\lambda t}$, the amplitudes of vibration $\rightarrow 0$ as $t \rightarrow \infty$.

\section*{EXAMPLE 1 Overdamped Motion}
It is readily verified that the solution of the initial-value problem

$$
\frac{d^{2} x}{d t^{2}}+5 \frac{d x}{d t}+4 x=0, \quad x(0)=1, \quad x^{\prime}(0)=1
$$
\footnotetext{\begin{itemize}
  \item An examination of the derivatives of (5) and (6) would show that these functions can have at most one relative maximum or one relative minimum for $t>0$.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-215}
\end{center}

(a)

\begin{center}
\begin{tabular}{ll}
\hline
$t$ & $\boldsymbol{x}(\boldsymbol{t})$ \\
\hline
1 & 0.601 \\
1.5 & 0.370 \\
2 & 0.225 \\
2.5 & 0.137 \\
3 & 0.083 \\
\hline
\end{tabular}
\end{center}

(b)

is


\begin{equation*}
x(t)=\frac{5}{3} e^{-t}-\frac{2}{3} e^{-4 t} \tag{8}
\end{equation*}


The problem can be interpreted as representing the overdamped motion of a mass on a spring. The mass starts from a position 1 unit below the equilibrium position with a downward velocity of $1 \mathrm{ft} / \mathrm{s}$.

To graph $x(t)$ we find the value of $t$ for which the function has an extremum-that is, the value of time for which the first derivative (velocity) is zero. Differentiating (8) gives

$$
x^{\prime}(t)=-\frac{5}{3} e^{-t}+\frac{8}{3} e^{-4 t}
$$

so $x^{\prime}(t)=0$ implies

$$
e^{3 t}=\frac{8}{5} \quad \text { or } \quad t=\frac{1}{3} \ln \frac{8}{5}=0.157
$$

It follows from the first derivative test, as well as our physical intuition, that $x(0.157)=1.069 \mathrm{ft}$ is actually a maximum. In other words, the mass attains an extreme displacement of 1.069 ft below the equilibrium position.

We should also check to see whether the graph crosses the $t$-axis-that is, whether the mass passes through the equilibrium position. This cannot happen in this instance since the equation $x(t)=0$, or $e^{3 t}=\frac{2}{5}$ has the physically irrelevant solution $t=\frac{1}{3} \ln \frac{2}{5}=-0.305$.

The graph of $x(t)$, along with some other pertinent data, is given in Figure

Figure 5.12 5.12 .

\section*{EXAMPLE 2 Critically Damped Motion}
An 8-lb weight stretches a spring 2 ft . Assuming a damping force numerically equal to two times the instantaneous velocity acts on the system, determine the equation of motion if the weight is released from the equilibrium position with an upward velocity of $3 \mathrm{ft} / \mathrm{s}$.

Solution From Hooke's law we have $8=k(2)$ or $k=4 \mathrm{lb} / \mathrm{ft}$, and from $m=W / g, m=\frac{8}{32}=\frac{1}{4}$ slug. Thus the differential equation of motion is


\begin{equation*}
\frac{1}{4} \frac{d^{2} x}{d t^{2}}=-4 x-2 \frac{d x}{d t} \quad \text { or } \quad \frac{d^{2} x}{d t^{2}}+8 \frac{d x}{d t}+16 x=0 \tag{9}
\end{equation*}


The initial conditions are

$$
x(0)=0, \quad x^{\prime}(0)=-3
$$

Now the auxiliary equation for (9) is

$$
m^{2}+8 m+16=(m+4)^{2}=0
$$

so $m_{1}=m_{2}=-4$. Hence the system is critically damped and


\begin{equation*}
x(t)=c_{1} e^{-4 t}+c_{2} t e^{-4 t} \tag{10}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-216}
\end{center}

Figure 5.13\\
The initial condition $x(0)=0$ immediately demands that $c_{1}=0$, whereas using $x^{\prime}(0)=-3$ gives $c_{2}=-3$. Thus the equation of motion is


\begin{equation*}
x(t)=-3 t e^{-4 t} \tag{11}
\end{equation*}


To graph $x(t)$ we proceed as in Example 1:

$$
x^{\prime}(t)=-3\left(-4 t e^{-4 t}+e^{-4 t}\right)=-3 e^{-4 t}(1-4 t)
$$

Clearly $x^{\prime}(t)=0$ when $t=\frac{1}{4}$. The corresponding extreme displacement is

$$
x\left(\frac{1}{4}\right)=-3\left(\frac{1}{4}\right) e^{-1}=-0.276 \mathrm{ft} .
$$

As shown in Figure 5.13, we interpret this value to mean that the weight reaches a maximum height of 0.276 ft above the equilibrium position.

\section*{EXAMPLE 8 Underdamped Motion}
A $16-\mathrm{lb}$ weight is attached to a 5 -ft-long spring. At equilibrium the spring measures 8.2 ft . If the weight is pushed up and released from rest at a point 2 ft above the equilibrium position, find the displacements $x(t)$ if it is further known that the surrounding medium offers a resistance numerically equal to the instantaneous velocity.

Solution The elongation of the spring after the weight is attached is $8.2-5=3.2 \mathrm{ft}$, so it follows from Hooke's law that $16=k(3.2)$ or $k=5 \mathrm{lb} / \mathrm{ft}$. In addition, $m=\frac{16}{32}=\frac{1}{2}$ slug, so the differential equation is given by


\begin{equation*}
\frac{1}{2} \frac{d^{2} x}{d t^{2}}=-5 x-\frac{d x}{d t} \quad \text { or } \quad \frac{d^{2} x}{d t^{2}}+2 \frac{d x}{d t}+10 x=0 \tag{1}
\end{equation*}


This latter equation is solved subject to the conditions

$$
x(0)=-2, \quad x^{\prime}(0)=0
$$

Proceeding, we find that the roots of $m^{2}+2 m+10=0$ are $m_{1}=-1+3 i$ and $m_{2}=-1-3 i$, which then implies the system is underdamped and


\begin{equation*}
x(t)=e^{-t}\left(c_{1} \cos 3 t+c_{2} \sin 3 t\right) \tag{13}
\end{equation*}


Now $x(0)=-2=c_{1}$, so

$$
\begin{gathered}
x(t)=e^{-t}\left(-2 \cos 3 t+c_{2} \sin 3 t\right) \\
x^{\prime}(t)=e^{-t}\left(6 \sin 3 t+3 c_{2} \cos 3 t\right)-e^{-t}\left(-2 \cos 3 t+c_{2} \sin 3 t\right)
\end{gathered}
$$

Then $x^{\prime}(0)=0=3 c_{2}+2$ gives $c_{2}=-\frac{2}{3}$. Thus we finally obtain


\begin{equation*}
x(t)=e^{-t}\left(-2 \cos 3 t-\frac{2}{3} \sin 3 t\right) \tag{14}
\end{equation*}


Alternative Form of the Solution In a manner identical to the procedure used in Section 5.1, we can write any solution

$$
x(t)=e^{-\lambda t}\left(c_{1} \cos \sqrt{\omega^{2}-\lambda^{2}} t+c_{2} \sin \sqrt{\omega^{2}-\lambda^{2}} t\right)
$$

in the alternative form


\begin{equation*}
x(t)=A e^{-\lambda t} \sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right) \tag{15}
\end{equation*}


where $A=\sqrt{c_{1}^{2}+c_{2}^{2}}$ and the phase angle $\phi$ is determined from the equations

$$
\sin \phi=\frac{c_{1}}{A}, \quad \cos \phi=\frac{c_{2}}{A}, \quad \tan \phi=\frac{c_{1}}{c_{2}}
$$

The coefficient $A e^{-\lambda t}$ is sometimes called the damped amplitude of vibrations. Because (15) is not a periodic function, the number $2 \pi / \sqrt{\omega^{2}-\lambda^{2}}$ is called the quasi period and $\sqrt{\omega^{2}-\lambda^{2}} / 2 \pi$ is the quasi frequency. The quasi period is the time interval between two successive maxima of $x(t)$.

To graph an equation such as (15), we first find the intercepts $t_{1}, t_{2}, \ldots$, $t_{k}, \ldots$; that is, for some integer $n$


\begin{equation*}
\sqrt{\omega^{2}-\lambda^{2}} t+\phi=n \pi \quad \text { or } \quad t=\frac{n \pi-\phi}{\sqrt{\omega^{2}-\lambda^{2}}} \tag{16}
\end{equation*}


In addition we note that $|x(t)| \leq A e^{-\lambda t}$ since

$$
\left|\sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)\right| \leq 1
$$

Indeed, the graph of (15) touches the graphs of $\pm A e^{-\lambda t}$ at the values $t_{1}^{*}, t_{2}^{*}, \ldots$, $t_{k}^{*}, \ldots$ for which

$$
\sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)= \pm 1
$$

This means $\sqrt{\omega^{2}-\lambda^{2}} t+\phi$ must be an odd multiple of $\pi / 2$; that is,


\begin{equation*}
\sqrt{\omega^{2}-\lambda^{2}} t+\phi=(2 n+1) \frac{\pi}{2} \quad \text { or } \quad t=\frac{(2 n+1) \pi / 2-\phi}{\sqrt{\omega^{2}-\lambda^{2}}} \text {. } \tag{17}
\end{equation*}


For example, if we are asked to graph $x(t)=e^{-0.5 t} \sin (2 t-\pi / 3)$, we find the intercepts on the positive $t$-axis by solving

$$
2 t_{1}-\frac{\pi}{3}=0, \quad 2 t_{2}-\frac{\pi}{3}=\pi, \quad 2 t_{3}-\frac{\pi}{3}=2 \pi, \quad \ldots
$$

which gives, respectively,

$$
t_{1}=\frac{\pi}{6}, \quad t_{2}=\frac{4 \pi}{6}, \quad t_{3}=\frac{7 \pi}{6}, \ldots .
$$

Notice that even though $x(t)$ is not periodic, the difference between the successive roots is $t_{k}-t_{k-1}=\pi / 2$ units or one-half the quasi period of $2 \pi / 2=\pi$ seconds. Also $\sin (2 t-\pi / 3)= \pm 1$ at the solutions of

or

$$
\begin{array}{rlrl}
2 t_{1}^{*}-\frac{\pi}{3} & =\frac{\pi}{2}, \quad 2 t_{2}^{*}-\frac{\pi}{3}=\frac{3 \pi}{2}, \quad 2 t_{3}^{*}-\frac{\pi}{3}=\frac{5 \pi}{2}, \quad \ldots \\
t_{1}^{*} & =\frac{5 \pi}{12}, \quad t_{2}^{*} & =\frac{11 \pi}{12}, \quad t_{3}^{*}=\frac{17 \pi}{12}, \quad \ldots
\end{array}
$$

It is readily shown that the difference between the successive $t_{k}^{*}$ values is also $\pi / 2$.* The graph of $x(t)$ is given in Figure 5.14.
\footnotetext{\begin{itemize}
  \item We note that the values of $t$ for which the graph of $x(t)$ touches the exponential graphs are not the values for which the function attains its relative extrema.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-218(1)}
\end{center}

Figure 5.14

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-218}
\end{center}

(a)

\begin{center}
\begin{tabular}{lllr}
\hline
$\boldsymbol{k}$ & $\boldsymbol{t}_{\boldsymbol{k}}$ & $\boldsymbol{t}_{\boldsymbol{k}}^{*}$ & \multicolumn{1}{c}{$\boldsymbol{x}\left(\boldsymbol{t}_{\boldsymbol{k}}^{*}\right)$} \\
\hline
 &  &  &  \\
1 & 0.631 & 1.154 & 0.665 \\
2 & 1.678 & 2.202 & -0.233 \\
3 & 2.725 & 3.249 & 0.082 \\
4 & 3.772 & 4.296 & -0.029 \\
\hline
\end{tabular}
\end{center}

(b)

Figure 5.15

\section*{EXAMPLE 4 Writing a Solution (14) in Form (15)}
Using (15), we can write the solution of the initial-value problem

$$
\frac{d^{2} x}{d t^{2}}+2 \frac{d x}{d t}+10 x=0, \quad x(0)=-2, \quad x^{\prime}(0)=0
$$

in Example 3 in the form $x(t)=A e^{-t} \sin (3 t+\phi)$.

From (14) we have $c_{1}=-2, c_{2}=-\frac{2}{3}$, so

$$
\begin{gathered}
A=\sqrt{4+\frac{4}{9}}=\frac{2}{3} \sqrt{10} \\
\tan \phi=\frac{-2}{-\frac{2}{3}}=3 \text { and } \tan ^{-1}(3)=1.249 \text { radians. }
\end{gathered}
$$

But since $\sin \phi<0$ and $\cos \phi<0$, we take $\phi$ to be the third-quadrant angle $\phi=\pi+1.249=4.391$ radians. Hence

$$
x(t)=\frac{2}{3} \sqrt{10} e^{-t} \sin (3 t+4.391)
$$

The graph of this function is given in Figure 5.15. The values of $t_{k}$ and $t_{k}^{*}$ given in the accompanying table are the intercepts and the points at which the graph of $x(t)$ touches the graphs of $\pm \frac{2}{3} \sqrt{10} e^{-t}$, respectively. In this example the quasi period is $2 \pi / 3$ seconds, and so the difference between the successive $t_{k}$ (and the successive $t_{k}^{*}$ ) is $\pi / 3$ units.

\section*{EXERCISES 5.2}
Answers to odd-numbered problems begin on page A-10.

In Problems 1 and 2 give a possible physical interpretation of the given initialvalue problem.

$$
\begin{array}{lr}
\text { 1. } \frac{1}{16} x^{\prime \prime}+2 x^{\prime}+x=0 & \text { 2. } \frac{16}{32} x^{\prime \prime}+x^{\prime}+2 x=0 \\
x(0)=0, x^{\prime}(0)=-1.5 & x(0)=-2, x^{\prime}(0)=1
\end{array}
$$

In Problems 3-6 the given figure represents the graph of an equation of motion for a mass on a spring. The spring-mass system is damped. Use the graph to determine

(a) whether the initial displacement of the mass is above or below the equilibrium position and

(b) whether the mass is initially released from rest, heading downward, or heading upward.

3.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-219(3)}
\end{center}

4.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-219}
\end{center}

Figure 5.16

Figure 5.17

5.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-219(1)}
\end{center}

6.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-219(2)}
\end{center}

Figure 5.18

Figure 5.19

\begin{enumerate}
  \setcounter{enumi}{6}
  \item A 4-lb weight is attached to a spring whose constant is $2 \mathrm{lb} / \mathrm{ft}$. The medium offers a resistance to the motion of the weight numerically equal to the instantaneous velocity. If the weight is released from a point 1 ft above the equilibrium position with a downward velocity of $8 \mathrm{ft} / \mathrm{s}$, determine the time at which the weight passes through the equilibrium position. Find the time at which the weight attains its extreme displacement from the equilibrium position. What is the position of the weight at this instant?

  \item A 4 -ft spring measures 8 ft long after an $8-\mathrm{lb}$ weight is attached to it. The medium through which the weight moves offers a resistance numerically equal to $\sqrt{2}$ times the instantaneous velocity. Find the equation of motion if the weight is released from the equilibrium position with a downward velocity of $5 \mathrm{ft} / \mathrm{s}$. Find the time at which the weight attains its extreme displacement from the equilibrium position. What is the position of the weight at this instant?

  \item A 1-kg mass is attached to a spring whose constant is $16 \mathrm{~N} / \mathrm{m}$ and the entire system is then submerged in a liquid that imparts a damping force numerically equal to 10 times the instantaneous velocity. Determine the equations of motion if

\end{enumerate}

(a) the weight is released from rest 1 m below the equilibrium position.

(b) the weight is released 1 m below the equilibrium position with an upward velocity of $12 \mathrm{~m} / \mathrm{s}$.

\begin{enumerate}
  \setcounter{enumi}{9}
  \item In parts (a) and (b) of Problem 9 determine whether the weight passes through the equilibrium position. In each case find the time at which the weight attains its extreme displacement from the equilibrium position. What is the position of the weight at this instant?

  \item A force of 2 lb stretches a spring 1 ft . A 3.2 lb weight is attached to the spring and the system is then immersed in a medium that imparts a damping force numerically equal to 0.4 times the instantaneous velocity.

\end{enumerate}

(a) Find the equation of motion if the weight is released from rest 1 ft above the equilibrium position.

(b) Express the equation of motion in the form given in (15).

(c) Find the first time at which the weight passes through the equilibrium position heading upward.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item After a $10-\mathrm{lb}$ weight is attached to a 5 -ft spring, the spring measures 7 ft long. The $10-\mathrm{lb}$ weight is removed and replaced with an $8-\mathrm{lb}$ weight and the entire system is placed in a medium offering a resistance numerically equal to the instantaneous velocity.
\end{enumerate}

(a) Find the equation of motion if the weight is released $\frac{1}{2} \mathrm{ft}$ below the equilibrium position with a downward velocity of $1 \mathrm{ft} / \mathrm{s}$.

(b) Express the equation of motion in the form given in (15).

(c) Find the times at which the weight passes through the equilibrium position heading downward.

(d) Graph the equation of motion.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item A $10-\mathrm{lb}$ weight attached to a spring stretches it 2 ft . The weight is attached to a dashpot damping device that offers a resistance numerically equal to $\beta(\beta>0)$ times the instantaneous velocity. Determine the values of the damping constant $\beta$ so that the subsequent motion is (a) overdamped, (b) critically damped, and (c) underdamped.

  \item A $24-\mathrm{lb}$ weight stretches a spring 4 ft . The subsequent motion takes place in a medium offering a resistance numerically equal to $\beta(\beta>0)$ times the instantaneous velocity. If the weight starts from the equilibrium position with an upward velocity of $2 \mathrm{ft} / \mathrm{s}$, show that if $\beta>3 \sqrt{2}$, the equation of motion is

\end{enumerate}

$$
x(t)=\frac{-3}{\sqrt{\beta^{2}-18}} e^{-2 \beta \ell / 3} \sinh \frac{2}{3} \sqrt{\beta^{2}-18} t
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item A mass of 40 g stretches a spring 10 cm . A damping device imparts a resistance to motion numerically equal to 560 (measured in dynes $/(\mathrm{cm} / \mathrm{s})$ ) times the instantaneous velocity. Find the equation of motion if the mass is released from the equilibrium position with a downward velocity of $2 \mathrm{~cm} / \mathrm{s}$.

  \item Find the equation of motion for the mass in Problem 15 if the damping constant is doubled.

  \item A mass of 1 slug is attached to a spring whose constant is $9 \mathrm{lb} / \mathrm{ft}$. The medium offers a resistance to the motion numerically equal to 6 times the instantaneous velocity. The mass is released from a point 8 in. above the equilibrium position with a downward velocity of $v_{0} \mathrm{ft} / \mathrm{s}$. Determine the values of $v_{0}$ such that the mass will subsequently pass through the equilibrium position.

  \item The quasi period of an underdamped, vibrating 1 -slug mass on a spring is $\pi / 2$ seconds. If the spring constant is $25 \mathrm{lb} / \mathrm{ft}$, find the damping constant $\beta$.

  \item In the case of underdamped motion show that the difference in times between two successive positive maxima of the equation of motion is $2 \pi / \sqrt{\omega^{2}-\lambda^{2}}$.

  \item Use (16) to show that the time interval between successive intercepts of (15) is one-half the quasi period.

  \item Use (17) to show that the time interval between successive values of $t$ for which the graph of (15) touches the graphs of $\pm A e^{-\lambda t}$ is one-half the quasi period.

  \item Use equation (17) to show that the intercepts of the graph of $x(t)=$ $A e^{-\lambda t} \sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)$ are halfway between the values of $t$ for which the graph of $x(t)$ touches the graphs of $\pm A e^{-\lambda t}$. The values of $t$ for which $x(t)$ is a maximum or minimum are not located halfway between the intercepts of the graph of $x(t)$. Verify this last statement by considering the function $x(t)=e^{-i} \sin (t+\pi / 4)$.

  \item In the case of underdamped motion show that the ratio between two consecutive maximum (or minimum) displacements $x_{n}$ and $x_{n+2}$ is the constant

\end{enumerate}

$$
\frac{x_{n}}{x_{n+2}}=e^{2 \pi \lambda / \sqrt{\omega^{2}-\lambda^{2}}}
$$

The number $\delta=\ln \left(x_{n} / x_{n+2}\right)=2 \pi \lambda / \sqrt{\omega^{2}-\lambda^{2}}$ is called the logarithmic decrement.

\begin{enumerate}
  \setcounter{enumi}{23}
  \item The logarithmic decrement defined in Problem 23 is an indicator of the rate at which the motion is damped out.
\end{enumerate}

(a) Describe the motion of an underdamped system if $\delta$ is a very small positive number.

(b) Compute the logarithmic decrement for the motion described in Problem 12 .

\subsection*{5.3 FORCED MOTION}
With Damping Suppose we now take into consideration an external force $f(t)$ acting on a vibrating mass on a spring. For example, $f(t)$ could represent a driving force causing an oscillatory vertical motion of the support of the spring. See Figure 5.20. The inclusion of $f(t)$ in the formulation of Newton's second law gives the differential equation of forced motion


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k x-\beta \frac{d x}{d t}+f(t) \tag{1}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-222}
\end{center}

Figure 5.20


\begin{align*}
& \frac{d^{2} x}{d t^{2}}+\frac{\beta}{m} \frac{d x}{d t}+\frac{k}{m} x=\frac{f(t)}{m}  \tag{2}\\
& \frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=F(t) \tag{3}
\end{align*}


where $F(t)=f(t) / m$ and, as in the preceding section, $2 \lambda=\beta / m, \omega^{2}=k / m$. To solve the latter nonhomogeneous equation we can use either the method of undetermined coefficients or variation of parameters.

\section*{EXAMPLE 1 Interpretation of an IVP}
Interpret and solve the initial-value problem


\begin{equation*}
\frac{1}{5} \frac{d^{2} x}{d t^{2}}+1.2 \frac{d x}{d t}+2 x=5 \cos 4 t, \quad x(0)=\frac{1}{2}, \quad x^{\prime}(0)=0 \tag{4}
\end{equation*}


Solution We can interpret the problem to represent a vibrational system consisting of a mass ( $m=\frac{1}{5}$ slug or kilogram) attached to a spring ( $k=2 \mathrm{lb} / \mathrm{ft}$ or $\mathrm{N} / \mathrm{m}$ ). The mass is released from rest $\frac{1}{2}$ unit (foot or meter) below the equilibrium position. The motion is damped $(\beta=1.2)$ and is being driven by an external periodic ( $T=\pi / 2$ seconds) force beginning at $t=0$. Intuitively we would expect that even with damping the system will remain in motion until such time as the forcing function is "turned off," in which case the amplitudes diminish. However, as the problem is given, $f(t)=5 \cos 4 t$ will remain "on" forever.

We first multiply (4) by 5 and solve the associated homogeneous equation

$$
\frac{d x^{2}}{d t^{2}}+6 \frac{d x}{d t}+10 x=0
$$

by the usual methods. Since $m_{1}=-3+i, m_{2}=-3-i$, it follows that

$$
x_{c}(t)=e^{-3 t}\left(c_{1} \cos t+c_{2} \sin t\right)
$$

Using the method of undetermined coefficients, we assume a particular solution of the form $x_{p}(t)=A \cos 4 t+B \sin 4 t$. Now

$$
x_{p}^{\prime}=-4 A \sin 4 t+4 B \cos 4 t \quad \text { and } \quad x_{p}^{\prime \prime}=-16 A \cos 4 t-16 B \sin 4 t
$$

so

$$
\begin{aligned}
x_{p}^{\prime \prime}+6 x_{p}^{\prime}+10 x_{p} & =(-6 A+24 B) \cos 4 t+(-24 A-6 B) \sin 4 t \\
& =25 \cos 4 t .
\end{aligned}
$$

The resulting system of equations

$$
-6 A+24 B=25, \quad-24 A-6 B=0
$$

yields $A=-\frac{25}{102}$ and $B=\frac{50}{51}$. It follows that


\begin{equation*}
x(t)=e^{-3 t}\left(c_{1} \cos t+c_{2} \sin t\right)-\frac{25}{102} \cos 4 t+\frac{50}{51} \sin 4 t \tag{5}
\end{equation*}


When we set $t=0$ in the above equation, we obtain $c_{1}=\frac{38}{51}$. By differentiating the expression and then setting $t=0$, we also find that $c_{2}=-\frac{86}{51}$. Therefore the equation of motion is

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-223}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-223(1)}
\end{center}

(b)


\begin{equation*}
x(t)=e^{-3 t}\left(\frac{38}{51} \cos t-\frac{86}{51} \sin t\right)-\frac{25}{102} \cos 4 t+\frac{50}{51} \sin 4 t \tag{6}
\end{equation*}


Transient and Steady-State Terms Notice that the complementary function

$$
x_{c}(t)=e^{-3 t}\left(\frac{38}{51} \cos t-\frac{86}{51} \sin t\right)
$$

in Example 1 possesses the property that

$$
\lim _{t \rightarrow \infty} x_{c}(t)=0
$$

Since $x_{c}(t)$ becomes negligible (namely, $\rightarrow 0$ ) as $t \rightarrow \infty$, it is said to be a transient term, or transient solution. Thus for large time the displacements of the weight in the preceding problem are closely approximated by the particular solution $x_{p}(t)$. This latter function is also called the steady-state solution. When $F$ is a periodic function, such as $F(t)=F_{0} \sin \gamma t$ or $F(t)=F_{0} \cos \gamma t$, the general solution of (3) consists of

$$
x(t)=\text { transient }+ \text { stead } y \text {-state }
$$

\section*{EXAMPLE 2 Transient and Steady-State Solutions}
The solution to the initial-value problem

$$
\frac{d^{2} x}{d t^{2}}+2 \frac{d x}{d t}+2 x=4 \cos t+2 \sin t, \quad x(0)=0, \quad x^{\prime}(0)=3
$$

is readily shown to be

$$
x=x_{c}+x_{p}=\underbrace{e^{-t} \sin t}_{\text {transient }}+\underbrace{2 \sin t}_{\text {steady-state }}
$$

Inspection of Figure 5.21 shows that the effect of the transient term on the solution is, in this case, negligible for about $t>2 \pi$.

Figure 5.21\\
Without Damping With a periodic impressed force and no damping force, there is no transient term in the solution of a problem. Also, we shall see that a periodic impressed force with a frequency near or the same as the frequency of free undamped vibrations can cause a severe problem in any oscillatory mechanical system.

\section*{EXAMPLE 3 Forced Undamped Motion}
Solve the initial-value problem


\begin{equation*}
\frac{d^{2} x}{d t^{2}}+\omega^{2} x=F_{0} \sin \gamma t, \quad x(0)=0, \quad x^{\prime}(0)=0 \tag{7}
\end{equation*}


where $F_{0}$ is a constant.

Solution The complementary function is $x_{c}(t)=c_{1} \cos \omega t+c_{2} \sin \omega t$. To obtain a particular solution we assume $x_{p}(t)=A \cos \gamma t+B \sin \gamma t$, so

$$
\begin{aligned}
& x_{p}^{\prime}=-A \gamma \sin \gamma t+B \gamma \cos \gamma t \quad \text { and } \quad x_{p}^{\prime \prime}=-A \gamma^{2} \cos \gamma t-B \gamma^{2} \sin \gamma t \\
& x_{p}^{\prime \prime}+\omega^{2} x_{p}=A\left(\omega^{2}-\gamma^{2}\right) \cos \gamma t+B\left(\omega^{2}-\gamma^{2}\right) \sin \gamma t \\
&=F_{0} \sin \gamma t
\end{aligned}
$$

It follows that $A\left(\omega^{2}-\gamma^{2}\right)=0, B\left(\omega^{2}-\gamma^{2}\right)=F_{0}$, and so

$$
A=0, \quad B=\frac{F_{0}}{\omega^{2}-\gamma^{2}} \quad(\gamma \neq \omega)
$$

Therefore

$$
x_{p}(t)=\frac{F_{0}}{\omega^{2}-\gamma^{2}} \sin \gamma t
$$

Applying the given initial conditions to the general solution

$$
x(t)=c_{1} \cos \omega t+c_{2} \sin \omega t+\frac{F_{0}}{\omega^{2}-\gamma^{2}} \sin \gamma t
$$

yields $c_{1}=0$ and $c_{2}=-\gamma F_{0} / \omega\left(\omega^{2}-\gamma^{2}\right)$. Thus the solution is


\begin{equation*}
x(t)=\frac{F_{0}}{\omega\left(\omega^{2}-\gamma^{2}\right)}(-\gamma \sin \omega t+\omega \sin \gamma t), \quad \gamma \neq \omega \tag{8}
\end{equation*}


Pure Resonance Although equation (8) is not defined for $\gamma=\omega$, it is interesting to observe that its limiting value as $\gamma \rightarrow \omega$ can be obtained by applying L'Hôpital's rule. This limiting process is analogous to "tuning in" the frequency of the driving force $(\gamma / 2 \pi)$ to the frequency of free vibrations $(\omega / 2 \pi)$. Intuitively we expect that over a length of time we should be able to substantially increase the amplitudes of vibration.* For $\gamma=\omega$ we define the solution to be

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-224}
\end{center}

Figure 5.22


\begin{align*}
x(t)=\lim _{\gamma \rightarrow \omega} F_{0} \frac{-\gamma \sin \omega t+\omega \sin \gamma t}{\omega\left(\omega^{2}-\gamma^{2}\right)} & =F_{0} \lim _{\gamma \rightarrow \omega} \frac{\frac{d}{d \gamma}(-\gamma \sin \omega t+\omega \sin \gamma t)}{\frac{d}{d \gamma}\left(\omega^{3}-\omega \gamma^{2}\right)} \\
& =F_{0} \lim _{\gamma \rightarrow \omega} \frac{-\sin \omega t+\omega t \cos \gamma t}{-2 \omega \gamma} \\
& =F_{0} \frac{-\sin \omega t+\omega t \cos \omega t}{-2 \omega^{2}} \\
& =\frac{F_{0}}{2 \omega^{2}} \sin \omega t-\frac{F_{0}}{2 \omega} t \cos \omega t \tag{9}
\end{align*}


As suspected, when $t \rightarrow \infty$, the displacements become large; in fact, $\left|x\left(t_{n}\right)\right| \rightarrow \infty$ when $t_{n}=n \pi / \omega, n=1,2, \ldots$. The phenomenon we have just described is known as pure resonance. The graph given in Figure 5.22 shows typical motion in this case.
\footnotetext{\begin{itemize}
  \item If we forget about the damping effects of shock absorbers, the situation is roughly equivalent to a number of passengers jumping up and down in the back of a bus in time with the natural vertical motion caused by equally spaced faults (such as cracks) in the road. Theoretically these passengers could upset the bus-assuming they are not kicked off first!
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-225}
\end{center}

(a)

\begin{center}
\begin{tabular}{ccc}
\hline
$\boldsymbol{\beta}$ & $\boldsymbol{\gamma}_{1}$ & $\boldsymbol{g}\left(\boldsymbol{\gamma}_{1}\right)$ \\
\hline
 &  &  \\
2 & 1.41 & 0.58 \\
1 & 1.87 & 1.03 \\
0.75 & 1.93 & 1.36 \\
0.50 & 1.97 & 2.02 \\
0.25 & 1.99 & 4.01 \\
\hline
\end{tabular}
\end{center}

(b)\\
In conclusion it should be noted that there is no actual need to use a limiting process on (8) to obtain the solution for $\gamma=\omega$. Alternatively, equation (9) follows by solving the initial-value problem

$$
\frac{d^{2} x}{d t^{2}}+\omega^{2} x=F_{0} \sin \omega t, \quad x(0)=0, \quad x^{\prime}(0)=0
$$

directly by conventional methods.

Resonance Curve In the case of underdamped vibrations, the general solution of the differential equation


\begin{equation*}
\frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=F_{0} \sin \gamma t \tag{10}
\end{equation*}


can be shown to be


\begin{equation*}
x(t)=A e^{-\lambda t} \sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)+\frac{F_{0}}{\sqrt{\left(\omega^{2}-\gamma^{2}\right)^{2}+4 \lambda^{2} \gamma^{2}}} \sin (\gamma t+\theta) \tag{11}
\end{equation*}


where $A=\sqrt{c_{1}^{2}+c_{2}^{2}}$ and the phase angles $\phi$ and $\theta$ are, respectively, defined by

$$
\begin{aligned}
& \sin \phi=\frac{c_{1}}{A}, \cos \phi=\frac{c_{2}}{A} \\
& \sin \theta=\frac{-2 \lambda \gamma}{\sqrt{\left(\omega^{2}-\gamma^{2}\right)^{2}+4 \lambda^{2} \gamma^{2}}}, \quad \cos \theta=\frac{\omega^{2}-\gamma^{2}}{\sqrt{\left(\omega^{2}-\gamma^{2}\right)^{2}+4 \lambda^{2} \gamma^{2}}}
\end{aligned}
$$

\section*{EXAMPLE 4 Resonance Curve}
Inspection of (11) shows that $x_{c}(t)$ is transient when damping is present, and hence for large values of time the solution is closely approximated by the steady-state solution

$$
x_{p}(t)=g(\gamma) \sin (\gamma t+\theta)
$$

where we define


\begin{equation*}
g(\gamma)=\frac{F_{0}}{\sqrt{\left(\omega^{2}-\gamma^{2}\right)^{2}+4 \lambda^{2} \gamma^{2}}} \tag{12}
\end{equation*}


Although the amplitude of $x_{p}$ is bounded as $t \rightarrow \infty$, it is easily shown that the maximum oscillations will occur at the value $\gamma_{1}=\sqrt{\omega^{2}-2 \lambda^{2}}$ (see Problem 11). Thus when the frequency of the external force is $\sqrt{\omega^{2}-2 \lambda^{2}} / 2 \pi$, the system is said to be in resonance.

In the specific case $k=4, m=1, F_{0}=2, g(\gamma)$ becomes


\begin{equation*}
g(\gamma)=\frac{2}{\sqrt{\left(4-\gamma^{2}\right)^{2}+\beta^{2} \gamma^{2}}} \tag{13}
\end{equation*}


Figure 5.23\\
Figure 5.23(a) shows the graph of (13) for various values of the damping coef-\\
ficients $\beta$. This family of graphs is called the resonance curve of the system. Observe the behavior of the amplitudes $g(\gamma)$ as $\beta \rightarrow 0$-that is, as the system approaches pure resonance.

Remarks If a mechanical system were actually described by a function such as (9) of this section, it would necessarily fail. Large oscillations of a weight on a spring would eventually force the spring beyond its elastic limit. One might argue too that the resonating model presented in Figure 5.22 is completely unrealistic since it ignores the retarding effects of everpresent damping forces. Although it is true that pure resonance cannot occur when the smallest amount of damping is taken into consideration, large and equally destructive amplitudes of vibration (although bounded as $t \rightarrow \infty$ ) can occur.

If you have ever looked out an airplane window while in flight, you have probably observed that the wings on an airplane are not perfectly rigid. A reasonable amount of flex or flutter is not only tolerated but necessary to prevent the wing from snapping like a piece of peppermint stick candy. In late 1959 and early 1960 two commercial plane crashes involving a relatively new model of propjet occurred, illustrating the destructive effects of large mechanical oscillations.

The unusual aspect of these crashes was that they both happened while the planes were in mid-flight. Barring midair collisions, the safest period during any flight is when the plane has attained its cruising altitude. It is well known that a plane is most vulnerable to an accident when it is least maneuverable-namely, during either take-off or landing. So, having two planes simply fall out of the sky was not only a tragedy but an embarrassment to the aircraft industry and a thoroughly puzzling problem to aerodynamic engineers. In crashes of this sort, a structural failure of some kind is immediately suspected. After a massive technical investigation, the problem was eventually traced in each case to an outboard engine and engine housing. Roughly, it was determined that when each plane surpassed a critical speed of approximately 400 mph , a propeller and engine began to wobble, causing a gyroscopic force that could not be quelled or damped by the engine housing. This external vibrational force was then transferred to the already oscillating wing. This, in itself, need not have been destructively dangerous since aircraft wings are designed to withstand the stress of unusual and excessive forces. (In fact the particular wing in question was so incredibly strong that test engineers and pilots who were deliberately trying to snap a wing under every conceivable flight condition failed to do so.) But, unfortunately, after a short period of time during which the engine wobbled rapidly, the frequency of the impressed force actually slowed to a point at which it approached and finally coincided with the maximum frequency of wing flutter (around 3 cycles per second). The resulting resonance finally accomplished what the test engineers could not do; namely, the amplitudes of wing flutter became large enough to snap the wing. See Figure 5.24.

The problem was solved in two steps. All models of this particular plane were required to fly at speeds substantially below 400 mph until

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-227}
\end{center}

Figure 5.25 each plane could be modified by considerably strengthening (or stiffening) the engine housings. A strengthened engine housing was shown to be able to impart a damping effect capable of preventing the critical resonance phenomenon even in the unlikely event of a subsequent engine wobble.*

You may be aware that soldiers usually do not march in step across bridges. The reason for breaking stride is simply to avoid any possibility of resonance occurring between the natural vibrations inherent in the bridge's structure and the frequency of the external force of a multitude of feet stomping in unison on the bridge.

Acoustic vibrations can be equally as destructive as large mechanical vibrations. In television commercials, jazz singers have inflicted destruction on the lowly wine glass. See Figure 5.25. Sounds from organs and piccolos have been known to crack windows.

As the horns blew, the people began to shout. When they heard the signal horn, they raised a tremendous shout. The wall collapsed. ... [Joshua 6:20]

Did the power of acoustic resonance cause the walls of Jericho to tumble down? This is the conjecture of some contemporary scholars.

The phenomenon of resonance is not always destructive, however. For example, it is resonance of an electrical circuit that enables a radio to be tuned to a specific station.

\section*{EXERCISES 5.3}
\section*{Answers to odd-numbered problems begin on page A-10.}
\begin{enumerate}
  \item A $16-\mathrm{lb}$ weight stretches a spring $\frac{8}{3} \mathrm{ft}$. Initially the weight starts from rest 2 ft below the equilibrium position, and the subsequent motion takes place in a medium that offers a damping force numerically equal to $\frac{1}{2}$ the instantaneous velocity. Find the equation of motion if the weight is driven by an external force equal to $f(t)=10 \cos 3 t$.

  \item A mass of 1 slug is attached to a spring whose constant is $5 \mathrm{lb} / \mathrm{ft}$. Initially the mass is released 1 ft below the equilibrium position with a downward velocity of $5 \mathrm{ft} / \mathrm{s}$, and the subsequent motion takes place in a medium that offers a damping force numerically equal to 2 times the instantaneous velocity.

\end{enumerate}

(a) Find the equation of motion if the mass is driven by an external force equal to $f(t)=12 \cos 2 t+3 \sin 2 t$.

(b) Graph the transient and steady-state solutions on the same coordinate axes.

(c) Graph the equation of motion.
\footnotetext{\begin{itemize}
  \item For a fascinating nontechnical account of the investigation, see Robert J. Serling, Loud and Clear (New York: Dell, 1970), Chapter 5.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-228}
\end{center}

Figure 5.26\\
3. A mass of 1 slug, when attached to a spring, stretches it 2 ft and then comes to rest in the equilibrium position. Starting at $t=0$, an external force equal to $f(t)=8 \sin 4 t$ is applied to the system. Find the equation of motion if the surrounding medium offers a damping force numerically equal to 8 times the instantaneous velocity.

\begin{enumerate}
  \setcounter{enumi}{3}
  \item In Problem 3 determine the equation of motion if the external force is $f(t)=e^{-t} \sin 4 t$. Analyze the displacements for $t \rightarrow \infty$.

  \item When a mass of 2 kilograms is attached to a spring whose constant is $32 \mathrm{~N} / \mathrm{m}$, it comes to rest in the equilibrium position. Starting at $t=0$, a force equal to $f(t)=68 e^{-2 t} \cos 4 t$ is applied to the system. Find the equation of motion in the absence of damping.

  \item In Problem 5 write the equation of motion in the form $x(t)=$ $A \sin (\omega t+\phi)+B e^{-2 t} \sin (4 t+\theta)$. What is the amplitude of vibrations after a very long time?

  \item A mass $m$ is attached to the end of a spring whose constant is $k$. After the mass reaches equilibrium, its support begins to oscillate vertically about a horizontal line $L$ according to a formula $h(t)$. The value of $h$ represents the distance in feet measured from $L$. See Figure 5.26. Determine the differential equation of motion if the entire system moves through a medium offering a damping force numerically equal to $\beta(d x / d t)$.

  \item Solve the differential equation of the preceding problem if the spring is stretched 4 ft by a weight of 16 lb , and $\beta=2, h(t)=5 \cos t, x(0)=0$, $x^{\prime}(0)=0$.

  \item A mass of 100 g is attached to a spring whose constant is 1600 dynes $/ \mathrm{cm}$. After the mass reaches equilibrium, its support oscillates according to the formula $h(t)=\sin 8 t$, where $h$ represents displacement from its original position. See Problem 7 and Figure 5.26.

\end{enumerate}

(a) In the absence of damping, determine the equation of motion if the mass starts from rest from the equilibrium position.

(b) At what times does the mass pass through the equilibrium position?

(c) At what times does the mass attain its extreme displacements?

(d) What are the maximum and minimum displacements?

(e) Graph the equation of motion.

\begin{enumerate}
  \setcounter{enumi}{9}
  \item Show that the general solution of equation (10) is given by (11).

  \item (a) Prove that $g(\gamma)$ given in (13) of Example 4 has a maximum value at $\gamma_{1}=\sqrt{\omega^{2}-2 \lambda^{2}}$. [Hint: Differentiate with respect to $\gamma$.]

\end{enumerate}

(b) What is the maximum value of $g(\gamma)$ at resonance?

\begin{enumerate}
  \setcounter{enumi}{11}
  \item (a) If $k=3 \mathrm{lb} / \mathrm{ft}$ and $m=1$ slug, use the information in Example 4 to show that the system is underdamped when the damping coefficient $\beta$ satisfies $0<\beta<2 \sqrt{3}$ but that resonance can occur only if $0<\beta<\sqrt{6}$.
\end{enumerate}

(b) Construct the resonance curve of the system when $F_{0}=3$.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item A mass of $\frac{1}{2}$ slug is suspended on a spring whose constant is $6 \mathrm{lb} / \mathrm{ft}$. The system is set in motion in a medium offering a damping force numerically equal to twice the instantaneous velocity. Find the steady-state solution if an external force $f(t)=40 \sin 2 t$ is applied to the system starting at $t=0$. Write this solution in the form of a constant multiple of $\sin (2 t+\theta)$.

  \item Verify that the mechanical system described in Problem 13 is in resonance. Show that the amplitude of the steady-state solution is the maximum value of $g(\gamma)$ described in Problem 11.

  \item (a) Show that the solution of the initial-value problem

\end{enumerate}

$$
\begin{aligned}
\frac{d^{2} x}{d t^{2}}+\omega^{2} x & =F_{0} \cos \gamma t, \quad x(0)=0, \quad x^{\prime}(0)=0 \\
x(t) & =\frac{F_{0}}{\omega^{2}-\gamma^{2}}(\cos \gamma t-\cos \omega t) .
\end{aligned}
$$

(b) Evaluate $\lim _{\gamma \rightarrow \omega} \frac{F_{0}}{\omega^{2}-\gamma^{2}}(\cos \gamma t-\cos \omega t)$.

\begin{enumerate}
  \setcounter{enumi}{15}
  \item Compare the result obtained in part (b) of Problem 15 with the solution obtained using variation of parameters when the external force is $F_{0} \cos \omega t$.
\end{enumerate}

In Problems 17 and 18 solve the given initial-value problem.\\
17. $\frac{d^{2} x}{d t^{2}}+4 x=-5 \sin 2 t+3 \cos 2 t, \quad x(0)=-1, \quad x^{\prime}(0)=1$\\
18. $\frac{d^{2} x}{d t^{2}}+9 x=5 \sin 3 t, \quad x(0)=2, \quad x^{\prime}(0)=0$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item (a) Show that $x(t)$ given in part (a) of Problem 15 can be written in the form
\end{enumerate}

$$
x(t)=\frac{-2 F_{0}}{\omega^{2}-\gamma^{2}} \sin \frac{1}{2}(\gamma-\omega) t \sin \frac{1}{2}(\gamma+\omega) t
$$

(b) If we define $\varepsilon=\frac{1}{2}(\gamma-\omega)$, show that when $\varepsilon$ is small an approximate solution is

$$
x(t)=\frac{F_{0}}{2 \varepsilon \gamma} \sin \varepsilon t \sin \gamma t
$$

When $\varepsilon$ is small, the frequency $\gamma / 2 \pi$ of the impressed force is close to the frequency $\omega / 2 \pi$ of free vibrations. When this occurs, the motion is as indicated in Figure 5.27. Oscillations of this kind are called beats and are due to the fact that the frequency of $\sin \varepsilon t$ is quite small in comparison to the frequency of $\sin \gamma t$. The dashed curves, or envelope of the graph of $x(t)$, are obtained from the graphs of $\pm\left(F_{0} / 2 \varepsilon \gamma\right) \sin \varepsilon t$. Use a computer with various values of $F_{0}, \varepsilon$, and $\gamma$ to verify the graph in Figure 5.27.

(c) Evaluate $\lim _{\varepsilon \rightarrow 0} \frac{F_{0}}{2 \varepsilon \gamma} \sin \varepsilon t \sin \gamma t$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-229}
\end{center}

Figure 5.27

\section*{ILLUSTRATED APPLICATIONS}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-230(2)}
\end{center}

After painstaking observations, Johannes Kepler formulated and then published in 1609 three laws of planetary motion. The first law, probably his most famous, states that a planet revolves around the sun in an elliptical orbit with the sun at one focus. His

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-230(1)}
\end{center}

second law of planetary motion states that the radius vector joining a planet with the sun sweeps out equal areas in equal intervals of time. See Problem 33, Exercises 3.2.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-230}
\end{center}

Around 1840, the Belgian mathematician P. F. Verhulst studied the nonlinear first-order differential equation $d P / d t=P(a-b P)$, called the logistic equation, in an attempt to model the population growth of various countries. This equation also provides a reasonable model for other growth phenomena such as the spread of flu throughout a static population, as found on the college campus illustrated here. See page 21, Section 3.3 , and the essay at the end of Chapter 3.\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-231(1)}

A ball or rocket projected straight up into the sky will fall back to earth under the influence of gravity unless it is given a sufficiently great velocity. The secondorder differential equation $m d^{2} y / d t^{2}=-k M m / y^{2}$ can be used to determine the so-called "escape velocity" an object needs to break free from the gravitational attraction of any celestial body such as the earth. The escape velocity is independent of the mass of the object, so on earth the escape velocity for a ball is the same as that for a rocket. See Section 3.3.\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-231}

The motion of a mass attached to a spring is described by a linear second-order differential equation of the form $x^{\prime \prime}+2 \lambda x^{\prime}+\omega^{2} x=f(t)$. An example of such a spring/mass system is the spring suspension system of some models of cars and trucks. See Chapter 5.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-232}
\end{center}

normal flutter

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-232(2)}
\end{center}

large flutter

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-232(3)}
\end{center}

In late 1959 and early 1960, two commercial airplane crashes occurred involving the popular Lockheed Electra, a new model four-engine propjet. Braniff Flight 542 crashed near Buffalo, Texas, in September, 1959. and Northwest Flight 710 went down near Tell City, Indiana, in March, 1960. In both cases a wing had separated from the plane while at cruising altitude. These crashes illustrate the destructive effects of large mechanical oscillations or resonance. See Section 5.3.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-232(1)}
\end{center}

A single differential equation can serve as the mathematical model for different phenomena. The differential equation governing the charge $q(t)$ on a capacitor in an $L-R-C$ series circuit has the same form as the differential equation governing the displacement $x(t)$ of a vibrating mass on a spring. See Sections 5.3 and 5.4.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-233(2)}
\end{center}

For years the 1940 collapse of the Tacoma Narrows Bridge was attributed to a resonance condition induced by wind blowing across its roadway and causing periodic vertical forces to act in the same direction as the vibration of the bridge. Recent studies suggest a different cause for the collapse. See the essay following Chapter 5. Compare the girder-stiffened roadway in this photograph, showing the reconstructed bridge, with the delicate 1940 design evident in the photographs on page 218.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-233(3)}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-233(1)}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-233}
\end{center}

Mechanical systems are often acted upon by a sharp external force known as an impulsive force. This kind of force, which occurs in the collision of two objects, is a force of very large and approximately constant magnitude that acts on the system for a short time. A racket smashing into a tennis ball imparts a tremendous force to the ball but is in physical contact with it for only a fraction of a second. Analogous situations include a club striking a golf ball, lightning striking an airplane wing, and a proton striking the nucleus of an atom. See Section 7.6.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Show that the solution of the initial-value problem
\end{enumerate}

$$
\frac{d^{2} x}{d t^{2}}+25 x=10 \cos 7 t, \quad x(0)=0, \quad x^{\prime}(0)=0
$$

is $x(t)=\frac{5}{6} \sin t \sin 6 t$. Use a graphics calculator or computer to obtain the graph of $x(t)$.

\subsection*{5.4 ELECTRIC CIRCUITS AND OTHER ANALOGOUS SYSTEMS}
\begin{itemize}
  \item Electrical vibrations
  \item Overdamped circuit - Critically damped circuit
  \item Underdamped circuit
  \item Steady-state current
  \item Reactance
  \item Impedance
  \item Extreme displacement
\end{itemize}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-234(3)}
\end{center}

(a)

\section*{Inductor}
inductance $L$ : henrys (h) voltage drop across: $L \frac{d i}{d t}$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-234(1)}
\end{center}

\section*{Resistor}
resistance $R$ : ohms $(\Omega)$ voltage drop across: $i R$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-234(2)}
\end{center}

Capacitor

capacitance $C$ : farads (f) voltage drop across: $\frac{1}{C} q$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-234}
\end{center}

(b)

$\boldsymbol{L} \boldsymbol{R}$ - $\boldsymbol{C}$ Series Circuits As mentioned in the introduction to this chapter, many different physical systems can be described by a linear second-order differential equation similar to the differential equation of forced motion with damping:


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}+\beta \frac{d x}{d t}+k x=f(t) \tag{1}
\end{equation*}


If $i(t)$ denotes current in an $\boldsymbol{L} \boldsymbol{R} \boldsymbol{R} \boldsymbol{C}$ series electrical circuit shown in Figure 5.28(a), then the voltage drops across the inductor, resistor, and capacitor are as shown in Figure 5.28(b). By Kirchhoff's second law, the sum of these voltages equals the voltage $E(t)$ impressed on the circuit; that is,


\begin{equation*}
L \frac{d i}{d t}+R i+\frac{1}{C} q=E(t) \tag{2}
\end{equation*}


But the charge $q(t)$ on the capacitor is related to the current $i(t)$ by $i=d q / d t$ and so (2) becomes the linear second-order differential equation


\begin{equation*}
L \frac{d^{2} q}{d t^{2}}+R \frac{d q}{d t}+\frac{1}{C} q=E(t) \tag{3}
\end{equation*}


The nomenclature used in the analysis of circuits is similar to that used to describe spring-mass systems.

If $E(t)=0$, the electrical vibrations of the circuit are said to be free. Since the auxiliary equation for (3) is $L m^{2}+R m+1 / C=0$, there will be three forms of the solution when $R \neq 0$, depending on the value of the discriminant $R^{2}-4 L / C$. We say that the circuit is

overdamped if $\quad R^{2}-4 L / C>0$,

critically damped if $R^{2}-4 L / C=0$,

In each of these three cases, the general solution of (3) contains the factor $e^{-R t / 2 L}$ and so $q(t) \rightarrow 0$ as $t \rightarrow \infty$. In the underdamped case when $q(0)=q_{0}$, the charge on the capacitor oscillates as it decays; in other words, the capacitor is charging and discharging as $t \rightarrow \infty$. When $E(t)=0$ and $R=0$, the circuit is said to be undamped and the electrical vibrations do not approach zero as $t$ increases without bound; the response of the circuit is simple harmonic.

\section*{EXAMPLE 1 Simple Harmonic Response}
Consider an $L-C$ series circuit in which $E(t)=0$. Determine the charge $q(t)$ on the capacitor for $t>0$ if its initial charge is $q_{0}$ and if initially there is no current flowing in the circuit.

Solution In an $L-C$ circuit there is no resistor, so from (3) we obtain

$$
L \frac{d^{2} q}{d t^{2}}+\frac{1}{C} q=0
$$

The initial conditions are $q(0)=q_{0}$ and $i(0)=0$. Since $q^{\prime}(t)=i(t)$, the latter condition is the same as $q^{\prime}(0)=0$. The general solution of the differential equation is

$$
q(t)=c_{1} \cos \frac{1}{\sqrt{L C}} t+c_{2} \sin \frac{1}{\sqrt{L C}} t
$$

Now the initial conditions imply $c_{1}=q_{0}$ and $c_{2}=0$, so

$$
q(t)=q_{0} \cos \frac{1}{\sqrt{L C}} t
$$

In Example 1 if we want to find the current in the circuit, we use $i(t)=q^{\prime}(t):$

$$
i(t)=-\frac{q_{0}}{\sqrt{L C}} \sin \frac{1}{\sqrt{L C}} t
$$

\section*{EXAMPLE 2 Underdamped Series Circuit}
Find the charge $q(t)$ on the capacitor in an $L-R-C$ series circuit when $L=0.25$ henry, $R=10$ ohms, $C=0.001$ farad, $E(t)=0, q(0)=q_{0}$ coulombs, and $i(0)=0$.

Solution Since $1 / C=1000$, equation (3) becomes

$$
\frac{1}{4} q^{\prime \prime}+10 q^{\prime}+1000 q=0 \quad \text { or } \quad q^{\prime \prime}+40 q^{\prime}+4000 q=0
$$

Solving this homogeneous equation in the usual manner, we find that the circuit is underdamped and

$$
q(t)=e^{-20 t}\left(c_{1} \cos 60 t+c_{2} \sin 60 t\right)
$$

Applying the initial conditions, we find $c_{1}=q_{0}$ and $c_{2}=q_{0} / 3$. Thus the solution is given by

$$
q(t)=q_{0} e^{-20 t}\left(\cos 60 t+\frac{1}{3} \sin 60 t\right)
$$

The solution in Example 2 can be written as a single sine function using the method discussed in Section 5.2. From (15) of that section, we find that

$$
q(t)=\frac{q_{0} \sqrt{10}}{3} e^{-20 t} \sin (60 t+1.249)
$$

When there is an impressed voltage $E(t)$ on the circuit, the electrical vibrations are said to be forced. Note in Example 1 that the free electrical vibrations are simple harmonic with period $2 \pi /(1 / \sqrt{L C})=2 \pi \sqrt{L C}$ and frequency $1 /(2 \pi \sqrt{L C})$. If a periodic voltage $E(t)$ with the same frequency were impressed on the circuit, the system would be in resonance. In the case when $R \neq 0$, the complementary function $q_{c}(t)$ of (3) is called a transient solution. If $E(t)$ is periodic or a constant, then the particular solution $q_{p}(t)$ of (3) is a steady-state solution.

\section*{EXAMPLE 3 Steady-State Current}
Find the steady-state solution $q_{p}(t)$ and the steady-state current in an $L-R-C$ series circuit when the impressed voltage is $E(t)=E_{0} \sin \gamma t$.

Solution The steady-state solution $q_{p}(t)$ is a particular solution of the differential equation

$$
L \frac{d^{2} q}{d t^{2}}+R \frac{d q}{d t}+\frac{1}{C} q=E_{0} \sin \gamma t
$$

Using the method of undetermined coefficients, we assume a particular solution of the form


\begin{equation*}
q_{p}(t)=A \sin \gamma t+B \cos \gamma t \tag{4}
\end{equation*}


Substituting (4) into the differential equation, simplifying, and equating coefficients gives

$$
A=\frac{E_{0}(L \gamma-1 / C \gamma)}{-\gamma\left[L^{2} \gamma^{2}-\frac{2 L}{C}+\frac{1}{C^{2} \gamma^{2}}+R^{2}\right]} \quad \text { and } \quad B=\frac{E_{0} R}{-\gamma\left[L^{2} \gamma^{2}-\frac{2 L}{C}+\frac{1}{C^{2} \gamma^{2}}+R^{2}\right]}
$$

It is convenient to express $A$ and $B$ in terms of some new symbols.

If $\quad X=L \gamma-\frac{1}{C \gamma}, \quad$ then $\quad X^{2}=L^{2} \gamma^{2}-\frac{2 L}{C}+\frac{1}{C^{2} \gamma^{2}}$.

If $Z=\sqrt{X^{2}+R^{2}}$, then $Z^{2}=L^{2} \gamma^{2}-\frac{2 L}{C}+\frac{1}{C^{2} \gamma^{2}}+R^{2}$.

Therefore $A=E_{0} X /\left(-\gamma Z^{2}\right)$ and $B=E_{0} R /\left(-\gamma Z^{2}\right)$ and so the steady-state charge is

$$
q_{p}(t)=-\frac{E_{0} X}{\gamma Z^{2}} \sin \gamma t-\frac{E_{0} R}{\gamma Z^{2}} \cos \gamma t
$$

Now the steady-state current is given by $i_{p}(t)=q_{p}^{\prime}(t)$ :


\begin{equation*}
i_{p}(t)=\frac{E_{0}}{Z}\left(\frac{R}{Z} \sin \gamma t-\frac{X}{Z} \cos \gamma t\right) \tag{5}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-237}
\end{center}

Figure 5.29\\
The quantities $X=L \gamma-1 / C \gamma$ and $Z=\sqrt{X^{2}+R^{2}}$ defined in Example 3 are called, respectively, the reactance and impedance of the circuit. Both the reactance and the impedance are measured in ohms.

Twisted Shaft The differential equation governing the torsional motion of a weight suspended from the end of an elastic shaft is


\begin{equation*}
I \frac{d^{2} \theta}{d t^{2}}+c \frac{d \theta}{d t}+k \theta=T(t) \tag{6}
\end{equation*}


As shown in Figure 5.29, the function $\theta(t)$ represents the amount of twist of the weight at any time.

By comparing equations (3) and (6) with (1), we see that, with the exception of terminology, there is absolutely no difference between the mathematics of vibrating springs, simple series circuits, and torsional vibrations. Table 5.1 gives a comparison of the analogous parts of these three kinds of systems.

Table 5.1

\begin{center}
\begin{tabular}{lll}
\hline
Mechanical & Series electrical & Torsional \\
\hline
$m$ (mass) & $L$ (inductance) & $I$ (moment of inertia) \\
$\beta$ (damping) & $R$ (resistance) & $c$ (damping) \\
$k$ (spring constant) & $\frac{1}{C}$ (reciprocal of capacitance- & $k$ (ellastic shaft \\
calledastance) & \begin{tabular}{c}
constant) \\
\end{tabular} &  \\
$f(t)$ (applied force) & $E(t)$ (impressed voltage) & $T(t)$ (applied torque) \\
\hline
\end{tabular}
\end{center}

Simple Pendulum In Example 3 of Section 1.2 it was seen that the angular displacements $\theta$ of a simple pendulum are described by the nonlinear secondorder equation

$$
\frac{d^{2} \theta}{d t^{2}}+\frac{g}{l} \sin \theta=0
$$

where $l$ is the length of the pendulum rod. For small displacements $\sin \theta$ is replaced by $\theta$, and the resulting differential equation


\begin{equation*}
\frac{d^{2} \theta}{d t^{2}}+\frac{g}{l} \theta=0 \tag{7}
\end{equation*}


indicates that the pendulum exhibits simple harmonic motion. Inspection of the solution (7) reveals that the period of small oscillations is given by the familiar formula from physics $T=2 \pi \sqrt{l / g}$.

\section*{EXERCISES 5.4}
\section*{Answers to odd-numbered problems begin on page A-11.}
In Problems 1 and 2 find the charge on the capacitor and the current in the given $L-C$ series circuit. Assume $q(0)=0$ and $i(0)=0$.

$$
\text { 1. } L=1 \text { henry, } C=\frac{1}{16} \text { farad, } E(t)=60 \text { volts }
$$

\begin{enumerate}
  \setcounter{enumi}{1}
  \item $L=5$ henrys, $C=0.01$ farad, $E(t)=20 t$ volts
\end{enumerate}

In Problems 3 and 4 without solving (3) determine whether the given $L-R-C$ series circuit is overdamped, critically damped, or underdamped.

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $L=3$ henrys, $R=10$ ohms, $C=0.1$ farad

  \item $L=1$ henry, $R=20$ ohms, $C=0.01$ farad

  \item Find the charge on the capacitor in an $L-R-C$ series circuit at $t=0.01$ second when $L=0.05$ henry, $R=2$ ohms, $C=0.01$ farad, $E(t)=0$ volts, $q(0)=5$ coulombs, and $i(0)=0$ amperes. Determine the first time at which the charge on the capacitor is equal to zero.

  \item Find the charge on the capacitor in an $L-R-C$ series circuit when $L=\frac{1}{4}$ henry, $R=20$ ohms, $C=\frac{1}{3(0)}$ farad, $E(t)=0$ volts, $q(0)=4$ coulombs, and $i(0)=0$ amperes. Is the charge on the capacitor ever equal to zero?

\end{enumerate}

In Problems 7 and 8 find the charge on the capacitor and the current in the given $L-R-C$ series circuit. Find the maximum charge on the capacitor.

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $L=\frac{5}{3}$ henrys, $R=10$ ohms, $C=\frac{1}{30}$ farad, $E(t)=300$ volts, $q(0)=0$ coulombs, $i(0)=0$ amperes

  \item $L=1$ henry, $R=100$ ohms, $C=0.0004$ farad, $E(t)=30$ volts, $q(0)=0$ coulombs, $i(0)=2$ amperes

  \item Find the steady-state charge and the steady-state current in an $L-R-C$ series circuit when $L=1$ henry, $R=2$ ohms, $C=0.25$ farad, and $E(t)=50 \cos t$ volts.

  \item Show that the amplitude of the steady-state current in the $L-R-C$ series circuit in Example 3 is given by $E_{0} / Z$, where $Z$ is the impedance of the circuit.

  \item Show that the steady-state current in an $L-R-C$ series circuit when $L=\frac{1}{2}$ henry, $R=20$ ohms, $C=0.001$ farad, and $E(t)=100 \sin 60 t$ volts is given by $i_{p}(t)=(4.160) \sin (60 t-0.588)$. [Hint: Use Problem 10.]

  \item Find the steady-state current in an $L-R-C$ series circuit when $L=\frac{1}{2}$ henry, $R=20$ ohms, $C=0.001$ farad, and $E(t)=100 \sin 60 t+$ $200 \cos 40 t$ volts.

  \item Find the charge on the capacitor in an $L-R-C$ series circuit when $L=\frac{1}{2}$ henry, $R=10$ ohms, $C=0.01$ farad, $E(t)=150$ volts, $q(0)=1$ coulomb, and $i(0)=0$ amperes. What is the charge on the capacitor after a long time?

  \item Show that if $L, R, C$, and $E_{0}$ are constant, then the amplitude of the steady-state current in Example 3 is a maximum when $\gamma=1 / \sqrt{L C}$. What is the maximum amplitude?

  \item Show that if $L, R, E_{0}$, and $\gamma$ are constant, then the amplitude of the steady-state current in Example 3 is a maximum when the capacitance is $C=1 / L \gamma^{2}$.

  \item Find the charge on the capacitor and the current in an $L-C$ circuit when $L=0.1$ henry, $C=0.1$ farad, $E(t)=100 \sin \gamma t$ volts, $q(0)=0$ coulombs, and $i(0)=0$ amperes.

  \item Find the charge on the capacitor and the current in an $L-C$ circuit when $E(t)=E_{0} \cos \gamma t$ volts, $q(0)=q_{0}$ coulombs, and $i(0)=i_{0}$ amperes.

  \item In Problem 17 find the current when the circuit is in resonance.

  \item Find the equation of motion describing the small displacements $\theta(t)$ of a simple pendulum of length 2 ft released at $t=0$ with a displacement of $\frac{1}{2}$ radian to the right of the vertical and angular velocity of $2 \sqrt{3} \mathrm{ft} / \mathrm{s}$ to the right. What are the amplitude, period, and frequency of motion?

  \item In Problem 19 at what times does the pendulum pass through its equilibrium position? At what times does the pendulum attain its extreme angular displacements on either side of its equilibrium position?

\end{enumerate}

\section*{CHAPTER 5 REVIEW}
When a mass is attached to a spring, it stretches to a position where the restoring force $k s$ of the spring is balanced by the weight $m g$. Any subsequent motion is then measured $x$ units (feet in the engineering system) above or below this equilibrium position. When the mass is above the equilibrium position, we adopt the convention that $x<0$, whereas when the mass is below the equilibrium position, we take $x>0$.

The differential equation of motion is obtained by equating Newton's second law $F=m a=m\left(d^{2} x / d t^{2}\right)$ with the net force acting on the mass at any time. We distinguish three cases.

Case I The equation


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k x \quad \text { or } \quad \frac{d^{2} x}{d t^{2}}+\omega^{2} x=0 \tag{1}
\end{equation*}


where $\omega^{2}=k / m$, describes the motion under the assumptions that no damping force and no external impressed forces are acting on the system. The solution of (1) is $x(t)=c_{1} \cos \omega t+c_{2} \sin \omega t$ and the mass is said to exhibit simple harmonic motion. The constants $c_{1}$ and $c_{2}$ are determined by the initial position $x(0)$ and the initial velocity $x^{\prime}(0)$ of the mass.

Case II When a damping force is present, the differential equation becomes


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k x-\beta \frac{d x}{d t} \quad \text { or } \quad \frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=0 \tag{2}
\end{equation*}


where $\beta>0,2 \lambda=\beta / m$, and $\omega^{2}=k / m$. The resulting motion is said to be overdamped, critically damped, or underdamped accordingly as $\lambda^{2}-\omega^{2}>0$, $\lambda^{2}-\omega^{2}=0$, or $\lambda^{2}-\omega^{2}<0$. The respective solutions of (2) are then

$$
x(t)=c_{1} e^{m_{1} t}+c_{2} e^{m_{2} t}
$$

where $m_{1}=-\lambda+\sqrt{\lambda^{2}-\omega^{2}}, m_{2}=-\lambda-\sqrt{\lambda^{2}-\omega^{2}}$;

$$
x(t)=c_{1} e^{m_{1} t}+c_{2} t e^{m_{1} t}
$$

where $m_{1}=-\lambda$; and

$$
x(t)=e^{-\lambda t}\left(c_{1} \cos \sqrt{\omega^{2}-\lambda^{2}} t+c_{2} \sin \sqrt{\omega^{2}-\lambda^{2}} t\right)
$$

In each case the damping force is responsible for the displacements becoming negligible for large time; that is, $x \rightarrow 0$ as $t \rightarrow \infty$.

The motion described in Cases I and II is said to be free motion.

Case III When an external force is impressed on the system for $t>0$, the differential equation becomes


\begin{equation*}
m \frac{d^{2} x}{d t^{2}}=-k x-\beta \frac{d x}{d t}+f(t) \quad \text { or } \quad \frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=F(t) \tag{3}
\end{equation*}


where $\lambda$ and $\omega^{2}$ are defined in Case II. The solution of the nonhomogeneous equation (3) is $x(t)=x_{c}+x_{p}$.

Since the complementary function $x_{c}$ always contains the factor $e^{-\lambda t}$, it will be transient; that is, $x_{c} \rightarrow 0$ as $t \rightarrow \infty$. If $F(t)$ is periodic, then $x_{p}$ will be a steady-state solution.

In the absence of a damping force, an impressed periodic force can cause the amplitudes of vibration to become very large. If the frequency of the external force is the same as the frequency $\omega / 2 \pi$ of free vibrations, we say that the system is in a state of pure resonance. In this case the amplitudes of vibrations become unbounded as $t \rightarrow \infty$. In the presence of a damping force, amplitudes of oscillatory motion are always bounded. However, large and potentially destructive amplitudes can occur.

When a series circuit containing an inductor, resistor, and capacitor is driven by an electromotive force $E(t)$, the resulting differential equations for the charge $q(t)$ or the current $i(t)$ are quite similar to equation (3). Hence the analysis of such circuits is the same as outlined above

\section*{CHAPTER 5 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-11.

Answer Problems 1-9 without referring back to the text. Fill in the blank or answer true or false.

\begin{enumerate}
  \item If a $10-\mathrm{lb}$ weight stretches a spring 2.5 ft , a $32-\mathrm{lb}$ weight will stretch it $\qquad$ ft .

  \item The period of simple harmonic motion of an $8-\mathrm{lb}$ weight attached to a spring whose constant is $6.25 \mathrm{lb} / \mathrm{ft}$ is $\qquad$ seconds.

  \item The differential equation of a weight on a spring is $x^{\prime \prime}+16 x=0$. If the weight is released at $t=0$ from 1 m above the equilibrium position with a downward velocity of $3 \mathrm{~m} / \mathrm{s}$, the amplitude of vibrations is $\qquad$ m .

  \item Pure resonance cannot take place in the presence of a damping force.

  \item In the presence of damping, the displacements of a weight on a spring will always approach zero as $t \rightarrow \infty$. $\qquad$

  \item A weight on a spring whose motion is critically damped can possibly pass through the equilibrium position twice. $\qquad$

  \item At critical damping any increase in damping will result in an $\qquad$ system.

  \item When simple harmonic motion is described by $x=(\sqrt{2} / 2) \sin (2 t+\phi)$, the phase angle $\phi$ is $\qquad$ when $x(0)=-\frac{1}{2}$ and $x^{\prime}(0)=1$.

  \item A $16-\mathrm{lb}$ weight attached to a spring exhibits simple harmonic motion. If the frequency of oscillations is $3 / 2 \pi$ vibrations/second, the spring constant is $\qquad$ .

  \item A 12-lb weight stretches a spring 2 ft . The weight is released from a point 1 ft below the equilibrium position with an upward velocity of $4 \mathrm{ft} / \mathrm{s}$.

\end{enumerate}

(a) Find the equation describing the resulting simple harmonic motion.

(b) What are the amplitude, period, and frequency of motion?

(c) At what times does the weight return to the point 1 ft below the equilibrium position?

(d) At what times does the weight pass through the equilibrium position moving upward? moving downward?

(e) What is the velocity of the weight at $t=3 \pi / 16$ second?

(f) At what times is the velocity zero?

\begin{enumerate}
  \setcounter{enumi}{10}
  \item A force of 2 lb stretches a spring 1 ft . With one end held fixed, an $8-\mathrm{lb}$ weight is attached to the other end and the system lies on a table that imparts a frictional force numerically equal to $\frac{3}{2}$ times the instantaneous velocity. Initially the weight is displaced 4 in. above the equilibrium position and released from rest. Find the equation of motion if the motion takes place along a horizontal straight line that is taken as the $x$-axis.

  \item A 32-lb weight stretches a spring 6 in. The weight moves through a medium offering a damping force numerically equal to $\beta$ times the instantaneous velocity. Determine the values of $\beta$ for which the system will exhibit oscillatory motion.

  \item A spring with constant $k=2$ is suspended in a liquid that offers a damping force numerically equal to 4 times the instantaneous velocity. If a mass $m$ is suspended from the spring, determine the values of $m$ for which the subsequent free motion is nonoscillatory.

  \item The vertical motion of a weight attached to a spring is described by the initial-value problem

\end{enumerate}

$$
\frac{1}{4} \frac{d^{2} x}{d t^{2}}+\frac{d x}{d t}+x=0, \quad x(0)=4, \quad x^{\prime}(0)=2
$$

Determine the maximum vertical displacement.

\begin{enumerate}
  \setcounter{enumi}{14}
  \item A 4-lb weight stretches a spring 18 in . A periodic force equal to $f(t)=$ $\cos \gamma t+\sin \gamma t$ is impressed on the system starting at $t=0$. In the absence of a damping force, for what value of $\gamma$ will the system be in a state of pure resonance?

  \item Find a particular solution for $\frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=A$, where $A$ is a\\
constant force.

  \item A $4-\mathrm{lb}$ weight is suspended from a spring whose constant is $3 \mathrm{lb} / \mathrm{ft}$. The entire system is immersed in a fluid offering a damping force numerically equal to the instantaneous velocity. Beginning at $t=0$, an external force equal to $f(t)=e^{-t}$ is impressed on the system. Determine the equation of motion if the weight is released from rest at a point 2 ft below the equilibrium position.

  \item (a) Two springs are attached in series as shown in Figure 5.30. If the mass of each spring is ignored, show that the effective spring constant $k$ is given by $1 / k=1 / k_{1}+1 / k_{2}$.

\end{enumerate}

(b) A weight of $W \mathrm{lb}$ stretches one spring $\frac{1}{2} \mathrm{ft}$ and stretches a different spring $\frac{1}{4} \mathrm{ft}$. The two springs are attached as in the figure and the weight $W$ is then attached to the double spring. Assume that the motion is free and that there is no damping force present. Determine the equation of motion if the weight is released at a point 1 ft below the

Figure 5.30 equilibrium position with a downward velocity of $\frac{2}{3} \mathrm{ft} / \mathrm{s}$.

(c) Show that the maximum speed of the weight is $\frac{2}{3} \sqrt{3 g+1}$.

\begin{enumerate}
  \setcounter{enumi}{18}
  \item A series circuit contains an inductance of $L=1$ henry, a capacitance of $C=10^{-4}$ farad, and an electromotive force of $E(t)=100 \sin 50 t$ volts. Initially the charge $q$ and current $i$ are zero.
\end{enumerate}

(a) Find the equation for the charge at time $t$.

(b) Find the equation for the current at time $t$.

(c) Find the times for which the charge on the capacitor is zero.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Show that the current $i(t)$ in an $L-R-C$ series circuit satisfies the differential equation
\end{enumerate}

$$
L \frac{d^{2} i}{d t^{2}}+R \frac{d i}{d t}+\frac{1}{C} i=E^{\prime}(t)
$$

where $E^{\prime}(t)$ denotes the derivative of $E(t)$.\\
by

Gilbert N. Lewis

Department of Mathematical and Computer Sciences, Michigan Technological University

\section*{TACOMA NARROWS SUSPENSION BRIDGE COLLAPSE}
As can be seen from equation (9) and Figure 5.22 of Section 5.3, the oscillations in the case of resonance become very large as time increases. In a physical system this would be catastrophic, since the ever-increasing amplitudes of oscillation would tear the system apart. Two historical examples of this have already been given (airplane wings and soldiers marching across bridges). In those examples, periodic forces of the same frequency as the natural frequency of the structures were set up in the direction of the vibrations, leading to the resonant destruction of the structures.

Another example that has, until very recently, been used to illustrate the phenomenon of resonance is the collapse of the Tacoma Narrows Bridge in the state of Washington. The bridge was completed and open to traffic in the summer of 1940 . It was soon noticed that large vibrations of the roadbed were induced when wind blew across it. "Galloping Gertie," as the bridge was called, became a tourist attraction; people liked to watch it vibrate and even take an exciting roller coaster ride across it. Finally, on November 7, 1940, the entire span was shaken apart by the large vibrations and collapsed. See Figure 5.31.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-243}
\end{center}

Figure 5.3I

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-244}
\end{center}

Figure 5.32\\
For fifty years, the popular and easily explained reason for the collapse was resonance. It was thought that, as the wind blew horizontally across the roadway, vortices (wind swirls) were shed from the downward side of the bridge alternately from above and below, thus setting up a periodic vertical force acting in the same direction as the vibration of the bridge. See Figure 5.32. It was further hypothesized that the frequency of this periodic force exactly matched the natural frequency of the bridge, thus setting up large amplitude vibrations (see equation (9)) and causing the bridge to fail. This explanation was (perhaps erroneously) attributed to the noted engineer von Karman. In his autobiography, he explained that the bridge collapse was indeed due to the von Karman vortices [4]. However, in a technical report to the Federal Works Agency, he and his coauthors concluded "it is very improbable that resonance with alternating vortices plays an important role in the oscillations of suspension bridges" [1]. Unfortunately, the resonance explanation has remained firmly entrenched in the popular and mathematical literature.

Resonance is a linear phenomenon (notice the linear differential equation (7) of Section 5.3). In addition, it is entirely dependent on an exact match between the natural frequency of the bridge (or portions thereof) and the frequency of any externally applied periodic forces. Furthermore, it requires that absolutely no damping be present in the system ( $\lambda=0$ in equation (3) of Section 5.3). It should not be surprising, therefore, that resonance was not the dominant factor in the collapse of the Tacoma Narrows Bridge.

If not resonance, then what? Recent research has provided an alternative explanation for the collapse of the bridge. Lazer and McKenna (see [3] for a good review article) contend that nonlinear effects, and not linear resonance, were the main factors leading to the large oscillations of the bridge [2]. There is no doubt that the wind blowing across the roadbed provided the external driving force that caused the motion. This force could even have been partly due to the shedding of vortices, as von Karman suggested. However, nonlinear interactions within the bridge and between the bridge and the external forces are a more probable culprit for the cause of the collapse.

In the linear theory, the supporting cables act as rigid elastic rods (springs). As such, the mathematical model gives rise to the linear differential equation (3), or equation (7) of Section 5.3, if no damping is present. This latter case leading to resonance is the only possible situation in the linear theory in which small external forces could lead to large amplitude vibrations. As has been mentioned, this scenario is highly unlikely.

On the other hand, nonlinear effects could yield large amplitude vibrations from small amplitude forces. They could also explain the transition from onedimensional axial (lengthwise) oscillations to transverse (across the roadway) oscillations, which were ultimately responsible for the collapse of the bridge.

The basic idea in the Lazer-McKenna model is the following. When the vertical supporting cables are under tension (the weight of the roadbed is pulling down on them), the cables act as rigid elastic linear rods, in which case the differential equation is linear. However, once oscillations are set up in the bridge system by external forces (wind and possibly earthquakes), the cables will not always be under tension, and there will be only gravity acting downward on the roadbed. In other words, the Hooke's law term, $(k / m) x$ in equation (2) of Section 5.3, will be missing. This transition from one type of linear differential equation to another is one source of the nonlinearity. Other sources of nonlin-\\
earity in suspension bridges might include the nonlinear and nonsymmetric design of the bridge or interactions of the supporting cables with the main cables or supporting towers. This nonlinearity is compounded by the fact that different cables in the bridge system may be under tension at different times. The net result of this nonlinearity, contend Lazer and McKenna, may be large amplitude oscillations under moderate external forces.

One other aspect of nonlinear equations is their unpredictability. This might explain, for example, why the bridge was observed to undergo large amplitude oscillations under light wind conditions yet seemed to be perfectly stable under higher wind conditions.

As Lazer and McKenna point out, the nonlinear theory of suspension bridges has not been thoroughly developed yet. However, numerical simulations of their suspension bridge model agree with actual observations. It seems likely that this approach will yield a more accurate explanation of the failure of the Tacoma Narrows Suspension Bridge.

\section*{REFERENCES}
\begin{enumerate}
  \item Amann, O. H., T. von Karman, and G. B. Woodruff. The Failure of the Tacoma Narrows Bridge. Federal Works Agency, 1941.

  \item Lazer, A. C., and P. J. McKenna. "Large-Amplitude Periodic Oscillations in Suspension Bridges: Some New Connections with Nonlinear Analysis." SIAM Review 32 (Dec. 1990): 537-578.

  \item Peterson, I. "Rock and Roll Bridge." Science News 137 (1991): 344-346.

  \item von Karman, T. The Wind and Beyond, Theodore von Karman, Pioneer in Aviation and Pathfinder in Space. Boston: Little, Brown, 1967.

\end{enumerate}

\section*{DIFFERENTIAL EQUATIONS WITH VARIABLE COEFFICIENTS}
\subsection*{6.1 Cauchy-Euler Equation}
6.2 Review of Power Series; Power Series Solutions

6.3 Solutions About Ordinary Points

6.4 Solutions About Singular Points

6.5 Two Special Equations

Chapter 6 Review

Chapter 6 Review Exercises

Up to now we have solved linear differential equations of order two or higher only in the case when the equation has constant coefficients. In applications, higher-order linear equations with nonconstant coefficients are just as important as, if not more so than, equations with constant coefficients. For example, if we wish to find the temperature or potential $u$ in the region bounded between two concentric spheres as shown in the accompanying figure, then under some circumstances we have to solve the differential equation

$$
r \frac{d^{2} u}{d r^{2}}+2 \frac{d u}{d r}=0
$$

where the variable $r>0$ represents the radial distance measured outward from the center of the spheres. Differential equations with variable coefficients such as

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-246}\\
and

$$
\begin{gathered}
x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-v^{2}\right) y=0 \\
\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+n(n+1) y=0 \\
y^{\prime \prime}-2 x y^{\prime}+2 n y=0
\end{gathered}
$$

occur in applications ranging from potential problems, temperature distributions, and vibrational phenomena to quantum mechanics.

The same ease with which we solved constant-coefficient differential equations does not carry over to equations with variable coefficients. In fact we cannot expect to be able to express the solution of even a simple linear equation such as $y^{\prime \prime}-2 x y=0$ in terms of the familiar elementary functions constructed from powers of $x$, sines, cosines, logarithms, and exponentials. The best we can do for the equation $y^{\prime \prime}-2 x y=0$ is to find a solution in the form of an infinite series. However, there is one type of variable-coefficient differential equation, called the Cauchy-Euler equation, whose general solution can always be written in terms of elementary functions. We begin the chapter with this equation.

\subsection*{6.1 CAUCHY-EULER EQUATION \\
 - Cauchy-Euler equation \\
 - Auxiliary equation \\
 - Reduction to constant coefficients}
Any linear differential equation of the form

$$
a_{n} x^{n} \frac{d^{n} y}{d x^{n}}+a_{n} \cdot x^{n} \cdot \frac{d^{n-1} y}{d x^{n-1}}+\cdots+a_{1} \cdot \frac{d}{d x} \div a_{0} y-s(x)
$$

where $a_{n}, a_{n-1}, \ldots, a_{0}$ are constants, is said to be a Cauchy-Euler equation,* or equidimensional equation. The distinguishing characteristic of this type of differential equation is that the degree of each monomial coefficient matches the order of differentiation:

$$
a_{n} x^{n} \frac{d^{\prime n} y}{d x^{n}}+a_{n-1} x^{\prime \prime} \quad \frac{d^{n-1} y}{d x^{n-1}}+\cdots
$$
\footnotetext{\begin{itemize}
  \item AUGUSTIN-LOUIS CAUCHY (1789-1857) Born during a period of upheaval in French history, Augustin-Louis Cauchy was destined to initiate a revolution of his own-in mathematics. For many original contributions, but especially for his efforts in clarifying mathematical obscurities and his incessant demand for satisfactory definitions and rigorous proofs of theorems, Cauchy is often called "the father of modern analysis." A prolific writer whose output was surpassed by only a few, Cauchy produced nearly 800 papers in astronomy, physics, and mathematics. It was he who developed the concept of convergence of an infinite series and the theory of functions of a complex variable. The same mind that was always open and inquiring in science and mathematics was narrow and unquestioning in many other areas. Outspoken and arrogant, Cauchy was passionate on political and religious issues. His stands on these issues often alienated him from his colleagues.
\end{itemize}
}

For the sake of discussion, we confine our attention to solving the homogeneous second-order equation

$$
a x^{2} \frac{d^{2} y}{d x^{2}}+b x \frac{d y}{d x}+c y=0
$$

The solution of higher-order equations follows analogously. Also, we can solve the nonhomogeneous equation

$$
a x^{2} \frac{d^{2} y}{d x^{2}}+b x \frac{d y}{d x}+c y=g(x)
$$

by variation of parameters once we have determined the complementary function $y_{c}(x)$.

Note The coefficient of $d^{2} y / d x^{2}$ is zero at $x=0$. Hence in order to guarantee that the fundamental results of Theorem 4.1 are applicable to the Cauchy-Euler equation, we shall confine our attention to finding the general solution on the interval $(0, \infty)$. Solutions on the interval $(-\infty, 0)$ can be obtained by substituting $t=-x$ in the differential equation.

Method of Solution We try a solution of the form $y=x^{m}$, where $m$ is to be determined. The first and second derivatives are, respectively,

$$
\frac{d y}{d x}=m x^{m-1} \quad \text { and } \quad \frac{d^{2} y}{d x^{2}}=m(m-1) x^{m-2}
$$

Consequently the differential equation becomes

$$
\begin{aligned}
a x^{2} \frac{d^{2} y}{d x^{2}}+b x \frac{d y}{d x}+c y & =a x^{2} \cdot m(m-1) x^{m-2}+b x \cdot m x^{m-1}+c x^{m} \\
& =a m(m-1) x^{m}+b m x^{m}+c x^{m} \\
& =x^{m}(a m(m-1)+b m+c)
\end{aligned}
$$

Thus $y=x^{m}$ is a solution of the differential equation whenever $m$ is a solution of the auxiliary equation


\begin{equation*}
a m(m-1)+b m+c=0 \quad \text { or } \quad a m^{2}+(b-a) m+c=0 \tag{1}
\end{equation*}


There are three different cases to be considered, depending on whether the roots of this quadratic equation are real and distinct, real and equal, or complex. In the last case, the roots appear as a conjugate pair.

Case I: Distinct Real Roots Let $m_{1}$ and $m_{2}$ denote the real roots of (1) such that $m_{1} \neq m_{2}$. Then $y_{1}=x^{m_{1}}$ and $y_{2}=x^{m_{2}}$ form a fundamental set of solutions. Hence the general solution is


\begin{equation*}
y=c_{1} x^{m_{1}}+c_{2} x^{m_{1}} . \tag{2}
\end{equation*}


\section*{EXAMPLE 1 Distinct Roots}
Solve $x^{2} \frac{d^{2} y}{d x^{2}}-2 x \frac{d y}{d x}-4 y=0$.

Solution Rather than just memorizing equation (1), it is preferable to assume $y=x^{m}$ as the solution a few times in order to understand the origin and the difference between this new form of the auxiliary equation and that obtained in Chapter 4. Differentiate twice,

$$
\frac{d y}{d x}=m x^{m-1}, \quad \frac{d^{2} y}{d x^{2}}=m(m-1) x^{m-2}
$$

and substitute back into the differential equation,

$$
\begin{aligned}
x^{2} \frac{d^{2} y}{d x^{2}}-2 x \frac{d y}{d x}-4 y & =x^{2} \cdot m(m-1) x^{m-2}-2 x \cdot m x^{m-1}-4 x^{m} \\
& =x^{m}(m(m-1)-2 m-4) \\
& =x^{m}\left(m^{2}-3 m-4\right)=0
\end{aligned}
$$

if $m^{2}-3 m-4=0$. Now $(m+1)(m-4)=0$ implies $m_{1}=-1, m_{2}=4$,

so

$$
y=c_{1} x^{-1}+c_{2} x^{4}
$$

Case II: Repeated Real Roots If the roots of (1) are repeated (that is, $m_{1}=m_{2}$ ), then we obtain only one solution-namely, $y=x^{m_{1}}$. When the roots of the quadratic equation $a m^{2}+(b-a) m+c=0$ are equal, the discriminant of the coefficients is necessarily zero. It follows from the quadratic formula that the root must be $m_{1}=-(b-a) / 2 a$.

Now we can construct a second solution $y_{2}$, using (4) of Section 4.2. We first write the Cauchy-Euler equation in the form

$$
\frac{d^{2} y}{d x^{2}}+\frac{b}{a x} \frac{d y}{d x}+\frac{c}{a x^{2}} y=0
$$

and make the identification $P(x)=b / a x$. Thus

$$
\begin{aligned}
y_{2} & =x^{m_{1}} \int \frac{e^{-\int(b / a x) d x}}{\left(x^{m_{1}}\right)^{2}} d x \\
& =x^{m_{1}} \int \frac{e^{-(b / a) \ln x}}{x^{2 m_{1}}} d x \\
& =x^{m_{1}} \int x^{-b / a} \cdot x^{-2 m_{1}} d x \quad \leftarrow e^{-(b) a) \ln x}=e^{\ln x x^{-b}}=x^{-b / a} \\
& =x^{m_{1}} \int x^{-b / a} \cdot x^{(b-a) / a} d x \leftarrow-2 m_{1}=(b-a) / a \\
& =x^{m_{1}} \int \frac{d x}{x}=x^{m_{1}} \ln x
\end{aligned}
$$

The general solution is then


\begin{equation*}
y=c_{1} x^{m_{1}}+c_{2} x^{m_{1}} \ln x \tag{3}
\end{equation*}


\section*{EXAMPLE 2 Repeated Roots}
Solve $4 x^{2} \frac{d^{2} y}{d x^{2}}+8 x \frac{d y}{d x}+y=0$.

Solution The substitution $y=x^{m}$ yields

$4 x^{2} \frac{d^{2} y}{d x^{2}}+8 x \frac{d y}{d x}+y=x^{m}(4 m(m-1) 8 m+1)=x^{m}\left(4 m^{2}+4 m+1\right)=0$

when $4 m^{2}+4 m+1=0$ or $(2 m+1)^{2}=0$. Since $m_{1}=-\frac{1}{2}$, the general solution is

$$
y=c_{1} x^{-1 / 2}+c_{2} x^{-1 / 2} \ln x \text {. }
$$

For higher-order equations, if $m_{1}$ is a root of multiplicity $k$, then it can be shown that

$$
x^{m_{1}}, \quad x^{m_{1}} \ln x, \quad x^{m_{1}}(\ln x)^{2}, \quad \ldots, \quad x^{m_{1}}(\ln x)^{k-1}
$$

are $k$ linearly independent solutions. Correspondingly, the general solution of the differential equation must then contain a linear combination of these $k$ solutions.

Case III: Conjugate Complex Roots If the roots of (1) are the conjugate pair $m_{1}=\alpha+i \beta, m_{2}=\alpha-i \beta$, where $\alpha$ and $\beta>0$ are real, then a solution is

$$
y=C_{1} x^{\alpha+i \beta}+C_{2} x^{\alpha-i \beta}
$$

But, as in the case of equations with constant coefficients, when the roots of the auxiliary equation are complex, we wish to write the solution in terms of real functions only. We note the identity

$$
x^{i \beta}=\left(e^{\ln x}\right)^{i \beta}=e^{i \beta \ln x},
$$

which, by Euler's formula, is the same as

$$
x^{i \beta}=\cos (\beta \ln x)+i \sin (\beta \ln x)
$$

Similarly we have

$$
x^{-i \beta}=\cos (\beta \ln x)-i \sin (\beta \ln x)
$$

Adding and subtracting the last two results yields, respectively,

$$
x^{i \beta}+x^{-i \beta}=2 \cos (\beta \ln x) \text { and } x^{i \beta}-x^{-i \beta}=2 i \sin (\beta \ln x) \text {. }
$$

From the fact that $y=C_{1} x^{\alpha+i \beta}+C_{2} x^{\alpha-i \beta}$ is a solution of $a x^{2} y^{\prime \prime}+b x y^{\prime}+$ $c y=0$ for any values of the constants $C_{1}$ and $C_{2}$ we see that

$$
\begin{array}{ll}
y_{1}=x^{\alpha}\left(x^{i \beta}+x^{-i \beta}\right) & \left(C_{1}=C_{2}=1\right) \\
y_{2}=x^{\alpha}\left(x^{i \beta}-x^{-i \beta}\right) & \left(C_{1}=1, C_{2}=-1\right)
\end{array}
$$

and

$$
y_{1}=2 x^{\alpha}(\cos (\beta \ln x)), \quad y_{2}=2 i x^{\alpha}(\sin (\beta \ln x))
$$

are also solutions. Since $W\left(x^{\alpha} \cos (\beta \ln x), x^{\alpha} \sin (\beta \ln x)\right)=\beta x^{2 \alpha-1} \neq 0, \beta>0$ on the interval $(0, \infty)$, we conclude that

$$
y_{1}=x^{\alpha} \cos (\beta \ln x) \quad \text { and } \quad y_{2}=x^{\alpha} \sin (\beta \ln x)
$$

constitute a fundamental set of real solutions of the differential equation. Hence, the general solution is


\begin{equation*}
y=x^{\alpha}\left[c_{1} \cos (\beta \ln x)+c_{2} \sin (\beta \ln x)\right] \tag{4}
\end{equation*}


\section*{EXAMPLE 3 An Initial-Value Problem}
Solve the initial-value problem

$$
x^{2} \frac{d^{2} y}{d x^{2}}+3 x \frac{d y}{d x}+3 y=0, \quad y(1)=1, \quad y^{\prime}(1)=-5
$$

Solution We have

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-251}
\end{center}

Figure 6.1

$x^{2} \frac{d^{2} y}{d x^{2}}+3 x \frac{d y}{d x}+3 y=x^{m}(m(m-1)+3 m+3)=x^{m}\left(m^{2}+2 m+3\right)=0$

when $m^{2}+2 m+3=0$. From the quadratic formula we find $m_{1}=-1+\sqrt{2} i$ and $m_{2}=-1-\sqrt{2} i$. If we make the identifications $\alpha=-1$ and $\beta=\sqrt{2}$, we see from (4) that the general solution of the differential equation is

$$
y=x^{-1}\left[c_{1} \cos (\sqrt{2} \ln x)+c_{2} \sin (\sqrt{2} \ln x)\right]
$$

By applying the conditions $y(1)=1, y^{\prime}(1)=-5$ to the foregoing solution, we find, in turn, $c_{1}=1$ and $c_{2}=-2 \sqrt{2}$. Thus the solution to the initial-value problem is

$$
y=x^{-1}[\cos (\sqrt{2} \ln x)-2 \sqrt{2} \sin (\sqrt{2} \ln x)]
$$

The graph of this solution, obtained with the aid of computer software, is given in Figure 6.1.

\section*{EXAMPLE 4 Third-Order Equation}
Solve the third-order Cauchy-Euler equation

$$
x^{3} \frac{d^{3} y}{d x^{3}}+5 x^{2} \frac{d^{2} y}{d x^{2}}+7 x \frac{d y}{d x}+8 y=0
$$

Solution The first three derivatives of $y=x^{m}$ are

$$
\frac{d y}{d x}=m x^{m-1}, \quad \frac{d^{2} y}{d x^{2}}=m(m-1) x^{m-2}, \quad \frac{d^{3} y}{d x^{3}}=m(m-1)(m-2) x^{m-3}
$$

so the given differential equation becomes

$$
\begin{aligned}
x^{3} \frac{d^{3} y}{d x^{3}}+5 x^{2} \frac{d^{2} y}{d x^{2}}+7 x \frac{d y}{d x}+8 y & =x^{3} m(m-1)(m-2) x^{m-3}+5 x^{2} m(m-1) x^{m-2}+7 x m x^{m-1}+8 x^{m} \\
& =x^{m}(m(m-1)(m-2)+5 m(m-1)+7 m+8) \\
& =x^{m}\left(m^{3}+2 m^{2}+4 m+8\right)
\end{aligned}
$$

In this case we see that $y=x^{m}$ will be a solution of the differential equation, provided $m$ is a root of the cubic equation

$$
m^{3}+2 m^{2}+4 m+8=0 \quad \text { or } \quad(m+2)\left(m^{2}+4\right)=0
$$

The roots are $m_{1}=-2, m_{2}=2 i, m_{3}=-2 i$. Hence the general solution is

$$
y=c_{1} x^{-2}+c_{2} \cos (2 \ln x)+c_{3} \sin (2 \ln x)
$$

\section*{EXAMPLE 5 Using Variation of Parameters}
Solve the nonhomogeneous equation

$$
x^{2} y^{\prime \prime}-3 x y^{\prime}+3 y=2 x^{4} e^{x}
$$

Solution The substitution $y=x^{m}$ leads to the auxiliary equation

$$
m(m-1)-3 m+3=0 \quad \text { or } \quad(m-1)(m-3)=0
$$

Thus

$$
y_{c}=c_{1} x+c_{2} x^{3}
$$

Before using variation of parameters to find a particular solution $y_{p}=$ $u_{1} y_{1}+u_{2} y_{2}$, recall that the formulas $u_{1}^{\prime}=W_{1} / W$ and $u_{2}^{\prime}=W_{2} / W$, where $W_{1}=$ $\left|\begin{array}{cc}0 & y_{2} \\ f(x) & y_{2}^{\prime}\end{array}\right|, W_{2}=\left|\begin{array}{cc}y_{1} & 0 \\ y_{1}^{\prime} & f(x)\end{array}\right|$, and $W$ is the Wronskian of $y_{1}$ and $y_{2}$, were derived under the assumption that the differential equation has been put into the special form $y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=f(x)$. Therefore we divide the given equation by $x^{2}$, and from

$$
y^{\prime \prime}-\frac{3}{x} y^{\prime}+\frac{3}{x^{2}} y=2 x^{2} e^{x}
$$

we make the identification $f(x)=2 x^{2} e^{x}$. Now with $y_{1}=x, y_{2}=x^{3}$, and

$$
W=\left|\begin{array}{rr}
x & x^{3} \\
1 & 3 x^{2}
\end{array}\right|=2 x^{3}, \quad W=\left|\begin{array}{cc}
0 & x^{3} \\
2 x^{2} e^{x} & 3 x^{2}
\end{array}\right|=-2 x^{5} e^{x}, \quad W_{2}=\left|\begin{array}{cc}
x & 0 \\
1 & 2 x^{2} e^{x}
\end{array}\right|=2 x^{3} e^{x}
$$

we find

$$
u_{1}^{\prime}=-\frac{2 x^{5} e^{x}}{2 x^{3}}=-x^{2} e^{x} \quad \text { and } \quad u_{2}^{\prime}=\frac{2 x^{3} e^{x}}{2 x^{3}}=e^{x}
$$

The integral of the latter function is immediate, but in the case of $u_{1}^{\prime}$ we integrate by parts twice. The results are

$$
u_{1}=-x^{2} e^{x}+2 x e^{x}-2 e^{x} \text { and } \quad u_{2}=e^{x}
$$

Hence

$$
\begin{aligned}
y_{p} & =u_{1} y_{1}+u_{2} y_{2} \\
& =\left(-x^{2} e^{x}+2 x e^{x}-2 e^{x}\right) x+e^{x} x^{3}=2 x^{2} e^{x}-2 x e^{x}
\end{aligned}
$$

Finally we have $y=y_{c}+y_{p}=c_{1} x+c_{2} x^{3}+2 x^{2} e^{x}-2 x e^{x}$.

Alternative Method of Solution Any Cauchy-Euler differential equation can be reduced to an equation with constant coefficients by means of the substitution $x=e^{t}$. The next example illustrates this method.

\section*{EXAMPLE 6 Reduction to Constant Coefficients}
Solve $x^{2} \frac{d^{2} y}{d x^{2}}-x \frac{d y}{d x}+y=\ln x$.

Solution With the substitution $x=e^{t}$ or $t=\ln x$, it follows that

$$
\begin{array}{rlrl}
\frac{d y}{d x} & =\frac{d y}{d t} \frac{d t}{d x}=\frac{1}{x} \frac{d y}{d t} & \leftarrow \text { chain rule } \\
\frac{d^{2} y}{d x^{2}} & =\frac{1}{x} \frac{d}{d x}\left(\frac{d y}{d t}\right)+\frac{d y}{d t}\left(-\frac{1}{x^{2}}\right) & \leftarrow \text { product and chain rule } \\
& =\frac{1}{x}\left(\frac{d^{2} y}{d t^{2}} \frac{1}{x}\right)+\frac{d y}{d t}\left(-\frac{1}{x^{2}}\right)=\frac{1}{x^{2}}\left(\frac{d^{2} y}{d t^{2}}-\frac{d y}{d t}\right)
\end{array}
$$

Substituting in the given differential equation and simplifying yields

$$
\frac{d^{2} y}{d t^{2}}-2 \frac{d y}{d t}+y=t
$$

Since this last equation has constant coefficients, its auxiliary equation is $m^{2}-2 m+1=0$, or $(m-1)^{2}=0$. Thus we obtain $y_{c}=c_{1} e^{t}+c_{2} t e^{t}$.

By undetermined coefficients we try a particular solution of the form $y_{p}=A+B t$. This assumption leads to $-2 B+A+B t=t$ so $A=2$ and $B=1$. Using $y=y_{c}+y_{p}$, we get

$$
y=c_{1} e^{t}+c_{2} t e^{t}+2+t,
$$

and so the general solution of the original differential equation on the interval $(0, \infty)$ is

$$
y=c_{1} x+c_{2} x \ln x+2+\ln x
$$

\section*{EXERCISES 6.1}
Answers to odd-numbered problems begin on page A-11.

In Problems 1-22 solve the given differential equation.

\begin{enumerate}
  \item $x^{2} y^{\prime \prime}-2 y=0$
  \item $4 x^{2} y^{\prime \prime}+y=0$
  \item $x y^{\prime \prime}+y^{\prime}=0$
  \item $x y^{\prime \prime}-y^{\prime}=0$
  \item $x^{2} y^{\prime \prime}+x y^{\prime}+4 y=0$
  \item $x^{2} y^{\prime \prime}+5 x y^{\prime}+3 y=0$
  \item $x^{2} y^{\prime \prime}-3 x y^{\prime}-2 y=0$
  \item $x^{2} y^{\prime \prime}+3 x y^{\prime}-4 y=0$
  \item $25 x^{2} y^{\prime \prime}+25 x y^{\prime}+y=0$
  \item $4 x^{2} y^{\prime \prime}+4 x y^{\prime}-y=0$
  \item $x^{2} y^{\prime \prime}+5 x y^{\prime}+4 y=0$
  \item $x^{2} y^{\prime \prime}+8 x y^{\prime}+6 y=0$
  \item $x^{2} y^{\prime \prime}-x y^{\prime}+2 y=0$
  \item $x^{2} y^{\prime \prime}-7 x y^{\prime}+41 y=0$
  \item $3 x^{2} y^{\prime \prime}+6 x y^{\prime}+y=0$
  \item $2 x^{2} y^{\prime \prime}+x y^{\prime}+y=0$
  \item $x^{3} y^{\prime \prime \prime}-6 y=0$
  \item $x^{3} y^{\prime \prime \prime}+x y^{\prime}-y=0$
  \item $x^{3} \frac{d^{3} y}{d x^{3}}-2 x^{2} \frac{d^{2} y}{d x^{2}}-2 x \frac{d y}{d x}+8 y=0$
  \item $x^{3} \frac{d^{3} y}{d x^{3}}-2 x^{2} \frac{d^{2} y}{d x^{2}}+4 x \frac{d y}{d x}-4 y=0$
  \item $x \frac{d^{4} y}{d x^{4}}+6 \frac{d^{3} y}{d x^{3}}=0$
  \item $x^{4} \frac{d^{4} y}{d x^{4}}+6 x^{3} \frac{d^{3} y}{d x^{3}}+9 x^{2} \frac{d^{2} y}{d x^{2}}+3 x \frac{d y}{d x}+y=0$
\end{enumerate}

In Problems 23-26 solve the given differential equation subject to the indicated initial conditions.\\
23. $x^{2} y^{\prime \prime}+3 x y^{\prime}=0, y(1)=0, y^{\prime}(1)=4$\\
24. $x^{2} y^{\prime \prime}-5 x y^{\prime}+8 y=0, y(2)=32, y^{\prime}(2)=0$\\
25. $x^{2} y^{\prime \prime}+x y^{\prime}+y=0, y(1)=1, y^{\prime}(1)=2$\\
26. $x^{2} y^{\prime \prime}-3 x y^{\prime}+4 y=0, y(1)=5, y^{\prime}(1)=3$

In Problems 27 and 28 solve the given differential equation subject to the indicated initial conditions. [Hint: Let $t=-x$.]\\
27. $4 x^{2} y^{\prime \prime}+y=0, y(-1)=2, y^{\prime}(-1)=4$\\
28. $x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=0, y(-2)=8, y^{\prime}(-2)=0$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-255}
\end{center}

Figure 6.2

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-255(1)}
\end{center}

Figure 6.3\\
Solve Problems $29-34$ by variation of parameters.\\
29. $x y^{\prime \prime}+y^{\prime}=x$\\
30. $x y^{\prime \prime}-4 y^{\prime}=x^{4}$\\
31. $2 x^{2} y^{\prime \prime}+5 x y^{\prime}+y=x^{2}-x$\\
32. $x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y=x^{4} e^{x}$\\
33. $x^{2} y^{\prime \prime}-x y^{\prime}+y=2 x$\\
34. $x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y=x^{3} \ln x$

In Problems 35-40 solve the given differential equation by means of the substitution $x=e^{t}$.

\begin{enumerate}
  \setcounter{enumi}{34}
  \item $x^{2} \frac{d^{2} y}{d x^{2}}+10 x \frac{d y}{d x}+8 y=x^{2}$

  \item $x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=\ln x^{2}$

  \item $x^{2} y^{\prime \prime}-3 x y^{\prime}+13 y=4+3 x$

  \item $2 x^{2} y^{\prime \prime}-3 x y^{\prime}-3 y=1+2 x+x^{2}$

  \item $x^{2} y^{\prime \prime}+9 x y^{\prime}-20 y=5 / x^{3}$

  \item $x^{3} \frac{d^{3} y}{d x^{3}}-3 x^{2} \frac{d^{2} y}{d x^{2}}+6 x \frac{d y}{d x}-6 y=3+\ln x^{3}$

  \item Consider two concentric spheres of radius $r=a$ and $r=b, a<b$, as shown in Figure 6.2. The temperature $u(r)$ in the region between the spheres is determined from the boundary-value problem

\end{enumerate}

$$
r \frac{d^{2} u}{d r^{2}}+2 \frac{d u}{d r}=0, \quad u(a)=u_{0}, \quad u(b)=u_{1}
$$

where $u_{0}$ and $u_{1}$ are constant. Solve for $u(r)$.

\begin{enumerate}
  \setcounter{enumi}{41}
  \item The temperature $u(r)$ in the circular ring shown in Figure 6.3 is determined from the boundary-value problem
\end{enumerate}

$$
r \frac{d^{2} u}{d r^{2}}+\frac{d u}{d r}=0, \quad u(a)=u_{0}, \quad u(b)=u_{1}
$$

where $u_{0}$ and $u_{1}$ are constant. Show that

$$
u(r)=\frac{u_{0} \ln (r / b)-u_{1} \ln (r / a)}{\ln (a / b)}
$$

In Problems 43-45 solve the given differential equation.

\begin{enumerate}
  \setcounter{enumi}{42}
  \item $(x-1)^{2} \frac{d^{2} y}{d x^{2}}-2(x-1) \frac{d y}{d x}-4 y=0$ [Hint: Let $t=x-1$.]

  \item $(3 x+4)^{2} y^{\prime \prime}+10(3 x+4) y^{\prime}+9 y=0$

  \item $(x+2)^{2} y^{\prime \prime}+(x+2) y^{\prime}+y=0$

\end{enumerate}

\subsection*{6.2 REVIEW OF POWER SERIES; POWER SERIES SOLUTIONS \\
 - Power series}
Review of Power Series The preceding section notwithstanding, most linear differential equations with variable coefficients cannot be solved in terms of elementary functions. A standard technique for solving higher-order linear dif-\\
ferential equations with variable coefficients is to try to find a solution in the form of an infinite series. Often the solution can be found in the form of a power series. Because of this, it is appropriate to list some of the more important facts about power series. However, for an in-depth review of the infinite series concept you should consult a calculus text.

\begin{itemize}
  \item Definition of a Power Series. A power series in $x-a$ is an infinite series of the form
\end{itemize}

$$
\sum_{n=0}^{\infty} c_{n}(x-a)^{n}
$$

A series such as this is also said to be a power series centered at $a$. For example, $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{2}} x^{n}$ is a power series in $x$; the series is centered at zero.

\begin{itemize}
  \item Convergence. For a specified value of $x$ a power series is a series of constants. If the series equals a finite real constant for the given $x$, then the series is said to converge at $x$. If the series does not converge at $x$, it is said to diverge at $x$.
  \item Interval of Convergence. Every power series has an interval of convergence. The interval of convergence is the set of all numbers for which the series converges.
  \item Radius of Convergence. Every interval of convergence has a radius of convergence $R$. For a power series $\sum_{n=0}^{\infty} c_{n}(x-a)^{n}$ we have just three possibilities:
\end{itemize}

(i) The series converges only at its center $a$. In this case $R=0$.

(ii) The series converges for all $x$ satisfying $|x-a|<R$, where $R>0$. The series diverges for $|x-a|>R$.

(iii) The series converges for all $x$. In this case we write $R=\infty$.

\begin{itemize}
  \item Convergence at an Endpoint. Recall that the absolute-value inequality $|x-a|<R$ is equivalent to $-R<x-a<R$, or $a-R<x<a+R$. If a power series converges for $|x-a|<R$, where $R>0$, it may or may not converge at the endpoints of the interval $a-R<x<a+R$. Figure 6.4 shows four possible intervals of convergence.
\end{itemize}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-256(3)}
\end{center}

(a) $[a-R, a+R]$

Series converges at both endpoints.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-256}
\end{center}

(b) $(a-R, a+R)$

Series diverges at both endpoints.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-256(2)}
\end{center}

(c) $[a-R, a+R)$\\
Series converges at $a-R$,\\
diverges at $a+R$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-256(1)}
\end{center}

(d) $(a-R, a+R]$

Series diverges at $a-R$, converges at $a+R$.

\begin{itemize}
  \item Absolute Convergence. Within its interval of convergence a power series converges absolutely. In other words, for $a-R<x<a+R$ the series of absolute values $\sum_{n=0}^{\infty}\left|c_{n}\right|\left|(x-a)^{n}\right|$ converges.
  \item Finding the Interval of Convergence. Convergence of a power series can often be determined by the ratio test:
\end{itemize}

$$
\lim _{n \rightarrow \infty}\left|\frac{c_{n+1}}{c_{n}}\right||x-a|=L
$$

The series will converge absolutely for those values of $x$ for which $L<1$. From this test we see that the radius of convergence is given by


\begin{equation*}
R=\lim _{n \rightarrow \infty}\left|\frac{c_{n}}{c_{n+1}}\right| \tag{1}
\end{equation*}


provided the limit exists.

\begin{itemize}
  \item A Power Series Represents a Function. A power series represents a function
\end{itemize}

$$
f(x)=\sum_{n=0}^{\infty} c_{n}(x-a)^{n}=c_{0}+c_{1}(x-a)+c_{2}(x-a)^{2}+c_{3}(x-a)^{3}+\cdots
$$

whose domain is the interval of convergence of the series. If the series has a radius of convergence $R>0$, then $f$ is continuous, differentiable, and integrable on the interval $\left(a-R, a+R\right.$ ). Moreover, $f^{\prime}(x)$ and $\int f(x) d x$ can be found from term-by-term differentiation and integration:

$$
\begin{aligned}
f^{\prime}(x)=c_{1}+2 c_{2}(x-a)+3 c_{3}(x-a)^{2}+\cdots=\sum_{n=1}^{\infty} n c_{n}(x-a)^{n-1} \\
\int f(x) d x=C+c_{0}(x-a)+c_{1} \frac{(x-a)^{2}}{2}+c_{2} \frac{(x-a)^{3}}{3}+\cdots=C+\sum_{n=0}^{\infty} c_{n} \frac{(x-a)^{n+1}}{n+1}
\end{aligned}
$$

Although the radius of convergence for both these series is $R$, the interval of convergence may differ from the original series in that convergence at an endpoint may be either lost by differentiation or gained through integration.

\begin{itemize}
  \item Series That Are Identically Zero. If $\sum_{n=0}^{\infty} c_{n}(x-a)^{n}=0, R>0$ for all real numbers $x$ in the interval of convergence, then $c_{n}=0$ for all $n$.
  \item Analytic at a Point. In calculus it is seen that functions such as $e^{x}, \cos x$, and $\ln (x-1)$ can be represented by power series by expansions in either Maclaurin or Taylor series. We say that a function $f$ is analytic at point $a$ if it can be represented by a power series in $x-a$ with a positive radius of convergence. The notion of analyticity at a point will be important in Sections 6.3 and 6.4.
  \item Arithmetic of Power Series. Power series can be combined through the operations of addition, multiplication, and division. The procedures for power series are similar to the way in which two polynomials are added, multiplied, and divided; that is, we add coefficients of like powers of $x$, use the distributive law and collect like terms, and perform\\
long division. For example, if the power series $f(x)=\sum_{n=0}^{\infty} c_{n} x^{n}$ and $g(x)=\sum_{n=0}^{\infty} b_{n} x^{n}$ both converge for $|x|<R$, then
\end{itemize}

$$
f(x)+g(x)=\sum_{n=0}^{\infty}\left(c_{n}+b_{n}\right) x^{n}
$$

and

$$
f(x) g(x)=c_{0} b_{0}+\left(c_{0} b_{1}+c_{1} b_{0}\right) x+\left(c_{0} b_{2}+c_{1} b_{1}+c_{2} b_{0}\right) x^{2}+\cdots
$$

\section*{EXAMPLE 1 Interval of Convergence}
Find the interval of convergence of the power series $\sum_{n=1}^{\infty} \frac{(x-3)^{n}}{2^{n} n}$.

Solution The power series is centered at 3. From (1), the radius of convergence is

$$
R=\lim _{n \rightarrow \infty} \frac{2^{n+1}(n+1)}{2^{n} n}=2
$$

The series converges absolutely for $|x-3|<2$, or $1<x<5$. At the left endpoint $x=1$ we find that the series of constants $\sum_{n=1}^{\infty}\left((-1)^{n} / n\right)$ is convergent by the alternating series test. At the right endpoint $x=5$ we find that the series is the divergent harmonic series $\sum_{n=1}^{\infty}(1 / n)$. Thus the interval of convergence is $[1,5)$.

\section*{EXAMPLE 2 Multiplying Series}
Find the first four terms of a power series in $x$ for $e^{x} \cos x$.

Solution From calculus the Maclaurin series for $e^{x}$ and $\cos x$ are, respectively,

$$
e^{x}=1+x+\frac{x^{2}}{2}+\frac{x^{3}}{6}+\frac{x^{4}}{24}+\cdots \quad \text { and } \quad \cos x=1-\frac{x^{2}}{2}+\frac{x^{4}}{24}+\cdots
$$

Multiplying out and collecting like terms yields

$$
\begin{aligned}
e^{x} \cos x & =\left(1+x+\frac{x^{2}}{2}+\frac{x^{3}}{6}+\frac{x^{4}}{24}+\cdots\right)\left(1-\frac{x^{2}}{2}+\frac{x^{4}}{24}-\cdots\right) \\
& =1+(1) x+\left(-\frac{1}{2}+\frac{1}{2}\right) x^{2}+\left(-\frac{1}{2}+\frac{1}{6}\right) x^{3}+\left(\frac{1}{24}-\frac{1}{4}+\frac{1}{24}\right) x^{4}+\cdots \\
& =1+x-\frac{x^{3}}{3}-\frac{x^{4}}{6}+\cdots
\end{aligned}
$$

In Example 2 the interval of convergence for the Maclaurin series for both $e^{x}$ and $\cos x$ is $(-\infty, \infty)$. Consequently the interval of convergence for the power series for $e^{x} \cos x$ is also $(-\infty, \infty)$.

\section*{EXAMPLE 3 Dividing Series}
Find the first four terms of a power series in $x$ for $\sec x$.

Solution We will use the Maclaurin series for $\cos x$ given in Example 2 and then use long division. Since $\sec x=1 / \cos x$, we have

$$
\begin{aligned}
& 1+\frac{x^{2}}{2}+\frac{5 x^{4}}{24}+\frac{61 x^{6}}{720}+\cdots \\
& \left.\cos x=1-\frac{x^{2}}{2}+\frac{x^{4}}{24}-\frac{x^{6}}{720}+\cdots\right) \\
& \frac{1-\frac{x^{2}}{2}+\frac{x^{4}}{24}-\frac{x^{6}}{720}+\cdots}{\frac{x^{2}}{2}-\frac{x^{4}}{24}+\frac{x^{6}}{720}+\cdots} \\
& \frac{x^{2}}{2}-\frac{x^{4}}{24}+\frac{x^{6}}{48} \quad-\cdots \\
& \frac{5 x^{4}}{24}-\frac{7 x^{6}}{360}+\cdots \\
& \frac{5 x^{4}}{24}-\frac{5 x^{6}}{48}+\cdots \\
& \frac{61 x^{6}}{720}-\cdots
\end{aligned}
$$

Thus


\begin{equation*}
\sec x=1+\frac{x^{2}}{2}+\frac{5 x^{4}}{24}+\frac{61 x^{6}}{720}+\cdots \tag{2}
\end{equation*}


The interval of convergence of this series is $(-\pi / 2, \pi / 2)$. (Why?)

The procedures shown in Examples 2 and 3 are obviously tedious to do by hand. Problems of this sort can be done using a computer algebra system (CAS) such as Mathematica. When you type the command Series $[\operatorname{Sec}[x],\{x, 0,8\}]$ and enter, Mathematica immediately gives the result obtained in (2).

For the remainder of this section, as well as this chapter, it is important that you become adept at simplifying the sum of two or more power series, each series expressed in summation (sigma) notation, to an expression with a single $\sum$. This often requires a shift of the summation indices.

\section*{EXAMPLE 4 Adding Two Series}
Write $\sum_{n=1}^{\infty} 2 n c_{n} x^{n-1}+\sum_{n=0}^{\infty} 6 c_{n} x^{n+1}$ as one series.

Solution In order to add the series, we require that both summation indices start with the same number and that the powers of $x$ in each series be "in phase"; that is, if one series starts with a multiple of, say, $x$ to the first power, then we want the other series to start with the same power. By writing

$$
\sum_{n=1}^{\infty} 2 n c_{n} x^{n-1}+\sum_{n=0}^{\infty} 6 c_{n} x^{n+1}=2 \cdot 1 \cdot c_{1} x^{0}+\sum_{n=2}^{\infty} 2 n c_{n} x^{n-1}+\sum_{n=0}^{\infty} 6 c_{n} x^{n+1}, \quad \text { (3) }
$$

we have both series on the right side start with $x^{1}$. To get the same summation index we are inspired by the exponents of $x$; we let $k=n-1$ in the first series and at the same time let $k=n+1$ in the second series. Thus the right side of (3) becomes


\begin{equation*}
2 c_{1}+\sum_{k=1}^{\infty} 2(k+1) c_{k+1} x^{k}+\sum_{k=1}^{\infty} 6 c_{k-1} x^{k} \tag{4}
\end{equation*}


Recall that the summation index is a "dummy" variable. The fact that $k=n-1$ in one case and $k=n+1$ in the other should cause no confusion if you keep in mind that it is the value of the summation index that is important. In both cases $k$ takes on the same successive values $1,2,3, \ldots$ for $n=2,3,4, \ldots$ (for $k=n-1$ ) and $n=0,1,2, \ldots$ (for $k=n+1$ ).

We are now in a position to add the series in (4) term by term:


\begin{equation*}
\sum_{n=1}^{\infty} 2 n c_{n} x^{n-1}+\sum_{n=0}^{\infty} 6 c_{n} x^{n+1}=2 c_{1}+\sum_{k=1}^{\infty}\left[2(k+1) c_{k+1}+6 c_{k-1}\right] x^{k} \tag{5}
\end{equation*}


If you are not convinced, then write out a few terms on both sides of (5).

Power Series Solution of a Differential Equation We saw in Section 1.1 that the function $y=e^{x^{2}}$ is an explicit solution of the linear first-order differential equation


\begin{equation*}
\frac{d y}{d x}-2 x y=0 \tag{6}
\end{equation*}


By replacing $x$ by $x^{2}$ in the Maclaurin series for $e^{x}$, we can write the solution of (6) as

$$
y=\sum_{n=0}^{\infty} \frac{x^{2 n}}{n!}
$$

This last series converges for all real values of $x$. In other words, knowing the solution in advance, we were able to find an infinite series solution of the differential equation.

We now propose to obtain a power series solution of equation (6) directly; the method of attack is similar to the technique of undetermined coefficients.

\section*{EXAMPLE 5 A Power Series Solution}
Find a solution of $d y / d x-2 x y=0$ in the form of a power series in $x$.

Solution If we assume that a solution of the given equation exists in the form


\begin{equation*}
y=\sum_{n=0}^{\infty} c_{n} x^{n} \tag{7}
\end{equation*}


we pose the question: Can we determine coefficients $c_{n}$ for which the power series converges to a function satisfying (6)? Formal* term-by-term differentiation of (7) gives

$$
\frac{d y}{d x}=\sum_{n=0}^{\infty} n c_{n} x^{n-1}=\sum_{n=1}^{\infty} n c_{n} x^{n-1}
$$

Note that since the first term in the first series (corresponding to $n=0$ ) is zero, we begin the summation with $n=1$. Using the last result and assumption (7), we find


\begin{equation*}
\frac{d y}{d x}-2 x y=\sum_{n=1}^{\infty} n c_{n} x^{n-1}-\sum_{n=0}^{\infty} 2 c_{n} x^{n+1} \tag{8}
\end{equation*}


We would like to add the two series in (8). To this end we write


\begin{equation*}
\frac{d y}{d x}-2 x y=1 \cdot c_{1} x^{0}+\sum_{n=2}^{\infty} n c_{n} x^{n-1}-\sum_{n=0}^{\infty} 2 c_{n} x^{n+1} \tag{9}
\end{equation*}


and then proceed as in Example 4 by letting $k=n-1$ in the first series and $k=n+1$ in the second. The right side of (9) becomes

$$
c_{1}+\sum_{k=1}^{\infty}(k+1) c_{k+1} x^{k}-\sum_{k=1}^{\infty} 2 c_{k-1} x^{k}
$$

After we add the series termwise, it follows that


\begin{equation*}
\frac{d y}{d x}-2 x y=c_{1}+\sum_{k=1}^{\infty}\left[(k+1) c_{k+1}-2 c_{k-1}\right] x^{k}=0 \tag{10}
\end{equation*}


Hence in order to have (10) identically zero it is necessary that the coefficients satisfy


\begin{equation*}
c_{1}=0 \quad \text { and } \quad(k+1) c_{k+1}-2 c_{k-1}=0, \quad k=1,2,3, \ldots . \tag{11}
\end{equation*}


Equation (11) provides a recurrence relation that determines the $c_{k}$. Since $k+1 \neq 0$ for all the indicated values of $k$, we can write (11) as


\begin{equation*}
c_{k+1}=\frac{2 c_{k-1}}{k+1} \tag{12}
\end{equation*}


Iteration of this last formula then gives

$$
k=1, \quad c_{2}=\frac{2}{2} c_{0}=c_{0}
$$
\footnotetext{\begin{itemize}
  \item At this point we do not know the interval of convergence.
\end{itemize}
}

$$
\begin{array}{ll}
k=2, & c_{3}=\frac{2}{3} c_{1}=0 \\
k=3, & c_{4}=\frac{2}{4} c_{2}=\frac{1}{2} c_{0}=\frac{1}{2!} c_{0} \\
k=4, & c_{5}=\frac{2}{5} c_{3}=0 \\
k=5, & c_{6}=\frac{2}{6} c_{4}=\frac{1}{3 \cdot 2!} c_{0}=\frac{1}{3!} c_{0} \\
k=6, & c_{7}=\frac{2}{7} c_{5}=0 \\
k=7, & c_{8}=\frac{2}{8} c_{6}=\frac{1}{4 \cdot 3!} c_{0}=\frac{1}{4!} c_{0}
\end{array}
$$

and so on. Thus from the original assumption (7), we find


\begin{align*}
y=\sum_{n=0}^{\infty} c_{n} x^{n} & =c_{0}+c_{1} x+c_{2} x^{2}+c_{3} x^{3}+c_{4} x^{4}+c_{5} x^{5}+\cdots \\
& =c_{0}+0+c_{0} x^{2}+0+\frac{1}{2!} c_{0} x^{4}+0+\frac{1}{3!} c_{0} x^{6}+0+\cdots \\
& =c_{0}\left[1+x^{2}+\frac{1}{2!} x^{4}+\frac{1}{3!} x^{6}+\cdots\right]=c_{0} \sum_{n=0}^{\infty} \frac{x^{2 n}}{n!} \tag{13}
\end{align*}


Since the iteration of (12) leaves $c_{0}$ completely undetermined, we have in fact found the general solution of (6).

The differential equation in Example 5, like the differential equation in the following example, can be easily solved by prior methods. The point of these two examples is to prepare you for the techniques considered in Sections 6.3 and 6.4.

\section*{EXAMPLE 6 A Power Series Solution}
Find solutions of $4 y^{\prime \prime}+y=0$ in the form of power series in $x$.

Solution If $y=\sum_{n=0}^{\infty} c_{n} x^{n}$, then

$$
y^{\prime}=\sum_{n=0}^{\infty} n c_{n} x^{n-1}=\sum_{n=1}^{\infty} n c_{n} x^{n-1} \quad \text { and } \quad y^{\prime \prime}=\sum_{n=1}^{\infty} n(n-1) c_{n} x^{n-2}=\sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2}
$$

Substituting the expressions for $y^{\prime \prime}$ and $y$ back into the differential equation gives

$$
4 y^{\prime \prime}+y=\underbrace{\sum_{n=2}^{\infty} 4 n(n-1) c_{n} x^{n-2}+\sum_{n=0}^{\infty} c_{n} x^{n}}
$$

If we substitute $k=n-2$ in the first series and $k=n$ in the second, we get (after using, in turn, $n=k+2$ and $n=k$ )

$$
\begin{aligned}
4 y^{\prime \prime}+y & =\sum_{k=0}^{\infty} 4(k+2)(k+1) c_{k+2} x^{k}+\sum_{k=0}^{\infty} c_{k} x^{k} \\
& =\sum_{k=0}^{\infty}\left[4(k+2)(k+1) c_{k+2}+c_{k}\right] x^{k}=0
\end{aligned}
$$

From this last identity we conclude that

or

$$
\begin{aligned}
4(k+2)(k+1) c_{k+2}+c_{k}=0 \\
c_{k+2}=\frac{-c_{k}}{4(k+2)(k+1)}, \quad k=0,1,2, \ldots
\end{aligned}
$$

From iteration of this recurrence relation it follows that

$$
\begin{aligned}
& c_{2}=\frac{-c_{0}}{4 \cdot 2 \cdot 1}=-\frac{c_{0}}{2^{2} \cdot 2!} \\
& c_{3}=\frac{-c_{1}}{4 \cdot 3 \cdot 2}=-\frac{c_{1}}{2^{2} \cdot 3!} \\
& c_{4}=\frac{-c_{2}}{4 \cdot 4 \cdot 3}=\frac{c_{0}}{2^{4} \cdot 4!} \\
& c_{5}=\frac{-c_{3}}{4 \cdot 5 \cdot 4}=\frac{c_{1}}{2^{4} \cdot 5!} \\
& c_{6}=\frac{-c_{4}}{4 \cdot 6 \cdot 5}=-\frac{c_{0}}{2^{6} \cdot 6!} \\
& c_{7}=\frac{-c_{5}}{4 \cdot 7 \cdot 6}=-\frac{c_{1}}{2^{6} \cdot 7!}
\end{aligned}
$$

and so forth. This iteration leaves both $c_{0}$ and $c_{1}$ arbitrary. From the original assumption we have

$$
\begin{aligned}
& y=c_{0}+c_{1} x+c_{2} x^{2}+c_{3} x^{3}+c_{4} x^{4}+c_{5} x^{5}+c_{6} x^{6}+c_{7} x^{7}+\cdots \\
& =c_{0}+c_{1} x-\frac{c_{0}}{2^{2} \cdot 2!} x^{2}-\frac{c_{1}}{2^{2} \cdot 3!} x^{3}+\frac{c_{0}}{2^{4} \cdot 4!} x^{4}+\frac{c_{1}}{2^{4} \cdot 5!} x^{5}-\frac{c_{0}}{2^{6} \cdot 6!} x^{6}-\frac{c_{1}}{2^{6} \cdot 7!} x^{7}+\cdots \\
& y=c_{0}\left[1-\frac{1}{2^{2} \cdot 2!} x^{2}+\frac{1}{2^{4} \cdot 4!} x^{4}-\frac{1}{2^{6} \cdot 6!} x^{6}+\cdots\right] \\
& +c_{1}\left[x-\frac{1}{2^{2} \cdot 3!} x^{3}+\frac{1}{2^{4} \cdot 5!} x^{5}-\frac{1}{2^{6} \cdot 7!} x^{7}+\cdots\right]
\end{aligned}
$$

is a general solution. When the series are written in summation notation,

$$
y_{1}(x)=c_{0} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k)!}\left(\frac{x}{2}\right)^{2 k} \quad \text { and } \quad y_{2}(x)=2 c_{1} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k+1)!}\left(\frac{x}{2}\right)^{2 k+1}
$$

the ratio test can be applied to show that both series converge for all $x$. You might also recognize the Maclaurin series as $y_{1}(x)=c_{0} \cos (x / 2)$ and $y_{2}(x)=2 c_{1} \sin (x / 2)$.

\section*{EXERCISES 6.2}
Answers to odd-numbered problems begin on page $A-12$.

In Problems 1-10 find the interval of convergence of the given power series.

\begin{enumerate}
  \item $\sum_{n=1}^{\infty} \frac{(-1)^{n}}{n} x^{n}$
  \item $\sum_{n=1}^{\infty} \frac{x^{n}}{n^{2}}$
  \item $\sum_{k=1}^{\infty} \frac{2^{k}}{k} x^{k}$
  \item $\sum_{k=0}^{\infty} \frac{5^{k}}{k!} x^{k}$
  \item $\sum_{n=1}^{\infty} \frac{(x-3)^{n}}{n^{3}}$
  \item $\sum_{n=1}^{\infty} \frac{(x+7)^{n}}{\sqrt{n}}$
  \item $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{10^{k}}(x-5)^{k}$
  \item $\sum_{k=1}^{\infty} \frac{k}{(k+2)^{2}}(x-4)^{k}$
  \item $\sum_{k=0}^{\infty} k!2^{k} x^{k}$
  \item $\sum_{k=1}^{\infty} \frac{k-1}{k^{2 k}} x^{k}$
\end{enumerate}

In Problems 11-20 find the first four terms of a power series in $x$ for the given function. Calculate the series by hand or use a CAS as instructed.\\
11. $e^{x} \sin x$\\
12. $e^{-x} \cos x$\\
13. $\sin x \cos x$\\
14. $e^{x} \ln (1-x)$\\
15. $\left(x-\frac{x^{3}}{3}+\frac{x^{5}}{5}-\frac{x^{7}}{7}+\cdots\right)^{2}$\\
16. $\left(1-\frac{x^{2}}{2}+\frac{x^{4}}{3}-\frac{x^{6}}{4}+\cdots\right)^{2}$\\
17. $\tan x$\\
18. $\frac{1}{e^{x}+e^{-x}}$\\
19. $\frac{1}{1-\frac{x^{2}}{2}+\frac{x^{4}}{3}-\frac{x^{6}}{4}+\cdots}$\\
20. $\frac{1}{\left(1-\frac{x^{2}}{2}+\frac{x^{4}}{3}-\frac{x^{6}}{4}+\cdots\right)^{2}}$

In Problems 21-30 solve each differential equation in the manner of the previous chapters and then compare the results with the solutions obtained by assuming a power series solution $y=\sum_{n=0}^{\infty} c_{n} x^{n}$.\\
21. $y^{\prime}+y=0$\\
22. $y^{\prime}=2 y$\\
23. $y^{\prime}-x^{2} y=0$\\
24. $y^{\prime}+x^{3} y=0$\\
25. $(1-x) y^{\prime}-y=0$\\
26. $(1+x) y^{\prime}-2 y=0$\\
27. $y^{\prime \prime}+y=0$\\
28. $y^{\prime \prime}-y=0$\\
29. $y^{\prime \prime}=y^{\prime}$\\
30. $2 y^{\prime \prime}+y^{\prime}=0$

\subsection*{6.3 SOLUTIONS ABOUT ORDINARY POINTS}

\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0 \tag{1}
\end{equation*}


is put into the standard form


\begin{equation*}
y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=0 \tag{2}
\end{equation*}


by dividing by the leading coefficient $a_{2}(x)$. We make the following definition.

DEFINITION 6.1 Ordinary and Singular Points

A point $x_{0}$ is said to be an ordinary point of the differential equation (1) if both $P(x)$ and $Q(x)$ in (2) are analytic* at $x_{0}$. A point that is not an ordinary point is said to be a singular point of the equation.

\section*{EXAMPLE 1 Ordinary Points of a DE}
Every finite value of $x$ is an ordinary point of

$$
y^{\prime \prime}+\left(e^{x}\right) y^{\prime}+(\sin x) y=0
$$

In particular we see that $x=0$ is an ordinary point since

$$
e^{x}=1+\frac{x}{1!}+\frac{x^{2}}{2!}+\cdots \quad \text { and } \quad \sin x=x-\frac{x^{3}}{3!}+\frac{x^{5}}{5!}-\cdots
$$

converge for all finite values of $x$.

\section*{EXAMPLE $2 \quad x=0$ Is an Ordinary Point}
The differential equation $x y^{\prime \prime}+(\sin x) y=0$ has an ordinary point at $x=0$ since it can be shown that $Q(x)=(\sin x) / x$ possesses the power series expansion

$$
Q(x)=1-\frac{x^{2}}{3!}+\frac{x^{4}}{5!}-\frac{x^{6}}{7!}+\cdots
$$

that converges for all finite values of $x$.

\section*{EXAMPLE $3 \quad x=0$ Is a Singular Point}
The differential equation $y^{\prime \prime}+(\ln x) y=0$ has a singular point at $x=0$ because $Q(x)=\ln x$ possesses no power series in $x$.

Polynomial Coefficients Primarily we shall be concerned with the case when (1) has polynomial coefficients. As a consequence of Definition 6.1, we note
\footnotetext{\begin{itemize}
  \item See page 232 .
\end{itemize}
}
that when $a_{2}(x), a_{1}(x)$, and $a_{0}(x)$ are polynomials with no common factors, a point $x=x_{0}$ is

(i) an ordinary point if $a_{2}\left(x_{0}\right) \neq 0$ or (ii) a singular point if $a_{2}\left(x_{0}\right)=0$.

EXAMPLE 4 Singular Points

(a) The singular points of the equation $\left(x^{2}-1\right) y^{\prime \prime}+2 x y^{\prime}+6 y=0$ are the solutions of $x^{2}-1=0$ or $x= \pm 1$. All other finite values of $x$ are ordinary points.

(b) Singular points need not be real numbers. The equation $\left(x^{2}+1\right) y^{\prime \prime}+$ $x y^{\prime}-y=0$ has singular points at the solutions of $x^{2}+1=0$-namely, $x= \pm i$. All other finite values of $x$, real or complex, are ordinary points.

\section*{EXAMPLE $5 \quad x=0$ Is a Singular Point of a Cauchy-Euler DE}
The Cauchy-Euler equation $a x^{2} y^{\prime \prime}+b x y^{\prime}+c y=0$, where $a, b$, and $c$ are constants, has a singular point at $x=0$. All other finite values of $x$, real or complex, are ordinary points.

For our purposes ordinary points and singular points will always be finite points. It is possible for a differential equation to have, say, a singular point at infinity. (See Problem 40, Exercises 6.4.)

We state the following theorem about the existence of power series solutions without proof.

\section*{THEOREM 6.1 Existence of Power Series Solutions}
If $x=x_{0}$ is an ordinary point of the differential equation (1), we can always find two linearly independent solutions in the form of power series centered at $x_{0}$ :


\begin{equation*}
y=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n} \tag{3}
\end{equation*}


A series solution converges at least for $\left|x-x_{0}\right|<R$, where $R$ is the distance from $x_{0}$ to the closest singular point (real or complex).

A solution of a differential equation of the form given in (3) is said to be a solution about the ordinary point $x_{0}$. The distance $R$ given in Theorem 6.1 is the minimum value for the radius of convergence. A differential equation could have a finite singular point and yet a solution could be valid for all $x$; for example, the differential equation may possess a polynomial solution.

To solve a linear second-order equation such as (1) we find two sets of coefficients $c_{n}$ so that we have two distinct power series $y_{1}(x)$ and $y_{2}(x)$, both expanded about the same ordinary point $x_{0}$. The procedure used to solve a\\
second-order equation is the same as that used in Example 6 of Section 6.2; that is, we assume a solution $y=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n}$ and then determine the $c_{n}$. The general solution of the differential equation is $y=C_{1} y_{1}(x)+C_{2} y_{2}(x)$; in fact, it can be shown that $C_{1}=c_{0}$ and $C_{2}=c_{1}$, where $c_{0}$ and $c_{1}$ are arbitrary.

Note For the sake of simplicity, we assume an ordinary point is always located at $x=0$, since, if not, the substitution $t=x-x_{0}$ translates the value $x=x_{0}$ to $t=0$.

\section*{EXAMPLE 6 Power Series Solutions}
Solve $y^{\prime \prime}-2 x y=0$.

Solution We see that $x=0$ is an ordinary point of the equation. Since there are no finite singular points, Theorem 6.1 guarantees two solutions of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n}$ convergent for $|x|<\infty$. Proceeding, we write

$$
y^{\prime}=\sum_{n=0}^{\infty} n c_{n} x^{n-1}=\sum_{n=1}^{\infty} n c_{n} x^{n-1}, \quad y^{\prime \prime}=\sum_{n=1}^{\infty} n(n-1) c_{n} x^{n-2}=\sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2}
$$

where we have used the fact that the first term in each series, corresponding to $n=0$ and $n=1$, respectively, is zero. Therefore

$$
\begin{aligned}
y^{\prime \prime}-2 x y & =\sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2}-\sum_{n=0}^{\infty} 2 c_{n} x^{n+1} \\
& =2 \cdot 1 c_{2} x^{0}+\underbrace{\sum_{n=3}^{\infty} n(n-1) c_{n} x^{n-2}-\sum_{n=0}^{\infty} 2 c_{n} x^{n+1}}_{\text {both series start with } x}
\end{aligned}
$$

Letting $k=n-2$ in the first series and $k=n+1$ in the second, we have

$$
\begin{aligned}
y^{\prime \prime}-2 x y & =2 c_{2}+\sum_{k=1}^{\infty}(k+2)(k+1) c_{k+2} x^{k}-\sum_{k=1}^{\infty} 2 c_{k-1} x^{k} \\
& =2 c_{2}+\sum_{k=1}^{\infty}\left[(k+2)(k+1) c_{k+2}-2 c_{k-1}\right] x^{k}=0
\end{aligned}
$$

We must then have

$$
2 c_{2}=0 \quad \text { and } \quad(k+2)(k+1) c_{k+2}-2 c_{k-1}=0
$$

The last expression is the same as

$$
\begin{gathered}
c_{k+2}=\frac{2 c_{k-1}}{(k+2)(k+1)}, \quad k=1,2,3, \ldots \\
c_{3}=\frac{2 c_{0}}{3 \cdot 2} \\
c_{4}=\frac{2 c_{1}}{4 \cdot 3} \\
c_{5}=\frac{2 c_{2}}{5 \cdot 4}=0
\end{gathered}
$$

$$
\begin{aligned}
& c_{6}=\frac{2 c_{3}}{6 \cdot 5}=\frac{2^{2}}{6 \cdot 5 \cdot 3 \cdot 2} c_{0} \\
& c_{7}=\frac{2 c_{4}}{7 \cdot 6}=\frac{2^{2}}{7 \cdot 6 \cdot 4 \cdot 3} c_{1} \\
& c_{8}=\frac{2 c_{5}}{8 \cdot 7}=0 \\
& c_{9}=\frac{2 c_{6}}{9 \cdot 8}=\frac{2^{3}}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2} c_{0} \\
& c_{10}=\frac{2 c_{7}}{10 \cdot 9}=\frac{2^{3}}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3} c_{1} \\
& c_{11}=\frac{2 c_{8}}{11 \cdot 10}=0
\end{aligned}
$$

and so on. It should be apparent that both $c_{0}$ and $c_{1}$ are arbitrary. Now

$$
\begin{aligned}
y= & c_{0}+c_{1} x+c_{2} x^{2}+c_{3} x^{3}+c_{4} x^{4}+c_{5} x^{5}+c_{6} x^{6}+c_{7} x^{7}+c_{8} x^{8} \\
& +c_{9} x^{9}+c_{10} x^{10}+c_{11} x^{11}+\cdots \\
= & c_{0}+c_{1} x+0+\frac{2}{3 \cdot 2} c_{0} x^{3}+\frac{2}{4 \cdot 3} c_{1} x^{4}+0+\frac{2^{2}}{6 \cdot 5 \cdot 3 \cdot 2} c_{0} x^{6} \\
& +\frac{2^{2}}{7 \cdot 6 \cdot 4 \cdot 3} c_{1} x^{7}+0+\frac{2^{3}}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2} c_{0} x^{9} \\
& +\frac{2^{3}}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3} c_{1} x^{10}+0+\cdots \\
= & c_{0}\left[1+\frac{2}{3 \cdot 2} x^{3}+\frac{2^{2}}{6 \cdot 5 \cdot 3 \cdot 2} x^{6}+\frac{2^{3}}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2} x^{9}+\cdots\right] \\
& +c_{1}\left[x+\frac{2}{4 \cdot 3} x^{4}+\frac{2^{2}}{7 \cdot 6 \cdot 4 \cdot 3} x^{7}+\frac{2^{3}}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3} x^{10}+\cdots\right]
\end{aligned}
$$

Although the pattern of the coefficients in Example 6 should be clear, it is sometimes useful to write the solutions in terms of summation notation. By using the properties of the factorial, we can write

and

$$
\begin{aligned}
& y_{1}(x)=c_{0}\left[1+\sum_{k=1}^{\infty} \frac{2^{k}[1 \cdot 4 \cdot 7 \cdots(3 k-2)]}{(3 k)!} x^{3 k}\right] \\
& y_{2}(x)=c_{1}\left[x+\sum_{k=1}^{\infty} \frac{2^{k}[2 \cdot 5 \cdot 8 \cdots(3 k-1)]}{(3 k+1)!} x^{3 k+1}\right]
\end{aligned}
$$

In this form the ratio test can be used to show that each series converges for $|x|<\infty$.

\section*{EXAMPLE 7 Discovering a Polynomial Solution}
Solve $\left(x^{2}+1\right) y^{\prime \prime}+x y^{\prime}-y=0$.

Solution Since the singular points are $x= \pm i$, a power series solution will converge at least for $|x|<1$. ${ }^{*}$ The assumption $y=\sum_{n=0}^{\infty} c_{n} x^{n}$ leads to

$$
\begin{aligned}
& \left(x^{2}+1\right) \sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2}+x \sum_{n=1}^{\infty} n c_{n} x^{n-1}-\sum_{n=0}^{\infty} c_{n} x^{n} \\
& =\sum_{n=2}^{\infty} n(n-1) c_{n} x^{n}+\sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2} \\
& +\sum_{n=1}^{\infty} n c_{n} x^{n}-\sum_{n=0}^{\infty} c_{n} x^{n} \\
& =2 c_{2} x^{0}-c_{0} x^{0}+6 c_{3} x+c_{1} x-c_{1} x+\underbrace{\infty}_{n=2} n(n-1) c_{n} x^{n} \\
& +\underbrace{\sum_{n=4}^{\infty} n(n-1) c_{n} x^{n-2}}_{k=n}+\underbrace{\sum_{n=2}^{\infty} n c_{n} x^{n}}_{k}-\underbrace{\sum_{n=2}^{\infty} c_{n} x^{n}}_{k} \\
& =2 c_{2}-c_{0}+6 c_{3} x \\
& +\sum_{k=2}^{\infty}\left[k(k-1) c_{k}+(k+2)(k+1) c_{k+2}+k c_{k}-c_{k}\right] x^{k} \\
& =2 c_{2}-c_{0}+6 c_{3} x \\
& +\sum_{k=2}^{\infty}\left[k(k+1)(k-1) c_{k}+(k+2)(k+1) c_{k+2}\right] x^{k}=0
\end{aligned}
$$

Thus

$$
2 c_{2}-c_{0}=0, \quad c_{3}=0
$$

$$
(k+1)(k-1) c_{k}+(k+2)(k+1) c_{k+2}=0
$$

After dividing by $(k+2)(k+1)$, we get

and

$$
\begin{gathered}
c_{2}=\frac{1}{2} c_{0} \quad \text { and } \quad c_{3}=0 \\
c_{k+2}=\frac{1-k}{k+2} c_{k}, \quad k=2,3,4, \ldots
\end{gathered}
$$

Iteration of the last formula gives

$$
\begin{aligned}
& c_{4}=-\frac{1}{4} c_{2}=-\frac{1}{2 \cdot 4} c_{0}=-\frac{1}{2^{2} 2!} c_{0} \\
& c_{5}=-\frac{2}{5} c_{3}=0 \\
& c_{6}=-\frac{3}{6} c_{4}=\frac{3}{2 \cdot 4 \cdot 6} c_{0}=\frac{1 \cdot 3}{2^{3} 3!} c_{0} \\
& c_{7}=-\frac{4}{7} c_{5}=0 \\
& c_{8}=-\frac{5}{8} c_{6}=-\frac{3 \cdot 5}{2 \cdot 4 \cdot 6 \cdot 8} c_{0}=-\frac{1 \cdot 3 \cdot 5}{2^{4} 4!} c_{0}
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item The modulus or magnitude of the complex number $x=i$ is $|x|=1$. If $x=a+b i$ is a singular point, then $|x|=\sqrt{a^{2}+b^{2}}$. See Appendix IV.
\end{itemize}
}

$$
\begin{aligned}
c_{9} & =-\frac{6}{9} c_{7}=0 \\
c_{10} & =-\frac{7}{10} c_{8}=\frac{3 \cdot 5 \cdot 7}{2 \cdot 4 \cdot 6 \cdot 8 \cdot 10} c_{0}=\frac{1 \cdot 3 \cdot 5 \cdot 7}{2^{5} 5!} c_{0}
\end{aligned}
$$

and so on. Therefore

$$
\begin{aligned}
y & =c_{0}+c_{1} x+c_{2} x^{2}+c_{3} x^{3}+c_{4} x^{4}+c_{5} x^{5}+c_{6} x^{6}+c_{7} x^{7}+c_{8} x^{8}+\cdots \\
& =c_{1} x+c_{0}\left[1+\frac{1}{2} x^{2}-\frac{1}{2^{2} 2!} x^{4}+\frac{1 \cdot 3}{2^{3} 3!} x^{6}-\frac{1 \cdot 3 \cdot 5}{2^{4} 4!} x^{8}+\frac{1 \cdot 3 \cdot 5 \cdot 7}{2^{5} 5!} x^{10}-\cdots\right]
\end{aligned}
$$

The solutions are

$$
\begin{aligned}
& y_{1}(x)=c_{0}\left[1+\frac{1}{2} x^{2}+\sum_{n=2}^{\infty}(-1)^{n-1} \frac{1 \cdot 3 \cdot 5 \cdots(2 n-3)}{2^{n} n!} x^{2 n}\right], \quad|x|<1 \\
& y_{2}(x)=c_{1} x
\end{aligned}
$$

\section*{EXAMP-L: \& A Three-Term Recurrence Relation}
If we seek a solution $y=\sum_{n=0}^{\infty} c_{n} x^{n}$ for the equation

$$
y^{\prime \prime}-(1+x) y=0
$$

we obtain $c_{2}=c_{0} / 2$ and the three-term recurrence relation

$$
c_{k+2}=\frac{c_{k}+c_{k-1}}{(k+1)(k+2)}, \quad k=1,2,3, \ldots
$$

To simplify the iteration we can first choose $c_{0} \neq 0, c_{1}=0$; this yields one solution. The other solution follows from next choosing $c_{0}=0, c_{1} \neq 0$. With the first assumption we find

$$
\begin{aligned}
& c_{2}=\frac{1}{2} c_{0} \\
& c_{3}=\frac{c_{1}+c_{0}}{2 \cdot 3}=\frac{c_{0}}{2 \cdot 3}=\frac{1}{6} c_{0} \\
& c_{4}=\frac{c_{2}+c_{1}}{3 \cdot 4}=\frac{c_{0}}{2 \cdot 3 \cdot 4}=\frac{1}{24} c_{0} \\
& c_{5}=\frac{c_{3}+c_{2}}{4 \cdot 5}=\frac{c_{0}}{4 \cdot 5}\left[\frac{1}{2 \cdot 3}+\frac{1}{2}\right]=\frac{1}{30} c_{0}
\end{aligned}
$$

and so on. Thus one solution is

$$
y_{1}(x)=c_{0}\left[1+\frac{1}{2} x^{2}+\frac{1}{6} x^{3}+\frac{1}{24} x^{4}+\frac{1}{30} x^{5}+\cdots\right]
$$

Similarly if we choose $c_{0}=0$, then

$$
\begin{aligned}
& c_{2}=0 \\
& c_{3}=\frac{c_{1}+c_{0}}{2 \cdot 3}=\frac{c_{1}}{2 \cdot 3}=\frac{1}{6} c_{1}
\end{aligned}
$$

$$
\begin{aligned}
& c_{4}=\frac{c_{2}+c_{1}}{3 \cdot 4}=\frac{c_{1}}{3 \cdot 4}=\frac{1}{12} c_{1} \\
& c_{5}=\frac{c_{3}+c_{2}}{4 \cdot 5}=\frac{c_{1}}{2 \cdot 3 \cdot 4 \cdot 5}=\frac{1}{120} c_{1}
\end{aligned}
$$

and so on. Hence another solution is

$$
y_{2}(x)=c_{1}\left[x+\frac{1}{6} x^{3}+\frac{1}{12} x^{4}+\frac{1}{120} x^{5}+\cdots\right]
$$

Each series converges for all finite values of $x$.

Nonpolynomial Coefficients The next example illustrates how to find a power series solution about an ordinary point of a differential equation when its coefficients are not polynomials. In this example we see an application of multiplication of two power series that was discussed in Section 6.2.

\section*{EXAMPLE 9 DE with a Nonpolynomial Coefficient}
Solve $y^{\prime \prime}+(\cos x) y=0$.

Solution Since $\cos x=1-\frac{x^{2}}{2!}+\frac{x^{4}}{4!}-\frac{x^{6}}{6!}+\cdots$, it is seen that $x=0$ is an ordinary point. Thus the assumption $y=\sum_{n=0}^{\infty} c_{n} x^{n}$ leads to

$$
\begin{aligned}
y^{\prime \prime}+(\cos x) y= & \sum_{n=2}^{\infty} n(n-1) c_{n} x^{n-2}+\left(1-\frac{x^{2}}{2!}+\frac{x^{4}}{4!}-\cdots\right) \sum_{n=0}^{\infty} c_{n} x^{n} \\
= & \left(2 c_{2}+6 c_{3} x+12 c_{4} x^{2}+20 c_{5} x^{3}+\cdots\right) \\
& +\left(1-\frac{x^{2}}{2}+\frac{x^{4}}{24}-\cdots\right)\left(c_{0}+c_{1} x+c_{2} x^{2}+c_{3} x^{3}+\cdots\right) \\
= & 2 c_{2}+c_{0}+\left(6 c_{3}+c_{1}\right) x+\left(12 c_{4}+c_{2}-\frac{1}{2} c_{0}\right) x^{2}+\left(20 c_{5}+c_{3}-\frac{1}{2} c_{1}\right) x^{3}+\cdots
\end{aligned}
$$

Since the last line is to be identically zero, we must have

$$
\begin{aligned}
2 c_{2}+c_{0} & =0 \\
6 c_{3}+c_{1} & =0 \\
12 c_{4}+c_{2}-\frac{1}{2} c_{0} & =0 \\
20 c_{5}+c_{3}-\frac{1}{2} c_{1} & =0
\end{aligned}
$$

and so on. Since $c_{0}$ and $c_{1}$ are arbitrary, we find

$$
y_{1}(x)=c_{0}\left[1-\frac{1}{2} x^{2}+\frac{1}{12} x^{4}-\cdots\right] \quad \text { and } \quad y_{2}(x)=c_{1}\left[x-\frac{1}{6} x^{3}+\frac{1}{30} x^{5}-\cdots\right]
$$

Since the differential equation has no singular points, both series converge for all finite values of $x$.

EXERCISES 6.3

\section*{Answers to odd-numbered problems begin on page A-12.}
In Problems 1-14 for each differential equation find two linearly independent power series solutions about the ordinary point $x=0$.

\begin{enumerate}
  \item $y^{\prime \prime}=x y$
  \item $y^{\prime \prime}+x^{2} y=0$
  \item $y^{\prime \prime}-2 x y^{\prime}+y=0$
  \item $y^{\prime \prime}-x y^{\prime}+2 y=0$
  \item $y^{\prime \prime}+x^{2} y^{\prime}+x y=0$
  \item $y^{\prime \prime}+2 x y^{\prime}+2 y=0$
  \item $(x-1) y^{\prime \prime}+y^{\prime}=0$
  \item $(x+2) y^{\prime \prime}+x y^{\prime}-y=0$
  \item $\left(x^{2}-1\right) y^{\prime \prime}+4 x y^{\prime}+2 y=0$
  \item $\left(x^{2}+1\right) y^{\prime \prime}-6 y=0$
  \item $\left(x^{2}+2\right) y^{\prime \prime}+3 x y^{\prime}-y=0$
  \item $\left(x^{2}-1\right) y^{\prime \prime}+x y^{\prime}-y=0$
  \item $y^{\prime \prime}-(x+1) y^{\prime}-y=0$
  \item $y^{\prime \prime}-x y^{\prime}-(x+2) y=0$
\end{enumerate}

In Problems 15-18 use the power series method to solve the given differential equation subject to the indicated initial conditions.\\
15. $(x-1) y^{\prime \prime}-x y^{\prime}+y=0, \quad y(0)=-2, y^{\prime}(0)=6$\\
16. $(x+1) y^{\prime \prime}-(2-x) y^{\prime}+y=0, \quad y(0)=2, y^{\prime}(0)=-1$\\
17. $y^{\prime \prime}-2 x y^{\prime}+8 y=0, \quad y(0)=3, y^{\prime}(0)=0$\\
18. $\left(x^{2}+1\right) y^{\prime \prime}+2 x y^{\prime}=0, \quad y(0)=0, y^{\prime}(0)=1$

In Problems 19-22 use the procedure illustrated in Example 9 to find two power series solutions of the given differential equation about the ordinary point $x=0$.\\
19. $y^{\prime \prime}+(\sin x) y=0$\\
20. $x y^{\prime \prime}+(\sin x) y=0 \quad$ [Hint: See Example 2.]\\
21. $y^{\prime \prime}+e^{-x} y=0$\\
22. $y^{\prime \prime}+e^{x} y^{\prime}-y=0$

In Problems 23 and 24 use the power series method to solve the nonhomogeneous equation.\\
23. $y^{\prime \prime}-x y=1$\\
24. $y^{\prime \prime}-4 x y^{\prime}-4 y=e^{x}$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item The differential equation $y^{\prime \prime}-2 x y^{\prime}+2 n y=0$ is known as Hermite's equation.* When $n \geq 0$ is an integer, Hermite's equation has a polynomial solution. Hermite polynomials have some importance in the study of quantum mechanics. Obtain the polynomial solutions corresponding to $n=1$ and $n=2$.

  \item In the analysis of a uniform thin column of length $L$ that is buckling under its own weight, the following boundary-value problem is encountered:

\end{enumerate}

$$
\theta^{\prime \prime}+\frac{\delta g}{E I}(L-x) \theta=0, \quad \theta(0)=0, \quad \theta^{\prime}(L)=0
$$

Here $E$ is Young's modulus, $I$ is the cross-sectional moment of inertia, $\delta$ is the constant linear density, $x$ is distance measured along the column,
\footnotetext{\begin{itemize}
  \item Named after the French mathematician Charles Hermite (1822-1901).
\end{itemize}
}
and $\theta(x)$ is the angular deflection of the column from the vertical at a point $P(x)$. See Figure 6.5. Obtain a power series solution of the differential equation that satisfies the condition $\theta^{\prime}(L)=0$. For convenience define $\lambda^{2}=\delta g L / E I$ and change the variable by letting $t=L-x$.

\subsection*{6.4 SOLUTIONS ABOUT SINGULAR POINTS \\
 - Regular singular point \\
 - Irregular singular point \\
 - Method of Frobenius \\
 - Indicial equation \\
 - Indicial roots}
\subsection*{6.4.1 REGULAR SINGULAR POINTS; METHOD OF FROBENIUS-CASE I}
We saw in the preceding section that there is no basic problem in finding a power series solution of


\begin{equation*}
a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0 \tag{1}
\end{equation*}


about an ordinary point $x=x_{0}$. However, when $x=x_{0}$ is a singular point, it is not always possible to find a solution of the form

$$
y=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n}
$$

it turns out that we may be able to find a solution of the form

$$
y=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n+r}
$$

where $r$ is a constant that must be determined

Regular and Irregular Singular Points Singular points are further classified as either regular or irregular. To define these concepts we again put (1) into the standard form


\begin{equation*}
y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=0 \tag{2}
\end{equation*}


\section*{DEFINITION 6.2 Regular and Irregular Singular Points}
A singular point $x=x_{0}$ of equation (1) is said to be a regular singular point if both $\left(x-x_{0}\right) P(x)$ and $\left(x-x_{0}\right)^{2} Q(x)$ are analytic at $x_{0}$. A singular point that is not regular is said to be an irregular singular point of the equation

Polynomial Coefficients In the case in which the coefficients in (1) are polynomials with no common factors, Definition 6.2 is equivalent to the following.

Let $a_{2}\left(x_{0}\right)=0$. Form $P(x)$ and $Q(x)$ by reducing $a_{1}(x) / a_{2}(x)$ and $a_{0}(x) / a_{2}(x)$ to lowest terms, respectively. If the factor $\left(x-x_{0}\right)$ appears at most to the first power in the denominator of $P(x)$ and at most to the second power in the denominator of $Q(x)$, then $x=x_{0}$ is a regular singular point.

\section*{EXAMPLE 1 Classification of Singular Points}
It should be clear that $x=-2$ and $x=2$ are singular points of the equation

$$
\left(x^{2}-4\right)^{2} y^{\prime \prime}+(x-2) y^{\prime}+y=0
$$

Dividing the equation by $\left(x^{2}-4\right)^{2}=(x-2)^{2}(x+2)^{2}$, we find that

$$
P(x)=\frac{1}{(x-2)(x+2)^{2}} \quad \text { and } \quad Q(x)=\frac{1}{(x-2)^{2}(x+2)^{2}}
$$

We now test $P(x)$ and $Q(x)$ at each singular point.

In order that $x=-2$ be a regular singular point, the factor $x+2$ can appear at most to the first power in the denominator of $P(x)$ and can appear at most to the second power in the denominator of $Q(x)$. Inspection of $P(x)$ and $Q(x)$ shows that the first condition is not satisfied, and so we conclude that $x=-2$ is an irregular singular point.

In order that $x=2$ be a regular singular point, the factor $x-2$ can appear at most to the first power in the denominator of $P(x)$ and can appear at most to the second power in the denominator of $Q(x)$. Further inspection of $P(x)$ and $Q(x)$ shows that both these conditions are satisfied, so $x=2$ is a regular singular point.

\section*{EXAMPLE 2 Classification of Singular Points}
Both $x=0$ and $x=-1$ are singular points of the differential equation

$$
x^{2}(x+1)^{2} y^{\prime \prime}+\left(x^{2}-1\right) y^{\prime}+2 y=0
$$

Inspection of

$$
P(x)=\frac{x-1}{x^{2}(x+1)} \quad \text { and } \quad Q(x)=\frac{2}{x^{2}(x+1)^{2}}
$$

shows that $x=0$ is an irregular singular point since $(x-0)$ appears to the second power in the denominator of $P(x)$. Note, however, that $x=-1$ is a regular singular point.

\section*{EXAMPLE 3 Classification of Singular Points}
(a) $x=1$ and $x=-1$ are regular singular points of

$$
\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+30 y=0
$$

(b) $x=0$ is an irregular singular point of

$$
\begin{gathered}
x^{3} y^{\prime \prime}-2 x y^{\prime}+5 y=0 \\
Q(x)=\frac{5}{x^{3}}
\end{gathered}
$$

(c) $x=0$ is a regular singular point of

$$
\begin{array}{r}
x y^{\prime \prime}-2 x y^{\prime}+5 y=0 \\
\text { since } \quad P(x)=-2 \text { and } Q(x)=\frac{5}{x}
\end{array}
$$

In part (c) of Example 3 notice that $(x-0)$ and $(x-0)^{2}$ do not even appear in the denominators of $P(x)$ and $Q(x)$, respectively. Remember, these factors can appear at most in this fashion. For a singular point $x=x_{0}$, any nonnegative power of $\left(x-x_{0}\right)$ less than one (namely, zero) and nonnegative power less than two (namely, zero and one) in the denominators of $P(x)$ and $Q(x)$, respectively, imply $x_{0}$ is a regular singular point.

Also, recall that singular points can be complex numbers. It should be apparent that both $x=3 i$ and $x=-3 i$ are regular singular points of the equation $\left(x^{2}+9\right) y^{\prime \prime}-3 x y^{\prime}+(1-x) y=0$ since

$$
P(x)=\frac{-3 x}{(x-3 i)(x+3 i)} \quad \text { and } \quad Q(x)=\frac{1-x}{(x-3 i)(x+3 i)}
$$

\section*{EXAMPLE 4 A Cauchy-Euler DE}
From our discussion of the Cauchy-Euler equation in Section 6.1, we can show that $y_{1}=x^{2}$ and $y_{2}=x^{2} \ln x$ are solutions of the equation $x^{2} y^{\prime \prime}-$ $3 x y^{\prime}+4 y=0$ on the interval $(0, \infty)$. If the procedure of Theorem 6.1 were attempted at the regular singular point $x=0$ (that is, an assumed solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n}$ ), we would succeed in obtaining only the solution $y_{1}=x^{2}$. The fact that we would not obtain the second solution is not really surprising since $\ln x$ does not possess a Taylor series expansion about $x=0$. It follows that $y_{2}=x^{2} \ln x$ does not have a power series in $x$.

\section*{EXAMPLE 5 Existence of Series Solutions}
The differential equation $6 x^{2} y^{\prime \prime}+5 x y^{\prime}+\left(x^{2}-1\right) y=0$ has a regular singular point at $x=0$ but does not possess any solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n}$. By the procedure that we shall now consider it can be shown, however, that there exist two series solutions of the form

$$
y=\sum_{n=0}^{\infty} c_{n} x^{n+1 / 2} \quad \text { and } \quad y=\sum_{n=0}^{\infty} c_{n} x^{n-1 / 3}
$$

Method of Frobenius To solve a differential equation such as (1) about a regular singular point we employ the following theorem due to Frobenius.*

\section*{THEOREM 6.2 Frobenius' Theorem}
If $x=x_{0}$ is a regular singular point of the differential equation (1), then there exists at least one series solution of the form


\begin{equation*}
y=\left(x-x_{0}\right)^{r} \sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n}=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n+r} \tag{3}
\end{equation*}


where the number $r$ is a constant that must be determined. The series will converge at least on some interval $0<x-x_{0}<R$.

Note the words at least in the second line of Theorem 6.2. This means that, in contrast to Theorem 6.1, we are not guaranteed two solutions of the indicated form. The method of Frobenius consists of identifying a regular singular point $x_{0}$, substituting $y=\sum_{n=0}^{\infty} c_{n}\left(x-x_{0}\right)^{n+r}$ into the differential equation, and determining the unknown exponent $r$ and the coefficients $c_{n}$.

As in the preceding section, for the sake of simplicity we shall always assume $x_{0}=0$.

\section*{EXAMPLE 6 Two Series Solutions}
Since $x=0$ is a regular singular point of the differential equation


\begin{equation*}
3 x y^{\prime \prime}+y^{\prime}-y=0 \tag{4}
\end{equation*}


we try a solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$. Now

$$
y^{\prime}=\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r-1}, \quad y^{\prime \prime}=\sum_{n=0}^{\infty}(n+r)(n+r-1) c_{n} x^{n+r-2}
$$

so

$$
\begin{aligned}
3 x y^{\prime \prime}+y^{\prime}-y= & 3 \sum_{n=0}^{\infty}(n+r)(n+r-1) c_{n} x^{n+r-1} \\
& +\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r-1}-\sum_{n=0}^{\infty} c_{n} x^{n+r}
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item FERDINAND GEORG FROBENIUS (1848-1917) Although the basic idea of this series method can be traced back to Euler, the German mathematician Ferdinand Frobenius was the first to prove the result, which he published in 1878. Frobenius made many contributions to the field of analysis, but his name appears more in texts on abstract algebra than in texts on differential equations. His most significant contributions to mathematics were in the field of group theory.
\end{itemize}
}

$$
\begin{aligned}
& =\sum_{n=0}^{\infty}(n+r)(3 n+3 r-2) c_{n} x^{n+r-1}-\sum_{n=0}^{\infty} c_{n} x^{n+r} \\
& =x^{r}[r(3 r-2) c_{0} x^{-1}+\underbrace{\sum_{n=1}^{\infty}(n+r)(3 n+3 r-2) c_{n} x^{n-1}}-\underbrace{\sum_{n=0}^{\infty} c_{n} x^{n}}_{n=0}] \\
& =x^{r}\left[r(3 r-2) c_{0} x^{-1}+\sum_{k=0}^{\infty}\left[(k+r+1)(3 k+3 r+1) c_{k+1}-c_{k}\right] x^{k}\right]=0
\end{aligned}
$$

which implies

$$
r(3 r-2) c_{0}=0
$$


\begin{equation*}
(k+r+1)(3 k+3 r+1) c_{k+1}-c_{k}=0, \quad k=0,1,2, \ldots \tag{5}
\end{equation*}


Since nothing is gained by taking $c_{0}=0$, we must then have


\begin{equation*}
r(3 r-2)=0 \tag{6}
\end{equation*}


and


\begin{equation*}
c_{k+1}=\frac{c_{k}}{(k+r+1)(3 k+3 r+1)}, \quad k=0,1,2, \ldots \tag{7}
\end{equation*}


The two values of $r$ that satisfy (6), $r_{1}=\frac{2}{3}$ and $r_{2}=0$, when substituted in (7), give two different recurrence relations:


\begin{align*}
& c_{k+1}=\frac{c_{k}}{(3 k+5)(k+1)}, \quad k=0,1,2, \ldots  \tag{8}\\
& c_{k+1}=\frac{c_{k}}{(k+1)(3 k+1)}, \quad k=0,1,2, \ldots \tag{9}
\end{align*}


Iteration of (8) gives

$$
\begin{aligned}
c_{1} & =\frac{c_{0}}{5 \cdot 1} \\
c_{2} & =\frac{c_{1}}{8 \cdot 2}=\frac{c_{0}}{2!5 \cdot 8} \\
c_{3} & =\frac{c_{2}}{11 \cdot 3}=\frac{c_{0}}{3!5 \cdot 8 \cdot 11} \\
c_{4} & =\frac{c_{3}}{14 \cdot 4}=\frac{c_{0}}{4!5 \cdot 8 \cdot 11 \cdot 14} \\
& \vdots \\
c_{n} & =\frac{c_{0}}{n!5 \cdot 8 \cdot 11 \cdots(3 n+2)}, \quad n=1,2,3, \ldots
\end{aligned}
$$

whereas iteration of (9) yields

$$
\begin{aligned}
& c_{1}=\frac{c_{0}}{1 \cdot 1} \\
& c_{2}=\frac{c_{1}}{2 \cdot 4}=\frac{c_{0}}{2!1 \cdot 4} \\
& c_{3}=\frac{c_{2}}{3 \cdot 7}=\frac{c_{0}}{3!1 \cdot 4 \cdot 7}
\end{aligned}
$$

$$
\begin{aligned}
c_{4} & =\frac{c_{3}}{4 \cdot 10}=\frac{c_{0}}{4!1 \cdot 4 \cdot 7 \cdot 10} \\
& \vdots \\
c_{n} & =\frac{c_{0}}{n!1 \cdot 4 \cdot 7 \cdots(3 n-2)}, \quad n=1,2,3, \ldots
\end{aligned}
$$

Thus we obtain two series solutions

and


\begin{align*}
& y_{1}=c_{0} x^{2 / \beta}\left[1+\sum_{n=1}^{\infty} \frac{1}{n!5 \cdot 8 \cdot 11 \cdots(3 n+2)} x^{n}\right]  \tag{10}\\
& y_{2}=c_{0} x^{0}\left[1+\sum_{n=1}^{\infty} \frac{1}{n!1 \cdot 4 \cdot 7 \cdots(3 n-2)} x^{n}\right] \tag{11}
\end{align*}


By the ratio test it can be demonstrated that both (10) and (11) converge for all finite values of $x$. Also it should be clear from the form of (10) and (11) that neither series is a constant multiple of the other and, therefore, $y_{1}(x)$ and $y_{2}(x)$ are linearly independent solutions on the $x$-axis. Hence by the superposition principle

$$
\begin{aligned}
y=C_{1} y_{1}(x)+C_{2} y_{2}(x)= & C_{1}\left[x^{2 / 3}+\sum_{n=1}^{\infty} \frac{1}{n!5 \cdot 8 \cdot 11 \cdots(3 n+2)} x^{n+2 / 3}\right] \\
& +C_{2}\left[1+\sum_{n=1}^{\infty} \frac{1}{n!1 \cdot 4 \cdot 7 \cdots(3 n-2)} x^{n}\right], \quad|x|<\infty
\end{aligned}
$$

is another solution of (4). On any interval not containing the origin, this combination represents the general solution of the differential equation.

Although Example 6 illustrates the general procedure for using the method of Frobenius, we hasten to point out that we may not always be able to find two solutions so readily or for that matter find two solutions that are infinite series consisting entirely of powers of $x$.

Indicial Equation Equation (6) is called the indicial equation of the problem, and the values $r_{1}=\frac{2}{3}$ and $r_{2}=0$ are called the indicial roots, or exponents, of the singularity. In general, if $x=0$ is a regular singular point of (1), then the functions $x P(x)$ and $x^{2} Q(x)$ obtained from (2) are analytic at zero; that is, the expansions


\begin{align*}
x P(x) & =p_{0}+p_{1} x+p_{2} x^{2}+\cdots \\
x^{2} Q(x) & =q_{0}+q_{1} x+q_{2} x^{2}+\cdots \tag{12}
\end{align*}


are valid on intervals that have a positive radius of convergence. After we substitute $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$ in (1) or (2) and simplify, the indicial equation is a quadratic equation in $r$ that results from equating the total coefficient of the lowest power of $x$ to zero. It is left as an exercise to show that the general indicial equation is


\begin{equation*}
r(r-1)+p_{0} r+q_{0}=0 \tag{13}
\end{equation*}


See Problem 38. We then solve the latter equation for the two values of the exponents and substitute these values into a recurrence relation such as (7). Theorem 6.2 guarantees that at least one solution of the assumed series form can be found.

\section*{EXAMPLE 7 Only One Series Solution}
The differential equation


\begin{equation*}
x y^{\prime \prime}+3 y^{\prime}-y=0 \tag{14}
\end{equation*}


has a regular singular point at $x=0$. The method of Frobenius yields

$$
x y^{\prime \prime}+3 y^{\prime}-y=x^{r}\left[r(r+2) c_{0} x^{-1}+\sum_{k=0}^{\infty}\left[(k+r+1)(k+r+3) c_{k+1}-c_{k}\right] x^{k}\right]=0
$$

so the indicial equation and exponents are $r(r+2)=0$ and $r_{1}=0, r_{2}=-2$, respectively.

Since


\begin{equation*}
(k+r+1)(k+r+3) c_{k+1}-c_{k}=0, \quad k=0,1,2, \ldots, \tag{15}
\end{equation*}


it follows that when $r_{1}=0$,

$$
\begin{aligned}
c_{k+1} & =\frac{c_{k}}{(k+1)(k+3)} \\
c_{1} & =\frac{c_{0}}{1 \cdot 3} \\
c_{2} & =\frac{c_{1}}{2 \cdot 4}=\frac{2 c_{0}}{2!4!} \\
c_{3} & =\frac{c_{2}}{3 \cdot 5}=\frac{2 c_{0}}{3!5!} \\
c_{4} & =\frac{c_{3}}{4 \cdot 6}=\frac{2 c_{0}}{4!6!} \\
& \vdots \\
c_{n} & =\frac{2 c_{0}}{n!(n+2)!}, \quad n=1,2,3, \ldots .
\end{aligned}
$$

Thus one series solution is


\begin{align*}
y_{1} & =c_{0} x^{0}\left[1+\sum_{n=1}^{\infty} \frac{2}{n!(n+2)!} x^{n}\right] \\
& =c_{0} \sum_{n=0}^{\infty} \frac{2}{n!(n+2)!} x^{n}, \quad|x|<\infty . \tag{16}
\end{align*}


Now when $r_{2}=-2$, (15) becomes


\begin{equation*}
(k-1)(k+1) c_{k+1}-c_{k}=0, \tag{17}
\end{equation*}


but note here that we do not divide by $(k-1)(k+1)$ immediately since this term is zero for $k=1$. However, we use the recurrence relation (17) for the cases $k=0$ and $k=1$ :

$$
-1 \cdot 1 c_{1}-c_{0}=0 \text { and } \quad 0 \cdot 2 c_{2}-c_{1}=0
$$

The latter equation implies that $c_{1}=0$ and so the former equation implies that $c_{0}=0$. Continuing, we find

$$
c_{k+1}=\frac{c_{k}}{(k-1)(k+1)}, \quad k=2,3,4, \ldots
$$

and so


\begin{align*}
c_{3} & =\frac{c_{2}}{1 \cdot 3} \\
c_{4} & =\frac{c_{3}}{2 \cdot 4}=\frac{2 c_{2}}{2!4!} \\
c_{5} & =\frac{c_{4}}{3 \cdot 5}=\frac{2 c_{2}}{3!5!} \\
& \vdots \\
c_{n} & =\frac{2 c_{2}}{(n-2)!n!}, \quad n=2,3,4, \ldots  \tag{18}\\
y_{2} & =c_{2} x^{-2} \sum_{n=2}^{\infty} \frac{2}{(n-2)!n!} x^{n}
\end{align*}


However, close inspection of (18) reveals that $y_{2}$ is simply a constant multiple of (16). To see this, let $k=n-2$ in (18). We conclude that the method of Frobenius gives only one series solution of (14).

Cases of Indicial Roots When using the method of Frobenius, we usually distinguish three cases corresponding to the nature of the indicial roots. For the sake of discussion let us suppose that $r_{1}$ and $r_{2}$ are the real solutions of the indicial equation and that, when appropriate, $r_{1}$ denotes the largest root.

Case I: Roots Not Differing by an Integer If $r_{1}$ and $r_{2}$ are distinct and do not differ by an integer, then there exist two linearly independent solutions of equation (1) of the form

\[
\begin{array}{ll}
y_{1}=\sum_{n=0}^{\infty} c_{n} x^{n+r_{1}}, & c_{0} \neq 0 \\
y_{2}=\sum_{n=0}^{\infty} b_{n} x^{n+r_{2}}, & b_{0} \neq 0 \tag{19b}
\end{array}
\]

\section*{EXAMPLE 8 Two Series Solutions}
Solve


\begin{equation*}
2 x y^{\prime \prime}+(1+x) y^{\prime}+y=0 \tag{20}
\end{equation*}


Solution If $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$, then

$$
\begin{aligned}
2 x y^{\prime \prime}+(1+x) y^{\prime}+y= & 2 \sum_{n=0}^{\infty}(n+r)(n+r-1) c_{n} x^{n+r-1}+\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r-1} \\
& +\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r}+\sum_{n=0}^{\infty} c_{n} x^{n+r} \\
= & \sum_{n=0}^{\infty}(n+r)(2 n+2 r-1) c_{n} x^{n+r-1}+\sum_{n=0}^{\infty}(n+r+1) c_{n} x^{n+r} \\
= & x^{r}[r(2 r-1) c_{0} x^{-1}+\underbrace{\sum_{n=1}^{\infty}(n+r)(2 n+2 r-1) c_{n} x^{n-1}}_{k=n-1}+\underbrace{\sum_{n=0}^{\infty}(n+r+1) c_{n} x^{n}}_{k=n}] \\
= & x^{r}\left[r(2 r-1) c_{0} x^{-1}+\sum_{k=0}^{\infty}\left[(k+r+1)(2 k+2 r+1) c_{k+1}+(k+r+1) c_{k}\right] x^{k}\right]=0
\end{aligned}
$$


\begin{align*}
& \quad r(2 r-1)=0 \\
& \text { which implies }  \tag{21}\\
& (k+r+1)(2 k+2 r+1) c_{k+1}+(k+r+1) c_{k}=0, \quad k=0,1,2, \ldots
\end{align*}


For $r_{1}=\frac{1}{2}$, we can divide by $k+\frac{3}{2}$ in (22) to obtain

$$
\begin{aligned}
c_{k+1} & =\frac{-c_{k}}{2(k+1)} \\
c_{1} & =\frac{-c_{0}}{2 \cdot 1} \\
c_{2} & =\frac{-c_{1}}{2 \cdot 2}=\frac{c_{0}}{2^{2} \cdot 2!} \\
c_{3} & =\frac{-c_{2}}{2 \cdot 3}=\frac{-c_{0}}{2^{3} \cdot 3!}
\end{aligned}
$$

$$
c_{n}=\frac{(-1)^{n} c_{0}}{2^{n} n!}, \quad n=1,2,3, \ldots
$$

Thus we have


\begin{align*}
y_{1} & =c_{0} x^{1 / 2}\left[1+\sum_{n=1}^{\infty} \frac{(-1)^{n}}{2^{n} n!} x^{n}\right] \\
& =c_{0} \sum_{n=0}^{\infty} \frac{(-1)^{n}}{2^{n} n!} x^{n+1 / 2} \tag{23}
\end{align*}


which converges for $x \geq 0$. As given, the series is not meaningful for $x<0$ because of the presence of $x^{1 / 2}$.

Now for $r_{2}=0$, (22) becomes

$$
\begin{aligned}
c_{k+1} & =\frac{-c_{k}}{2 k+1} \\
c_{1} & =\frac{-c_{0}}{1} \\
c_{2} & =\frac{-c_{1}}{3}=\frac{c_{0}}{1 \cdot 3} \\
c_{3} & =\frac{-c_{2}}{5}=\frac{-c_{0}}{1 \cdot 3 \cdot 5} \\
c_{4} & =\frac{-c_{3}}{7}=\frac{c_{0}}{1 \cdot 3 \cdot 5 \cdot 7} \\
& \vdots \\
c_{n} & =\frac{(-1)^{n} c_{0}}{1 \cdot 3 \cdot 5 \cdot 7 \cdots(2 n-1)}, \quad n=1,2,3, \ldots
\end{aligned}
$$

We conclude that a second solution to (20) is


\begin{equation*}
y_{2}=c_{0}\left[1+\sum_{n=1}^{\infty} \frac{(-1)^{n}}{1 \cdot 3 \cdot 5 \cdot 7 \cdots(2 n-1)} x^{n}\right], \quad|x|<\infty \tag{24}
\end{equation*}


On the interval $(0, \infty)$, the general solution is $y=C_{1} y_{1}(x)+C_{2} y_{2}(x)$.

\subsection*{6.4.2 METHOD OF FROBENIUS-CASES II AND III}
When the roots of the indicial equation differ by a positive integer, we may or may not be able to find two solutions of (1) having form (3). If not, then one solution corresponding to the smaller root contains a logarithmic term. When the exponents are equal, a second solution always contains a logarithm. This latter situation is analogous to the solutions of the Cauchy-Euler differential equation when the roots of the auxiliary equation are equal. We have the next two cases.

Case II: Roots Differing by a Positive Integer If $r_{1}-r_{2}=N$, where $N$ is a positive integer, then there exist two linearly independent solutions of equation (1) of the form

\[
\begin{array}{ll}
y_{1}=\sum_{n=1}^{\infty} c_{n} x^{n+n}, & c_{0} \neq 0 \\
y_{2}=C y_{1}(x) \ln x+\sum_{n=0}^{\infty} b_{n} x^{n+r_{2}}, & b_{0} \neq 0, \tag{25b}
\end{array}
\]

where $C$ is a constant that could be zero.

Case III: Equal Indicial Roots If $r_{1}=r_{2}$, there always exist two linearly independent solutions of equation (1) of the form


\begin{align*}
& y_{1}=\sum_{n=0}^{\infty} c_{n} x^{n+r_{1}}, \quad c_{0} \neq 0  \tag{26a}\\
& y_{2}=y_{1}(x) \ln x+\sum_{n=1}^{\infty} b_{n} x^{n+r} . \tag{26b}
\end{align*}


\section*{aXAMPLla 9 Two Solutions: A Polynomial and an Infinite Series}
Solve


\begin{equation*}
x y^{\prime \prime}+(x-6) y^{\prime}-3 y=0 \tag{27}
\end{equation*}


Solution The assumption $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$ leads to


\begin{align*}
& x y^{\prime \prime}+(x-6) y^{\prime}-3 y \\
&= \sum_{n=0}^{\infty}(n+r)(n+r-1) c_{n} x^{n+r-1}-6 \sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r-1}+\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r}-3 \sum_{n=0}^{\infty} c_{n} x^{n+r} \\
&= x^{r}[r(r-7) c_{0} x^{-1}+\underbrace{\sum_{n=1}^{\infty}(n+r)(n+r-7) c_{n} x^{n-1}}_{k=n-1}+\underbrace{\left.\sum_{n=0}^{\infty}(n+r-3) c_{n} x^{n}\right]}_{k=n}] \\
&=x^{r}\left[r(r-7) c_{0} x^{-1}+\sum_{k=0}^{\infty}\left[(k+r+1)(k+r-6) c_{k+1}+(k+r-3) c_{k}\right] x^{k}\right]=0 \\
& \text { Thus } r(r-7)=0 \text { so } r_{1}=7, r_{2}=0, r_{1}-r_{2}=7, \text { and } \\
&(k+r+1)(k+r-6) c_{k+1}+(k+r-3) c_{k}=0, \quad k=0,1,2, \ldots \tag{28}
\end{align*}


For the smaller root $r_{2}=0$, (28) becomes


\begin{equation*}
(k+1)(k-6) c_{k+1}+(k-3) c_{k}=0 \tag{29}
\end{equation*}


Since $k-6=0$ when $k=6$, we do not divide by this term until $k>6$. We find

$$
\begin{aligned}
& 1 \cdot(-6) c_{1}+(-3) c_{0}=0 \\
& 2 \cdot(-5) c_{2}+(-2) c_{1}=0 \\
& 3 \cdot(-4) c_{3}+(-1) c_{2}=0 \\
& 4 \cdot(-3) c_{4}+0 \cdot c_{3}=0 \\
& 5 \cdot(-2) c_{5}+1 \cdot c_{4}=0 \\
& 6 \cdot(-1) c_{6}+2 \cdot c_{5}=0 \\
& 7 \cdot 0 c_{7}+3 \cdot c_{6}=0
\end{aligned}
$$

Hence $\quad c_{1}=-\frac{1}{2} c_{0}$


\begin{align*}
& c_{2}=-\frac{1}{5} c_{1}=\frac{1}{10} c_{0}  \tag{30}\\
& c_{3}=-\frac{1}{12} c_{2}=-\frac{1}{120} c_{0}
\end{align*}


Finally, the general solution of $(27)$ on the interval $(0, \infty)$ is

$$
\begin{aligned}
y & =C_{1} y_{1}(x)+C_{2} y_{2}(x) \\
& =C_{1}\left[1-\frac{1}{2} x+\frac{1}{10} x^{2}-\frac{1}{120} x^{3}\right]+C_{2}\left[x^{7}+\sum_{k=1}^{\infty} \frac{(-1)^{k} 4 \cdot 5 \cdot 6 \cdots(k+3)}{k!8 \cdot 9 \cdot 10 \cdots(k+7)} x^{k+7}\right]
\end{aligned}
$$

It is interesting to observe that in Example 9 the larger root $r_{1}=7$ was not used. Had we used it, we would have obtained a series solution of the form*


\begin{equation*}
y=\sum_{n=0}^{\infty} c_{n} x^{n+7} \tag{34}
\end{equation*}


where the $c_{n}$ are defined by (28) with $r_{1}=7$ :

$$
c_{k+1}=\frac{-(k+4)}{(k+8)(k+1)} c_{k}, \quad k=0,1,2, \ldots
$$

Iteration of this latter recurrence relation then would yield only one solutionnamely, the solution given by (33) (with $c_{0}$ playing the part of $c_{7}$ ).

When the roots of the indicial equation differ by a positive integer, the second solution may contain a logarithm. In practice this is something we do not know in advance but that is determined after we have found the indicial roots and have carefully examined the recurrence relation that defines the coefficients $c_{n}$. As the foregoing example shows, we just may be lucky enough to find two solutions that involve only powers of $x$. On the other hand, if we fail to find a second series-type solution, we can always use the fact that


\begin{equation*}
y_{2}=y_{1}(x) \int \frac{e^{-\int P(x) d x}}{y_{1}^{2}(x)} d x \tag{35}
\end{equation*}


is also a solution of the equation $y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=0$, whenever $y_{1}$ is a known solution (see Section 4.2).

\section*{EXAMPLE 10 Finding a Second Solution of (14)}
Find the general solution of $x y^{\prime \prime}+3 y^{\prime}-y=0$.

Solution Recall from Example 7 that the method of Frobenius provides only one solution to this equation-namely,


\begin{equation*}
y_{1}=\sum_{n=0}^{\infty} \frac{2}{n!(n+2)!} x^{n}=1+\frac{1}{3} x+\frac{1}{24} x^{2}+\frac{1}{360} x^{3}+\cdots \tag{36}
\end{equation*}


From (35) we obtain a second solution:

$$
y_{2}=y_{1}(x) \int \frac{e^{-\int(3 / x) d x}}{y_{1}^{2}(x)} d x=y_{1}(x) \int \frac{d x}{x^{3}\left[1+\frac{1}{3} x+\frac{1}{24} x^{2}+\frac{1}{360} x^{3}+\cdots\right]^{2}}
$$
\footnotetext{\begin{itemize}
  \item Observe that both (33) and (34) start with the power $x^{7}$. In Case II it is always a good idea to work with the smaller root first.
\end{itemize}
}


\begin{align*}
& =y_{1}(x) \int \frac{d x}{x^{3}\left[1+\frac{2}{3} x+\frac{7}{36} x^{2}+\frac{1}{30} x^{3}+\cdots\right]} \leftarrow \text { squaring } \\
& =y_{1}(x) \int \frac{1}{x^{3}}\left[1-\frac{2}{3} x+\frac{1}{4} x^{2}-\frac{19}{270} x^{3}+\cdots\right] d x \leftarrow \text { long division } \\
& =y_{1}(x) \int\left[\frac{1}{x^{3}}-\frac{2}{3 x^{2}}+\frac{1}{4 x}-\frac{19}{270}+\cdots\right] d x \\
& =y_{1}(x)\left[-\frac{1}{2 x^{2}}+\frac{2}{3 x}+\frac{1}{4} \ln x-\frac{19}{270} x+\cdots\right] \\
y_{2} & =\frac{1}{4} y_{1}(x) \ln x+y_{1}(x)\left[-\frac{1}{2 x^{2}}+\frac{2}{3 x}-\frac{19}{270} x+\cdots\right] \tag{37}
\end{align*}


Hence on the interval $(0, \infty)$ the general solution is


\begin{equation*}
y=C_{1} y_{1}(x)+C_{2}\left[\frac{1}{4} y_{1}(x) \ln x+y_{1}(x)\left(-\frac{1}{2 x^{2}}+\frac{2}{3 x}-\frac{19}{270} x+\cdots\right)\right], \tag{38}
\end{equation*}


where $y_{1}(x)$ is defined by (36).

Alternative Procedure There are several alternative procedures to formula (35) when the method of Frobenius fails to provide a second series solution. Although the next method is somewhat tedious, it is nonetheless straightforward. The basic idea is to assume a solution of either the form (25b) or the form (26b) and determine coefficients $b_{n}$ in terms of the coefficients $c_{n}$ that define the known solution $y_{1}(x)$.

\section*{EXAMPLE 11 Example 10 Revisited}
The smaller of the two indicial roots for the equation $x y^{\prime \prime}+3 y^{\prime}-y=0$ is $r_{2}=-2$. From (25b) we now assume a second solution


\begin{equation*}
y_{2}=y_{1} \ln x+\sum_{n=0}^{\infty} b_{n} x^{n-2} \tag{39}
\end{equation*}


where


\begin{equation*}
y_{1}=\sum_{n=0}^{\infty} \frac{2}{n!(n+2)!} x^{n} \tag{40}
\end{equation*}


Differentiation of (39) gives

$$
\begin{aligned}
& y_{2}^{\prime}=\frac{y_{1}}{x}+y_{1}^{\prime} \ln x+\sum_{n=0}^{\infty}(n-2) b_{n} x^{n-3} \\
& y_{2}^{\prime \prime}=-\frac{y_{1}}{x^{2}}+\frac{2 y_{1}^{\prime}}{x}+y_{1}^{\prime \prime} \ln x+\sum_{n=0}^{\infty}(n-2)(n-3) b_{n} x^{n-4}
\end{aligned}
$$

So


\begin{align*}
x y_{2}^{\prime \prime}+3 y_{2}^{\prime}-y_{2}= & \ln x[\underbrace{x y_{1}^{\prime \prime}+3 y_{1}^{\prime}-y_{1}}_{\text {zero }}]+2 y_{1}^{\prime}+\frac{2 y_{1}}{x}+\sum_{n=0}^{\infty}(n-2)(n-3) b_{n} x^{n-3} \\
& +3 \sum_{n=0}^{\infty}(n-2) b_{n} x^{n-3}-\sum_{n=0}^{\infty} b_{n} x^{n-2} \\
= & 2 y_{1}^{\prime}+\frac{2 y_{1}}{x}+\sum_{n=0}^{\infty}(n-2) n b_{n} x^{n-3}-\sum_{n=0}^{\infty} b_{n} x^{n-2} \tag{41}
\end{align*}


where we have combined the first two summations and used the fact that $x y_{1}^{\prime \prime}+3 y_{1}^{\prime}-y_{1}=0$.

By differentiating (40), we can write (41) as


\begin{align*}
\sum_{n=0}^{\infty} \frac{4 n}{n!(n+2)!} x^{n-1} & +\sum_{n=0}^{\infty} \frac{4}{n!(n+2)!} x^{n-1}+\sum_{n=0}^{\infty}(n-2) n b_{n} x^{n-3}-\sum_{n=0}^{\infty} b_{n} x^{n-2} \\
& =0(-2) b_{0} x^{-3}+\left(-b_{0}-b_{1}\right) x^{-2}+\underbrace{\sum_{n=0}^{\infty} \frac{4(n+1)}{n!(n+2)!} x^{n-1}}_{k=n}+\underbrace{\sum_{n=2}^{\infty}(n-2) n b_{n} x^{n-3}}_{k=n-2}-\underbrace{\sum_{n=1}^{\infty} b_{n} x^{n-2}}_{k=n-1} \\
& =-\left(b_{0}+b_{1}\right) x^{-2}+\sum_{k=0}^{\infty}\left[\frac{4(k+1)}{k!(k+2)!}+k(k+2) b_{k+2}-b_{k+1}\right] x^{k-1} \tag{42}
\end{align*}


Setting (42) equal to zero then gives $b_{1}=-b_{0}$ and


\begin{equation*}
\frac{4(k+1)}{k!(k+2)!}+k(k+2) b_{k+2}-b_{k+1}=0, \quad \text { for } k=0,1,2, \ldots \tag{43}
\end{equation*}


When $k=0$ in (43), we have $2+0 \cdot 2 b_{2}-b_{1}=0$ so $b_{1}=2, b_{0}=-2$, but $b_{2}$ is arbitrary.

Rewriting (43) as


\begin{equation*}
b_{k+2}=\frac{b_{k+1}}{k(k+2)}-\frac{4(k+1)}{k!(k+2)!k(k+2)} \tag{44}
\end{equation*}


and evaluating for $k=1,2, \ldots$ gives

$$
\begin{aligned}
& b_{3}=\frac{b_{2}}{3}-\frac{4}{9} \\
& b_{4}=\frac{1}{8} b_{3}-\frac{1}{32}=\frac{1}{24} b_{2}-\frac{25}{288}
\end{aligned}
$$

and so on. Thus we can finally write


\begin{align*}
y_{2} & =y_{1} \ln x+b_{0} x^{-2}+b_{1} x^{-1}+b_{2}+b_{3} x+\cdots \\
& =y_{1} \ln x-2 x^{-2}+2 x^{-1}+b_{2}+\left(\frac{b_{2}}{3}-\frac{4}{9}\right) x+\cdots \tag{45}
\end{align*}


where $b_{2}$ is arbitrary.

Equivalent Solutions At this point you may be wondering whether (37) and (45) are really equivalent. If we choose $C_{2}=4$ in (38), then


\begin{align*}
y_{2} & =y_{1} \ln x+y_{1}\left(-\frac{2}{x^{2}}+\frac{8}{3 x}-\frac{38}{135} x+\cdots\right) \\
& =y_{1} \ln x+\left(1+\frac{1}{3} x+\frac{1}{24} x^{2}+\frac{1}{360} x^{3}+\cdots\right)\left(-\frac{2}{x^{2}}+\frac{8}{3 x}-\frac{38}{135} x+\cdots\right) \\
& =y_{1} \ln x-2 x^{-2}+2 x^{-1}+\frac{29}{36}-\frac{19}{108} x+\cdots \tag{46}
\end{align*}


which is precisely what we obtain from (45) if $b_{2}$ is chosen as $29 / 36$.

The next example illustrates the case when the indicial roots are equal.

\section*{EXAMPLE 12 A General Solution}
Find the general solution of


\begin{equation*}
x y^{\prime \prime}+y^{\prime}-4 y=0 \tag{47}
\end{equation*}


Solution The assumption $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$ leads to

$$
\begin{aligned}
x y^{\prime \prime}+y^{\prime}-4 y & =\sum_{n=0}^{\infty}(n+r)(n+r-1) c_{n} x^{n+r-1}+\sum_{n=0}^{\infty}(n+r) c_{n} x^{n+r-1}-4 \sum_{n=0}^{\infty} c_{n} x^{n+r} \\
& =\sum_{n=0}^{\infty}(n+r)^{2} c_{n} x^{n+r-1}-4 \sum_{n=0}^{\infty} c_{n} x^{n+r} \\
& =x^{r}[r^{2} c_{0} x^{-1}+\underbrace{\sum_{n=1}^{\infty}(n+r)^{2} c_{n} x^{n-1}}_{k=n-1}-4 \underbrace{\sum_{n=0}^{\infty} c_{n} x^{n}}_{k=n}] \\
& =x^{r}\left[r^{2} c_{0} x^{-1}+\sum_{k=0}^{\infty}\left[(k+r+1)^{2} c_{k+1}-4 c_{k}\right] x^{k}\right]=0 .
\end{aligned}
$$

Therefore $r^{2}=0$, and so the indicial roots are equal: $r_{1}=r_{2}=0$. Moreover, we have


\begin{equation*}
(k+r+1)^{2} c_{k+1}-4 c_{k}=0, \quad k=0,1,2 \ldots . \tag{48}
\end{equation*}


Clearly the root $r_{1}=0$ will only yield one solution corresponding to the coefficients defined by the iteration of

The result is


\begin{align*}
c_{k+1} & =\frac{4 c_{k}}{(k+1)^{2}}, \quad k=0,1,2, \ldots \\
y_{1} & =c_{0} \sum_{n=0}^{\infty} \frac{4^{n}}{(n!)^{2}} x^{n}, \quad|x|<\infty \tag{49}
\end{align*}


To obtain the second linearly independent solution we set $c_{0}=1$ in (49) and then use (35):

$$
\begin{aligned}
y_{2}=y_{1}(x) \int \frac{e^{-\int(1 / x) d x}}{y_{1}^{2}(x)} d x & =y_{1}(x) \int \frac{d x}{x\left[1+4 x+4 x^{2}+\frac{16}{9} x^{3}+\cdots\right]^{2}} \\
& =y_{1}(x) \int \frac{d x}{x\left[1+8 x+24 x^{2}+\frac{16}{9} x^{3}+\cdots\right]}
\end{aligned}
$$


\begin{align*}
& =y_{1}(x) \int \frac{1}{x}\left[1-8 x+40 x^{2}-\frac{1472}{9} x^{3}+\cdots\right] d x \\
& =y_{1}(x) \int\left[\frac{1}{x}-8+40 x-\frac{1472}{9} x^{2}+\cdots\right] d x \\
& =y_{1}(x)\left[\ln x-8 x+20 x^{2}-\frac{1472}{27} x^{3}+\cdots\right] \tag{50}
\end{align*}


Thus on the interval $(0, \infty)$ the general solution of $(47)$ is

$y=C_{1} y_{1}(x)+C_{2}\left[y_{1}(x) \ln x+y_{1}(x)\left(-8 x+20 x^{2}-\frac{1472}{27} x^{3}+\cdots\right)\right]$,

where $y_{1}(x)$ is defined by (49).

As in Case II we can also determine $y_{2}(x)$ of Example 12 directly from assumption (26b).

Remarks (i) We purposely have not considered two further complications when solving a differential equation such as (1) about a point $x_{0}$ for which $a_{2}\left(x_{0}\right)=0$. When using (3), it is quite possible that the roots of the indicial equation could tum out to be complex numbers. When the exponents $r_{1}$ and $r_{2}$ are complex, the statement $r_{1}>r_{2}$ is meaningless and must be replaced with $\operatorname{Re}\left(r_{1}\right)>\operatorname{Re}\left(r_{2}\right)$ (for example, if $r=\alpha+i \beta$, then $\operatorname{Re}(r)=\alpha$ ). In particular, when the indicial equation has real coefficients, the complex roots will be a conjugate pair $r_{1}=\alpha+i \beta, r_{2}=\alpha-i \beta$, and $r_{1}-r_{2}=2 i \beta \neq$ integer. Thus for $x_{0}=0$ there will always exist two solutions

$$
y_{1}=\sum_{n=0}^{\infty} c_{n} x^{n+r_{1}} \quad \text { and } \quad y_{2}=\sum_{n=0}^{\infty} b_{n} x^{n+r_{2}}
$$

Unfortunately both solutions give complex values of $y$ for each real choice of $x$. This latter difficulty can be surmounted by the superposition principle. Since a combination of solutions is also a solution to the differential equation, we could form appropriate combinations of $y_{1}(x)$ and $y_{2}(x)$ to yield real solutions (see Case III of the solution of the Cauchy-Euler equation).

(ii) If $x=0$ is an irregular singular point, it should be noted that we may not be able to find any solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n+\tau}$.

(iii) In the advanced study of differential equations it is sometimes important to examine the nature of a singular point at $\infty$. A differential equation is said to have a singular point at $\infty$ if, after the substitution $z=1 / x$, the resulting equation has a singular point at $z=0$. For example, the differential equation $y^{\prime \prime}+x y=0$ has no finite singular points. However, by the chain rule the substitution $z=1 / x$ transforms the equation into

$$
z^{5} \frac{d^{2} y}{d z^{2}}+2 z^{4} \frac{d y}{d z}+y=0
$$

(Verify this.) Inspection of $P(z)=2 / z$ and $Q(z)=1 / z^{5}$ shows that $z=0$ is an irregular singular point of the equation. Hence $\infty$ is an irregular singular point. See Problem 40.

\section*{EXERCISES 6.4}
Answers to odd-numbered problems begin on page A-13.

\subsection*{6.4.1 Regular Singular Points; Method of Frobenius-Case I}
In Problems 1-10 determine the singular points of each differential equation. Classify each singular point as regular or irregular.

\begin{enumerate}
  \item $x^{3} y^{\prime \prime}+4 x^{2} y^{\prime}+3 y=0$
  \item $x y^{\prime \prime}-(x+3)^{-2} y=0$
  \item $\left(x^{2}-9\right)^{2} y^{\prime \prime}+(x+3) y^{\prime}+2 y=0$
  \item $y^{\prime \prime}-\frac{1}{x} y^{\prime}+\frac{1}{(x-1)^{3}} y=0$
  \item $\left(x^{3}+4 x\right) y^{\prime \prime}-2 x y^{\prime}+6 y=0$
  \item $x^{2}(x-5)^{2} y^{\prime \prime}+4 x y^{\prime}+\left(x^{2}-25\right) y=0$
  \item $\left(x^{2}+x-6\right) y^{\prime \prime}+(x+3) y^{\prime}+(x-2) y=0$
  \item $x\left(x^{2}+1\right)^{2} y^{\prime \prime}+y=0$
  \item $x^{3}\left(x^{2}-25\right)(x-2)^{2} y^{\prime \prime}+3 x(x-2) y^{\prime}+7(x+5) y=0$
  \item $\left(x^{3}-2 x^{2}-3 x\right)^{2} y^{\prime \prime}+x(x-3)^{2} y^{\prime}-(x+1) y=0$
\end{enumerate}

In Problems 11-22 show that the indicial roots do not differ by an integer. Use the method of Frobenius to obtain two linearly independent series solutions about the regular singular point $x_{0}=0$. Form the general solution on $(0, \infty)$.\\
11. $2 x y^{\prime \prime}-y^{\prime}+2 y=0$\\
12. $2 x y^{\prime \prime}+5 y^{\prime}+x y=0$\\
13. $4 x y^{\prime \prime}+\frac{1}{2} y^{\prime}+y=0$\\
14. $2 x^{2} y^{\prime \prime}-x y^{\prime}+\left(x^{2}+1\right) y=0$\\
15. $3 x y^{\prime \prime}+(2-x) y^{\prime}-y=0$\\
16. $x^{2} y^{\prime \prime}-\left(x-\frac{2}{9}\right) y=0$\\
17. $2 x y^{\prime \prime}-(3+2 x) y^{\prime}+y=0$\\
18. $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{4}{9}\right) y=0$\\
19. $9 x^{2} y^{\prime \prime}+9 x^{2} y^{\prime}+2 y=0$\\
20. $2 x^{2} y^{\prime \prime}+3 x y^{\prime}+(2 x-1) y=0$\\
21. $2 x^{2} y^{\prime \prime}-x(x-1) y^{\prime}-y=0$\\
22. $x(x-2) y^{\prime \prime}+y^{\prime}-2 y=0$

\subsection*{6.4.2 Method of Frobenius-Cases II and III}
In Problems 23-34 show that the indicial roots differ by an integer. Use the method of Frobenius to obtain two linearly independent series solutions about the regular singular point $x_{0}=0$. Form the general solution on $(0, \infty)$.\\
23. $x y^{\prime \prime}+2 y^{\prime}-x y=0$\\
24. $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{1}{4}\right) y=0$\\
25. $x(x-1) y^{\prime \prime}+3 y^{\prime}-2 y=0$\\
26. $y^{\prime \prime}+\frac{3}{x} y^{\prime}-2 y=0$\\
27. $x y^{\prime \prime}+(1-x) y^{\prime}-y=0$\\
28. $x y^{\prime \prime}+y=0$\\
29. $x y^{\prime \prime}+y^{\prime}+y=0$\\
30. $x y^{\prime \prime}-x y^{\prime}+y=0$\\
31. $x^{2} y^{\prime \prime}+x(x-1) y^{\prime}+y=0$\\
32. $x y^{\prime \prime}+y^{\prime}-4 x y=0$\\
33. $x y^{\prime \prime}+(x-1) y^{\prime}-2 y=0$\\
34. $x y^{\prime \prime}-y^{\prime}+x^{3} y=0$

In Problems 35 and 36 note that $x_{0}=0$ is an irregular singular point of each equation. In each case determine whether the method of Frobenius yields a solution.\\
35. $x^{3} y^{\prime \prime}+y=0 \quad$ 36. $x^{2} y^{\prime \prime}-y^{\prime}+y=0$

\begin{enumerate}
  \setcounter{enumi}{36}
  \item Solve the Cauchy-Euler equation $x^{2} y^{\prime \prime}+3 x y^{\prime}-8 y=0$ by the method of Frobenius.

  \item If $x=0$ is a regular singular point, use (12) in (2) to show that (13) is the indicial equation obtained from the method of Frobenius.

  \item Use (13) to find the indicial equation and exponents of

\end{enumerate}

$$
x^{2} y^{\prime \prime}+\left(\frac{5}{3} x+x^{2}\right) y^{\prime}-\frac{1}{3} y=0
$$

\begin{enumerate}
  \setcounter{enumi}{39}
  \item (a) Show that the differential equation $x^{2} y^{\prime \prime}-4 y=0$ has a singular point at $\infty$. [Hint: See page 263.]
\end{enumerate}

(b) Classify the singular point at $\infty$ as either regular or irregular.

\subsection*{6.5 TWO SPECIAL EQUATIONS \\
 - Bessel's equation - Parametric Bessel equation \\
 Bessel functions \\
 - Legendre's equation $\cdot$ Legendre polynomials}
The two equations


\begin{align*}
x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\nu^{2}\right) y & =0  \tag{1}\\
\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+n(n+1) y & =0
\end{align*}


occur frequently in advanced studies in applied mathematics, physics, and engineering. They are called Bessel's equation and Legendre's equation, respectively.* In solving (1) we shall assume $\nu \geq 0$, whereas in (2) we shall consider only the case when $n$ is a nonnegative integer. Since we seek series solutions of each equation about $x=0$, we observe that the origin is a regular singular point of Bessel's equation, but it is an ordinary point of Legendre's equation.
\footnotetext{\begin{itemize}
  \item FRIEDRICH WILHELM BESSEL (1784-1846) Bessel was a German astronomer who in 1838 was the first to measure the distance to a star (61 Cygni). In 1840 he predicted the existence of a planetary mass beyond the orbit of Uranus. The planet Neptune was discovered six years later. Bessel was also the first person to calculate the orbit of Halley's comet. Although Bessel certainly studied equation (I) in his work on planetary motion, the differential equation and its solution were probably discovered by Daniel Bernoulli in his research on determining the displacements of an oscillating chain.
\end{itemize}

ADRIEN MARIE LEGENDRE (I752-1833) A French mathematician, Legendre is best remembered for spending almost forty years of his life studying and calculating elliptic integrals. However, the particular polynomial solutions of the equation that bears his name were encountered in his studies of gravitation.
}

\subsection*{6.5.1 Solution of Bessel's Equation}
If we assume $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$, then


\begin{align*}
x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\nu^{2}\right) y= & \sum_{n=0}^{\infty} c_{n}(n+r)(n+r-1) x^{n+r}+\sum_{n=0}^{\infty} c_{n}(n+r) x^{n+r}+\sum_{n=0}^{\infty} c_{n} x^{n+r+2}-\nu^{2} \sum_{n=0}^{\infty} c_{n} x^{n+r} \\
= & c_{0}\left(r^{2}-r+r-\nu^{2}\right) x^{r}+x^{r} \sum_{n=1}^{\infty} c_{n}\left[(n+r)(n+r-1)+(n+r)-\nu^{2}\right] x^{n} \\
& +x^{r} \sum_{n=0}^{\infty} c_{n} x^{n+2} \\
= & c_{0}\left(r^{2}-\nu^{2}\right) x^{r}+x^{r} \sum_{n=1}^{\infty} c_{n}\left[(n+r)^{2}-\nu^{2}\right] x^{n}+x^{r} \sum_{n=0}^{\infty} c_{n} x^{n+2} \tag{3}
\end{align*}


From (3) we see that the indicial equation is $r^{2}-\nu^{2}=0$, so the indicial roots are $r_{1}=\nu$ and $r_{2}=-\nu$. When $r_{1}=\nu$, (3) becomes

$$
\begin{aligned}
& x^{\nu} \sum_{n=1}^{\infty} c_{n} n(n+2 \nu) x^{n}+x^{\nu} \sum_{n=0}^{\infty} c_{n} x^{n+2} \\
& \quad=x^{\nu}[(1+2 \nu) c_{1} x+\underbrace{\sum_{n=2}^{\infty} c_{n} n(n+2 \nu) x^{n}}_{k=n-2}+\underbrace{\sum_{n=0}^{\infty} c_{n} x^{n+2}}_{k=n}] \\
& \quad=x^{\nu}\left[(1+2 \nu) c_{1} x+\sum_{k=0}^{\infty}\left[(k+2)(k+2+2 \nu) c_{k+2}+c_{k}\right] x^{k+2}\right]=0
\end{aligned}
$$

Therefore by the usual argument we can write


\begin{align*}
& (1+2 \nu) c_{1}=0 \\
& (k+2)(k+2+2 \nu) c_{k+2}+c_{k}=0 \\
& c_{k+2}=\frac{-c_{k}}{(k+2)(k+2+2 \nu)}, \quad k=0,1,2, \ldots . \tag{4}
\end{align*}


The choice $c_{1}=0$ in (4) implies $c_{3}=c_{5}=c_{7}=\cdots=0$, so for $k=0,2,4, \ldots$ we find, after letting $k+2=2 n, n=1,2,3, \ldots$, that


\begin{equation*}
c_{2 n}=-\frac{c_{2 n-2}}{2^{2} n(n+\nu)} \tag{5}
\end{equation*}


Thus


\begin{align*}
c_{2} & =-\frac{c_{0}}{2^{2} \cdot 1 \cdot(1+\nu)} \\
c_{4} & =-\frac{c_{2}}{2^{2} \cdot 2(2+\nu)}=\frac{c_{0}}{2^{4} \cdot 1 \cdot 2(1+\nu)(2+\nu)} \\
c_{6} & =-\frac{c_{4}}{2^{2} \cdot 3(3+\nu)}=-\frac{c_{0}}{2^{6} \cdot 1 \cdot 2 \cdot 3(1+\nu)(2+\nu)(3+\nu)} \\
& \vdots  \tag{6}\\
c_{2 n} & =\frac{(-1)^{n} c_{0}}{2^{2 n} n!(1+\nu)(2+\nu) \cdots(n+\nu)}, \quad n=1,2,3, \ldots
\end{align*}


It is standard practice to choose $c_{0}$ to be a specific value-namely,

$$
c_{0}=\frac{1}{2^{\nu} \Gamma(1+\nu)}
$$

where $\Gamma(1+\nu)$ is the Gamma function. See Appendix I. Since this latter function possesses the convenient property $\Gamma(1+\alpha)=\alpha \Gamma(\alpha)$, we can reduce the indicated product in the denominator of (6) to one term. For example,

$$
\begin{aligned}
& \Gamma(1+\nu+1)=(1+\nu) \Gamma(1+\nu) \\
& \Gamma(1+\nu+2)=(2+\nu) \Gamma(2+\nu)=(2+\nu)(1+\nu) \Gamma(1+\nu)
\end{aligned}
$$

Hence we can write (6) as

$$
\begin{aligned}
c_{2 n} & =\frac{(-1)^{n}}{2^{2 n+\nu} n!(1+\nu)(2+\nu) \cdots(n+\nu) \Gamma(1+\nu)} \\
& =\frac{(-1)^{n}}{2^{2 n+\nu} n!\Gamma(1+\nu+n)}, \quad n=0,1,2, \cdots
\end{aligned}
$$

It follows that one solution is

$$
y=\sum_{n=0}^{\infty} c_{2 n} x^{2 n+\nu}=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu}
$$

If $\nu \geq 0$, the series converges at least on the interval $[0, \infty)$.

Bessel Functions of the First Kind The foregoing series solution is usually denoted by $J_{\nu}(x)$ :


\begin{equation*}
J_{\nu}(x)=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu} \tag{7}
\end{equation*}


Also, for the second exponent $r_{2}=-\nu$, we obtain, in exactly the same manner,


\begin{equation*}
J_{-\nu}(x)=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1-\nu+n)}\left(\frac{x}{2}\right)^{2 n-\nu} \tag{8}
\end{equation*}


The functions $J_{\nu}(x)$ and $J_{-\nu}(x)$ are called Bessel functions of the first kind of order $\nu$ and $-\nu$, respectively. Depending on the value of $\nu$, (8) may contain negative powers of $x$ and hence converge on $(0, \infty)$.*

Now some care must be taken in writing the general solution of (1). When $\nu=0$, it is apparent that (7) and (8) are the same. If $\nu>0$ and $r_{1}-r_{2}=$ $\nu-(-\nu)=2 \nu$ is not a positive integer, it follows from Case I of Section 6.4 that $J_{\nu}(x)$ and $J_{-\nu}(x)$ are linearly independent solutions of (1) on $(0, \infty)$, and so the general solution on the interval would be $y=c_{1} J_{\nu}(x)+c_{2} J_{-\nu}(x)$. But we also know from Case II of Section 6.4 that when $r_{1}-r_{2}=2 \nu$ is a positive integer, a second series solution of (1) may exist. In this second case we distinguish two possibilities. When $\nu=m=$ positive integer, $J_{-m}(x)$ defined by (8) and $J_{m}(x)$ are not linearly independent solutions. It can be shown that $J_{-m}$ is a constant multiple of $J_{m}$ (see Property ( $i$ ) on page 269). In addition, $r_{1}-r_{2}=2 \nu$ can be a positive integer when $\nu$ is
\footnotetext{\begin{itemize}
  \item If we replace $x$ by $|x|$, the series given in (7) and (8) converge for $0<|x|<\infty$.
\end{itemize}
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-293}
\end{center}

Figure 6.6 half an odd positive integer. It can be shown in this latter event that $J_{\nu}(x)$ and $J_{-\nu}(x)$ are linearly independent. In other words, the general solution of $(1)$ on $(0, \infty)$ is


\begin{equation*}
y=c_{1} J_{\nu}(x)+c_{2} J_{-\nu}(x), \quad \nu \neq \text { integer. } \tag{9}
\end{equation*}


The graphs of $y=J_{0}(x)$ and $y=J_{1}(x)$ are given in Figure 6.6. Observe that the graphs of $J_{0}$ and $J_{1}$ resemble damped cosine and sine graphs, respectively.*

\section*{EXAMPLE 1 General Solution: $\boldsymbol{v}$ Not an Integer}
Find the general solution of the equation $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{1}{4}\right) y=0$ on $(0, \infty)$.

Solution We identify $\nu^{2}=\frac{1}{4}$ and so $\nu=\frac{1}{2}$. From (9) we see that the general solution of the differential equation is $y=c_{1} J_{1 / 2}(x)+c_{2} J_{-1 / 2}(x)$.

Bessel Functions of the Second Kind If $\nu \neq$ integer, the function defined by the linear combination


\begin{equation*}
Y_{\nu}(x)=\frac{\cos \nu \pi J_{\nu}(x)-J_{-\nu}(x)}{\sin \nu \pi} \tag{10}
\end{equation*}


and the function $J_{\nu}(x)$ are linearly independent solutions of (1). Thus another form of the general solution of (1) is $y=c_{1} J_{\nu}(x)+c_{2} Y_{\nu}(x)$, provided $\nu \neq$ integer. As $\nu \rightarrow m, m$ an integer, (10) has the indeterminate form $0 / 0$. However, it can be shown by L'Hôpital's rule that $\lim _{\nu \rightarrow m} Y_{\nu}(x)$ exists. Moreover, the function

$$
Y_{m}(x)=\lim _{\nu \rightarrow m} Y_{\nu}(x)
$$

and $J_{m}(x)$ are linearly independent solutions of $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-m^{2}\right) y=0$. Hence for any value of $\nu$ the general solution of (1) on $(0, \infty)$ can be written as


\begin{equation*}
y=c_{1} J_{\nu}(x)+c_{2} Y_{\nu}(x) \tag{11}
\end{equation*}


$Y_{\nu}(x)$ is sometimes called Neumann's function; $\dagger$ more commonly, $Y_{\nu}(x)$ is called the Bessel function of the second kind of order $\nu$. Figure 6.7 shows the graphs of $Y_{0}(x)$ and $Y_{1}(x)$.

\section*{EXAMPLE 2 General Solution: $\boldsymbol{v}$ an Integer}
Find the general solution of the equation $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-9\right) y=0$ on $(0, \infty)$.
\footnotetext{\begin{itemize}
  \item Bessel functions belong to a class of functions that are called "almost periodic."
\end{itemize}

$\dagger$ The function in (10) is also denoted by $N_{\nu}(x)$ in honor of the German mathematician C. Neumann (1832-1925), who investigated its properties.
}

Solution Since $\nu^{2}=9$, we identify $\nu=3$. It follows from (11) that the general solution of the differential equation is $y=c_{1} J_{3}(x)+c_{2} Y_{3}(x)$.

Parametric Bessel Equation By replacing $x$ by $\lambda x$ in (1) and using the chain rule, we obtain an alternative form of Bessel's equation known as the parametric Bessel equation:


\begin{equation*}
x^{2} y^{\prime \prime}+x y^{\prime}+\left(\lambda^{2} x^{2}-\nu^{2}\right) y=0 \tag{12}
\end{equation*}


The general solution of (12) is


\begin{equation*}
y=c_{1} J_{\nu}(\lambda x)+c_{2} Y_{\nu}(\lambda x) . \tag{13}
\end{equation*}


Properties We list below a few of the more useful properties of Bessel functions of order $m, m=0,1,2, \ldots$ :

$$
\begin{aligned}
& \text { (i) } J_{-m}(x)=(-1)^{m} J_{m}(x) \\
& \text { (ii) } J_{m}(-x)=(-1)^{m} J_{m}(x) \\
& \text { (iii) } J_{m}(0)= \begin{cases}0, & m>0 \\
1, & m=0\end{cases} \\
& \text { (iv) } \lim _{x \rightarrow 0^{+}} Y_{m}(x)=-\infty
\end{aligned}
$$

Note that Property (ii) indicates $J_{m}(x)$ is an even function if $m$ is an even integer and an odd function if $m$ is an odd integer. The graphs of $Y_{0}(x)$ and $Y_{1}(x)$ in Figure 6.7 illustrate Property (iv): $Y_{m}(x)$ is unbounded at the origin. This last fact is not obvious from (10). It can be shown either from (10) or by the methods of Section 6.4 that for $x>0$,

$$
Y_{0}(x)=\frac{2}{\pi} J_{0}(x)\left[\gamma+\ln \frac{x}{2}\right]-\frac{2}{\pi} \sum_{k=1}^{\infty} \frac{(-1)^{k}}{(k!)^{2}}\left(1+\frac{1}{2}+\cdots+\frac{1}{k}\right)\left(\frac{x}{2}\right)^{2 k}
$$

where $\gamma=0.57721566 \ldots$ is Euler's constant. Observe that because of the presence of the logarithmic term, $Y_{0}(x)$ is discontinuous at $x=0$.

Numerical Values Some functional values of $J_{0}(x), J_{1}(x), Y_{0}(x)$, and $Y_{1}(x)$ for selected values of $x$ are given in Table 6.1. The first five nonnegative zeros of $J_{0}(x), J_{1}(x), Y_{0}(x)$, and $Y_{1}(x)$ are given in Table 6.2.

Table 6.1 Numerical Values of $J_{0}, J_{1}, Y_{0}$, and $Y_{1}$

\begin{center}
\begin{tabular}{rrrrr}
\hline
$\boldsymbol{x}$ & \multicolumn{1}{c}{$\boldsymbol{J}_{\mathbf{0}}(\boldsymbol{x})$} & \multicolumn{1}{l}{$\boldsymbol{J}_{\mathbf{1}}(\boldsymbol{x})$} & \multicolumn{1}{c}{$\boldsymbol{Y}_{\mathbf{0}}(\boldsymbol{x})$} & \multicolumn{1}{c}{$\boldsymbol{Y}_{\mathbf{1}}(\boldsymbol{x})$} \\
\hline
0 & 1.0000 & 0.0000 & - & - \\
1 & 0.7652 & 0.4401 & 0.0883 & -0.7812 \\
2 & 0.2239 & 0.5767 & 0.5104 & -0.1070 \\
3 & -0.2601 & 0.3391 & 0.3769 & 0.3247 \\
4 & -0.3971 & -0.0660 & -0.0169 & 0.3979 \\
5 & -0.1776 & -0.3276 & -0.3085 & 0.1479 \\
6 & 0.1506 & -0.2767 & -0.2882 & -0.1750 \\
7 & 0.3001 & -0.0047 & -0.0259 & -0.3027 \\
8 & 0.1717 & 0.2346 & 0.2235 & -0.1581 \\
9 & -0.0903 & 0.2453 & 0.2499 & 0.1043 \\
10 & -0.2459 & 0.0435 & 0.0557 & 0.2490 \\
11 & -0.1712 & -0.1768 & -0.1688 & 0.1637 \\
12 & 0.0477 & -0.2234 & -0.2252 & -0.0571 \\
13 & 0.2069 & -0.0703 & -0.0782 & -0.2101 \\
14 & 0.1711 & 0.1334 & 0.1272 & -0.1666 \\
15 & -0.0142 & 0.2051 & 0.2055 & 0.0211 \\
\hline
\end{tabular}
\end{center}

Table 6.2 Zeros of $J_{0}, J_{1}, Y_{0}$, and $Y_{1}$

\begin{center}
\begin{tabular}{rrrr}
\hline
\multicolumn{1}{c}{$\boldsymbol{J}_{\mathbf{0}}(\boldsymbol{x})$} & \multicolumn{1}{c}{$\boldsymbol{J}_{\mathbf{1}}(\boldsymbol{x})$} & \multicolumn{1}{c}{$\boldsymbol{Y}_{\mathbf{0}}(\boldsymbol{x})$} & \multicolumn{1}{c}{$\boldsymbol{Y}_{\mathbf{1}}(\boldsymbol{x})$} \\
\hline
 &  &  &  \\
2.4048 & 0.0000 & 0.8936 & 2.1971 \\
5.5201 & 3.8317 & 3.9577 & 5.4297 \\
8.6537 & 7.0156 & 7.0861 & 8.5960 \\
11.7915 & 10.1735 & 10.2223 & 11.7492 \\
14.9309 & 13.3237 & 13.3611 & 14.8974 \\
\hline
\end{tabular}
\end{center}

Recurrence Relation Recurrence formulas that relate Bessel functions of different orders are important in theory and in applications. In the next example we derive a differential recurrence relation.

\section*{EXAMPLE 3 Derivation Using the Series Definition}
Derive the formula $x J_{\nu}^{\prime}(x)=\nu J_{\nu}(x)-x J_{\nu+1}(x)$.

Solution It follows from (7) that

$$
\begin{aligned}
x J_{\nu}(x) & =\sum_{n=0}^{\infty} \frac{(-1)^{n}(2 n+\nu)}{n!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu} \\
& =\nu \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu}+2 \sum_{n=0}^{\infty} \frac{(-1)^{n} n}{n!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu} \\
& =\nu J_{v}(x)+x \underbrace{\infty}_{k=n-1} \frac{(-1)^{n}}{(n-1)!\Gamma(1+\nu+n)}\left(\frac{x}{2}\right)^{2 n+\nu-1} \\
& =\nu J_{\nu}(x)-x \sum_{k=0}^{\infty} \frac{(-1)^{k}}{k!\Gamma(2+\nu+k)}\left(\frac{x}{2}\right)^{2 k+\nu+1} \\
& =\nu J_{\nu}(x)-x J_{\nu+1}(x)
\end{aligned}
$$

The result in Example 3 can be written in an alternative form. Dividing $x J_{\nu}^{\prime}(x)-\nu J_{\nu}(x)=-x J_{\nu+1}(x)$ by $x$ gives

$$
J_{\nu}^{\prime}(x)-\frac{\nu}{x} J_{\nu}(x)=-J_{\nu+1}(x)
$$

This last expression is recognized as a linear first-order differential equation in $J_{v}(x)$. Multiplying both sides of the equality by the integrating factor $x^{-\nu}$ then yields


\begin{equation*}
\frac{d}{d x}\left[x^{-\nu} J_{\nu}(x)\right]=-x^{-\nu} J_{\nu+1}(x) \text {. } \tag{14}
\end{equation*}


We leave it as an exercise to derive a similar formula:


\begin{equation*}
\frac{d}{d x}\left[x^{\nu} J_{\nu}(x)\right]=x^{\nu} J_{\nu-1}(x) \tag{15}
\end{equation*}


(See Problem 20.)

When $\nu=$ half an odd integer, $J_{\nu}(x)$ can be expressed in terms of $\sin x$, $\cos x$, and powers of $x$. Such Bessel functions are called spherical Bessel functions.

EXAMPLE 4 Spherical Bessel Function: $\boldsymbol{v}=\frac{1}{2}$

Find an alternative expression for $J_{1 / 2}(x)$. Use the fact that $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$.

Solution With $\nu=\frac{1}{2}$, we have from (7)

$$
J_{1 / 2}(x)=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma\left(1+\frac{1}{2}+n\right)}\left(\frac{x}{2}\right)^{2 n+1 / 2}
$$

Now in view of the property $\Gamma(1+\alpha)=\alpha \Gamma(\alpha)$ we obtain

$$
\begin{aligned}
& n=0, \quad \Gamma\left(1+\frac{1}{2}\right)=\frac{1}{2} \Gamma\left(\frac{1}{2}\right)=\frac{1}{2} \sqrt{\pi} \\
& n=1, \quad \Gamma\left(1+\frac{3}{2}\right)=\frac{3}{2} \Gamma\left(\frac{3}{2}\right)=\frac{3}{2^{2}} \sqrt{\pi} \\
& n=2, \quad \Gamma\left(1+\frac{5}{2}\right)=\frac{5}{2} \Gamma\left(\frac{5}{2}\right)=\frac{5 \cdot 3}{2^{3}} \sqrt{\pi}=\frac{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1}{2^{3} 4 \cdot 2} \sqrt{\pi}=\frac{5!}{2^{5} 2!} \sqrt{\pi} \\
& n=3, \quad \Gamma\left(1+\frac{7}{2}\right)=\frac{7}{2} \Gamma\left(\frac{7}{2}\right)=\frac{7 \cdot 5!}{2^{6} 2!} \sqrt{\pi}=\frac{7 \cdot 6 \cdot 5!}{2^{6} \cdot 6 \cdot 2!} \sqrt{\pi}=\frac{7!}{2^{7} 3!} \sqrt{\pi} \\
& \text { In general, } \quad \Gamma\left(1+\frac{1}{2}+n\right)=\frac{(2 n+1)!}{2^{2 n+1} n!} \sqrt{\pi} .
\end{aligned}
$$

Hence

$$
J_{1 / 2}(x)=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\frac{(2 n+1)!\sqrt{\pi}}{2^{2 n+1} n!}}\left(\frac{x}{2}\right)^{2 n+1 / 2}=\sqrt{\frac{2}{\pi x}} \sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n+1)!} x^{2 n+1}
$$

Since the series in the last line is the Maclaurin series for $\sin x$, we have shown that

$$
J_{1 / 2}(x)=\sqrt{\frac{2}{\pi x}} \sin x
$$

\subsection*{6.5.2 Solution of LegENDRE's EquATIon}
Since $x=0$ is an ordinary point of equation (2), we assume a solution of the form $y=\sum_{k=0}^{\infty} c_{k} x^{k}$. Therefore

$$
\begin{aligned}
& \left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+n(n+1) y=\left(1-x^{2}\right) \sum_{k=0}^{\infty} c_{k} k(k-1) x^{k-2}-2 \sum_{k=0}^{\infty} c_{k} k x^{k}+n(n+1) \sum_{k=0}^{\infty} c_{k} x^{k} \\
& =\sum_{k=2}^{\infty} c_{k} k(k-1) x^{k-2}-\sum_{k=2}^{\infty} c_{k} k(k-1) x^{k}-2 \sum_{k=1}^{\infty} c_{k} k x^{k}+n(n+1) \sum_{k=0}^{\infty} c_{k} x^{k} \\
& =\left[n(n+1) c_{0}+2 c_{2}\right] x^{0}+\left[n(n+1) c_{1}-2 c_{1}+6 c_{3}\right] x \\
& +\underbrace{\sum_{k=4}^{\infty} c_{k} k(k-1) x^{k-2}}_{j=k-2}-\underbrace{\sum_{k=2}^{\infty} c_{k} k(k-1) x^{k}}_{j=k}-2 \underbrace{\sum_{k=2}^{\infty} c_{k} k x^{k}}_{j=k}+n(n+1) \underbrace{\sum_{k=2}^{\infty} c_{k} x^{k}}_{j=k} \\
& =\left[n(n+1) c_{0}+2 c_{2}\right]+\left[(n-1)(n+2) c_{1}+6 c_{3}\right] x \\
& +\sum_{j=2}^{\infty}\left[(j+2)(j+1) c_{j+2}+(n-j)(n+j+1) c_{j}\right] x^{j}=0
\end{aligned}
$$

implies that

$$
\left.\begin{array}{rl}
n(n+1) c_{0}+2 c_{2} & =0 \\
(n-1)(n+2) c_{1}+6 c_{3} & =0
\end{array}\right]
$$

Iterating (16) gives

$$
\begin{aligned}
c_{4} & =-\frac{(n-2)(n+3)}{4 \cdot 3} c_{2}=\frac{(n-2) n(n+1)(n+3)}{4!} c_{0} \\
c_{5} & =-\frac{(n-3)(n+4)}{5 \cdot 4} c_{3}=\frac{(n-3)(n-1)(n+2)(n+4)}{5!} c_{1} \\
c_{6} & =-\frac{(n-4)(n+5)}{6 \cdot 5} c_{4}=-\frac{(n-4)(n-2) n(n+1)(n+3)(n+5)}{6!} c_{0} \\
c_{7} & =-\frac{(n-5)(n+6)}{7 \cdot 6} c_{5} \\
& =-\frac{(n-5)(n-3)(n-1)(n+2)(n+4)(n+6)}{7!} c_{1}
\end{aligned}
$$

and so on. Thus for at least $|x|<1$, we obtain two linearly independent power series solutions.


\begin{align*}
& y_{1}(x)=c_{0}\left[1-\frac{n(n+1)}{2!} x^{2}+\frac{(n-2) n(n+1)(n+3)}{4!} x^{4}\right. \\
&\left.-\frac{(n-4)(n-2) n(n+1)(n+3)(n+5)}{6!} x^{6}+\cdots\right]  \tag{1}\\
& y_{2}(x)=c_{1}\left[x-\frac{(n-1)(n+2)}{3!} x^{3}+\frac{(n-3)(n-1)(n+2)(n+4)}{5!} x^{5}\right. \\
&\left.-\frac{(n-5)(n-3)(n-1)(n+2)(n+4)(n+6)}{7!} x^{7}+\cdots\right]
\end{align*}


Notice that if $n$ is an even integer, the first series terminates, whereas $y_{2}(x)$ is an infinite series. For example, if $n=4$, then

$$
y_{1}(x)=c_{0}\left[1-\frac{4 \cdot 5}{2!} x^{2}+\frac{2 \cdot 4 \cdot 5 \cdot 7}{4!} x^{4}\right]=c_{0}\left[1-10 x^{2}+\frac{35}{3} x^{4}\right]
$$

Similarly, when $n$ is an odd integer, the series for $y_{2}(x)$ terminates with $x^{n}$; that is, when $n$ is a nonnegative integer we obtain an nth-degree polynomial solution of Legendre's equation.

Since we know that a constant multiple of a solution of Legendre's equation is also a solution, it is traditional to choose specific values for $c_{0}$ and $c_{1}$, depending on whether $n$ is an even or odd positive integer, respectively. For $n=0$ we choose $c_{0}=1$ and for $n=2,4,6, \ldots$

$$
c_{0}=(-1)^{n / 2} \frac{1 \cdot 3 \cdots(n-1)}{2 \cdot 4 \cdots n}
$$

whereas for $n=1$ we choose $c_{1}=1$ and for $n=3,5,7, \ldots$

$$
c_{1}=(-1)^{(n-1) / 2} \frac{1 \cdot 3 \cdots n}{2 \cdot 4 \cdots(n-1)}
$$

For example, when $n=4$, we have

$$
\begin{aligned}
y_{1}(x) & =(-1)^{4 / 2} \frac{1 \cdot 3}{2 \cdot 4}\left[1-10 x^{2}+\frac{35}{3} x^{4}\right] \\
& =\frac{3}{8}-\frac{30}{8} x^{2}+\frac{35}{8} x^{4} \\
& =\frac{1}{8}\left(35 x^{4}-30 x^{2}+3\right)
\end{aligned}
$$

Legendre Polynomials These specific $n$ th-degree polynomial solutions are called Legendre polynomials and are denoted by $P_{n}(x)$. From the series for $y_{1}(x)$ and $y_{2}(x)$ and from the above choices of $c_{0}$ and $c_{1}$, we find that the first several Legendre polynomials are

\[
\begin{array}{ll}
P_{0}(x)=1, & P_{1}(x)=x \\
P_{2}(x)=\frac{1}{2}\left(3 x^{2}-1\right), & P_{3}(x)=\frac{1}{2}\left(5 x^{3}-3 x\right),  \tag{18}\\
P_{4}(x)=\frac{1}{8}\left(35 x^{4}-30 x^{2}+3\right), & P_{5}(x)=\frac{1}{8}\left(63 x^{5}-70 x^{3}+15 x\right)
\end{array}
\]

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-298}
\end{center}

Figure 6.8

Remember, $P_{0}(x), P_{1}(x), P_{2}(x), P_{3}(x), \ldots$ are, in turn, particular solutions of the differential equations

\[
\begin{array}{ll}
n=0, & \left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}=0 \\
n=1, & \left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+2 y=0  \tag{19}\\
n=2, & \left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+6 y=0 \\
n=3, & \left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+12 y=0
\end{array}
\]

The graphs of the first four Legendre polynomials on the interval $-1 \leq x \leq 1$ are given in Figure 6.8.

Properties The following properties of the Legendre polynomials are apparent in (18) and Figure 6.8:

$$
\text { (i) } P_{n}(-x)=(-1)^{n} P_{n}(x)
$$

$$
\begin{array}{ll}
\text { (ii) } P_{n}(1)=1 & \text { (iii) } P_{n}(-1)=(-1)^{n} \\
\text { (iv) } P_{n}(0)=0, n \text { odd } & \text { (v) } P_{n}^{\prime}(0)=0, n \text { even }
\end{array}
$$

Property ( $i$ ) indicates that $P_{n}(x)$ is an even or odd function according to whether $n$ is even or odd.

Recurrence Relation Recurrence relations that relate Legendre polynomials of different degrees are also very important in some aspects of their application. We shall derive one such relation using the formula


\begin{equation*}
\left(1-2 x t+t^{2}\right)^{-1 / 2}=\sum_{n=0}^{\infty} P_{n}(x) t^{n} \tag{20}
\end{equation*}


The function on the left is called a generating function for the Legendre polynomials. Its derivation follows from the binomial theorem and is left as an exercise. (See Problem 43.)

Differentiating both sides of (20) with respect to $t$ gives

$$
\left(1-2 x t+t^{2}\right)^{-3 / 2}(x-t)=\sum_{n=0}^{\infty} n P_{n}(x) t^{n-1}=\sum_{n=1}^{\infty} n P_{n}(x) t^{n-1}
$$

so after multiplying by $1-2 x t+t^{2}$, we have


\begin{gather*}
(x-t)\left(1-2 x t+t^{2}\right)^{-1 / 2}=\left(1-2 x t+t^{2}\right) \sum_{n=1}^{\infty} n P_{n}(x) t^{n-1} \\
(x-t) \sum_{n=0}^{\infty} P_{n}(x) t^{n}=\left(1-2 x t+t^{2}\right) \sum_{n=1}^{\infty} n P_{n}(x) t^{n-1} \tag{21}
\end{gather*}


We multiply out and rewrite (21) as

$$
\begin{array}{r}
\sum_{n=0}^{\infty} x P_{n}(x) t^{n}-\sum_{n=0}^{\infty} P_{n}(x) t^{n+1}-\sum_{n=1}^{\infty} n P_{n}(x) t^{n-1}+2 x \sum_{n=1}^{\infty} n P_{n}(x) t^{n}-\sum_{n=1}^{\infty} n P_{n}(x) t^{n+1}=0 \\
\text { or } x+x^{2} t+\sum_{n=2}^{\infty} x P_{n}(x) t^{n}-t-\sum_{n=1}^{\infty} P_{n}(x) t^{n+1}-x-2\left(\frac{3 x^{2}-1}{2}\right) t \\
-\sum_{n=3}^{\infty} n P_{n}(x) t^{n-1}+2 x^{2} t+2 x \sum_{n=2}^{\infty} n P_{n}(x) t^{n}-\sum_{n=1}^{\infty} n P_{n}(x) t^{n+1}=0
\end{array}
$$

Observing the appropriate cancellations, simplifying, and changing the summation indices gives

$$
\sum_{k=2}^{\infty}\left[-(k+1) P_{k+1}(x)+(2 k+1) x P_{k}(x)-k P_{k-1}(x)\right] t^{k}=0
$$

Equating the total coefficient of $t^{k}$ to zero gives the three-term recurrence relation


\begin{equation*}
(k \cdots 1) P_{n},(x) \quad(2 k+1) x P_{k}(x)+k P_{k}(x)=0 . \quad k=2 \ldots 3+\cdots \tag{22}
\end{equation*}


This formula is also valid when $k=1$.

In (18) we listed the first six Legendre polynomials. If, say, we wish to find $P_{6}(x)$, we could use (22) with $k=5$. This relation then expresses $P_{6}(x)$ in terms of the known quantities $P_{4}(x)$ and $P_{5}(x)$. (See Problem 45.)

\section*{EXERCISES 6.5}
Answers to odd-numbered problems begin on page $A-13$.

\subsection*{6.5.I Solution of Bessel's Equation}
In Problems 1-8 find the general solution of the given differential equation on $(0, \infty)$

$\begin{array}{ll}\text { 1. } x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\frac{1}{9}\right) y=0 & \text { 2. } x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-1\right) y=0\end{array}$\\
3. $4 x^{2} y^{\prime \prime}+4 x y^{\prime}+\left(4 x^{2}-25\right) y=0$\\
4. $16 x^{2} y^{\prime \prime}+16 x y^{\prime}+\left(16 x^{2}-1\right) y=0$\\
5. $x y^{\prime \prime}+y^{\prime}+x y=0$\\
6. $\frac{d}{d x}\left[x y^{\prime}\right]+\left(x-\frac{4}{x}\right) y=0$\\
7. $x^{2} y^{\prime \prime}+x y^{\prime}+\left(9 x^{2}-4\right) y=0$\\
8. $x^{2} y^{\prime \prime}+x y^{\prime}+\left(36 x^{2}-\frac{1}{4}\right) y=0$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item Use the change of variables $y=x^{-1 / 2} v(x)$ to find the general solution of the equation
\end{enumerate}

$$
x^{2} y^{\prime \prime}+2 x y^{\prime}+\lambda^{2} x^{2} y=0, \quad x>0
$$

\begin{enumerate}
  \setcounter{enumi}{9}
  \item Verify that the differential equation
\end{enumerate}

$$
x y^{\prime \prime}+(1-2 n) y^{\prime}+x y=0, \quad x>0
$$

possesses the particular solution $y=x^{n} J_{n}(x)$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item Verify that the differential equation
\end{enumerate}

$$
x y^{\prime \prime}+(1+2 n) y^{\prime}+x y=0, \quad x>0
$$

possesses the particular solution $y=x^{-n} J_{n}(x)$.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item Verify that the differential equation
\end{enumerate}

$$
x^{2} y^{\prime \prime}+\left(\lambda^{2} x^{2}-\nu^{2}+\frac{1}{4}\right) y=0, \quad x>0
$$

possesses the particular solution $y=\sqrt{x} J_{\nu}(\lambda x)$, where $\lambda>0$.

In Problems 13-18 use the results of Problems 10, 11, and 12 to find a particular solution of the given differential equation on $(0, \infty)$.\\
13. $y^{\prime \prime}+y=0$\\
14. $x y^{\prime \prime}-y^{\prime}+x y=0$\\
15. $x y^{\prime \prime}+3 y^{\prime}+x y=0$\\
16. $4 x^{2} y^{\prime \prime}+\left(16 x^{2}+1\right) y=0$\\
17. $x^{2} y^{\prime \prime}+\left(x^{2}-2\right) y=0$\\
18. $x y^{\prime \prime}-5 y^{\prime}+x y=0$

In Problems 19-22 derive the given recurrence relation.\\
19. $x J_{\nu}^{\prime}(x)=-\nu J_{\nu}(x)+x J_{\nu-1}(x) \quad[$ Hint: $2 n+\nu=2(n+\nu)-\nu$.]\\
20. $\frac{d}{d x}\left[x^{\nu} J_{\nu}(x)\right]=x^{\nu} J_{v-1}(x)$\\
21. $2 \nu J_{\nu}(x)=x J_{\nu+1}(x)+x J_{v-1}(x)$\\
22. $2 J_{\nu}^{\prime}(x)=J_{\nu-1}(x)-J_{\nu+1}(x)$

In Problems 23-26 use (14) or (15) to obtain the given result.\\
23. $\int_{0}^{x} r J_{0}(r) d r=x J_{1}(x)$\\
24. $J_{0}^{\prime}(x)=J_{-1}(x)=-J_{1}(x)$\\
25. $\int x^{n} J_{0}(x) d x=x^{n} J_{1}(x)+(n-1) x^{n-1} J_{0}(x)-(n-1)^{2} \int x^{n-2} J_{0}(x) d x$\\
26. $\int x^{3} J_{0}(x) d x=x^{3} J_{1}(x)+2 x^{2} J_{0}(x)-4 x J_{1}(x)+c$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item Proceed as in Example 4 and express $J_{-1 / 2}(x)$ in terms of $\cos x$ and a power of $x$.
\end{enumerate}

In Problems 28-33 use the recurrence relation given in Problem 21 and the results obtained in Problem 27 and Example 4 to express the given Bessel function in terms of $\sin x, \cos x$, and powers of $x$.\\
28. $J_{3 / 2}(x)$\\
29. $J_{-3 / 2}(x)$\\
30. $J_{5 / 2}(x)$\\
31. $J_{-5 / 2}(x)$\\
32. $J_{7,2}(x)$\\
33. $J_{-7 / 2}(x)$

\begin{enumerate}
  \setcounter{enumi}{33}
  \item Show that $i^{-\nu} J_{\nu}(i x), i^{2}=-1$ is a real function. The function defined by $I_{\nu}(x)=i^{-\nu} J_{\nu}(i x)$ is called a modified Bessel function of the first kind of order $\nu$.

  \item Find the general solution of the differential equation

\end{enumerate}

$$
x^{2} y^{\prime \prime}+x y^{\prime}-\left(x^{2}+\nu^{2}\right) y=0, \quad x>0, \quad \nu \neq \text { integer. }
$$

[Hint: $\left.i^{2} x^{2}=-x^{2}.\right]$

\begin{enumerate}
  \setcounter{enumi}{35}
  \item If $y_{1}=J_{0}(x)$ is one solution of the zero-order Bessel equation, verify that another solution is
\end{enumerate}

$$
y_{2}=J_{0}(x) \ln x+\frac{x^{2}}{4}-\frac{3 x^{4}}{128}+\frac{11 x^{6}}{13,824}-\cdots
$$

\begin{enumerate}
  \setcounter{enumi}{36}
  \item Use (8) with $\nu=m$, where $m$ is a positive integer, and the fact that $1 / \Gamma(N)=0$, where $N$ is a negative integer, to show that
\end{enumerate}

$$
J_{-m}(x)=(-1)^{m} J_{m}(x)
$$

\begin{enumerate}
  \setcounter{enumi}{37}
  \item Use (7) with $\nu=m$, where $m$ is a nonnegative integer, to show that
\end{enumerate}

$$
J_{m}(-x)=(-1)^{m} J_{m}(x)
$$

\subsection*{6.5.2 Solution of Legendre's Equation}
\begin{enumerate}
  \setcounter{enumi}{38}
  \item (a) Use the explicit solutions $y_{1}(x)$ and $y_{2}(x)$ of Legendre's equation and the appropriate choices of $c_{0}$ and $c_{1}$ to find the Legendre polynomials $P_{6}(x)$ and $P_{7}(x)$.
\end{enumerate}

(b) Write the differential equations for which $P_{6}(x)$ and $P_{7}(x)$ are particular solutions.

\begin{enumerate}
  \setcounter{enumi}{39}
  \item Show that Legendre's equation has an alternative form
\end{enumerate}

$$
\frac{d}{d x}\left[\left(1-x^{2}\right) \frac{d y}{d x}\right]+n(n+1) y=0
$$

\begin{enumerate}
  \setcounter{enumi}{40}
  \item Show that the equation
\end{enumerate}

$$
\sin \theta \frac{d^{2} y}{d \theta^{2}}+\cos \theta \frac{d y}{d \theta}+n(n+1)(\sin \theta) y=0
$$

can be transformed into Legendre's equation by means of the substitution $x=\cos \theta$.

\begin{enumerate}
  \setcounter{enumi}{41}
  \item The general Legendre polynomial can be written as
\end{enumerate}

$$
P_{n}(x)=\sum_{k=0}^{[n / 2]} \frac{(-1)^{k}(2 n-2 k)!}{2^{n} k!(n-k)!(n-2 k)!} x^{n-2 k}
$$

where $[n / 2]$ is the greatest integer not greater than $n / 2$. Verify the results for $n=0,1,2,3,4,5$.

\begin{enumerate}
  \setcounter{enumi}{42}
  \item Use binomial series to formally show that
\end{enumerate}

$$
\left(1-2 x t+t^{2}\right)^{-1 / 2}=\sum_{n=0}^{\infty} P_{n}(x) t^{n}
$$

\begin{enumerate}
  \setcounter{enumi}{43}
  \item Use Problem 43 to show that $P_{n}(1)=1$ and $P_{n}(-1)=(-1)^{n}$.

  \item Use the recurrence relation (22) and $P_{0}(x)=1, P_{1}(x)=x$ to generate the next five Legendre polynomials.

  \item The Legendre polynomials are also generated by Rodrigues' formula*

\end{enumerate}

$$
P_{n}(x)=\frac{1}{2^{n} n!} \frac{d^{n}}{d x^{n}}\left(x^{2}-1\right)^{n}
$$

Verify the results for $n=0,1,2,3$.

\begin{enumerate}
  \setcounter{enumi}{46}
  \item Use the explicit Legendre polynomials $P_{0}(x), P_{1}(x), P_{2}(x)$, and $P_{3}(x)$ to evaluate $\int_{-1}^{1} P_{n}^{2}(x) d x$ for $n=0,1,2,3$. Generalize the results.

  \item Use the explicit Legendre polynomials $P_{0}(x), P_{1}(x), P_{2}(x)$, and $P_{3}(x)$ to evaluate $\int_{-1}^{1} P_{n}(x) P_{m}(x) d x$ for $n \neq m$. Generalize the results.

  \item We know that $y_{1}=x$ is a solution of Legendre's equation when $n=1,\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+2 y=0$. Show that a second linearly independent solution on the interval $-1<x<1$ is

\end{enumerate}

$$
y_{2}=\frac{x}{2} \ln \left(\frac{1+x}{1-x}\right)-1
$$

\section*{CHAPTER 6 REVIEW}
The remarkable characteristic of a Cauchy-Euler equation is that even though it is a differential equation with variable coefficients, it can be solved in terms of elementary functions. A second-order Cauchy-Euler equation is any differential
\footnotetext{\begin{itemize}
  \item ONLINDE RODRIGUES (1794-1851) Rodrigues was a French banker and amateur mathematician. In mathematics he is remembered solely for the discovery of this one formula in 1816. In politics he is remembered as the financial backer and disciple of Count de Saint-Simon, the founder of French socialism.
\end{itemize}
}
equation of the form $a x^{2} y^{\prime \prime}+b x y^{\prime}+c y=g(x)$, where $a, b$, and $c$ are constants. To solve the homogeneous equation we try a solution of the form $y=x^{m}$ and this in turn leads to an algebraic auxiliary equation $\operatorname{am}(m-1)+b m+c=0$. Accordingly, when the roots are real and distinct, real and equal, or complex conjugates, the general solutions on the interval $(0, \infty)$ are, respectively,

and

$$
\begin{aligned}
& y=c_{1} x^{m_{1}}+c_{2} x^{m_{2}} \\
& y=c_{1} x^{m_{1}}+c_{2} x^{m_{1}} \ln x \\
& y=x^{\alpha}\left[c_{1} \cos (\beta \ln x)+c_{2} \sin (\beta \ln x)\right] .
\end{aligned}
$$

We say that $x=0$ is an ordinary point of the linear second-order differential equation $a_{2}(x) y^{\prime \prime}+a_{1}(x) y^{\prime}+a_{0}(x) y=0$ when $a_{2}(0) \neq 0$ and $a_{2}(x), a_{1}(x)$, $a_{0}(x)$ are polynomials having no common factors. Every solution has the form of a power series in $x, y=\sum_{n=0}^{\infty} c_{n} x^{n}$. To find the coefficients $c_{n}$ we substitute the basic assumption into the differential equation, and after appropriate algebraic manipulations we determine a recurrence relation by equating to zero the combined total coefficient of $x^{k}$. Iteration of the recurrence relation yields two distinct sets of coefficients, one set containing the arbitrary coefficient $c_{0}$ and the other containing $c_{1}$. Using each set of coefficients, we form two linearly independent solutions $y_{1}(x)$ and $y_{2}(x)$. A solution is valid at least on an interval defined by $|x|<R$, where $R$ is the distance from $x=0$ to the closest singular point of the equation. If $a_{2}(0)=0$, then $x=0$ is a singular point. Singular points are classified as either regular or irregular. To determine whether $x=0$ is a regular singular point, we examine the denominators of the rational functions $P$ and $Q$ that result when the equation is put into the form $y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=0$. It is understood that $a_{1}(x) / a_{2}(x)$ and $a_{0}(x) / a_{2}(x)$ are reduced to lowest terms. If $x$ appears at most to the first power in the denominator of $P(x)$ and at most to the second power in the denominator of $Q(x)$ then $x=0$ is a regular singular point. Around the regular singular point $x=0$, the method of Frobenius guarantees that there exists at least one solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$. The exponent $r$ is a root of a quadratic indicial equation. When the indicial roots $r_{1}$ and $r_{2}\left(r_{1}>r_{2}\right)$ satisfy $r_{1}-r_{2} \neq$ an integer, then we can always find two linearly independent solutions of the assumed form. When $r_{1}-r_{2}=$ a positive integer, then we could possibly find two solutions, but when $r_{1}-r_{2}=0$, or $r_{1}=r_{2}$, we can find only one solution of the form $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$.

Bessel's equation $x^{2} y^{\prime \prime}+x y^{\prime}+\left(x^{2}-\nu^{2}\right) y=0$ has a regular singular point at $x=0$, whereas $x=0$ is an ordinary point of Legendre's equation $\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+n(n+1) y=0$. The latter equation possesses a polynomial solution when $n$ is a nonnegative integer.

CHAPTER 6 REVIEW EXERCISES

\section*{Answers to odd-numbered problems begin on page A-15.}
In Problems 1-4 solve the given Cauchy-Euler equation.

\begin{enumerate}
  \item $6 x^{2} y^{\prime \prime}+5 x y^{\prime}-y=0$

  \item $2 x^{3} y^{\prime \prime \prime}+19 x^{2} y^{\prime \prime}+39 x y^{\prime}+9 y=0$\\
$\begin{array}{ll}\text { 3. } x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=2 x^{4}+x^{2} & \text { 4. } x^{2} y^{\prime \prime}-x y^{\prime}+y=x^{3}\end{array}$

  \item Specify the ordinary points of $\left(x^{3}-8\right) y^{\prime \prime}-2 x y^{\prime}+y=0$.

  \item Specify the singular points of $\left(x^{4}-16\right) y^{\prime \prime}+2 y=0$.

\end{enumerate}

In Problems $7-10$ specify the regular and irregular singular points of the given differential equation.

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $\left(x^{3}-10 x^{2}+25 x\right) y^{\prime \prime}+y^{\prime}=0 \quad$ 8. $\left(x^{3}-10 x^{2}+25 x\right) y^{\prime \prime}+y=0$

  \item $x^{2}\left(x^{2}-9\right)^{2} y^{\prime \prime}-\left(x^{2}-9\right) y^{\prime}+x y=0$

  \item $x\left(x^{2}+1\right)^{3} y^{\prime \prime}+y^{\prime}-8 x y=0$

\end{enumerate}

In Problems 11 and 12 specify an interval around $x=0$ for which a power series solution of the given differential equation will converge.\\
11. $y^{\prime \prime}-x y^{\prime}+6 y=0$\\
12. $\left(x^{2}-4\right) y^{\prime \prime}-2 x y^{\prime}+9 y=0$

In Problems 13-16 for each differential equation find two power series solutions about the ordinary point $x=0$.\\
13. $y^{\prime \prime}+x y=0$\\
14. $y^{\prime \prime}-4 y=0$\\
15. $(x-1) y^{\prime \prime}+3 y=0$\\
16. $y^{\prime \prime}-x^{2} y^{\prime}+x y=0$

In Problems 17-22 find two linearly independent solutions of each equation.\\
17. $2 x^{2} y^{\prime \prime}+x y^{\prime}-(x+1) y=0$\\
18. $2 x y^{\prime \prime}+y^{\prime}+y=0$\\
19. $x(1-x) y^{\prime \prime}-2 y^{\prime}+y=0$\\
20. $x^{2} y^{\prime \prime}-x y^{\prime}+\left(x^{2}+1\right) y=0$\\
21. $x y^{\prime \prime}-(2 x-1) y^{\prime}+(x-1) y=0$\\
22. $x^{2} y^{\prime \prime}-x^{2} y^{\prime}+\left(x^{2}-2\right) y=0$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item Without referring to Section 6.5 use the method of Frobenius to obtain a solution of the Bessel equation for $\nu=0: x y^{\prime \prime}+y^{\prime}+x y=0$.
\end{enumerate}

\section*{LAPLACE TRANSFORM}
\subsection*{7.1 Laplace Transform}
7.2 Inverse Transform

7.3 Translation Theorems and Derivatives of a Transform

7.4 Transforms of Derivatives, Integrals, and Periodic Functions

7.5 Applications

7.6 Dirac Delta Function

Chapter 7 Review

Chapter 7 Review Exercises

In this chapter we examine the definition and properties of an integral known as the Laplace transform.

We shall see in Section 7.5 that when the Laplace transform is applied to a linear $n$ th-order differential equation with constant coefficients

$$
a_{n} \frac{d^{n} y}{d t^{n}}+a_{n-1} \frac{d^{n-1} y}{d t^{n-1}}+\cdots+a_{1} \frac{d y}{d t}+a_{0} y=g(t)
$$

the differential equation is transformed into an algebraic equation that involves the conditions $y(0), y^{\prime}(0), y^{\prime \prime}(0), \ldots, y^{(n-1)}(0)$. As a consequence of this property, the Laplace transform is well suited to the solution of certain kinds of initial-value problems.

Recall that in physical systems such as as a spring-mass system or a series electrical circuit, the right-hand member in the differential equations

$$
\begin{gathered}
m \frac{d^{2} x}{d t^{2}}+\beta \frac{d x}{d t}+k x=f(t) \\
L \frac{d^{2} q}{d t^{2}}+R \frac{d q}{d t}+\frac{1}{C} q=E(t)
\end{gathered}
$$

is a driving function and represents either an external force $f(t)$ or an impressed voltage $E(t)$. In Chapter 5 we solved problems in which the functions $f$ and $E$ were continuous. However, piecewise continuous driving\\
functions are not uncommon. For example, the impressed voltage on a circuit could be

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-306}
\end{center}

In this case, solving the differential equation of the circuit is difficult but not impossible. The Laplace transform is an invaluable aid in solving problems such as these.

\subsection*{7.1 LAPLACE TRANSFORM \\
 - Linear operation \\
 $\bullet$ Laplace transform \\
 - Linear transform \\
 - Piecewise continuons - Exponential order}
In elementary calculus you learned that differentiation and integration transform a function into another function. For example, the function $f(x)=x^{2}$ is transformed, in turn, into a linear function, a family of cubic polynomial functions, and a constant by the operations of differentiation, indefinite integration, and definite integration:

$$
\frac{d}{d x} x^{2}=2 x, \quad \int x^{2} d x=\frac{x^{3}}{3}+c, \quad \int_{0}^{3} x^{2} d x=9
$$

Moreover, these three operations possess the linearity property. This means that for any constants $\alpha$ and $\beta$,


\begin{gather*}
\frac{d}{d x}[\alpha f(x)+\beta g(x)]=\alpha \frac{d}{d x} f(x)+\beta \frac{d}{d x} g(x) \\
\int[\alpha f(x)+\beta g(x)] d x=\alpha \int f(x) d x+\beta \int g(x) d x  \tag{1}\\
\int_{a}^{b}[\alpha f(x)+\beta g(x)] d x=\alpha \int_{a}^{b} f(x) d x+\beta \int_{a}^{b} g(x) d x
\end{gather*}


provided each derivative and integral exists.

If $f(x, y)$ is a function of two variables, then a definite integral of $f$ with respect to one of the variables leads to a function of the other variable. For example, by holding $y$ constant we see that $\int_{1}^{2} 2 x y^{2} d x=3 y^{2}$. Similarly, a definite integral such as $\int_{a}^{b} K(s, t) f(t) d t$ transforms a function $f(t)$ into a function of the variable $s$. We are particularly interested in integral transforms of this last kind, where the interval of integration is the unbounded interval $[0, \infty)$.

Basic Definition If $f(t)$ is defined for $t \geq 0$, then the improper integral $\int_{0}^{\infty} K(s, t) f(t) d t$ is defined by means of a limit:

$$
\int_{0}^{\infty} K(s, t) f(t) d t=\lim _{b \rightarrow \infty} \int_{0}^{b} K(s, t) f(t) d t
$$

If the limit exists, the integral exists or is convergent; if the limit does not exist, the integral does not exist and is said to be divergent. The foregoing limit will, in general, exist for only certain values of the variable $s$. The choice $K(s, t)=$ $e^{-s t}$ gives us an especially important integral transform.

\section*{DEFINITION 7.1 Laplace Transform}
Let $f$ be a function defined for $t \geq 0$. Then the integral


\begin{equation*}
\mathscr{L}\{f(t)\}=\int_{0}^{\infty} e^{-s t} f(t) d t \tag{2}
\end{equation*}


is said to be the Laplace transform* of $f$ provided the integral converges.

When the defining integral (2) converges, the result is a function of $s$. In general discussion, we shall use a lowercase letter to denote the function being transformed and the corresponding capital letter to denote its Laplace transform; for example,

$$
\mathscr{L}\{f(t)\}=F(s), \quad \mathscr{L}\{g(t)\}=G(s), \quad \mathscr{L}\{y(t)\}=Y(s)
$$

\section*{EXAMPLE 1 Applying Definition 7.1}
Evaluate $\mathscr{L}\{1\}$.

Solution

$$
\begin{aligned}
\mathscr{L}\{1\} & =\int_{0}^{\infty} e^{-s t}(1) d t=\lim _{b \rightarrow \infty} \int_{0}^{b} e^{-s t} d t \\
& =\left.\lim _{b \rightarrow \infty} \frac{-e^{-s t}}{s}\right|_{0} ^{b}=\lim _{b \rightarrow \infty} \frac{-e^{-s b}+1}{s} \\
& =\frac{1}{s}
\end{aligned}
$$
\footnotetext{*PIERRE SIMON MARQUIS DE LAPLACE (1749-1827) A noted mathematician, physicist, and astronomer, Laplace was called by some of his enthusiastic contemporaries the "Newton of France." Although Laplace made use of the integral transform (2) in his work in probability theory, it is likely that the integral was first discovered by Euler Laplace's noted treatises were Mécanique Céleste and Théorie Analytique des Probabilités. Born into a poor farming family, Laplace became a friend of Napoleon but was elevated to the nobility by Louis XVIII after the Restoration.
}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-308(1)}
\end{center}

Figure 7.1

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-308(2)}
\end{center}

Figure 7.2

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-308(4)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-308(3)}
\end{center}

(b)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-308}
\end{center}

(c) provided $s>0$. In other words, when $s>0$, the exponent $-s b$ is negative and $e^{-s b} \rightarrow 0$ as $b \rightarrow \infty$. When $s<0$, the integral is divergent.

The use of the limit sign becomes somewhat tedious, so we shall adopt the notation $\mid{ }_{0}^{\infty}$ as a shorthand to writing $\lim _{b \rightarrow \infty}() \mid{ }_{0}^{b}$. For example,

$$
\mathscr{L}\{1\}=\int_{0}^{\infty} e^{-s t} d t=\left.\frac{-e^{-s t}}{s}\right|_{0} ^{\infty}=\frac{1}{s}, \quad s>0
$$

where it is understood that at the upper limit we mean $e^{-s t} \rightarrow 0$ as $t \rightarrow \infty$ for $s>0$.

$\mathscr{L}$ a Linear Transform For a sum of functions we can write

$$
\int_{0}^{\infty} e^{-s t}[\alpha f(t)+\beta g(t)] d t=\alpha \int_{0}^{\infty} e^{-s t} f(t) d t+\beta \int_{0}^{\infty} e^{-s t} g(t) d t
$$

whenever both integrals converge. Hence it follows that


\begin{equation*}
\mathscr{L}\{\alpha f(t)+\beta g(t)\}=\alpha \mathscr{L}\{f(t)\}+\beta \mathscr{L}\{g(t)\}=\alpha F(s)+\beta G(s) . \tag{3}
\end{equation*}


Because of the property given in (3), $\mathscr{L}$ is said to be a linear transform, or linear operator.

Sufficient Conditions for Existence of $\mathscr{L}\{f(t)\} \quad$ The integral that defines the Laplace transform does not have to converge. For example, neither $\mathscr{L}\{1 / t\}$ nor $\mathscr{L}\left\{e^{t^{2}}\right\}$ exists. Sufficient conditions that guarantee the existence of $\mathscr{L}\{f(t)\}$ are that $f$ be piecewise continuous on $[0, \infty)$ and that $f$ be of exponential order for $t>T$. Recall that a function $f$ is piecewise continuous on $[0, \infty)$ if, in any interval $0 \leq a \leq t \leq b$, there are at most a finite number of points $t_{k}, k=1,2, \ldots, n\left(t_{k-1}<t_{k}\right)$ at which $f$ has finite discontinuities and is continuous on each open interval $t_{k-1}<t<t_{k}$. See Figure 7.1. The concept of exponential order is defined in the following manner.

DEFINITION 7.2 Exponential Order

A function $f$ is said to be of exponential order if there exist numbers $c$, $M>0$, and $T>0$ such that $|f(t)| \leq M e^{c t}$ for $t>T$.

If, for example, $f$ is an increasing function, then the condition $|f(t)| \leq M e^{c t}, t>T$ simply states that the graph of $f$ on the interval $(T, \infty)$ does not grow faster than the graph of the exponential function $M e^{c t}$, where $c$ is a positive constant. See Figure 7.2. The functions $f(t)=t, f(t)=e^{-t}$, and $f(t)=2 \cos t$ are all of exponential order for $t>0$ since we have, respectively,

$$
|t| \leq e^{t}, \quad\left|e^{-t}\right| \leq e^{t}, \quad|2 \cos t| \leq 2 e^{t}
$$

A comparison of the graphs on the interval $(0, \infty)$ is given in Figure 7.3 .

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-309}
\end{center}

Figure 7.4\\
A function such as $f(t)=e^{t^{2}}$ is not of exponential order since, as shown in Figure 7.4, its graph grows faster than any positive linear power of $e$ for $t>c>0$.

A positive integral power of $t$ is always of exponential order since, for $c>0$,

$$
\left|t^{n}\right| \leq M e^{c t} \quad \text { or } \quad\left|\frac{t^{n}}{e^{c t}}\right| \leq M \quad \text { for } t>T
$$

is equivalent to showing that $\lim _{t \rightarrow \infty} t^{n} / e^{c t}$ is finite for $n=1,2,3, \ldots$ The result follows by $n$ applications of L'Hôpital's rule.

\section*{THEOREM 7.1 Sufficient Conditions for Existence}
Let $f(t)$ be piecewise continuous on the interval $[0, \infty)$ and of exponential order for $t>T$; then $\mathscr{L}\{f(t)\}$ exists for $s>c$.

Proof $\mathscr{L}\{f(t)\}=\int_{0}^{T} e^{-s t} f(t) d t+\int_{T}^{\infty} e^{-s t} f(t) d t=I_{1}+I_{2}$.

The integral $I_{1}$ exists because it can be written as a sum of integrals over intervals for which $e^{-s t} f(t)$ is continuous. Now

$$
\begin{aligned}
\left|I_{2}\right| & \leq \int_{T}^{\infty}\left|e^{-s t} f(t)\right| d t \leq M \int_{T}^{\infty} e^{-s t} e^{c t} d t \\
& =M \int_{T}^{\infty} e^{-(s-c) t} d t=-\left.M \frac{e^{-(s-c) t}}{s-c}\right|_{T} ^{\infty}=M \frac{e^{-(s-c) T}}{s-c}
\end{aligned}
$$

for $s>c$. Since $\int_{T}^{\infty} M e^{-(s-c) t} d t$ converges, the integral $\int_{T}^{\infty}\left|e^{-s t} f(t)\right| d t$ converges by the comparison test for improper integrals. This, in turn, implies that $I_{2}$ exists for $s>c$. The existence of $I_{1}$ and $I_{2}$ implies that $\mathscr{L}\{f(t)\}=$ $\int_{0}^{\infty} e^{-s t} f(t) d t$ exists for $s>c$.

Throughout this entire chapter we shall be concerned only with functions that are both piecewise continuous and of exponential order. We note, however, that these conditions are sufficient but not necessary for the existence of a Laplace transform. The function $f(t)=t^{-1 / 2}$ is not piecewise continuous on the interval $[0, \infty)$, but its Laplace transform exists. See Problem 44.

\section*{EXAMPLE 2 Applying Definition 7.I}
Evaluate $\mathscr{L}\{t\}$.

Solution From Definition 7.1 we have

$$
\mathscr{L}\{t\}=\int_{0}^{\infty} e^{-s t} t d t
$$

Integrating by parts and using $\lim _{t \rightarrow \infty} t e^{-s t}=0, s>0$, along with the result of Example 1, we obtain

$$
\mathscr{L}\{t\}=\left.\frac{-t e^{-s t}}{s}\right|_{0} ^{\infty}+\frac{1}{s} \int_{0}^{\infty} e^{-s t} d t=\frac{1}{s} \mathscr{L}\{1\}=\frac{1}{s}\left(\frac{1}{s}\right)=\frac{1}{s^{2}}
$$

\section*{EXAMPLE 3 Applying Definition 7.1}
Evaluate $\mathscr{L}\left\{e^{-3 r}\right\}$.

Solution From Definition 7.1 we have

$$
\begin{aligned}
\mathscr{L}\left\{e^{-3 t}\right\} & =\int_{0}^{\infty} e^{-s t} e^{-3 t} d t \\
& =\int_{0}^{\infty} e^{-(s+3) t} d t \\
& =\left.\frac{-e^{-(s+3) t}}{s+3}\right|_{0} ^{\infty} \\
& =\frac{1}{s+3}, \quad s>-3 .
\end{aligned}
$$

The result follows from the fact that $\lim _{t \rightarrow \infty} e^{-(s+3) t}=0$ for $s+3>0$ or $s>-3$.

\section*{EXAMPLE 4 Applying Definition 7.I}
Evaluate $\mathscr{L}\{\sin 2 t\}$.

Solution From Definition 7.1 and integration by parts we have

$$
\begin{aligned}
\mathscr{L}\{\sin 2 t\} & =\int_{0}^{\infty} e^{-s t} \sin 2 t d t \\
& =\left.\frac{-e^{-s t} \sin 2 t}{s}\right|_{0} ^{\infty}+\frac{2}{s} \int_{0}^{\infty} e^{-s t} \cos 2 t d t \\
& =\frac{2}{s} \int_{0}^{\infty} e^{-s t} \cos 2 t d t, \quad s>0 \\
& =\frac{2}{s}\left[\left.\frac{-e^{-s t} \cos 2 t}{s}\right|_{0} ^{\infty}-\frac{2}{s} \int_{0}^{\infty} e^{-s t} \sin 2 t d t\right] \\
& =\frac{2}{s^{2}}-\frac{4}{s^{2}} \mathscr{L}\{\sin 2 t\} . \quad \quad \underset{\lim }{t \rightarrow \infty} e^{-s t} \cos 2 t=0, s>0
\end{aligned}
$$

Now we solve for $\mathscr{L}\{\sin 2 t\}$ :

$$
\begin{aligned}
{\left[1+\frac{4}{s^{2}}\right] \mathscr{L}\{\sin 2 t\} } & =\frac{2}{s^{2}} \\
\mathscr{L}\{\sin 2 t\} & =\frac{2}{s^{2}+4}, \quad s>0
\end{aligned}
$$

\section*{EXAMPLE 5 Using Linearity}
Evaluate $\mathscr{L}\{3 t-5 \sin 2 t\}$.

Solution From Examples 2 and 4 and the linearity property of the Laplace transform we can write

$$
\begin{aligned}
\mathscr{L}\{3 t-5 \sin 2 t\} & =3 \mathscr{L}\{t\}-5 \mathscr{L}\{\sin 2 t\} \\
& =3 \cdot \frac{1}{s^{2}}-5 \cdot \frac{2}{s^{2}+4} \\
& =\frac{-7 s^{2}+12}{s^{2}\left(s^{2}+4\right)}, \quad s>0
\end{aligned}
$$

\section*{EXAMPLE 6 Applying Definition 7.1}
Evaluate (a) $\mathscr{L}\left\{t e^{-2 t}\right\}$ and (b) $\mathscr{L}\left\{t^{2} e^{-2 t}\right\}$.

\section*{Solution}
(a) From Definition 7.1 and integration by parts we have

$$
\begin{aligned}
\mathscr{L}\left\{t e^{-2 t}\right\} & =\int_{0}^{\infty} e^{-s t}\left(t e^{-2 t}\right) d t \\
& =\int_{0}^{\infty} t e^{-(s+2) t} d t \\
& =\left.\frac{-t e^{-(s+2) t}}{s+2}\right|_{0} ^{\infty}+\frac{1}{s+2} \int_{0}^{\infty} e^{-(s+2) t} d t \\
& =\left.\frac{-e^{-(s+2) t}}{(s+2)^{2}}\right|_{0} ^{\infty}, \quad s>-2 \\
& =\frac{1}{(s+2)^{2}}, \quad s>-2 .
\end{aligned}
$$

(b) Again, integration by parts gives

$$
\begin{aligned}
\mathscr{L}\left\{t^{2} e^{-2 r}\right\} & =\left.\frac{-t^{2} e^{-(s+2) t}}{s+2}\right|_{0} ^{\infty}+\frac{2}{s+2} \int_{0}^{\infty} t e^{-(s+2) t} d t \\
& =\frac{2}{s+2} \int_{0}^{\infty} e^{-s t}\left(t e^{-2 t}\right) d t, \quad s>-2 \\
& =\frac{2}{s+2} \mathscr{L}\left\{t e^{-2 t}\right\}=\frac{2}{s+2}\left[\frac{1}{(s+2)^{2}}\right] \leftarrow \text { from part (a) } \\
& =\frac{2}{(s+2)^{3}}, \quad s>-2 .
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-312}
\end{center}

Figure 7.5

\section*{EXAMPLE 7 Transform of a Piecewise-Defined Function}
Evaluate $\mathscr{L}\{f(t)\}$ for $f(t)=\left\{\begin{array}{lr}0, & 0 \leq t<3 \\ 2, & t \geq 3\end{array}\right.$

Solution This piecewise continuous function is shown in Figure 7.5. Since $f$ is defined in two pieces, $\mathscr{L}\{f(t)\}$ is expressed as the sum of two integrals:

$$
\begin{aligned}
\mathscr{L}\{f(t)\}=\int_{0}^{\infty} e^{-s t} f(t) d t & =\int_{0}^{3} e^{-s t}(0) d t+\int_{3}^{\infty} e^{-s t}(2) d t \\
& =-\left.\frac{2 e^{-s t}}{s}\right|_{3} ^{\infty} \\
& =\frac{2 e^{-3 s}}{s}, \quad s>0
\end{aligned}
$$

We state the generalization of some of the preceding examples by means of the next theorem. From this point on we shall also refrain from stating any restrictions on $s$; it is understood that $s$ is sufficiently restricted to guarantee the convergence of the appropriate Laplace transform.

\section*{THEOREM 7.2 Transforms of Some Basic Functions}
(a) $\mathscr{L}\{1\}=\frac{1}{s}$\\
(b) $\mathscr{L}\left\{t^{n}\right\}=\frac{n!}{s^{n+1}}, \quad n=1,2,3, \ldots$\\
(c) $\mathscr{L}\left\{e^{a r}\right\}=\frac{1}{s-a}$\\
(d) $\mathscr{L}\{\sin k t\}=\frac{k}{s^{2}+k^{2}}$\\
(e) $\mathscr{L}\{\cos k t\}=\frac{s}{s^{2}+k^{2}}$\\
(f) $\mathscr{L}\{\sinh k t\}=\frac{k}{s^{2}-k^{2}}$\\
(g) $\mathscr{L}\{\cosh k t\}=\frac{s}{s^{2}-k^{2}}$

Part (b) of Theorem 7.2 can be justified in the following manner: Integration by parts yields

$$
\begin{gathered}
\mathscr{L}\left\{t^{n}\right\}=\int_{0}^{\infty} e^{-s t} t^{n} d t=-\left.\frac{1}{s} e^{-s t} t^{n}\right|_{0} ^{\infty}+\frac{n}{s} \int_{0}^{\infty} e^{-s t} t^{n-1} d t=\frac{n}{s} \int_{0}^{\infty} e^{-s t} t^{n-1} d t \\
\mathscr{L}\left\{t^{n}\right\}=\frac{n}{s} \mathscr{L}\left\{t^{n-1}\right\}, \quad n=1,2,3, \ldots
\end{gathered}
$$

or

Now $\mathscr{L}\{1\}=1 / s$, so it follows by recursion that

$$
\begin{aligned}
\mathscr{L}\{t\} & =\frac{1}{s} \mathscr{L}\{1\}=\frac{2}{s^{2}} \\
\mathscr{L}\left\{t^{2}\right\} & =\frac{2}{s} \mathscr{L}\{t\}=\frac{2}{s}\left(\frac{1}{s^{2}}\right)=\frac{2!}{s^{3}} \\
\mathscr{L}\left\{t^{3}\right\} & =\frac{3}{s} \mathscr{L}\left\{t^{2}\right\}=\frac{3}{s}\left(\frac{2}{s^{3}}\right)=\frac{3!}{s^{4}}
\end{aligned}
$$

Although a rigorous proof requires mathematical induction, it seems reasonable to conclude from the foregoing results that in general

$$
\mathscr{L}\left\{t^{n}\right\}=\frac{n}{s} \mathscr{L}\left\{t^{n-1}\right\}=\frac{n}{s}\left[\frac{(n-1)!}{s^{n}}\right]=\frac{n!}{s^{n+1}}
$$

The justifications of parts (f) and (g) of Theorem 7.2 are left to you. See Problems 33 and 34 .

\section*{EXAMPLE 8 Trigonometric Identity and Linearity}
Evaluate $\mathscr{L}\left\{\sin ^{2} t\right\}$.

Solution With the aid of a trigonometric identity, linearity, and parts (a) and (e) of Theorem 7.2, we obtain

$$
\begin{aligned}
\mathscr{L}\left\{\sin ^{2} t\right\} & =\mathscr{L}\left\{\frac{1-\cos 2 t}{2}\right\}=\frac{1}{2} \mathscr{L}\{1\}-\frac{1}{2} \mathscr{L}\{\cos 2 t\} \\
& =\frac{1}{2} \cdot \frac{1}{s}-\frac{1}{2} \cdot \frac{s}{s^{2}+4} \\
& =\frac{2}{s\left(s^{2}+4\right)} .
\end{aligned}
$$

\section*{EXERCISES 7.1}
Answers to odd-numbered problems begin on page A-15.

In Problems 1-18 use Definition 7.1 to find $\mathscr{L}\{f(t)\}$.

\begin{enumerate}
  \item $f(t)=\left\{\begin{array}{rr}-1, & 0 \leq t<1 \\ 1, & t \geq 1\end{array} \quad\right.$ 2. $f(t)=\left\{\begin{array}{rr}4, & 0 \leq t<2 \\ 0, & t \geq 2\end{array}\right.$
  \item $f(t)=\left\{\begin{array}{rr}t, & 0 \leq t<1 \\ 1, & t \geq 1\end{array}\right.$
  \item $f(t)=\left\{\begin{array}{lr}2 t+1, & 0 \leq t<1 \\ 0, & t \geq 1\end{array}\right.$
  \item $f(t)=\left\{\begin{array}{lr}\sin t, & 0 \leq t<\pi \\ 0, & t \geq \pi\end{array}\right.$
  \item $f(t)=\left\{\begin{array}{lr}0, & 0 \leq t<\pi / 2 \\ \cos t, & t \geq \pi / 2\end{array}\right.$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-313(2)}
\end{center}

Figure 7.6

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-313(1)}
\end{center}

Figure 7.7

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-313}
\end{center}

Figure 7.8\\
10. $f(t)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-313(3)}
\end{center}

Figure 7.9\\
11. $f(t)=e^{t+7}$\\
12. $f(t)=e^{-2 i-5}$\\
13. $f(t)=t e^{4 t}$\\
14. $f(t)=t^{2} e^{3 t}$\\
15. $f(t)=e^{-t} \sin t$\\
16. $f(t)=e^{t} \cos t$\\
17. $f(t)=t \cos t$\\
18. $f(t)=t \sin t$

In Problems 19-42 use Theorem 7.2 to find $\mathscr{L}\{f(t)\}$.\\
19. $f(t)=2 t^{4}$\\
20. $f(t)=t^{5}$\\
21. $f(t)=4 t-10$\\
22. $f(t)=7 t+3$\\
23. $f(t)=t^{2}+6 t-3$\\
24. $f(t)=-4 t^{2}+16 t+9$\\
25. $f(t)=(t+1)^{3}$\\
26. $f(t)=(2 t-1)^{3}$\\
27. $f(t)=1+e^{4 t}$\\
28. $f(t)=t^{2}-e^{-9 t}+5$\\
29. $f(t)=\left(1+e^{2 t}\right)^{2}$\\
30. $f(t)=\left(e^{t}-e^{-t}\right)^{2}$\\
31. $f(t)=4 t^{2}-5 \sin 3 t$\\
32. $f(t)=\cos 5 t+\sin 2 t$\\
33. $f(t)=\sinh k t$\\
34. $f(t)=\cosh k t$\\
35. $f(t)=e^{t} \sinh t$\\
36. $f(t)=e^{-t} \cosh t$\\
37. $f(t)=\sin 2 t \cos 2 t$\\
38. $f(t)=\cos ^{2} t$\\
39. $f(t)=\cos t \cos 2 t$\\
[Hint: Examine $\left.\cos \left(t_{1} \pm t_{2}\right).\right]$\\
40. $f(t)=\sin t \sin 2 t$\\
41. $f(t)=\sin t \cos 2 t \quad\left[\right.$ Hint: Examine $\sin \left(t_{1} \pm t_{2}\right)$ ]\\
42. $f(t)=\sin ^{3} t \quad\left[\right.$ Hint: $\sin ^{3} t=\sin t \sin ^{2} t$.]\\
43. The gamma function is defined by the integral

$$
\Gamma(\alpha)=\int_{0}^{\infty} t^{\alpha-1} e^{-t} d t, \quad \alpha>0
$$

See Appendix I. Show that $\mathscr{L}\left\{t^{\alpha}\right\}=\frac{\Gamma(\alpha+1)}{s^{\alpha+1}}, \alpha>-1$.

In Problems 44-46 use the result of Problem 43 to find $\mathscr{L}\{f(t)\}$.\\
44. $f(t)=t^{-1 / 2}$\\
45. $f(t)=t^{1 / 2}$\\
46. $f(t)=t^{3 / 2}$

\begin{enumerate}
  \setcounter{enumi}{46}
  \item Show that the function $f(t)=1 / t^{2}$ does not possess a Laplace transform.
\end{enumerate}

$\left\{\right.$ Hint: $\mathscr{L}\{f(t)\}=\int_{0}^{1} e^{-s t} f(t) d t+\int_{1}^{\infty} e^{-s t} f(t) d t$. Use the definition of an improper integral to show that $\int_{0}^{1} e^{-s t} f(t) d t$ does not exist.]

\begin{enumerate}
  \setcounter{enumi}{47}
  \item Show that if the functions $f$ and $g$ are of exponential order for $t>T$, then the product fg is of exponential order for $t>T$.
\end{enumerate}

\subsection*{7.2 INVERSE TRANSFORM \\
 - Inverse Laplace transform \\
 - Use of partial fractions}
In the preceding section we were concerned with the problem of transforming a function $f(t)$ into another function $F(s)$ by means of the integral $\int_{0}^{\infty} e^{-s t} f(t) d t$. We denoted this symbolically by $\mathscr{L}\{f(t)\}=F(s)$. We now turn the problem around; namely, given $F(s)$, find the function $f(t)$ corresponding to this transform. We say $f(t)$ is the inverse Laplace transform of $F(s)$ and write

$$
f(t)=\mathscr{L}^{-1}\{F(s)\}
$$

The analogue of Theorem 7.2 for the inverse transform is the following:

\section*{THEOREM 7.3 Some Inverse Transforms}
(a) $1=\mathscr{L}^{-1}\left\{\frac{1}{s}\right\}$\\
(b) $t^{n}=\mathscr{L}^{-1}\left\{\frac{n!}{s^{n+1}}\right\}, n=1,2,3, \ldots$\\
(c) $e^{a t}=\mathscr{L}^{-1}\left\{\frac{1}{s-a}\right\}$\\
(d) $\sin k t=\mathscr{L}^{-1}\left\{\frac{k}{s^{2}+k^{2}}\right\}$\\
(e) $\cos k t=\mathscr{L}^{-1}\left\{\frac{s}{s^{2}+k^{2}}\right\}$\\
(f) $\sinh k t=\mathscr{L}^{-1}\left\{\frac{k}{s^{2}-k^{2}}\right\}$\\
(g) $\cosh k t=\mathscr{L}^{-1}\left\{\frac{s}{s^{2}-k^{2}}\right\}$

$\mathscr{L}^{-1}$ a Linear Transform We shall assume that the inverse Laplace transform is itself a linear transform;* that is, for constants $\alpha$ and $\beta$,

$$
\mathscr{L}^{-1}\{\alpha F(s)+\beta G(s)\}=\alpha \mathscr{L}^{-1}\{F(s)\}+\beta \mathscr{L}^{-1}\{G(s)\}
$$

where $F$ and $G$ are the transforms of some functions $f$ and $g$.

The inverse Laplace transform of a function $F(s)$ may not be unique. It is possible that $\mathscr{L}\left\{f_{1}(t)\right\}=\mathscr{L}\left\{f_{2}(t)\right\}$ and yet $f_{1} \neq f_{2}$. See Problems 35 and 36 . For our purposes this is not as bad as it appears. If $f_{1}$ and $f_{2}$ are piecewise continuous on $[0, \infty)$ and of exponential order for $t>0$ and if $\mathscr{L}\left\{f_{1}(t)\right\}=\mathscr{L}\left\{f_{2}(t)\right\}$, then it can be proved that the functions $f_{1}$ and $f_{2}$ are essentially the same; that is, they can differ only at points of discontinuity. However, if $f_{1}$ and $f_{2}$ are continuous on $[0, \infty)$ and $\mathscr{L}\left\{f_{1}(t)\right\}=\mathscr{L}\left\{f_{2}(t)\right\}$, then $f_{1}=f_{2}$ on the interval.

\section*{EXAMPLEI Applying Theorem 7.3}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{s^{5}}\right\}$.
\footnotetext{\begin{itemize}
  \item The inverse Laplace transform is actually another integral. However, evaluation of this integral demands the use of complex variables, which is beyond the scope of this text.
\end{itemize}
}

Solution To match the form given in part (b) of Theorem 7.3, we identify $n=4$ and then multiply and divide by 4 !. It follows that

$$
\mathscr{L}^{-1}\left\{\frac{1}{s^{5}}\right\}=\frac{1}{4!} \mathscr{L}^{-1}\left\{\frac{4!}{s^{5}}\right\}=\frac{1}{24} t^{4}
$$

\section*{EXAMPLE 2 Applying Theorem 7.3}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{s^{2}+64}\right\}$.

Solution Identifying $k^{2}=64$, we multiply and divide by 8 and use part (d) of Theorem 7.3:

$$
\mathscr{L}^{-1}\left\{\frac{1}{s^{2}+64}\right\}=\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{8}{s^{2}+64}\right\}=\frac{1}{8} \sin 8 t
$$

\section*{EXAMPLE 3 Termwise Division and Linearity}
Evaluate $\mathscr{L}^{-1}\left\{\frac{3 s+5}{s^{2}+7}\right\}$

Solution The given function of $s$ can be written as two expressions by means of termwise division:

$$
\frac{3 s+5}{s^{2}+7}=\frac{3 s}{s^{2}+7}+\frac{5}{s^{2}+7}
$$

From the linearity property of the inverse transform and parts (e) and (d) of Theorem 7.3 , we then have

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{3 s+5}{s^{2}+7}\right\} & =3 \mathscr{L}^{-1}\left\{\frac{s}{s^{2}+7}\right\}+\frac{5}{\sqrt{7}} \mathscr{L}^{-1}\left\{\frac{\sqrt{7}}{s^{2}+7}\right\} \\
& =3 \cos \sqrt{7} t+\frac{5}{\sqrt{7}} \sin \sqrt{7} t
\end{aligned}
$$

Partial Fractions The use of partial fractions is very important in finding inverse Laplace transforms. Here we review three basic cases of that theory. For example, the denominators of

(i) $F(s)=\frac{1}{(s-1)(s+2)(s+4)} \quad$ (ii) $F(s)=\frac{s+1}{s^{2}(s+2)^{3}} \quad$ (iii) $F(s)=\frac{3 s-2}{s^{3}\left(s^{2}+4\right)}$

contain, respectively, only distinct linear factors, repeated linear factors, and a quadratic factor that is irreducible.*
\footnotetext{\begin{itemize}
  \item Irreducible means that the quadratic factor has no real zeros.
\end{itemize}
}

\section*{EXAMPLE 4 Partial Fractions: Distinct Linear Factors}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{(s-1)(s+2)(s+4)}\right\}$.

Solution There exist unique constants $A, B$, and $C$ so that

$$
\begin{aligned}
\frac{1}{(s-1)(s+2)(s+4)} & =\frac{A}{s-1}+\frac{B}{s+2}+\frac{C}{s+4} \\
& =\frac{A(s+2)(s+4)+B(s-1)(s+4)+C(s-1)(s+2)}{(s-1)(s+2)(s+4)}
\end{aligned}
$$

Since the denominators are identical, the numerators are identical:

$$
1=A(s+2)(s+4)+B(s-1)(s+4)+C(s-1)(s+2)
$$

By comparing coefficients of powers of $s$ on both sides of the equality, we know that the last equation is equivalent to a system of three equations in the three unknowns $A, B$, and $C$. However, you might recall the following shortcut for determining these unknowns. If we set $s=1, s=-2$, and $s=-4$, the zeros of the common denominator $(s-1)(s+2)(s+4)$, we obtain, in turn,

$$
\begin{array}{ll}
1=A(3)(5), & A=\frac{1}{15} \\
1=B(-3)(2), & B=-\frac{1}{6} \\
1=C(-5)(-2), & C=\frac{1}{10}
\end{array}
$$

Hence we can write

$$
\frac{1}{(s-1)(s+2)(s+4)}=\frac{1 / 15}{s-1}-\frac{1 / 6}{s+2}+\frac{1 / 10}{s+4}
$$

and thus, from part (c) of Theorem 7.3,

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{1}{(s-1)(s+2)(s+4)}\right\} & =\frac{1}{15} \mathscr{L}^{-1}\left\{\frac{1}{s-1}\right\}-\frac{1}{6} \mathscr{L}^{-1}\left\{\frac{1}{s+2}\right\}+\frac{1}{10} \mathscr{L}^{-1}\left\{\frac{1}{s+4}\right\} \\
& =\frac{1}{15} e^{t}-\frac{1}{6} e^{-2 t}+\frac{1}{10} e^{-4 t}
\end{aligned}
$$

\section*{EXAMPLE 5 Partial Fractions: Repeated Linear Factors}
Evaluate $\mathscr{L}^{-1}\left\{\frac{s+1}{s^{2}(s+2)^{3}}\right\}$.

Solution Assume

$$
\frac{s+1}{s^{2}(s+2)^{3}}=\frac{A}{s}+\frac{B}{s^{2}}+\frac{C}{s+2}+\frac{D}{(s+2)^{2}}+\frac{E}{(s+2)^{3}}
$$

so that

$$
s+1=A s(s+2)^{3}+B(s+2)^{3}+C s^{2}(s+2)^{2}+D s^{2}(s+2)+E s^{2}
$$

Setting $s=0$ and $s=-2$ gives $B=\frac{1}{8}$ and $E=-\frac{1}{4}$, respectively. By equating the coefficients of $s^{4}, s^{3}$, and $s$, we obtain

$$
\begin{aligned}
& 0=A+C \\
& 0=6 A+B+4 C+D \\
& 1=8 A+12 B
\end{aligned}
$$

from which it follows that $A=-\frac{1}{16}, C=\frac{1}{16}$, and $D=0$. Hence from parts (a), (b), and (c) of Theorem 7.3,

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{s+1}{s^{2}(s+2)^{3}}\right\} & =\mathscr{L}^{-1}\left\{-\frac{1 / 16}{s}+\frac{1 / 8}{s^{2}}+\frac{1 / 16}{s+2}-\frac{1 / 4}{(s+2)^{3}}\right\} \\
& =-\frac{1}{16} \mathscr{L}^{-1}\left\{\frac{1}{s}\right\}+\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{1}{s^{2}}\right\}+\frac{1}{16} \mathscr{L}^{-1}\left\{\frac{1}{s+2}\right\}-\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{2}{(s+2)^{3}}\right\} \\
& =-\frac{1}{16}+\frac{1}{8} t+\frac{1}{16} e^{-2 t}-\frac{1}{8} t^{2} e^{-2 t}
\end{aligned}
$$

Here we have also used $\mathscr{L}^{-1}\left\{2 /(s+2)^{3}\right\}=t^{2} e^{-2 t}$ from Example 6 of Section 7.1.

\section*{EXAMPLE 6 Partial Fractions: Irreducible Quadratic Factor}
Evaluate $\mathscr{L}^{-1}\left\{\frac{3 s-2}{s^{3}\left(s^{2}+4\right)}\right\}$.

Solution Assume

$$
\frac{3 s-2}{s^{3}\left(s^{2}+4\right)}=\frac{A}{s}+\frac{B}{s^{2}}+\frac{C}{s^{3}}+\frac{D s+E}{s^{2}+4}
$$

so that

$$
3 s-2=A s^{2}\left(s^{2}+4\right)+B s\left(s^{2}+4\right)+C\left(s^{2}+4\right)+(D s+E) s^{3}
$$

Setting $s=0$ gives immediately $C=-\frac{1}{2}$. Now the coefficients of $s^{4}, s^{3}, s^{2}$, and $s$ are, respectively,

$$
0=A+D, \quad 0=B+E, \quad 0=4 A+C, \quad 3=4 B
$$

from which we obtain $B=\frac{3}{4}, E=-\frac{3}{4}, A=\frac{1}{8}$, and $D=-\frac{1}{8}$. Therefore from parts (a), (b), (e), and (d) of Theorem 7.3 we have

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{3 s-2}{s^{3}\left(s^{2}+4\right)}\right\}= & \mathscr{L}^{-1}\left\{\frac{1 / 8}{s}+\frac{3 / 4}{s^{2}}-\frac{1 / 2}{s^{3}}+\frac{-s / 8-3 / 4}{s^{2}+4}\right\} \\
= & \frac{1}{8} \mathscr{L}^{-1}\left\{\frac{1}{s}\right\}+\frac{3}{4} \mathscr{L}^{-1}\left\{\frac{1}{s^{2}}\right\}-\frac{1}{4} \mathscr{L}^{-1}\left\{\frac{2}{s^{3}}\right\} \\
& -\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{s}{s^{2}+4}\right\}-\frac{3}{8} \mathscr{L}^{-1}\left\{\frac{2}{s^{2}+4}\right\} \\
= & \frac{1}{8}+\frac{3}{4} t-\frac{1}{4} t^{2}-\frac{1}{8} \cos 2 t-\frac{3}{8} \sin 2 t .
\end{aligned}
$$

Not every arbitrary function of $s$ is a Laplace transform of a piecewise function of exponential order.

\section*{THEOREM 7.4 Behavior of $F(s)$ as $s \rightarrow \infty$}
Let $f(t)$ be piecewise continuous on $[0, \infty)$ and of exponential order for $t>T$; then $\lim _{s \rightarrow \infty} \mathscr{L}\{f(t)\}=0$.

Proof Since $f(t)$ is piecewise continuous $0 \leq t \leq T$, it is necessarily bounded on the interval. That is, $|f(t)| \leq M_{1}=M_{1} e^{0 t}$. Also, $|f(t)| \leq M_{2} e^{\gamma t}$ for $t>T$. If $M$ denotes the maximum of $\left\{M_{1}, M_{2}\right\}$ and $c$ denotes the maximum of $\{0, \gamma\}$, then

$$
|\mathscr{L}\{f(t)\}| \leq \int_{0}^{\infty} e^{-s t}|f(t)| d t \leq M \int_{0}^{\infty} e^{-s t} \cdot e^{c t} d t=-\left.M \frac{e^{-(s-c) t}}{s-c}\right|_{0} ^{\infty}=\frac{M}{s-c}
$$

for $s>c$. As $s \rightarrow \infty$, we have $|\mathscr{L}\{f(t)\}| \rightarrow 0$ and so $\mathscr{L}\{f(t)\} \rightarrow 0$.

\section*{EXAMPLE 7}
\section*{Applying Theorem 7.4}
The functions $F_{1}(s)=s^{2}$ and $F_{2}(s)=s /(s+1)$ are not the Laplace transforms of piecewise continuous functions of exponential order since $F_{1}(s) \nrightarrow 0$ and $F_{2}(s) \nrightarrow 0$ as $s \rightarrow \infty$. We say that $\mathscr{L}^{-1}\left\{F_{1}(s)\right\}$ and $\mathscr{L}^{-1}\left\{F_{2}(s)\right\}$ do not exist.

Remarks There is another way of determining the coefficients in a partial fraction decomposition in the special case when $\mathscr{L}\{f(t)\}=F(s)$ is a quotient of polynomials $P(s) / Q(s)$ and $Q(s)$ is a product of distinct linear factors:

$$
F(s)=\frac{P(s)}{\left(s-r_{1}\right)\left(s-r_{2}\right) \cdots\left(s-r_{n}\right)}
$$

Let's illustrate by means of a specific example. From the theory of partial fractions we know there exist unique constants $A, B$, and $C$ such that


\begin{equation*}
\frac{s^{2}+4 s-1}{(s-1)(s-2)(s+3)}=\frac{A}{s-1}+\frac{B}{s-2}+\frac{C}{s+3} \tag{1}
\end{equation*}


Suppose we multiply both sides of this last expression by, say, $s-1$, simplify, and then set $s=1$. Since the coefficients of $B$ and $C$ are zero we get

$$
\left.\frac{s^{2}+4 s-1}{(s-2)(s+3)}\right|_{s=1}=A \quad \text { or } \quad A=-1
$$

Written another way,

$$
\left.\frac{s^{2}+4 s-1}{(s-1)(s-2)(s+3)}\right|_{s=1}=A
$$

where we have shaded or covered up the factor that canceled when the left side of (1) was multiplied by $s-1$. We do not evaluate this covered-up\\
factor at $s=1$. Now to obtain $B$ and $C$ we simply evaluate the left member of (1) while covering, in turn, $s-2$ and $s+3$ :

$$
\begin{gathered}
\left.\frac{s^{2}+4 s-1}{(s-1)(s-2)(s+3)}\right|_{s=2}=B \quad \text { or } B=\frac{11}{5} \\
\left.\frac{s^{2}+4 s-1}{(s-1)(s-2)(s+3)}\right|_{s=-3}=C \quad \text { or } \quad C=-\frac{1}{5}
\end{gathered}
$$

Note carefully that in the calculation of $C$ we evaluated at $s=-3$. By filling in the details in arriving at this last expression you will see why this is so. You should also verify by other means that

$$
\frac{s^{2}+4 s-1}{(s-1)(s-2)(s+3)}=\frac{-1}{s-1}+\frac{11 / 5}{s-2}+\frac{-1 / 5}{s+3}
$$

This cover-up method is a simplified version of a result known as Heaviside's expansion theorem.*

\section*{EXERCISES 7.2}
\section*{Answers to odd-numbered problems begin on page A-15.}
In Problems 1-34 use Theorem 7.3 to find the given inverse transform.\\
1. $\mathscr{L}^{-1}\left\{\frac{1}{s^{3}}\right\}$\\
2. $\mathscr{L}^{-1}\left\{\frac{1}{s^{4}}\right\}$\\
3. $\mathscr{L}^{-1}\left\{\frac{1}{s^{2}}-\frac{48}{s^{5}}\right\}$\\
4. $\mathscr{L}^{-1}\left\{\left(\frac{2}{s}-\frac{1}{s^{3}}\right)^{2}\right\}$\\
5. $\mathscr{L}^{-1}\left\{\frac{(s+1)^{3}}{s^{4}}\right\}$\\
6. $\mathscr{L}^{-1}\left\{\frac{(s+2)^{2}}{s^{3}}\right\}$\\
7. $\mathscr{L}^{-1}\left\{\frac{1}{s^{2}}-\frac{1}{s}+\frac{1}{s-2}\right\}$\\
8. $\mathscr{L}^{-1}\left\{\frac{4}{s}+\frac{6}{s^{5}}-\frac{1}{s+8}\right\}$
\footnotetext{\begin{itemize}
  \item OLIVER HEAVISIDE (I850-1925) Many of the results that we present in this chapter were devised by the English electrical engineer Oliver Heaviside and are set forth in his 1899 treatise Electromagnetic Theory. Heaviside originally utilized the Laplace transform as a means of solving linear differential equations with constant coefficients that arose in his investigation of transmission lines. Since many of his results lacked formal proof, the Heaviside operational calculus, as his procedures came to be called, initially met with scorn from mathematicians. A curmudgeon, Heaviside, in turn, called these "establishment" mathematicians "woodenheaded." When Heaviside, using his symbolic methods, was able to obtain answers to problems that mathematicians could not solve, their scorn turned to censure and his papers were no longer published in mathematics journals. Heaviside was also the discoverer of a layer of maximum electron density, called the Heaviside layer, in the upper atmosphere that reflects radio waves back to earth. He lived the last years of his life as a recluse in poverty. forgotten by the scientific community. He died in an unheated house in 1925.
\end{itemize}

True to their nature, mathematicians eventually seized his ideas, put them on a sound mathematical foundation, and then proceeded to generalize them into an abstract theory.
}
definition of the Laplace transform. Indeed, we shall see that evaluating transforms such as $\mathscr{L}\left\{e^{4 t} \cos 6 t\right\}, \mathscr{L}\left\{t^{3} \sin 2 t\right\}$, and $\mathscr{L}\left\{t^{10} e^{-t}\right\}$ is fairly straightforward, provided we know $\mathscr{L}\{\cos 6 t\}, \mathscr{L}\{\sin 2 t\}$, and $\mathscr{L}\left\{t^{10}\right\}$, respectively. Though extensive tables can be constructed and we have included a table in Appendix II, it is nonetheless a good idea to know the Laplace transforms of basic functions such as $t^{n}, e^{a t}, \sin k t, \cos k t, \sinh k t$, and $\cosh k t$.

If we know $\mathscr{L}\{f(t)\}=F(s)$, we can compute the Laplace transform $\mathscr{L}\left\{e^{a t} f(t)\right\}$ with no additional effort other than translating, or shifting, $F(s)$ to $F(s-a)$. This result is known as the first translation theorem, or first shifting theorem.

\section*{THEOREM 7.5 First Translation Theorem}
If $a$ is any real number, then

$$
\mathscr{L}\left\{e^{a t} f(t)\right\}=F(s-a),
$$

where $F(s)=\mathscr{L}\{f(t)\}$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-322}
\end{center}

Figure 7.10

Proof The proof is immediate, since by Definition 7.1

$$
\mathscr{L}\left\{e^{a t} f(t)\right\}=\int_{0}^{\infty} e^{-s t} e^{a t} f(t) d t=\int_{0}^{\infty} e^{-(s-a) t} f(t) d t=F(s-a)
$$

If we consider $s$ a real variable, then the graph of $F(s-a)$ is the graph of $F(s)$ shifted on the $s$-axis by the amount $|a|$ units. If $a>0$, the graph of $F(s)$ is shifted $a$ units to the right, whereas if $a<0$, the graph is shifted $|a|$ units to the left. See Figure 7.10.

For emphasis it is sometimes useful to use the symbolism

$$
\mathscr{L}\left\{e^{a t} f(t)\right\}=\mathscr{L}\{f(t)\}_{s \rightarrow s-a}
$$

where $s \rightarrow s-a$ means that we replace $s$ in $F(s)$ by $s-a$.

\section*{EXAMPLE 1 First Translation Theorem}
Evaluate (a) $\mathscr{L}\left\{e^{5 t} t^{3}\right\}$ and (b) $\mathscr{L}\left\{e^{-2 t} \cos 4 t\right\}$.

Solution The results follow from Theorem 7.5.

(a) $\mathscr{L}\left\{e^{5} t^{3}\right\}=\mathscr{L}\left\{t^{3}\right\}_{s \rightarrow s-5}$

$$
=\left.\frac{3!}{s^{4}}\right|_{s \rightarrow s-5}=\frac{6}{(s-5)^{4}}
$$

(b) $\mathscr{L}\left\{e^{-2 t} \cos 4 t\right\}=\mathscr{L}\{\cos 4 t\}_{s \rightarrow s+2} \quad \leftarrow a=-2$ so $s-a=s-(-2)=s+2$

$$
=\left.\frac{s}{s^{2}+16}\right|_{s \rightarrow s+2}=\frac{s+2}{(s+2)^{2}+16}
$$

Inverse Form of the First Translation Theorem The inverse form of Theorem 7.5 can be written


\begin{equation*}
\mathscr{L}^{-1}\{F(s-a)\}=\mathscr{L}^{-1}\left\{\left.F(s)\right|_{s \rightarrow s-a}\right\}=e^{a l} f(t) \tag{1}
\end{equation*}


where $f(t)=\mathscr{L}^{-1}\{F(s)\}$.

\section*{EXAMPLE 2 Completing the Square}
Evaluate $\mathscr{L}^{-1}\left\{\frac{s}{s^{2}+6 s+11}\right\}$.

\section*{Solution}
$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{s}{s^{2}+6 s+11}\right\} & =\mathscr{L}^{-1}\left\{\frac{s}{(s+3)^{2}+2}\right\} \leftarrow \text { completion of square } \\
& =\mathscr{L}^{-1}\left\{\frac{s+3-3}{(s+3)^{2}+2}\right\} \leftarrow \text { adding zero in the numerator } \\
& =\mathscr{L}^{-1}\left\{\frac{s+3}{(s+3)^{2}+2}-\frac{3}{(s+3)^{2}+2}\right\} \leftarrow \text { termwise division } \\
& =\mathscr{L}^{-1}\left\{\frac{s+3}{(s+3)^{2}+2}\right\}-3 \mathscr{L}^{-1}\left\{\frac{1}{(s+3)^{2}+2}\right\} \\
& =\mathscr{L}^{-1}\left\{\left.\frac{s}{s^{2}+2}\right|_{s \rightarrow s+3}\right\}-\frac{3}{\sqrt{2}} \mathscr{L}^{-1}\left\{\left.\frac{\sqrt{2}}{s^{2}+2}\right|_{s \rightarrow s+3}\right\} \\
& =e^{-3 t} \cos \sqrt{2} t-\frac{3}{\sqrt{2}} e^{-3 t} \sin \sqrt{2} t \leftarrow \text { from (1) and Theorem } 7.3
\end{aligned}
$$

\section*{EXAMPLE 3 Completing the Square and Linearity}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{(s-1)^{3}}+\frac{1}{s^{2}+2 s-8}\right\}$.

Solution Completing the square in the second denominator and using linearity yields

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{1}{(s-1)^{3}}+\frac{1}{s^{2}+2 s-8}\right\} & =\mathscr{L}^{-1}\left\{\frac{1}{(s-1)^{3}}+\frac{1}{(s+1)^{2}-9}\right\} \\
& =\frac{1}{2!} \mathscr{L}^{-1}\left\{\frac{2!}{(s-1)^{3}}\right\}+\frac{1}{3} \mathscr{L}^{-1}\left\{\frac{3}{(s+1)^{2}-9}\right\} \\
& =\frac{1}{2!} \mathscr{L}^{-1}\left\{\left.\frac{2!}{s^{3}}\right|_{s \rightarrow s-1}\right\}+\frac{1}{3} \mathscr{L}^{-1}\left\{\left.\frac{3}{s^{2}-9}\right|_{s \rightarrow s+1}\right\} \\
& =\frac{1}{2} e^{t} t^{2}+\frac{1}{3} e^{-t} \sinh 3 t
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324(4)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324(3)}
\end{center}

(b)

Figure 7.11

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324(2)}
\end{center}

Figure 7.12\\
Unit Step Function In engineering one frequently encounters functions that can be either "on" or "off." For example, an external force acting on a mechanical system or a voltage impressed on a circuit can be turned off after a period of time. It is thus convenient to define a special function called the unit step function.

\section*{DEFINITION 7.3 Unit Step Function}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324}
\end{center}

$$
U(t-a)=\left\{\begin{array}{rr}
0, & 0 \leq t<a \\
1, & t \geq a
\end{array}\right.
$$

Notice that we define $\mathscr{U}(t-a)$ only on the nonnegative $t$-axis since this is all that we are concerned with in the study of the Laplace transform. In a

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324(1)}
\end{center}

\section*{EXAMPLE 4 Graphs of Unit Step Functions}
Graph (a) $U(t)$ and (b) $U(t-2)$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-324(5)}
\end{center}

The respective graphs are given in Figure 7.11.

When multiplied by another function defined for $t \geq 0$, the unit step function "turns off" a portion of the graph of the function. For example, Figure 7.12 illustrates the graph of $\sin t, t \geq 0$ when multiplied by $\because(t-2 \pi)$ :

$$
f(t)=\sin t U(t-2 \pi)=\left\{\begin{array}{lr}
0, & 0 \leq t<2 \pi \\
\sin t, & t \geq 2 \pi
\end{array}\right.
$$

The unit step function can also be used to write piecewise-defined functions in a compact form. For instance, the piecewise-defined function

can be written as

\[
f(t)=\left\{\begin{array}{lr}
g(t), & 0 \leq t<a  \tag{2}\\
h(t), & t \geq a
\end{array}\right.
\]


\begin{equation*}
f(t)=g(t)-g(t) U(t-a)+h(t) U(t-a) \tag{3}
\end{equation*}


To verify this, we use the definition of $U(t-a)$ :

$$
f(t)=\left\{\begin{array}{l}
g(t)-g(t) \cdot 0+h(t) \cdot 0, \quad 0 \leq t<a \\
g(t)-g(t) \cdot 1+h(t) \cdot 1, \quad t \geq a .
\end{array}\right.
$$

Similarly, a function of the type

\[
f(t)=\left\{\begin{array}{lr}
0, & 0 \leq t<a  \tag{4}\\
g(t), & a \leq t<b \\
0, & t \geq b
\end{array}\right.
\]

can be written


\begin{equation*}
f(t)=g(t)[U(t-a)-U(t-b)] . \tag{5}
\end{equation*}


\section*{EXAMPLE 5 Voltage Expressed in Terms of a Unit Step Function}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-325}
\end{center}

Figure 7.13

The voltage in a circuit is given by

$$
E(t)=\left\{\begin{array}{lr}
20 t, & 0 \leq t<5 \\
0, & t \geq 5
\end{array}\right.
$$

Graph $E(t)$. Express $E(t)$ in terms of unit step functions.

Solution The graph of this piecewise-defined function is given in Figure 7.13. Now from (2) and (3) with $g(t)=20 t$ and $h(t)=0$, we get

$$
E(t)=20 t-20 t U(t-5)
$$

\section*{EXAMPLE 6 Comparison of Functions}
Consider the function $y=f(t)$ defined by $f(t)=t^{3}$. Compare the graphs of\\
(a) $f(t)=t^{3}$\\
(b) $f(t)=t^{3}, \quad t \geq 0$\\
(c) $f(t-2), \quad t \geq 0$\\
(d) $f(t-2) U(t-2), \quad t \geq 0$

Solution The respective graphs are given in Figure 7.14.

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-325(2)}\\
(a)

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-325(1)}\\
(b)\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-325(3)}\\
(c)\\
(d)

Figure 7.14

In general, if $a>0$, then the graph of $y=f(t-a)$ is the graph of $y=f(t), t \geq 0$ shifted $a$ units to the right on the $t$-axis. However, when $y=f(t-a)$ is multiplied by the unit step function $\mathscr{U}(t-a)$ in the manner illustrated in part (d) of Example 6, then the graph of the function


\begin{equation*}
y=f(t-a) \cup(t-a) \tag{6}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-326(1)}
\end{center}

(a) $f(t), t \geq 0$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-326}
\end{center}

(b) $f(t-a) \mathscr{U}(t-a)$ coincides with the graph of $y=f(t-a)$ for $t \geq a$ but is identically zero for $0 \leq t<a$. See Figure 7.15.

We saw in Theorem 7.5 that an exponential multiple of $f(t)$ results in a translation or shift of the transform $F(s)$ on the $s$-axis. In the next theorem we see that whenever $F(s)$ is multiplied by an appropriate exponential function, the inverse transform of this product is the shifted function given in (6). This result is called the second translation theorem, or second shifting theorem.

\section*{THEOREM 7.6 Second Translation Theorem}
If $a$ is a positive constant, then

$$
\mathscr{L}\{f(t-a) U(t-a)\}=e^{-a s} F(s)
$$

where $F(s)=\mathscr{L}\{f(t)\}$.

Proof From Definition 7.1 we have

$$
\begin{aligned}
& \mathscr{L}\{f(t-a) \mathscr{U}(t-a)\}=\int_{0}^{\infty} e^{-s t} f(t-a) \mathscr{U}(t-a) d t \\
& =\int_{0}^{a} e^{-s t} f(t-a) \underbrace{\mathscr{U ( t - a )}}_{\text {zero for }} d t+\int_{a}^{\infty} e^{-s t} f(t-a) \underbrace{\mathscr{U ( t - a )}}_{\text {one for }} d t \\
& 0 \leq t<a \quad t \geq a \\
& =\int_{a}^{\infty} e^{-s t} f(t-a) d t
\end{aligned}
$$

Now let $v=t-a, d v=d t$; then

$$
\begin{aligned}
\mathscr{L}\{f(t-a) \mathscr{U}(t-a)\} & =\int_{0}^{\infty} e^{-s(v+a)} f(v) d v \\
& =e^{-a s} \int_{0}^{\infty} e^{-s v} f(v) d v=e^{-a s} \mathscr{L}\{f(t)\}
\end{aligned}
$$

\section*{EXAMPLE 7 Second Translation Theorem}
Evaluate $\mathscr{L}\left\{(t-2)^{3} U(t-2)\right\}$.

Solution With the identification $a=2$, it follows from Theorem 7.6 that

$$
\mathscr{L}\left\{(t-2)^{3} U(t-2)\right\}=e^{-2 s} \mathscr{L}\left\{t^{3}\right\}=e^{-2 s} \frac{3!}{s^{4}}=\frac{6}{s^{4}} e^{-2 s}
$$

We often wish to find the Laplace transform of just the unit step function. This can be found from either Definition 7.1 or Theorem 7.6. If we identify $f(t)=1$ in Theorem 7.6, then $f(t-a)=1, F(s)=\mathscr{L}\{1\}=1 / s$, and so


\begin{equation*}
\mathscr{L}\{\mathscr{U}(t-a)\}=\frac{e^{-a s}}{s} \tag{7}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-327}
\end{center}

Figure 7.16

\section*{EXAMPLE 8 Second Translation Theorem and Linearity}
Find the Laplace transform of the function shown in Figure 7.16.

Solution With the aid of the unit step function, we can write

$$
f(t)=2-3 U(t-2)+U(t-3)
$$

Using linearity and the result in (7) it follows that

$$
\begin{aligned}
\mathscr{L}\{f(t)\} & =\mathscr{L}\{2\}-3 \mathscr{L}\{\mathscr{U}(t-2)\}+\mathscr{L}\{\mathscr{U}(t-3)\} \\
& =\frac{2}{s}-3 \frac{e^{-2 s}}{s}+\frac{e^{-3 s}}{s}
\end{aligned}
$$

\section*{EXAMPLEE 9 Second Translation Theorem}
Evaluate $\mathscr{L}\{\sin t \mathscr{U}(t-2 \pi)\}$.

Solution With $a=2 \pi$ we have from Theorem 7.6

$$
\begin{aligned}
\mathscr{L}\{\sin t \mathscr{U}(t-2 \pi)\} & =\mathscr{L}\{\sin (t-2 \pi) \mathscr{U}(t-2 \pi)\} \leftarrow \sin t \text { has period } 2 \pi \\
& =e^{-2 \pi s} \mathscr{L}\{\sin t\} \\
& =\frac{e^{-2 \pi s}}{s^{2}+1}
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-327(1)}
\end{center}

Figure 7.17

\section*{EXAMPLE 10 Fixing Up a Function to Use Theorem 7.6}
Find the Laplace transform of the function shown in Figure 7.17.

Solution An equation of the straight line is found to be $y=2 t-3$. To "turn off" this graph on the interval $0 \leq t<1$ we form $(2 t-3) U(t-1)$. Now Theorem 7.6 is not immediately applicable in the evaluation of $\mathscr{L}\{(2 t-3) \mathscr{U}(t-1)\}$, since the function being transformed lacks the precise form $f(t-a) U(t-a)$. However, by rewriting $2 t-3$ in terms of $t-1$,

$$
2 t-3=2(t-1)-1
$$

we can identify $f(t-1)=2(t-1)-1$ and consequently $f(t)=2 t-1$. We are now in a position to apply the second translation theorem:

$$
\begin{aligned}
\mathscr{L}\{(2 t-3) \mathscr{U}(t-1)\} & =\mathscr{L}\{(2(t-1)-1) \mathscr{U}(t-1)\} \\
& =e^{-s} \mathscr{L}\{2 t-1\} \\
& =e^{-s}\left(\frac{2}{s^{2}}-\frac{1}{s}\right)
\end{aligned}
$$

Inverse Form of the Second Translation Theorem The inverse form of Theorem 7.6 is


\begin{equation*}
\mathscr{L}^{-1}\left\{e^{-a s} F(s)\right\}=f(t-a) \mathscr{U}(t-a) \tag{8}
\end{equation*}


where $a>0$ and $f(t)=\mathscr{L}^{-1}\{F(s)\}$.

\section*{EXAMPLLE 11 Inverse by Formula (8)}
Evaluate $\mathscr{L}^{-1}\left\{\frac{e^{-\pi s / 2}}{s^{2}+9}\right\}$ Solution We identify $a=\frac{\pi}{2}$ and $f(t)=\mathscr{L}^{-1}\left\{\frac{1}{s^{2}+9}\right\}=\frac{1}{3} \sin 3 t$. Thus\\
from (8),

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{e^{-\pi s / 2}}{s^{2}+9}\right\} & =\frac{1}{3} \mathscr{L}^{-1}\left\{\frac{3}{s^{2}+9}\right\}_{t \rightarrow t-\pi / 2} U\left(t-\frac{\pi}{2}\right) \\
& =\frac{1}{3} \sin 3\left(t-\frac{\pi}{2}\right) U\left(t-\frac{\pi}{2}\right) \\
& =\frac{1}{3} \cos 3 t b U\left(t-\frac{\pi}{2}\right)
\end{aligned}
$$

If $F(s)=\mathscr{L}\{f(t)\}$ and if we assume that interchanging of differentiation and integration is possible, then

$$
\begin{aligned}
& \frac{d}{d s} F(s)=\frac{d}{d s} \int_{0}^{\infty} e^{-s t} f(t) d t=\int_{0}^{\infty} \frac{\partial}{\partial s}\left[e^{-s t} f(t)\right] d t=-\int_{0}^{\infty} e^{-s t} t f(t) d t=-\mathscr{L}\{t f(t)\} \\
& \text { that is, } \\
& \qquad \begin{aligned}
\mathscr{L}\{t f(t)\} & =-\frac{d}{d s} \mathscr{L}\{f(t)\}
\end{aligned} \\
& \text { Similarly, }\left\{t^{2} f(t)\right\}=\mathscr{L}\{t \cdot t f(t)\}=-\frac{d}{d s} \mathscr{L}\{t f(t)\} \\
& =-\frac{d}{d s}\left(-\frac{d}{d s} \mathscr{L}\{f(t)\}\right)=\frac{d^{2}}{d s^{2}} \mathscr{L}\{f(t)\}
\end{aligned}
$$

The preceding two cases suggest the general result for $\mathscr{L}\left\{t^{n} f(t)\right\}$.

\section*{THEOREM 7.7 Derivatives of Transforms}
For $n=1,2,3, \ldots$,

$$
\mathscr{L}\left\{t^{n} f(t)\right\}=(-1)^{n} \frac{d^{n}}{d s^{n}} F(s),
$$

where $F(s)=\mathscr{L}\{f(t)\}$.

\section*{EXAMPLE 12 Applying Theorem 7.7}
Evaluate (a) $\mathscr{L}\left\{t e^{3 n}\right\}$, (b) $\mathscr{L}\{t \sin k t\}$, (c) $\mathscr{L}\left\{t^{2} \sin k t\right\}$, and (d) $\mathscr{L}\left\{t e^{-t} \cos t\right\}$.

Solution We make use of results (c), (d), and (e) of Theorem 7.2.

(a) Note in this first example we could also use the first translation theorem. To apply Theorem 7.7 we identify $n=1$ and $f(t)=e^{3 t}$ :

$$
\mathscr{L}\left\{t e^{3 t}\right\}=-\frac{d}{d s} \mathscr{L}\left\{e^{3 t}\right\}=-\frac{d}{d s}\left(\frac{1}{s-3}\right)=\frac{1}{(s-3)^{2}}
$$

(b)

$$
\begin{aligned}
\mathscr{L}\{t \sin k t\} & =-\frac{d}{d s} \mathscr{L}\{\sin k t\} \\
& =-\frac{d}{d s}\left(\frac{k}{s^{2}+k^{2}}\right) \\
& =\frac{2 k s}{\left(s^{2}+k^{2}\right)^{2}}
\end{aligned}
$$

(c) With $n=2$ in Theorem 7.7 this transform can be written

$$
\mathscr{L}\left\{t^{2} \sin k t\right\}=\frac{d^{2}}{d s^{2}} \mathscr{L}\{\sin k t\}
$$

and so by carrying out the two derivatives we obtain the result. Alternatively, we can make use of the result already obtained in part (b). Since $t^{2} \sin k t=$ $t(t \sin k t)$, we have

$$
\begin{aligned}
\mathscr{L}\left\{t^{2} \sin k t\right\} & =-\frac{d}{d s} \mathscr{L}\{t \sin k t\} \\
& =-\frac{d}{d s}\left(\frac{2 k s}{\left(s^{2}+k^{2}\right)^{2}}\right) . \leftarrow \text { from part (b) }
\end{aligned}
$$

Differentiating and simplifying then gives

(d)

$$
\begin{aligned}
& \mathscr{L}\left\{t^{2} \sin k t\right\}=\frac{6 k s^{2}-2 k^{3}}{\left(s^{2}+k^{2}\right)^{3}} . \\
& \mathscr{L}\left\{t e^{-t} \cos t\right\}=-\frac{d}{d s} \mathscr{L}\left\{e^{-t} \cos t\right\} \\
&=-\frac{d}{d s} \mathscr{L}\{\cos t\}_{s \rightarrow s+1} \leftarrow \text { first translation } \\
&=-\frac{d}{d s}\left(\frac{s+1}{(s+1)^{2}+1}\right) \\
&=\frac{(s+1)^{2}-1}{\left[(s+1)^{2}+1\right]^{2}}
\end{aligned}
$$

\section*{EXERCISES 7.3}
Answers to odd-numbered problems begin on page A-16.

In Problems 1-44 find either $F(s)$ or $f(t)$ as indicated.

\begin{enumerate}
  \item $\mathscr{L}\left\{t e^{10 t}\right\}$
  \item $\mathscr{L}\left\{t e^{-6 r}\right\}$
  \item $\mathscr{L}\left\{t^{3} e^{-2 n}\right\}$
  \item $\mathscr{L}\left\{t^{10} e^{-7 t}\right\}$
  \item $\mathscr{L}\left\{e^{t} \sin 3 t\right\}$
  \item $\mathscr{L}\left\{e^{-2 t} \cos 4 t\right\}$
  \item $\mathscr{L}\left\{e^{5 t} \sinh 3 t\right\}$
  \item $\mathscr{L}\left\{\frac{\cosh t}{e^{t}}\right\}$
  \item $\mathscr{L}\left\{t\left(e^{t}+e^{2 t}\right)^{2}\right\}$
  \item $\mathscr{L}\left\{e^{2 t}(t-1)^{2}\right\}$
  \item $\mathscr{L}\left\{e^{-t} \sin ^{2} t\right\}$
  \item $\mathscr{L}\left\{e^{t} \cos ^{2} 3 t\right\}$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-330(3)}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-330(1)}
\end{center}

Figure 7.18

In Problems 45-50 match the given graph with one of the functions in (a)-(f). The graph of $f(t)$ is given in Figure 7.18.

(a) $f(t)-f(t) \mathscr{U}(t-a)$

(b) $f(t-b) U(t-b)$

(c) $f(t) U(t-a)$

(d) $f(t)-f(t) U(t-b)$

(e) $f(t) U(t-a)-f(t) U(t-b)$

(f) $f(t-a) U(t-a)-f(t-a) U(t-b)$

45.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-330}
\end{center}

Figure 7.19

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-330(2)}
\end{center}

Figure 7.20\\
47. $f(t)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-331(1)}
\end{center}

Figure 7.21\\
48. $f(t)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-331(2)}
\end{center}

Figure 7.22

49.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-331}
\end{center}

Figure 7.24

In Problems 51-58 write each function in terms of unit step functions. Find the Laplace transform of the given function.\\
51. $f(t)=\left\{\begin{array}{rr}2, & 0 \leq t<3 \\ -2, & t \geq 3\end{array} \quad\right.$ 52. $f(t)=\left\{\begin{array}{rr}1, & 0 \leq t<4 \\ 0, & 4 \leq t<5 \\ 1, & t \geq 5\end{array}\right.$\\
53. $f(t)=\left\{\begin{array}{lr}0, & 0 \leq t<1 \\ t^{2}, & t \geq 1\end{array}\right.$\\
54. $f(t)=\left\{\begin{array}{lr}0, & 0 \leq t<\frac{3 \pi}{2} \\ \sin t, & t \geq \frac{3 \pi}{2}\end{array}\right.$\\
55. $f(t)=\left\{\begin{array}{lr}t, & 0 \leq t<2 \\ 0, & t \geq 2\end{array}\right.$\\
56. $f(t)=\left\{\begin{array}{lr}\sin t, & 0 \leq t<2 \pi \\ 0, & t \geq 2 \pi\end{array}\right.$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-332(1)}
\end{center}

rectangular pulse

Figure 7.25\\
58.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-332}
\end{center}

staircase function

Figure 7.26

In Problems 59 and 60 sketch the graph of the given function.\\
59. $f(t)=\mathscr{L}^{-1}\left\{\frac{1}{s^{2}}-\frac{e^{-s}}{s^{2}}\right\}$\\
60. $f(t)=\mathscr{L}^{-1}\left\{\frac{2}{s}-\frac{3 e^{-s}}{s^{2}}+\frac{5 e^{-2 s}}{s^{2}}\right\}$

In Problems 61-64 use Theorem 7.7 in the form $(n=1)$

$$
f(t)=-\frac{1}{t} \mathscr{L}^{-1}\left\{\frac{d}{d s} F(s)\right\}
$$

to evaluate the given inverse Laplace transform.\\
61. $\mathscr{L}^{-1}\left\{\ln \frac{s-3}{s+1}\right\}$\\
62. $\mathscr{L}^{-1}\left\{\ln \frac{s^{2}+1}{s^{2}+4}\right\}$\\
63. $\mathscr{L}^{-1}\left\{\frac{\pi}{2}-\tan ^{-1} \frac{s}{2}\right\}$\\
64. $\mathscr{L}^{-1}\left\{\frac{1}{s}-\cot ^{-1} \frac{4}{s}\right\}$

\subsection*{7.4 TRANSFORMS OF DERIVATIVES, INTEGRALS, AND PERIODIC FUNCTIONS \\
 - Convolution}
Our goal is to use the Laplace transform to solve certain kinds of differential equations. To that end we need to evaluate quantities such as $\mathscr{L}\{d y / d t\}$ and $\mathscr{L}\left\{d^{2} y / d t^{2}\right\}$. For example, if $f^{\prime}$ is continuous for $t \geq 0$, then integration by parts gives


\begin{align*}
\mathscr{L}\left\{f^{\prime}(t)\right\}=\int_{0}^{\infty} e^{-s t} f^{\prime}(t) d t & =\left.e^{-s t} f(t)\right|_{0} ^{\infty}+s \int_{0}^{\infty} e^{-s t} f(t) d t \\
& =-f(0)+s \mathscr{L}\{f(t)\} \\
\mathscr{L}\left\{f^{\prime}(t)\right\} & =s F(s)-f(0) . \tag{1}
\end{align*}


Here we have assumed that $e^{-s t} f(t) \rightarrow 0$ as $t \rightarrow \infty$. Similarly, the transform of the second derivative is

$$
\begin{aligned}
\mathscr{L}\left\{f^{\prime \prime}(t)\right\}=\int_{0}^{\infty} e^{-s t} f^{\prime \prime}(t) d t & =\left.e^{-s t} f^{\prime}(t)\right|_{0} ^{\infty}+s \int_{0}^{\infty} e^{-s t} f^{\prime}(t) d t \\
& =-f^{\prime}(0)+s \mathscr{L}\left\{f^{\prime}(t)\right\} \\
& =s[s F(s)-f(0)]-f^{\prime}(0)
\end{aligned}
$$

or


\begin{equation*}
\mathscr{L}\left\{f^{\prime \prime}(t)\right\}=s^{2} F(s)-s f(0)-f^{\prime}(0) \tag{2}
\end{equation*}


The results in (1) and (2) are special cases of the next theorem, which gives the Laplace transform of the $n$th derivative of $f$. The proof is omitted.

\section*{THEOREM 7.8 Transform of a Derivative}
If $f(t), f^{\prime}(t), \ldots, f^{(n-1)}(t)$ are continuous on $[0, \infty)$ and are of exponential order and if $f^{n}(t)$ is piecewise continuous on $[0, \infty)$, then

$$
\mathscr{L}\left\{f^{n}(t)\right\}=s^{n} F(s)-s^{n-1} f(0)-s^{n-2} f^{\prime}(0)-\cdots-f^{(n-1)}(0)
$$

where $F(s)=\mathscr{L}\{f(t)\}$.

\section*{EXAMPLE 1 Applying Theorem 7.8}
Observe that the sum $k t \cos k t+\sin k t$ is the derivative of $t \sin k t$. Hence

$$
\begin{aligned}
\mathscr{L}\{k t \cos k t+\sin k t\} & =\mathscr{L}\left\{\frac{d}{d t}(t \sin k t)\right\} \\
& =s \mathscr{L}\{t \sin k t\} \leftarrow \text { by (1) } \\
& =s\left(-\frac{d}{d s} \mathscr{L}\{\sin k t\}\right) \leftarrow \text { from Theorem 7.7 } \\
& =s\left(\frac{2 k s}{\left(s^{2}+k^{2}\right)^{2}}\right)=\frac{2 k s^{2}}{\left(s^{2}+k^{2}\right)^{2}}
\end{aligned}
$$

Convolution If functions $f$ and $g$ are piecewise continuous on $[0, \infty)$, then the convolution of $f$ and $g$, denoted by $f * g$, is given by the integral

$$
f * g=\int_{0}^{t} f(\tau) g(t-\tau) d \tau
$$

It is left as an exercise to show that $\int_{0}^{t} f(\tau) g(t-\tau) d \tau=\int_{0}^{t} f(t-\tau) g(\tau) d \tau$; that is, $f * g=g * f$. See Problem 29. This means that the convolution of two functions is commutative.

\section*{EXAMPLE 2 Convolution of Two Functions}
The convolution of $f(t)=e^{t}$ and $g(t)=\sin t$ is


\begin{align*}
e^{t} * \sin t & =\int_{0}^{t} e^{\tau} \sin (t-\tau) d \tau  \tag{3}\\
& =\frac{1}{2}\left(-\sin t-\cos t+e^{t}\right) \tag{4}
\end{align*}


It is possible to find the Laplace transform of the convolution of two functions, such as (3), without actually evaluating the integral as we did in (4). The result that follows is known as the convolution theorem.

\section*{THEOREM 7.9 Convolution Theorem}
Let $f(t)$ and $g(t)$ be piecewise continuous on $[0, \infty)$ and of exponential order; then

$$
\mathscr{L}\{f * g\}=\mathscr{L}\{f(t)\} \mathscr{L}\{g(t)\}=F(s) G(s) .
$$

Proof Let

$$
F(s)=\mathscr{L}\{f(t)\}=\int_{0}^{\infty} e^{-s \tau} f(\tau) d \tau
$$

and

$$
G(s)=\mathscr{L}\{g(t)\}=\int_{0}^{\infty} e^{-s \beta} g(\beta) d \beta
$$

Proceeding formally, we have

$$
\begin{aligned}
F(s) G(s) & =\left(\int_{0}^{\infty} e^{-s \tau} f(\tau) d \tau\right)\left(\int_{0}^{\infty} e^{-s \beta} g(\beta) d \beta\right) \\
& =\int_{0}^{\infty} \int_{0}^{\infty} e^{-s(\tau+\beta)} f(\tau) g(\beta) d \tau d \beta \\
& =\int_{0}^{\infty} f(\tau) d \tau \int_{0}^{\infty} e^{-s(\tau+\beta)} g(\beta) d \beta
\end{aligned}
$$

Holding $\tau$ fixed, we let $t=\tau+\beta, d t=d \beta$ so that

$$
F(s) G(s)=\int_{0}^{\infty} f(\tau) d \tau \int_{\tau}^{\infty} e^{-s t} g(t-\tau) d t
$$

In the $t \tau$-plane we are integrating over the shaded region in Figure 7.27. Since $f$ and $g$ are piecewise continuous on $[0, \infty)$ and of exponential order, it is possible

Figure 7.27 to interchange the order of integration:

$$
F(s) G(s)=\int_{0}^{\infty} e^{-s t} d t \int_{0}^{t} f(\tau) g(t-\tau) d \tau=\int_{0}^{\infty} e^{-s t}\left\{\int_{0}^{t} f(\tau) g(t-\tau) d \tau\right\} d t=\mathscr{L}\{f * g\}
$$

When $g(t)=1$ and $G(s)=1 / s$, the convolution theorem implies that the Laplace transform of the integral of a function $f$ is


\begin{equation*}
\mathscr{L}\left\{\int_{0}^{t} f(\tau) d \tau\right\}=\frac{F(s)}{s} \tag{5}
\end{equation*}


\section*{EXAMPLE 3 Transform of a Convolution}
Evaluate $\mathscr{L}\left\{\int_{0}^{t} e^{\tau} \sin (t-\tau) d \tau\right\}$

Solution With $f(t)=e^{t}$ and $g(t)=\sin t$, the convolution theorem states that the Laplace transform of the convolution of $f$ and $g$ is the product of their Laplace transforms:

$$
\begin{aligned}
\mathscr{L}\left\{\int_{0}^{t} e^{\tau} \sin (t-\tau) d \tau\right\} & =\mathscr{L}\left\{e^{t}\right\} \cdot \mathscr{L}\{\sin t\} \\
& =\frac{1}{s-1} \cdot \frac{1}{s^{2}+1}=\frac{1}{(s-1)\left(s^{2}+1\right)}
\end{aligned}
$$

Inverse Form of the Convolution Theorem The convolution theorem is sometimes useful in finding the inverse Laplace transform of a product of two Laplace transforms. From Theorem 7.9 we have


\begin{equation*}
\mathscr{L}^{-1}\{F(s) G(s)\}=f * g . \tag{6}
\end{equation*}


\section*{EXAMPLE 4 Inverse Transform as a Convolution}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{(s-1)(s+4)}\right\}$.

Solution Partial fractions could be used, but if we identify

$$
F(s)=\frac{1}{s-1} \quad \text { and } \quad G(s)=\frac{1}{s+4}
$$

then

$$
\mathscr{L}^{-1}\{F(s)\}=f(t)=e^{t} \quad \text { and } \quad \mathscr{L}^{-1}\{G(s)\}=g(t)=e^{-4 t}
$$

Hence from (6) we obtain

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{1}{(s-1)(s+4)}\right\} & =\int_{0}^{t} f(\tau) g(t-\tau) d t=\int_{0}^{t} e^{\tau} e^{-4(t-\tau)} d \tau \\
& =e^{-4 t} \int_{0}^{t} e^{5 \tau} d \tau \\
& =\left.e^{-4 t} \frac{1}{5} e^{5 \tau}\right|_{0} ^{t} \\
& =\frac{1}{5} e^{t}-\frac{1}{5} e^{-4 t}
\end{aligned}
$$

\section*{EXAMPLE 5 Inverse Transform as a Convolution}
Evaluate $\mathscr{L}^{-1}\left\{\frac{1}{\left(s^{2}+k^{2}\right)^{2}}\right\}$

Solution

$$
\text { Let } \quad F(s)=G(s)=\frac{1}{s^{2}+k^{2}}
$$

so that

$$
f(t)=g(t)=\frac{1}{k} \mathscr{L}^{-1}\left\{\frac{k}{s^{2}+k^{2}}\right\}=\frac{1}{k} \sin k t
$$

In this case (6) gives


\begin{equation*}
\mathscr{L}^{-1}\left\{\frac{1}{\left(s^{2}+k^{2}\right)^{2}}\right\}=\frac{1}{k^{2}} \int_{0}^{t} \sin k \tau \sin k(t-\tau) d \tau \tag{7}
\end{equation*}


Now recall from trigonometry that

$$
\begin{aligned}
& \cos (A+B)=\cos A \cos B-\sin A \sin B \\
& \cos (A-B)=\cos A \cos B+\sin A \sin B
\end{aligned}
$$

Subtracting the first from the second gives the identity

$$
\sin A \sin B=\frac{1}{2}[\cos (A-B)-\cos (A+B)]
$$

If we set $A=k \tau$ and $B=k(t-\tau)$, we can carry out the integration in (7):

$$
\begin{aligned}
\mathscr{L}^{-1}\left\{\frac{1}{\left(s^{2}+k^{2}\right)^{2}}\right\} & =\frac{1}{2 k^{2}} \int_{0}^{t}[\cos k(2 \tau-t)-\cos k t] d \tau \\
& =\frac{1}{2 k^{2}}\left[\frac{1}{2 k} \sin k(2 \tau-t)-\tau \cos k t\right]_{0}^{t} \\
& =\frac{\sin k t-k t \cos k t}{2 k^{3}}
\end{aligned}
$$

Transform of a Periodic Function If a periodic function has period $T, T>0$, then $f(t+T)=f(t)$. The Laplace transform of a periodic function can be obtained by an integration over one period.

\section*{THEOREM 7.10 Transform of a Periodic Function}
Let $f(t)$ be piecewise continuous on $[0, \infty)$ and of exponential order. If $f(t)$ is periodic with period $T$, then


\begin{equation*}
\mathscr{L}\{f(t)\}=\frac{1}{1-e^{-s T}} \int_{0}^{T} e^{-s t} f(t) d t \tag{8}
\end{equation*}


Proof Write the Laplace transform as two integrals:


\begin{equation*}
\mathscr{L}\{f(t)\}=\int_{0}^{T} e^{-s t} f(t) d t+\int_{T}^{\infty} e^{-s t} f(t) d t \tag{9}
\end{equation*}


When we let $t=u+T$, the last integral in (9) becomes

$$
\int_{T}^{\infty} e^{-s t} f(t) d t=\int_{0}^{\infty} e^{-s(u+T)} f(u+T) d u=e^{-s T} \int_{0}^{\infty} e^{-s u} f(u) d u=e^{-s T} \mathscr{L}\{f(t)\}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-337}
\end{center}

Figure 7.28\\
Hence (9) is

$$
\mathscr{L}\{f(t)\}=\int_{0}^{T} e^{-s t} f(t) d t+e^{-s T} \mathscr{L}\{f(t)\}
$$

Solving for $\mathscr{L}\{f(t)\}$ yields the result given in (8).

\section*{EXAMPLE 6 Transform of a Periodic Function}
Find the Laplace transform of the periodic function shown in Figure 7.28.

Solution On the interval $0 \leq t<2$ the function can be defined by

$$
f(t)= \begin{cases}t, & 0 \leq t<1 \\ 0, & 1 \leq t<2\end{cases}
$$

and outside the interval by $f(t+2)=f(t)$. Identifying $T=2$, we use (8) and integration by parts to obtain


\begin{align*}
\mathscr{L}\{f(t)\} & =\frac{1}{1-e^{-2 s}} \int_{0}^{2} e^{-s t} f(t) d t  \tag{10}\\
& =\frac{1}{1-e^{-2 s}}\left[\int_{0}^{1} e^{-s t} t d t+\int_{1}^{2} e^{-s t} 0 d t\right] \\
& =\frac{1}{1-e^{-2 s}}\left[-\frac{e^{-s}}{s}+\frac{1-e^{-s}}{s^{2}}\right]  \tag{11}\\
& =\frac{1-(s+1) e^{-s}}{s^{2}\left(1-e^{-2 s}\right)} .
\end{align*}


The result in (11) of Example 6 can be obtained without actually integrating by making use of the second translation theorem. If we define

$$
g(t)=\left\{\begin{array}{lr}
t, & 0 \leq t<1 \\
0, & t \geq 1
\end{array}\right.
$$

then $f(t)=g(t)$ on the interval $[0, T]$, where $T=2$. But we can express $g$ in terms of unit step functions as

$$
g(t)=t-t \mathscr{U}(t-1)=t-(t-1) U(t-1)-\mathscr{U}(t-1) .
$$

Thus (10) can be written as

$$
\begin{aligned}
\mathscr{L}\{f(t)\} & =\frac{1}{1-e^{-2 s}} \mathscr{L}\{g(t)\} \\
& =\frac{1}{1-e^{-2 s}} \mathscr{L}\{t-(t-1) \mathscr{U}(t-1)-\mathscr{U}(t-1)\} \\
& =\frac{1}{1-e^{-2 s}}\left[\frac{1}{s^{2}}-\frac{1}{s^{2}} e^{-s}-\frac{1}{s} e^{-s}\right]
\end{aligned}
$$

Inspection of the expression inside the brackets reveals that it is identical to $(11)$.

\section*{EXERCISES 7.4}
Answers to odd-numbered problems begin on page A-16.

\begin{enumerate}
  \item Use the result $(d / d t) e^{t}=e^{t}$ and (1) of this section to evaluate $\mathscr{L}\left\{e^{t}\right\}$.

  \item Use the result $(d / d t) \cos ^{2} t=-\sin 2 t$ and (1) of this section to evaluate $\mathscr{L}\left\{\cos ^{2} t\right\}$.

\end{enumerate}

In Problems 3 and 4 suppose a function $y(t)$ has the properties that $y(0)=1$ and $y^{\prime}(0)=-1$. Find the Laplace transform of the given expression.

$$
\begin{array}{ll}
\text { 3. } y^{\prime \prime}+3 y^{\prime} & \text { 4. } y^{\prime \prime}-4 y^{\prime}+5 y
\end{array}
$$

In Problems 5 and 6 suppose a function $y(t)$ has the properties that $y(0)=2$ and $y^{\prime}(0)=3$. Solve for the Laplace transform $\mathscr{L}\{y(t)\}=Y(s)$.\\
5. $y^{\prime \prime}-2 y^{\prime}+y=0$\\
6. $y^{\prime \prime}+y=1$

In Problems 7-20 evaluate the given Laplace transform without evaluating the integral.\\
7. $\mathscr{L}\left\{\int_{0}^{1} e^{\tau} d \tau\right\}$\\
8. $\mathscr{L}\left\{\int_{0}^{\iota} \cos \tau d \tau\right\}$\\
9. $\mathscr{L}\left\{\int_{0}^{t} e^{-\tau} \cos \tau d \tau\right\}$\\
10. $\mathscr{L}\left\{\int_{0}^{t} \tau \sin \tau d \tau\right\}$\\
11. $\mathscr{L}\left\{\int_{0}^{t} \tau e^{t-\tau} d \tau\right\}$\\
12. $\mathscr{L}\left\{\int_{0}^{t} \sin \tau \cos (t-\tau) d \tau\right\}$\\
13. $\mathscr{L}\left\{t \int_{0}^{t} \sin \tau d \tau\right\}$\\
14. $\mathscr{L}\left\{t \int_{0}^{t} \tau e^{-\tau} d \tau\right\}$\\
15. $\mathscr{L}\left\{1 * t^{3}\right\}$\\
16. $\mathscr{L}\left\{1 * e^{-2 t}\right\}$\\
17. $\mathscr{L}\left\{t^{2} * t^{4}\right\}$\\
18. $\mathscr{L}\left\{t^{2} * t e\right\}$\\
19. $\mathscr{L}\left\{e^{-t} * e^{t} \cos t\right\}$\\
20. $\mathscr{L}\left\{e^{2 t} * \sin t\right\}$

In Problems 21 and 22 suppose $\mathscr{L}^{-1}\{F(s)\}=f(t)$. Find the inverse Laplace transform of the given function.\\
21. $\frac{1}{s+5} F(s)$\\
22. $\frac{s}{s^{2}+4} F(s)$

In Problems 23-28 use (6) to find $f(t)$.\\
23. $\mathscr{L}^{-1}\left\{\frac{1}{s(s+1)}\right\}$\\
24. $\mathscr{L}^{-1}\left\{\frac{1}{s\left(s^{2}+1\right)}\right\}$\\
25. $\mathscr{L}^{-1}\left\{\frac{1}{(s+1)(s-2)}\right\}$\\
26. $\mathscr{L}^{-1}\left\{\frac{1}{(s+1)^{2}}\right\}$\\
27. $\mathscr{L}^{-1}\left\{\frac{s}{\left(s^{2}+4\right)^{2}}\right\}$\\
28. $\mathscr{L}^{-1}\left\{\frac{1}{\left(s^{2}+4 s+5\right)^{2}}\right\}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item Prove the commutative property of the convolution integral $f * g=g * f$.

  \item Prove the distributive property of the convolution integral $f *(g+h)=$ $f * g+f * h$.

\end{enumerate}

In Problems 31-38 use Theorem 7.10 to find the Laplace transform of the given periodic function.

31.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339(4)}
\end{center}

meander function

Figure 7.29

33.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339(5)}
\end{center}

sawtooth function

Figure 7.31

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339(3)}
\end{center}

full-wave rectification of $\sin t$

Figure 7.33

\begin{enumerate}
  \setcounter{enumi}{36}
  \item $f(t)=\sin t$
\end{enumerate}

$f(t+2 \pi)=f(t)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339}
\end{center}

square wave

Figure 7.30

34.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339(1)}
\end{center}

triangular wave

Figure 7.32

36.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-339(2)}
\end{center}

half-wave rectification of $\sin t$

Figure 7.34

\begin{enumerate}
  \setcounter{enumi}{37}
  \item $f(t)=\cos t$
\end{enumerate}

$f(t+2 \pi)=f(t)$

\subsection*{7.5 APPLICATIONS}
Since $\mathscr{L}\left\{y^{(n)}(t)\right\}, n>1$ depends on $y(t)$ and its $n-1$ derivatives evaluated at $t=0$, the Laplace transform is ideally suited to initial-value problems for linear differential equations with constant coefficients. This kind of differential equation can be reduced to an algebraic equation in the transformed function $Y(s)$. To see this, consider the initial-value problem

$$
\begin{aligned}
& a_{n} \frac{d^{n} y}{d t^{n}}+a_{n-1} \frac{d^{n-1} y}{d t^{n-1}}+\cdots+a_{1} \frac{d y}{d t}+a_{0} y=g(t) \\
& y(0)=y_{0}, \quad y^{\prime}(0)=y_{0}^{\prime}, \quad \ldots, \quad y^{(n-1)}(0)=y_{0}^{(n-1)}
\end{aligned}
$$

where $a_{i}, i=0,1, \ldots, n$ and $y_{0}, y_{0}^{\prime}, \ldots, y_{0}^{(n-1)}$ are constants. By the linearity property of the Laplace transform, we can write


\begin{equation*}
a_{n} \mathscr{L}\left\{\frac{d^{n} y}{d t^{n}}\right\}+a_{n-1} \mathscr{L}\left\{\frac{d^{n-1} y}{d t^{n-1}}\right\}+\cdots+a_{0} \mathscr{L}\{y\}=\mathscr{L}\{g(t)\} \tag{1}
\end{equation*}


From Theorem 7.8, (1) becomes

$$
\begin{aligned}
& a_{n}\left[s^{n} Y(s)-s^{n-1} y(0)-\cdots-y^{(n-1)}(0)\right] \\
& \quad+a_{n-1}\left[s^{n-1} Y(s)-s^{n-2} y(0)-\cdots-y^{(n-2)}(0)\right]+\cdots+a_{0} Y(s)=G(s)
\end{aligned}
$$

equation

or

transformed equation

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-340}\\
transformed equation

solution of original equation

Figure 7.35


\begin{align*}
{\left[a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots+a_{0}\right] Y(s)=} & a_{n}\left[s^{n-1} y_{0}+\cdots+y_{0}^{(n-1)}\right] \\
& +a_{n-1}\left[s^{n-2} y_{0}+\cdots+y_{0}^{(n-2)}\right]+\cdots+G(s), \tag{2}
\end{align*}


where $Y(s)=\mathscr{L}\{y(t)\}$ and $G(s)=\mathscr{L}\{g(t)\}$. By solving (2) for $Y(s)$, we find $y(t)$ by determining the inverse transform

$$
y(t)=\mathscr{L}^{-1}\{Y(s)\}
$$

The procedure is outlined in Figure 7.35. Note that this method incorporates the prescribed initial conditions directly into the solution. Hence there is no need for the separate operations of determining constants in the general solution of the differential equation.

\section*{EXAMPLE 1 DE Transformed into an Algebraic Equation}
Solve $\frac{d y}{d t}-3 y=e^{2 t}, y(0)=1$.

Solution We first take the transform of each member of the given differential equation:

$$
\mathscr{L}\left\{\frac{d y}{d t}\right\}-3 \mathscr{L}\{y\}=\mathscr{L}\left\{e^{2 t}\right\}
$$

We then use $\mathscr{L}\{d y / d t\}=s Y(s)-y(0)=s Y(s)-1$ and $\mathscr{L}\left\{e^{2 r}\right\}=1 /(s-2)$.

Solving

$$
s Y(s)-1-3 Y(s)=\frac{1}{s-2}
$$

for $Y(s)$ gives

$$
Y(s)=\frac{s-1}{(s-2)(s-3)}
$$

By partial fractions,

$$
\frac{s-1}{(s-2)(s-3)}=\frac{A}{s-2}+\frac{B}{s-3}
$$

which yields

$$
s-1=A(s-3)+B(s-2)
$$

Setting $s=2$ and $s=3$ in the last equation, we obtain $A=-1$ and $B=2$, respectively. Consequently

$$
Y(s)=\frac{-1}{s-2}+\frac{2}{s-3}
$$

and

$$
y(t)=-\mathscr{L}^{-1}\left\{\frac{1}{s-2}\right\}+2 \mathscr{L}^{-1}\left\{\frac{1}{s-3}\right\}
$$

From part (c) of Theorem 7.3 it follows that

$$
y(t)=-e^{2 t}+2 e^{3 t}
$$

\section*{EXAMPLE 2 An Initial-Value Problem}
Solve $y^{\prime \prime}-6 y^{\prime}+9 y=t^{2} e^{3 t}, y(0)=2, y^{\prime}(0)=6$.

Solution

$$
\mathscr{L}\left\{y^{\prime \prime}\right\}-6 \mathscr{L}\left\{y^{\prime}\right\}+9 \mathscr{L}\{y\}=\mathscr{L}\left\{t^{2} e^{3 \pi}\right\}
$$

$$
\underbrace{s^{2} Y(s)-s y(0)-y^{\prime}(0)}_{\mathscr{L}\left\{y^{\prime \prime}\right\}}-6[\underbrace{s Y(s)-y(0)}_{\mathscr{L}\left\{y^{\prime}\right\}}]+\underbrace{9 Y(s)}_{\mathscr{L}\{y\}}=\underbrace{\frac{2}{s-3}}_{\mathscr{L}\left\{t^{2} e^{3}\right\}} .
$$

Using the initial conditions and simplifying gives

$$
\begin{aligned}
&\left(s^{2}-6 s+9\right) Y(s)=2 s-6+\frac{2}{(s-3)^{3}} \\
&(s-3)^{2} Y(s)=2(s-3)+\frac{2}{(s-3)^{3}} \\
& Y(s)=\frac{2}{s-3}+\frac{2}{(s-3)^{5}} \\
& y(t)=2 \mathscr{L}^{-1}\left\{\frac{1}{s-3}\right\}+\frac{2}{4!} \mathscr{L}^{-1}\left\{\frac{4!}{(s-3)^{5}}\right\}
\end{aligned}
$$

Recall from the first translation theorem that

$$
\mathscr{L}^{-1}\left\{\left.\frac{4!}{s^{5}}\right|_{s \rightarrow s-3}\right\}=t^{4} e^{3 t}
$$

Hence we have

$$
y(t)=2 e^{3 t}+\frac{1}{12} t^{4} e^{3 t}
$$

\section*{EXAMPLE 3 Using the First Translation Theorem}
$$
\text { Solve } y^{\prime \prime}+4 y^{\prime}+6 y=1+e^{-t}, y(0)=0, y^{\prime}(0)=0 \text {. }
$$

Solution

$$
\mathscr{L}\left\{y^{\prime \prime}\right\}+4 \mathscr{L}\left\{y^{\prime}\right\}+6 \mathscr{L}\{y\}=\mathscr{L}\{1\}+\mathscr{L}\left\{e^{-\tau}\right\}
$$

$s^{2} Y(s)-s y(0)-y^{\prime}(0)+4[s Y(s)-y(0)]+6 Y(s)=\frac{1}{s}+\frac{1}{s+1}$

$$
\left(s^{2}+4 s+6\right) Y(s)=\frac{2 s+1}{s(s+1)}
$$

$$
Y(s)=\frac{2 s+1}{s(s+1)\left(s^{2}+4 s+6\right)}
$$

By partial fractions,

$$
\frac{2 s+1}{s(s+1)\left(s^{2}+4 s+6\right)}=\frac{A}{s}+\frac{B}{s+1}+\frac{C s+D}{s^{2}+4 s+6}
$$

which implies

$$
2 s+1=A(s+1)\left(s^{2}+4 s+6\right)+B s\left(s^{2}+4 s+6\right)+(C s+D) s(s+1)
$$

Setting $s=0$ and $s=-1$ gives, respectively, $A=\frac{1}{6}$ and $B=\frac{1}{3}$. Equating the coefficients of $s^{3}$ and $s$ gives

$$
\begin{array}{r}
A+B+C=0 \\
10 A+6 B+D=2
\end{array}
$$

so it follows that $C=-\frac{1}{2}$ and $D=-\frac{5}{3}$. Thus

$$
\begin{aligned}
Y(s) & =\frac{1 / 6}{s}+\frac{1 / 3}{s+1}+\frac{-s / 2-5 / 3}{s^{2}+4 s+6} \\
& =\frac{1 / 6}{s}+\frac{1 / 3}{s+1}+\frac{(-1 / 2)(s+2)-2 / 3}{(s+2)^{2}+2} \\
& =\frac{1 / 6}{s}+\frac{1 / 3}{s+1}-\frac{1}{2} \frac{s+2}{(s+2)^{2}+2}-\frac{2}{3} \frac{1}{(s+2)^{2}+2}
\end{aligned}
$$

Finally, from parts (a) and (c) of Theorem 7.3 and the first translation theorem we obtain

$$
\begin{aligned}
y(t)= & \frac{1}{6} \mathscr{L}^{-1}\left\{\frac{1}{s}\right\}+\frac{1}{3} \mathscr{L}^{-1}\left\{\frac{1}{s+1}\right\}-\frac{1}{2} \mathscr{L}^{-1}\left\{\frac{s+2}{(s+2)^{2}+2}\right\} \\
& -\frac{2}{3 \sqrt{2}} \mathscr{L}^{-1}\left\{\frac{\sqrt{2}}{(s+2)^{2}+2}\right\} \\
= & \frac{1}{6}+\frac{1}{3} e^{-t}-\frac{1}{2} e^{-2 t} \cos \sqrt{2} t-\frac{\sqrt{2}}{3} e^{-2 t} \sin \sqrt{2} t
\end{aligned}
$$

\section*{EXAMPLE 4 Using Theorems 7.3 and 7.7}
Solve $x^{\prime \prime}+16 x=\cos 4 t, x(0)=0, x^{\prime}(0)=1$.

Solution Recall that this initial-value problem could describe the forced, undamped, and resonant motion of a mass on a spring. The mass starts with an initial velocity of 1 foot per second in the downward direction from the equilibrium position.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-343}
\end{center}

Figure 7.36\\
Transforming the equation gives

$$
\begin{aligned}
\left(s^{2}+16\right) X(s) & =1+\frac{s}{s^{2}+16} \\
X(s) & =\frac{1}{s^{2}+16}+\frac{s}{\left(s^{2}+16\right)^{2}}
\end{aligned}
$$

With the aid of part (d) of Theorem 7.3 and Theorem 7.7, we find

$$
\begin{aligned}
x(t) & =\frac{1}{4} \mathscr{L}^{-1}\left\{\frac{4}{s^{2}+16}\right\}+\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{8 s}{\left(s^{2}+16\right)^{2}}\right\} \\
& =\frac{1}{4} \sin 4 t+\frac{1}{8} t \sin 4 t
\end{aligned}
$$

\section*{EXAMPLE 5 Using a Unit Step Function}
Solve $x^{\prime \prime}+16 x=f(t), x(0)=0, x^{\prime}(0)=1$,

where

$$
f(t)=\left\{\begin{array}{lr}
\cos 4 t, & 0 \leq t<\pi \\
0, & t \geq \pi
\end{array}\right.
$$

Solution The function $f(t)$ can be interpreted as an external force that is acting on a mechanical system for only a short period of time and then is removed. See Figure 7.36. Although this problem could be solved by conventional means, the procedure is not at all convenient when $f(t)$ is defined in a piecewise manner. With the aid of (2) and (3) of Section 7.3 and the periodicity of the cosine, we can rewrite $f$ in terms of the unit step function as

$$
f(t)=\cos 4 t-\cos 4 t थ(t-\pi)=\cos 4 t-\cos 4(t-\pi) \mathscr{U}(t-\pi) .
$$

The second translation theorem then yields

$$
\begin{aligned}
\mathscr{L}\left\{x^{\prime \prime}\right\}+16 \mathscr{L}\{x\} & =\mathscr{L}\{f(t)\} \\
s^{2} X(s)-s x(0)-x^{\prime}(0)+16 X(s) & =\frac{s}{s^{2}+16}-\frac{s}{s^{2}+16} e^{-\pi s} \\
\left(s^{2}+16\right) X(s) & =1+\frac{s}{s^{2}+16}-\frac{s}{s^{2}+16} e^{-\pi s} \\
X(s) & =\frac{1}{s^{2}+16}+\frac{s}{\left(s^{2}+16\right)^{2}}-\frac{s}{\left(s^{2}+16\right)^{2}} e^{-\pi s}
\end{aligned}
$$

From part (b) of Example 12 in Section 7.3 (with $k=4$ ) along with (8) of that section, we find

$$
\begin{aligned}
x(t)= & \frac{1}{4} \mathscr{L}^{-1}\left\{\frac{4}{s^{2}+16}\right\}+\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{8 s}{\left(s^{2}+16\right)^{2}}\right\} \\
& -\frac{1}{8} \mathscr{L}^{-1}\left\{\frac{8 s}{\left(s^{2}+16\right)^{2}} e^{-\pi s}\right\} \\
= & \frac{1}{4} \sin 4 t+\frac{1}{8} t \sin 4 t-\frac{1}{8}(t-\pi) \sin 4(t-\pi) U(t-\pi)
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-344}
\end{center}

Figure 7.37\\
The foregoing solution is the same as

$$
x(t)=\left\{\begin{array}{lr}
\frac{1}{4} \sin 4 t+\frac{1}{8} t \sin 4 t, & 0 \leq t<\pi \\
\frac{2+\pi}{8} \sin 4 t, & t \geq \pi
\end{array}\right.
$$

Observe from the graph of $x(t)$ in Figure 7.37 that the amplitudes of vibration become steady as soon as the external force is turned off.

\section*{EXAMPLE 6 Using the Second Translation Theorem}
Solve $y^{\prime \prime}+2 y^{\prime}+y=f(t), y(0)=0, y^{\prime}(0)=0$,

where

$$
f(t)=U(t-1)-2 U(t-2)+U(t-3) .
$$

Solution By the second translation theorem and simplification, the transform of the differential equation is

or

$$
\begin{aligned}
(s+1)^{2} Y(s) & =\frac{e^{-s}}{s}-2 \frac{e^{-2 s}}{s}+\frac{e^{-3 s}}{s} \\
Y(s) & =\frac{e^{-s}}{s(s+1)^{2}}-2 \frac{e^{-2 s}}{s(s+1)^{2}}+\frac{e^{-3 s}}{s(s+1)^{2}}
\end{aligned}
$$

With the aid of partial fractions, the last equation becomes

$$
\begin{aligned}
Y(s)= & {\left[\frac{1}{s}-\frac{1}{s+1}-\frac{1}{(s+1)^{2}}\right] e^{-s}-2\left[\frac{1}{s}-\frac{1}{s+1}-\frac{1}{(s+1)^{2}}\right] e^{-2 s} } \\
& +\left[\frac{1}{s}-\frac{1}{s+1}-\frac{1}{(s+1)^{2}}\right] e^{-3 s} .
\end{aligned}
$$

Again using the inverse form of the second translation theorem, we find

$$
\begin{aligned}
y(t)= & {\left[1-e^{-(t-1)}-(t-1) e^{-(t-1)}\right] U(t-1)-2\left[1-e^{-(t-2)}-(t-2) e^{-(t-2)}\right] U(t-2) } \\
& +\left[1-e^{-(t-3)}-(t-3) e^{-(t-3)}\right] U(t-3) .
\end{aligned}
$$

Volterra Integral Equation The convolution theorem is useful in solving other types of equations in which an unknown function appears under an integral sign. In the next example we solve a Volterra integral equation

$$
f(t)=g(t)+\int_{0}^{t} f(\tau) h(t-\tau) d \tau
$$

for $f(t)$. The functions $g(t)$ and $h(t)$ are known.

\section*{EXAMPLE 7 An Integral Equation}
Solve $f(t)=3 t^{2}-e^{-t}-\int_{0}^{t} f(\tau) e^{t-\tau} d \tau$ for $f(t)$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-345(1)}
\end{center}

Figure 7.38\\
Solution It follows from Theorem 7.9 that

$$
\begin{aligned}
\mathscr{L}\{f(t)\} & =3 \mathscr{L}\left\{t^{2}\right\}-\mathscr{L}\left\{e^{-t}\right\}-\mathscr{L}\{f(t)\} \mathscr{L}\left\{e^{r}\right\} \\
F(s) & =3 \cdot \frac{2}{s^{3}}-\frac{1}{s+1}-F(s) \cdot \frac{1}{s-1} .
\end{aligned}
$$

Solving the last equation for $F(s)$ gives

$$
\begin{aligned}
F(s) & =\frac{6(s-1)}{s^{4}}-\frac{s-1}{s(s+1)} \\
& =\frac{6}{s^{3}}-\frac{6}{s^{4}}+\frac{1}{s}-\frac{2}{s+1} . \quad \leftarrow \text { termwise division and partial fractions }
\end{aligned}
$$

The inverse transform is

$$
\begin{aligned}
f(t) & =3 \mathscr{L}^{-1}\left\{\frac{2!}{s^{3}}\right\}-\mathscr{L}^{-1}\left\{\frac{3!}{s^{4}}\right\}+\mathscr{L}^{-1}\left\{\frac{1}{s}\right\}-2 \mathscr{L}^{-1}\left\{\frac{1}{s+1}\right\} \\
& =3 t^{2}-t^{3}+1-2 e^{-t}
\end{aligned}
$$

Series Circuits In a single loop or series circuit, Kirchhoff's second law states that the sum of the voltage drops across an inductor, resistor, and capacitor is equal to the impressed voltage $E(t)$. Now it is known that

the voltage drop across the inductor $=L \frac{d i}{d t}$,

the voltage drop across the resistor $=R i(t)$,

and

$$
\text { the voltage drop across the capacitor }=\frac{1}{C} \int_{0}^{t} i(\tau) d \tau
$$

where $i(t)$ is the current and $L, R$, and $C$ are constants. See Section 1.2. It follows that the current in a circuit, such as that shown in Figure 7.38, is governed by the integrodifferential equation


\begin{equation*}
L \frac{d i}{d t}+R i+\frac{1}{C} \int_{0}^{t} i(\tau) d \tau=E(t) \tag{3}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-345}
\end{center}

Figure 7.39

\section*{EXAMPLEE 8 An Integrodifferential Equation}
Determine the current $i(t)$ in a single loop $L-R-C$ circuit when $L=0.1$ henry, $R=20$ ohms, $C=10^{-3}$ farad, $i(0)=0$, and the impressed voltage $E(t)$ is as given in Figure 7.39.

Solution Since the voltage is off for $t \geq 1$, we can write


\begin{equation*}
E(t)=120 t-120 t \mathscr{U}(t-1) \tag{4}
\end{equation*}


But in order to use the second translation theorem we must rewrite (4) as

$$
E(t)=120 t-120(t-1) U(t-1)-120 U(t-1)
$$

Equation (3) then becomes


\begin{equation*}
0.1 \frac{d i}{d t}+20 i+10^{3} \int_{0}^{t} i(\tau) d \tau=120 t-120(t-1) \mathscr{U}(t-1)-120 \mathscr{U}(t-1) \tag{5}
\end{equation*}


Now recall from (5) of Section 7.4 that

$$
\mathscr{L}\left\{\int_{0}^{t} i(\tau) d \tau\right\}=\frac{I(s)}{s}
$$

where $I(s)=\mathscr{L}\{i(t)\}$. Thus the transform of equation (5) is

$$
0.1 s I(s)+20 I(s)+10^{3} \frac{I(s)}{s}=120\left[\frac{1}{s^{2}}-\frac{1}{s^{2}} e^{-s}-\frac{1}{s} e^{-s}\right]
$$

or, after multiplying by 10 s ,

$$
\begin{aligned}
(s+100)^{2} I(s) & =1200\left[\frac{1}{s}-\frac{1}{s} e^{-s}-e^{-s}\right] \\
I(s) & =1200\left[\frac{1}{s(s+100)^{2}}-\frac{1}{s(s+100)^{2}} e^{-s}-\frac{1}{(s+100)^{2}} e^{-s}\right]
\end{aligned}
$$

By partial fractions we can write

$$
\begin{aligned}
I(s)=1200\left[\frac{1 / 10,000}{s}-\right. & \frac{1 / 10,000}{s+100}-\frac{1 / 100}{(s+100)^{2}}-\frac{1 / 10,000}{s} e^{-s} \\
& \left.+\frac{1 / 10,000}{s+100} e^{-s}+\frac{1 / 100}{(s+100)^{2}} e^{-s}-\frac{1}{(s+100)^{2}} e^{-s}\right]
\end{aligned}
$$

Employing the inverse form of the second translation theorem, we obtain

$$
\begin{aligned}
& i(t)=\frac{3}{25}[1-थ(t-1)]-\frac{3}{25}\left[e^{-100 t}-e^{-100(t-1)} U(t-1)\right] \\
& -12 t e^{-100 t}-1188(t-1) e^{-100(t-1)} U(t-1)
\end{aligned}
$$

\section*{EXAMPLE 9 A Periodic Impressed Voltage}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-346}
\end{center}

Figure 7.40\\
The differential equation for the current $i(t)$ in a single loop $L-R$ series circuit is


\begin{equation*}
L \frac{d i}{d t}+R i=E(t) \tag{6}
\end{equation*}


Determine the current $i(t)$ when $i(0)=0$ and $E(t)$ is the square wave function shown in Figure 7.40.

Solution The Laplace transform of the equation is


\begin{equation*}
L s I(s)+R I(s)=\mathscr{L}\{E(t)\} \tag{7}
\end{equation*}


Since $E(t)$ is periodic with period $T=2$, we use (8) of Section 7.4:

$$
\begin{aligned}
\mathscr{L}\{E(t)\} & =\frac{1}{1-e^{-2 s}} \int_{0}^{2} e^{-s t} f(t) d t \\
& =\frac{1}{1-e^{-2 s}}\left(\int_{0}^{1} 1 \cdot e^{-s t} d t+\int_{1}^{2} 0 \cdot e^{-s t} d t\right) \\
& =\frac{1}{1-e^{-2 s}} \frac{1-e^{-s}}{s} \leftarrow 1-e^{-2 s}=\left(1+e^{-s}\right)\left(1-e^{-s}\right) \\
& =\frac{1}{s\left(1+e^{-s}\right)^{2}}
\end{aligned}
$$

Hence from (7) we find


\begin{equation*}
I(s)=\frac{1 / L}{s(s+R / L)\left(1+e^{-s}\right)} \tag{8}
\end{equation*}


To find the inverse Laplace transform of this function we first make use of a geometric series. Recall, for $|x|<1$, that

$$
\frac{1}{1+x}=1-x+x^{2}-x^{3}+\cdots
$$

With the identification $x=e^{-s}$ we then have for $s>0$

$$
\begin{gathered}
\frac{1}{1+e^{-s}}=1-e^{-s}+e^{-2 s}-e^{-3 s}+\cdots \\
\frac{1}{s(s+R / L)}=\frac{L / R}{s}-\frac{L / R}{s+R / L}
\end{gathered}
$$

If we write

(8) becomes

$$
\begin{aligned}
I(s) & =\frac{1}{R}\left(\frac{1}{s}-\frac{1}{s+R / L}\right)\left(1-e^{-s}+e^{-2 s}-e^{-3 s}+\cdots\right) \\
& =\frac{1}{R}\left(\frac{1}{s}-\frac{e^{-s}}{s}+\frac{e^{-2 s}}{s}-\frac{e^{-3 s}}{s}+\cdots\right)-\frac{1}{R}\left(\frac{1}{s+R / L}-\frac{e^{-s}}{s+R / L}+\frac{e^{-2 s}}{s+R / L}-\frac{e^{-3 s}}{s+R / L}+\cdots\right)
\end{aligned}
$$

By applying the inverse form of the second translation theorem to each term of both series, we obtain

$$
\begin{aligned}
& i(t)= \frac{1}{R}(1-U(t-1)+U(t-2)-U(t-3)+\cdots) \\
&-\frac{1}{R}\left(e^{-R t / L}-e^{-R(t-1) / L} U(t-1)+e^{-R(t-2) / L} U(t-2)-e^{-R(t-3) / L} U(t-3)+\cdots\right) \\
& \quad \text { or, equivalently, }
\end{aligned}
$$

$$
i(t)=\frac{1}{R}\left(1-e^{-R t / L}\right)+\frac{1}{R} \sum_{n=1}^{\infty}(-1)^{n}\left(1-e^{-R(t-n) / L}\right) U(t-n)
$$

To interpret the solution in Example 9 let us assume for the sake of illustration that $R=1, L=1$, and $0 \leq t<4$. In this case

$$
i(t)=1-e^{-t}-\left(1-e^{t-1}\right) \mathscr{U}(t-1)+\left(1-e^{-(t-2)}\right) \mathscr{U}(t-2)-\left(1-e^{-(t-3)}\right) U(t-3)
$$

in other words,

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-347}
\end{center}

Figure 7.4I

$$
i(t)= \begin{cases}1-e^{-t}, & 0 \leq t<1 \\ -e^{-t}+e^{-(t-1)}, & 1 \leq t<2 \\ 1-e^{-t}+e^{-(t-1)}-e^{-(t-2)}, & 2 \leq t<3 \\ -e^{-t}+e^{-(t-1)}-e^{-(t-2)}+e^{-(t-3)}, & 3 \leq t<4\end{cases}
$$

The graph of $i(t)$ on the interval $0 \leq t<4$ is given in Figure 7.41.

Beams In Example 9 of Section 1.2 we saw that the static deflection $y(x)$ of a uniform beam of length $L$ carrying a load $w(x)$ per unit length is found from the fourth-order differential equation


\begin{equation*}
E I \frac{d^{4} y}{d x^{4}}=w(x) \tag{9}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-348}
\end{center}

Figure 7.42

where $E$ is Young's modulus of elasticity and $I$ is a moment of inertia of a cross section of the beam. To apply the Laplace transform to (9) we tacitly assume that $w(x)$ and $y(x)$ are defined on $(0, \infty)$ rather than on $(0, L)$. Note too that the next example is a boundary-value problem rather than an initial-value problem.

\section*{EXAMPLE 10 A Boundary-Value Problem}
A beam of length $L$ is embedded at both ends. See Figure 7.42. In this case the deflection $y(x)$ must satisfy (9) and the conditions

$$
y(0)=0, \quad y(L)=0, \quad y^{\prime}(0)=0, \quad \text { and } \quad y^{\prime}(L)=0
$$

The first two conditions indicate that there is no vertical deflection at the ends; the last two conditions mean that the line of deflection is horizontal (zero slope) at the ends. Find the deflection of the beam when a constant load $w_{0}$ is uniformly distributed along its length-that is, when $w(x)=w_{0}, 0<x<L$.

Solution Transforming (9) with respect to the variable $x$ gives

$$
\begin{aligned}
E I\left(s^{4} Y(s)-s^{3} y(0)-s^{2} y^{\prime}(0)-s y^{\prime \prime}(0)-y^{\prime \prime \prime}(0)\right) & =\frac{w_{0}}{s} \\
s^{4} Y(s)-s y^{\prime \prime}(0)-y^{\prime \prime \prime}(0) & =\frac{w_{0}}{E I s}
\end{aligned}
$$

If we let $c_{1}=y^{\prime \prime}(0)$ and $c_{2}=y^{\prime \prime \prime}(0)$, then

$$
Y(s)=\frac{c_{1}}{s^{3}}+\frac{c_{2}}{s^{4}}+\frac{w_{0}}{E I s^{5}}
$$

and consequently

$$
\begin{aligned}
y(x) & =\frac{c_{1}}{2!} \mathscr{L}^{-1}\left\{\frac{2!}{s^{3}}\right\}+\frac{c_{2}}{3!} \mathscr{L}^{-1}\left\{\frac{3!}{s^{4}}\right\}+\frac{w_{0}}{4!E I} \mathscr{L}^{-1}\left\{\frac{4!}{s^{5}}\right\} \\
& =\frac{c_{1}}{2} x^{2}+\frac{c_{2}}{6} x^{3}+\frac{w_{0}}{24 E I} x^{4}
\end{aligned}
$$

Applying the given conditions $y(L)=0$ and $y^{\prime}(L)=0$ to the last equation yields the system

$$
\begin{aligned}
\frac{c_{1}}{2} L^{2}+\frac{c_{2}}{6} L^{3}+\frac{w_{0}}{24 E I} L^{4} & =0 \\
c_{1} L+\frac{c_{2}}{2} L^{2}+\frac{w_{0}}{6 E I} L^{3} & =0
\end{aligned}
$$

Solving, we find $c_{1}=w_{0} L^{2} / 12 E I$ and $c_{2}=-w_{0} L / 2 E I$. Thus the deflection is given by

$$
y(x)=\frac{w_{0} L^{2}}{24 E I} x^{2}-\frac{w_{0} L}{12 E I} x^{3}+\frac{w_{0}}{24 E I} x^{4}=\frac{w_{0}}{24 E I} x^{2}(x-L)^{2}
$$

\section*{EXERCISES 7.5}
Answers to odd-numbered problems begin on page A-16.

A table of the transforms of some basic functions is given in Appendix II.

In Problems 1-26 use the Laplace transform to solve the given differential equation subject to the indicated initial conditions. Where appropriate, write $f$ in terms of unit step functions.

\begin{enumerate}
  \item $\frac{d y}{d t}-y=1, \quad y(0)=0$
  \item $\frac{d y}{d t}+2 y=t, \quad y(0)=-1$
  \item $y^{\prime}+4 y=e^{-4 t}, \quad y(0)=2$
  \item $y^{\prime}-y=\sin t, \quad y(0)=0$
  \item $y^{\prime \prime}+5 y^{\prime}+4 y=0, \quad y(0)=1, y^{\prime}(0)=0$
  \item $y^{\prime \prime}-6 y^{\prime}+13 y=0, \quad y(0)=0, y^{\prime}(0)=-3$
  \item $y^{\prime \prime}-6 y^{\prime}+9 y=t, \quad y(0)=0, y^{\prime}(0)=1$
  \item $y^{\prime \prime}-4 y^{\prime}+4 y=t^{3}, \quad y(0)=1, y^{\prime}(0)=0$
  \item $y^{\prime \prime}-4 y^{\prime}+4 y=t^{3} e^{2 t}, \quad y(0)=0, y^{\prime}(0)=0$
  \item $y^{\prime \prime}-2 y^{\prime}+5 y=1+t, \quad y(0)=0, y^{\prime}(0)=4$
  \item $y^{\prime \prime}+y=\sin t, \quad y(0)=1, y^{\prime}(0)=-1$
  \item $y^{\prime \prime}+16 y=1, \quad y(0)=1, y^{\prime}(0)=2$
  \item $y^{\prime \prime}-y^{\prime}=e^{t} \cos t, \quad y(0)=0, y^{\prime}(0)=0$
  \item $y^{\prime \prime}-2 y^{\prime}=e^{t} \sinh t, \quad y(0)=0, y^{\prime}(0)=0$
  \item $2 y^{\prime \prime \prime}+3 y^{\prime \prime}-3 y^{\prime}-2 y=e^{-t}, \quad y(0)=0, y^{\prime}(0)=0, y^{\prime \prime}(0)=1$
  \item $y^{\prime \prime \prime}+2 y^{\prime \prime}-y^{\prime}-2 y=\sin 3 t, \quad y(0)=0, y^{\prime}(0)=0, y^{\prime \prime}(0)=1$
  \item $y^{(4)}-y=0, \quad y(0)=1, y^{\prime}(0)=0, y^{\prime \prime}(0)=-1, y^{\prime \prime \prime}(0)=0$
  \item $y^{(4)}-y=t, \quad y(0)=0, y^{\prime}(0)=0, y^{\prime \prime}(0)=0, y^{\prime \prime \prime}(0)=0$
  \item $y^{\prime}+y=f(t)$, where $f(t)=\left\{\begin{array}{lr}0, & 0 \leq t>1 \\ 5, & t \geq 1\end{array}, y(0)=0\right.$
  \item $y^{\prime}+y=f(t)$, where $f(t)=\left\{\begin{array}{rr}1, & 0 \leq t<1 \\ -1, & t \geq 1\end{array}, y(0)=0\right.$
  \item $y^{\prime}+2 y=f(t)$, where $f(t)=\left\{\begin{array}{lr}t, & 0 \leq t<1 \\ 0, & t \geq 1\end{array}, y(0)=0\right.$
  \item $y^{\prime \prime}+4 y=f(t)$, where $f(t)=\left\{\begin{array}{lr}1, & 0 \leq t<1 \\ 0, & t \geq 1\end{array}, y(0)=0, y^{\prime}(0)=-1\right.$
  \item $y^{\prime \prime}+4 y=\sin t U(t-2 \pi), \quad y(0)=1, y^{\prime}(0)=0$
  \item $y^{\prime \prime}-5 y^{\prime}+6 y=\vartheta(t-1), \quad y(0)=0, y^{\prime}(0)=1$
  \item $y^{\prime \prime}+y=f(t)$, where $f(t)=\left\{\begin{array}{lc}0, & 0 \leq t<\pi \\ 1, & \pi \leq t<2 \pi, y(0)=0, y^{\prime}(0)=1 \\ 0, & t \geq 2 \pi\end{array}\right.$
  \item $y^{\prime \prime}+4 y^{\prime}+3 y=1-थ(t-2)-थ(t-4)+U(t-6)$, $y(0)=0, y^{\prime}(0)=0$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-350(2)}
\end{center}

Figure 7.43

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-350(1)}
\end{center}

Figure 7.44

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-350}
\end{center}

Figure 7.45\\
In Problems 27 and 28 use the Laplace transform to solve the given differential equation subject to the indicated boundary conditions.

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $y^{\prime \prime}+2 y^{\prime}+y=0, \quad y^{\prime}(0)=2, y(1)=2$

  \item $y^{\prime \prime}-9 y^{\prime}+20 y=1, \quad y(0)=0, y^{\prime}(1)=0$

\end{enumerate}

In Problems 29-38 use the Laplace transform to solve the given integral equation or integrodifferential equation.

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $f(t)+\int_{0}^{t}(t-\tau) f(\tau) d \tau=t$

  \item $f(t)=2 t-4 \int_{0}^{t} \sin \tau f(t-\tau) d \tau$

  \item $f(t)=t e^{t}+\int_{0}^{t} \tau f(t-\tau) d \tau$

  \item $f(t)+2 \int_{0}^{t} f(\tau) \cos (t-\tau) d \tau=4 e^{-t}+\sin t$

  \item $f(t)+\int_{0}^{t} f(\tau) d \tau=1$

  \item $f(t)=\cos t+\int_{0}^{t} e^{-\tau} f(t-\tau) d \tau$

  \item $f(t)=1+t-\frac{8}{3} \int_{0}^{t}(\tau-t)^{3} f(\tau) d \tau$

  \item $t-2 f(t)=\int_{0}^{t}\left(e^{\tau}-e^{-\tau}\right) f(t-\tau) d \tau$

  \item $y^{\prime}(t)=1-\sin t-\int_{0}^{t} y(\tau) d \tau, \quad y(0)=0$

  \item $\frac{d y}{d t}+6 y(t)+9 \int_{0}^{t} y(\tau) d \tau=1, \quad y(0)=0$

  \item Use equation (3) to determine the current $i(t)$ in a single loop $L-R-C$ circuit when $L=0.005$ henry, $R=1$ ohm, $\mathrm{C}=0.02$ farad, $E(t)=$ $100[1-U(t-1)]$ volts, and $i(0)=0$.

  \item Solve Problem 39 when $E(t)=100[t-(t-1) U(t-1)]$.

  \item Recall that the differential equation for the charge $q(t)$ on the capacitor in an $R$ - $C$ series circuit is

\end{enumerate}

$$
R \frac{d q}{d t}+\frac{1}{C} q=E(t)
$$

where $E(t)$ is the impressed voltage. See Section 3.2. Use the Laplace transform to determine the charge $q(t)$ when $q(0)=0$ and $E(t)=E_{0} e^{-k t}, k>0$. Consider two cases: $k \neq 1 / R C$ and $k=1 / R C$.

\begin{enumerate}
  \setcounter{enumi}{41}
  \item Use the Laplace transform to determine the charge on the capacitor in an $R-C$ series circuit if $q(0)=q_{0}, R=10$ ohms, $C=0.1$ farad, and $E(t)$ is as given in Figure 7.43.

  \item Use the Laplace transform to determine the charge on the capacitor in an $R-C$ series circuit if $q(0)=0, R=2.5$ ohms, $C=0.08$ farad, and $E(t)$ is as given in Figure 7.44.

  \item Use the Laplace transform to determine the charge $q(t)$ on the capacitor in an $R$ - $C$ series circuit when $q(0)=0, R=50$ ohms, $C=0.01$ farad, and $E(t)$ is as given in Figure 7.45.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-351(3)}
\end{center}

Figure 7.46

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-351(2)}
\end{center}

Figure 7.47

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-351}
\end{center}

Figure 7.48

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-351(1)}
\end{center}

Figure 7.49\\
45. Use the Laplace transform to determine the current $i(t)$ in a single loop $L-R$ series circuit when $i(0)=0, L=1$ henry, $R=10$ ohms, and $E(t)$ is as given in Figure 7.46.

\begin{enumerate}
  \setcounter{enumi}{45}
  \item Solve equation (6) subject to $i(0)=0$, where $E(t)$ is as given in Figure 7.47. [Hint: See Problem 31, Exercises 7.4.]

  \item Solve equation (6) subject to $i(0)=0$, where $E(t)$ is as given in Figure 7.48. Specify the solution for $0 \leq t<2$. [Hint: See Problem 33, Exercises 7.4.]

  \item Recall that the differential equation for the instantaneous charge $q(t)$ on the capacitor in an $L-R-C$ series circuit is given by

\end{enumerate}


\begin{equation*}
L \frac{d^{2} q}{d t^{2}}+R \frac{d q}{d t}+\frac{1}{C} q=E(t) \tag{10}
\end{equation*}


See Section 5.4. Use the Laplace transform to determine $q(t)$ when $L=$ 1 henry, $R=20$ ohms, $C=0.005$ farad, $E(t)=150$ volts, $t>0$, and $q(0)=0, i(0)=0$. What is the current $i(t)$ ? What is the charge $q(t)$ if the same constant voltage is turned off for $t \geq 2$ ?

\begin{enumerate}
  \setcounter{enumi}{48}
  \item Determine the charge $q(t)$ and current $i(t)$ for a series circuit in which $L=1$ henry, $R=20$ ohms, $C=0.01$ farad, $E(t)=120 \sin 10 t$ volts, $q(0)=0$, and $i(0)=0$. What is the steady-state current?

  \item Consider the battery of constant voltage $E_{0}$ that charges the capacitor shown in Figure 7.49. If we divide by $L$ and define $\lambda=R / 2 L$ and $\omega^{2}=$ $1 / L C$, then $(10)$ becomes

\end{enumerate}

$$
\frac{d^{2} q}{d t^{2}}+2 \lambda \frac{d q}{d t}+\omega^{2} q=\frac{E_{0}}{L}
$$

Use the Laplace transform to show that the solution of this equation, subject to $q(0)=0$ and $i(0)$, is

$$
q(t)= \begin{cases}E_{0} C\left[1-e^{-\lambda t}\left(\cosh \sqrt{\lambda^{2}-\omega^{2}} t+\frac{\lambda}{\sqrt{\lambda^{2}-\omega^{2}}} \sinh \sqrt{\lambda^{2}-\omega^{2}} t\right),\right. & \lambda>\omega \\ E_{0} C\left[1-e^{-\lambda t}(1+\lambda t)\right], & \lambda=\omega \\ E_{0} C\left[1-e^{-\lambda t}\left(\cos \sqrt{\omega^{2}-\lambda^{2}} t+\frac{\lambda}{\sqrt{\omega^{2}-\lambda^{2}}} \sin \sqrt{\omega^{2}-\lambda^{2}} t\right)\right], & \lambda<\omega\end{cases}
$$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item Use the Laplace transform to determine the charge $q(t)$ on the capacitor in an $L-C$ series circuit when $q(0)=0, i(0)=0$, and $E(t)=E_{0} e^{-k t}, k>0$.

  \item Suppose a $32-\mathrm{lb}$ weight stretches a spring 2 ft . If the weight is released from rest at the equilibrium position, determine the equation of motion if an impressed force $f(t)=\sin t$ acts on the system for $0 \leq t<2 \pi$ and is then removed. Ignore any damping forces. [Hint: Write the impressed force in terms of the unit step function.]

  \item A 4-lb weight stretches a spring 2 ft . The weight is released from rest 18 in. above the equilibrium position, and the resulting motion takes place in a medium offering a damping force numerically equal to $\frac{7}{8}$ times the instantaneous velocity. Use the Laplace transform to determine the equation of motion.

  \item A 16-lb weight is attached to a spring whose constant is $k=4.5 \mathrm{lb} / \mathrm{ft}$. Beginning at $t=0$, a force equal to $f(t)=4 \sin 3 t+2 \cos 3 t$ acts on the system. Assuming that no damping forces are present, use the

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-352(1)}
\end{center}

Figure 7.50

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-352}
\end{center}

Figure 7.5I\\
Laplace transform to find the equation of motion if the weight is released from rest from the equilibrium position.

\begin{enumerate}
  \setcounter{enumi}{54}
  \item For a cantilever beam embedded at its left end $(x=0)$ and free at its right end $(x=L)$, the deflection $y(x)$ must satisfy (9) and
\end{enumerate}


\begin{equation*}
y(0)=0, \quad y^{\prime}(0)=0, \quad y^{\prime \prime}(L)=0, \quad y^{\prime \prime \prime}(L)=0 \tag{11}
\end{equation*}


The first two conditions state that the deflection and slope are zero at $x=0$, and the last two conditions state that the bending moment and shear force are zero at $x=L$. Use the Laplace transform to solve equation (9) subject to (11) when a constant load $w_{0}$ is uniformly distributed along the length of the beam. See Figure 7.50. Find the deflection at the midpoint of the beam. Find the maximum deflection of the beam.

\begin{enumerate}
  \setcounter{enumi}{55}
  \item Solve Problem 55 when the load is given by
\end{enumerate}

$$
w(x)= \begin{cases}0, & 0<x<L / 3 \\ w_{0}, & L / 3<x<2 L / 3 \\ 0, & 2 L / 3<x<L\end{cases}
$$

Write $w(x)$ in terms of unit step functions.

\begin{enumerate}
  \setcounter{enumi}{56}
  \item Solve Problem 55 when the load is given by
\end{enumerate}

$$
w(x)= \begin{cases}w_{0}, & 0<x<L / 2 \\ 0, & L / 2<x<L\end{cases}
$$

\begin{enumerate}
  \setcounter{enumi}{57}
  \item The static deflection $y(x)$ of a beam that is hinged at both ends must satisfy the differential equation (9) and the conditions
\end{enumerate}


\begin{equation*}
y(0)=0, \quad y^{\prime \prime}(0)=0, \quad y(L)=0, \quad y^{\prime \prime}(L)=0 \tag{12}
\end{equation*}


Use the Laplace transform to solve (9) subject to (12) when $w(x)=w_{0}$, $0<x<L$. See Figure 7.51.

In Problems 59 and 60 use the Laplace transform and Theorem 7.7 to find a solution of the given equation.

\begin{enumerate}
  \setcounter{enumi}{58}
  \item $t y^{\prime \prime}-y^{\prime}=t^{2}, \quad y(0)=0$

  \item $t y^{\prime \prime}+2 t y^{\prime}+2 y=0, \quad y(0)=0$

  \item In this problem we show how the convolution integral can be used to find a solution of an initial-value problem of the type

\end{enumerate}


\begin{equation*}
a y^{\prime \prime}+b y^{\prime}+c y=g(t), \quad y(0)=0, \quad y^{\prime}(0)=0 \tag{13}
\end{equation*}


(a) Show that the solution $y_{1}(t)$ of the initial-value problem

$$
\begin{gathered}
a y^{\prime \prime}+b y^{\prime}+c y=0, \quad y(0)=0, \quad y^{\prime}(0)=1 \\
y_{1}(t)=\mathscr{L}^{-1}\left\{\frac{a}{a s^{2}+b s+c}\right\}
\end{gathered}
$$

(b) Use the result in part (a) to show that the solution $y_{2}(t)$ of the initialvalue problem in (13) is given by

$$
y_{2}(t)=\frac{1}{a} g * y_{1}
$$

\begin{enumerate}
  \setcounter{enumi}{61}
  \item Use the procedure outlined in Problem 61 to find a solution of the initial-value problem
\end{enumerate}

$$
y^{\prime \prime}+y=\sec t, \quad y(0)=0, \quad y^{\prime}(0)=0
$$

\subsection*{7.6 DIRAC DELTA FUNCTION \\
 - Unit impulse - Dirac delta function}
Laplace transform of delta function

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-353}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-353(1)}
\end{center}

(b) behavior of $\delta_{a}$ as $a \rightarrow 0$

Figure 7.52

Unit Impulse Mechanical systems are often acted upon by an external force (or emf in an electrical circuit) of large magnitude that acts only for a very short period of time. For example, a vibrating airplane wing could be struck by lightning, a mass on a spring could be given a sharp blow by a ball peen hammer, a ball (baseball, golf ball, tennis ball) could be sent soaring when struck violently by some kind of club (baseball bat, golf club, tennis racket). The function

\[
\delta_{a}\left(t-t_{0}\right)=\left\{\begin{array}{lr}
0, & 0 \leq t<t_{0}-a  \tag{1}\\
\frac{1}{2 a}, & t_{0}-a \leq t<t_{0}+a \\
0, & t \geq t_{0}+a
\end{array}\right.
\]

$a>0, t_{0}>0$, shown in Figure 7.52(a), could serve as a mathematical model for such a force. For a small value of $a, \delta_{a}\left(t-t_{0}\right)$ is essentially a constant function of large magnitude that is "on" for just a very short period of time around $t_{0}$. The behavior of $\delta_{a}\left(t-t_{0}\right)$ as $a \rightarrow 0$ is illustrated in Figure 7.52(b). The function $\delta_{a}\left(t-t_{0}\right)$ is called a unit impulse since it possesses the integration property

$$
\int_{0}^{\infty} \delta_{a}\left(t-t_{0}\right) d t=1
$$

Dirac Delta Function In practice it is convenient to work with another type of unit impulse, a "function" that approximates $\delta_{a}\left(t-t_{0}\right)$ and is defined by the limit


\begin{equation*}
\delta\left(t-t_{0}\right)=\lim _{a \rightarrow 0} \delta_{a}\left(t-t_{0}\right) \tag{2}
\end{equation*}


The latter expression, which is not a function at all, can be characterized by the two properties

$$
\text { (i) } \delta\left(t-t_{0}\right)=\left\{\begin{array}{ll}
\infty, & t=t_{0} \\
0, & t \neq t_{0}
\end{array}, \quad \text { and } \quad \text { (ii) } \int_{0}^{\infty} \delta\left(t-t_{0}\right) d t=1\right.
$$

The expression $\delta\left(t-t_{0}\right)$ is called the Dirac delta function.*

It is possible to obtain the Laplace transform of the Dirac delta function by the formal assumption that

$$
\mathscr{L}\left\{\delta\left(t-t_{0}\right)\right\}=\lim _{a \rightarrow 0} \mathscr{L}\left\{\delta_{a}\left(t-t_{0}\right)\right\}
$$
\footnotetext{\begin{itemize}
  \item PAUL ADRIAN MAURICE DIRAC (1902-1984) The delta function was the invention of the contemporary British physicist P. A. M. Dirac. Along with Max Planck, Werner Heisenberg, Erwin Schrödinger, and Albert Einstein, Dirac was one of the founding fathers, in the era 1900-1930, of a new way of describing the behavior of atoms, molecules, and elementary particles called quantum mechanics. For their pioneering work in this field, Dirac and Schrödinger shared the 1933 Nobel Prize in physics. The Dirac delta function was used extensively throughout his 1932 classic treatise, The Principles of Quantum Mechanics.
\end{itemize}
}

\section*{THEOREM 7.11 Transform of the Dirac Delta Function}
For $t_{0}>0$,


\begin{equation*}
\mathscr{L}\left\{\delta\left(t-t_{0}\right)\right\}=e^{-s t_{0}} \tag{3}
\end{equation*}


Proof To begin, we can write $\delta_{a}\left(t-t_{0}\right)$ in terms of the unit step function by virtue of (4) and (5) of Section 7.3:

$$
\delta_{a}\left(t-t_{0}\right)=\frac{1}{2 a}\left[U\left(t-\left(t_{0}-a\right)\right)-U\left(t-\left(t_{0}+a\right)\right)\right]
$$

By linearity and (7) of Section 7.3 the Laplace transform of this last expression is


\begin{align*}
\mathscr{L}\left\{\delta_{a}\left(t-t_{0}\right)\right\} & =\frac{1}{2 a}\left[\frac{e^{-s\left(t_{0}-a\right)}}{s}-\frac{e^{-s\left(t_{0}+a\right)}}{s}\right] \\
\text { or } \quad \mathscr{L}\left\{\delta_{a}\left(t-t_{0}\right)\right\} & =e^{-s t_{0}}\left(\frac{e^{s a}-e^{-s a}}{2 s a}\right) .
\end{align*}


Since (4) has the indeterminate form $0 / 0$ as $a \rightarrow 0$, we apply L'Hôpital's rule:

$$
\mathscr{L}\left\{\delta\left(t-t_{0}\right)\right\}=\lim _{a \rightarrow 0} \mathscr{L}\left\{\delta_{a}\left(t-t_{0}\right)\right\}=e^{-s t_{0}} \lim _{a \rightarrow 0}\left(\frac{e^{s a}-e^{-s a}}{2 s a}\right)=e^{-s t_{0}} .
$$

Now when $t_{0}=0$, it seems plausible to conclude from (3) that

$$
\mathscr{L}\{\delta(t)\}=1
$$

The last result emphasizes the fact that $\delta(t)$ is not the usual type of function that we have been considering, since we expect from Theorem 7.4 that $\mathscr{L}\{f(t)\} \rightarrow 0$ as $s \rightarrow \infty$.

\section*{EXAMPLE 1 Two Initial-Value Problems}
Solve $y^{\prime \prime}+y=4 \delta(t-2 \pi)$ subject to

(a) $y(0)=1, y^{\prime}(0)=0$ and (b) $y(0)=0, y^{\prime}(0)=0$.

The two initial-value problems could serve as models for describing the motion of a mass on a spring moving in a medium in which damping is negligible. At $t=2 \pi$ seconds the mass is given a sharp blow. In (a) the mass is released from rest 1 unit below the equilibrium position. In (b) the mass is at rest in the equilibrium position.

\section*{Solution}
(a) From (3) the Laplace transform of the differential equation is

$$
s^{2} Y(s)-s+Y(s)=4 e^{-2 \pi s} \quad \text { or } \quad Y(s)=\frac{s}{s^{2}+1}+\frac{4 e^{-2 \pi s}}{s^{2}+1}
$$

Utilizing the inverse form of the second translation theorem, we find

$$
y(t)=\cos t+4 \sin (t-2 \pi) U(t-2 \pi)
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-355}
\end{center}

Figure 7.53

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-355(1)}
\end{center}

Figure 7.54\\
Since $\sin (t-2 \pi)=\sin t$, the foregoing solution can be written as

\[
y(t)=\left\{\begin{array}{lr}
\cos t, & 0 \leq t<2 \pi  \tag{5}\\
\cos t+4 \sin t, & t \geq 2 \pi
\end{array}\right.
\]

In Figure 7.53 we see from the graph of (5) that the mass is exhibiting simple harmonic motion until it is struck at $t=2 \pi$. The influence of the unit impulse is to increase the amplitude of vibration to $\sqrt{17}$ for $t>2 \pi$.

(b) In this case the transform of the equation is simply

and so


\begin{align*}
Y(s) & =\frac{4 e^{-2 \pi s}}{s^{2}+1} \\
y(t) & =4 \sin (t-2 \pi) \mathscr{U}(t-2 \pi) \\
& =\left\{\begin{array}{lr}
0, & 0 \leq t<2 \pi \\
4 \sin t, & t \geq 2 \pi
\end{array}\right. \tag{6}
\end{align*}


The graph of (6) in Figure 7.54 shows, as we would expect from the initial conditions, that the mass exhibits no motion until it is struck at $t=2 \pi$.

Remarks If $\delta\left(t-t_{0}\right)$ were a function in the usual sense, then property ( $i$ ) on page 328 would imply $\int_{0}^{\infty} \delta\left(t-t_{0}\right) d t=0$ rather than $\int_{0}^{\infty} \delta\left(t-t_{0}\right) d t$ $=1$. Since the Dirac delta function did not "behave" like an ordinary function, even though its users produced correct results, it was met initially with great scorn by mathematicians. However, in the 1940s Dirac's controversial function was put on a rigorous footing by the French mathematician Laurent Schwartz in his book La Théorie de distribution, and this, in turn, led to an entirely new branch of mathematics known as the theory of distributions, or generalized functions. In the modern theory of generalized functions, (2) is not an accepted definition of $\delta\left(t-t_{0}\right)$, nor does one speak of a function whose values are either $\infty$ or 0 . Although this theory is much beyond the level of this text, it suffices for our purposes to say that the Dirac delta function is defined in terms of its effect or action on other functions. To see this let us suppose that $f$ is a continuous function on $[0, \infty)$. Then, by the mean value theorem for integrals, it follows that

$$
\int_{0}^{\infty} f(t) \delta_{a}\left(t-t_{0}\right) d t=\int_{t_{0}-a}^{t_{0}+a} f(t)\left(\frac{1}{2 a}\right) d t=\frac{1}{2 a}(2 a f(c))=f(c)
$$

where $c$ is some number in the interval $t_{0}-a<t<t_{0}+a$. As $a \rightarrow 0$ we must have $c \rightarrow t_{0}$, so


\begin{gather*}
\int_{0}^{\infty} f(t) \delta\left(t-t_{0}\right) d t=\lim _{a \rightarrow 0} \int_{0}^{\infty} f(t) \delta_{a}\left(t-t_{0}\right) d t=\lim _{a \rightarrow 0} f(c) \\
\int_{0}^{\infty} f(t) \delta\left(t-t_{0}\right) d t=f\left(t_{0}\right) \tag{7}
\end{gather*}


Although we have used the intuitive definition (2) to arrive at (7), the result is nevertheless valid and can be obtained in a rigorous fashion. The\\
result in (7) can be taken as the definition of $\delta\left(t-t_{0}\right)$. It is known as the sifting property since $\delta\left(t-t_{0}\right)$ has the effect of sifting the value $f\left(t_{0}\right)$ from the values of $f$. Note that property (ii) on page 328 is consistent with (7) when $f(t)=1,0 \leq t<\infty$. The integral operation (7) that corresponds a number $f\left(t_{0}\right)$ with a function $f$ leads to the notion of a linear functional. We stop at this point and urge the curious reader to consult an advanced text.*

\section*{EXERCISES 7.6}
Answers to odd-numbered problems begin on page A-17.

In Problems 1-12 use the Laplace transform to solve the given differential equation subject to the indicated initial conditions.

\begin{enumerate}
  \item $y^{\prime}-3 y=\delta(t-2), \quad y(0)=0$

  \item $y^{\prime}+y=\delta(t-1), \quad y(0)=2$

  \item $y^{\prime \prime}+y=\delta(t-2 \pi), \quad y(0)=0, y^{\prime}(0)=1$

  \item $y^{\prime \prime}+16 y=\delta(t-2 \pi), \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+y=\delta\left(t-\frac{\pi}{2}\right)+\delta\left(t-\frac{3 \pi}{2}\right), \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+y=\delta(t-2 \pi)+\delta(t-4 \pi), \quad y(0)=1, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+2 y^{\prime}=\delta(t-1), \quad y(0)=0, y^{\prime}(0)=1$

  \item $y^{\prime \prime}-2 y^{\prime}=1+\delta(t-2), \quad y(0)=0, y^{\prime}(0)=1$

  \item $y^{\prime \prime}+4 y^{\prime}+5 y=\delta(t-2 \pi), \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+2 y^{\prime}+y=\delta(t-1), \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+4 y^{\prime}+13 y=\delta(t-\pi)+\delta(t-3 \pi), \quad y(0)=1, y^{\prime}(0)=0$

  \item $y^{\prime \prime}-7 y^{\prime}+6 y=e^{t}+\delta(t-2)+\delta(t-4), \quad y(0)=0, y^{\prime}(0)=0$

  \item A uniform beam of length $L$ carries a concentrated load $w_{0}$ at $x=L / 2$. The beam is embedded at its left end and is free at its right end. Use the Laplace transform to determine the deflection $y(x)$ from

\end{enumerate}

$$
E I \frac{d^{4} y}{d x^{4}}=w_{0} \delta\left(x-\frac{L}{2}\right)
$$

where $y(0)=0, y^{\prime}(0)=0, y^{\prime \prime}(L)=0$, and $y^{\prime \prime \prime}(L)=0$.

\begin{enumerate}
  \setcounter{enumi}{13}
  \item Solve the differential equation in Problem 13 subject to $y(0)=0$, $y^{\prime}(0)=0, y(L)=0, y^{\prime}(L)=0$. In this case the beam is embedded at both ends. See Figure 7.55.
\end{enumerate}

Figure 7.55\\
15. Use (7) to obtain (3).

\begin{enumerate}
  \setcounter{enumi}{15}
  \item Use (7) to evaluate $\int_{0}^{\infty} t^{2} e^{-3 t} \delta(t-4) d t$.
\footnotetext{  \begin{itemize}
    \item See M. J. Lighthill, Introduction to Fourier Analysis and Generalized Functions (New York: Cambridge University Press, 1958).
  \end{itemize}
}

  \item Use the Laplace transform and (7) to solve

\end{enumerate}

$$
y^{\prime \prime}+2 y^{\prime}+2 y=\cos t \delta(t-3 \pi)
$$

subject to $y(0)=1$ and $y^{\prime}(0)=-1$.

\begin{enumerate}
  \setcounter{enumi}{17}
  \item To emphasize the unusual nature of the Dirac delta function, show that the "solution" of the initial-value problem $y^{\prime \prime}+\omega^{2} y=\delta(t), y(0)=0$, $y^{\prime}(0)=0$ does not satisfy the initial condition $y^{\prime}(0)=0$.

  \item Solve the initial-value problem

\end{enumerate}

$$
L \frac{d i}{d t}+R i=\delta(t), \quad i(0)=0
$$

where $L$ and $R$ are constants. Does the solution satisfy the condition at $t=0$ ?

\begin{enumerate}
  \setcounter{enumi}{19}
  \item If $\delta^{\prime}\left(t-t_{0}\right)$ denotes the derivative of the Dirac delta function, then it is known that $\mathscr{L}\left\{\delta^{\prime}\left(t-t_{0}\right)\right\}=s e^{-s t_{0}}, t_{0} \geq 0$. Use this result to solve $y^{\prime}+5 y=\delta^{\prime}(t)$ subject to $y(0)=0$.
\end{enumerate}

\section*{CHAPTER 7 REVIEW}
The Laplace transform of a function $f(t), t \geq 0$ is defined by the integral

$$
\mathscr{L}\{f(t)\}=\int_{0}^{\infty} e^{-s t} f(t) d t=F(s)
$$

The parameter $s$ is usually restricted in such a manner that convergence of the integral is guaranteed. When it is applied to a linear differential equation with constant coefficients such as $a y^{\prime \prime}+b y^{\prime}+c y=g(t)$, there results an algebraic equation

$$
a\left[s^{2} Y(s)-s y(0)-y^{\prime}(0)\right]+b[s Y(s)-y(0)]+c Y(s)=G(s)
$$

which depends on the initial conditions $y(0)$ and $y^{\prime}(0)$. When these values are known, we determine $y(t)$ by evaluating $y(t)=\mathscr{L}^{-1}\{Y(s)\}$.

\section*{CHAPTER 7 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-17.

In Problems 1 and 2 use the definition of the Laplace transform to find $\mathscr{L}\{f(t)\}$.

$$
\text { 1. } f(t)=\left\{\begin{array}{lr}
t, & 0 \leq t<1 \\
2-t, & t \geq 1
\end{array} \quad \text { 2. } f(t)=\left\{\begin{array}{lr}
0, & 0 \leq t<2 \\
1, & 2 \leq t<4 \\
0, & t \geq 4
\end{array}\right.\right.
$$

In Problems 3-24 fill in the blanks or answer true or false.

\begin{enumerate}
  \setcounter{enumi}{2}
  \item If $f$ is not piecewise continuous on $[0, \infty)$, then $\mathscr{L}\{f(t)\}$ will not exist.

  \item The function $f(t)=\left(e^{t}\right)^{10}$ is not of exponential order.

  \item $F(s)=s^{2} /\left(s^{2}+4\right)$ is not the Laplace transform of a function that is piecewise continuous and of exponential order.

  \item If $\mathscr{L}\{f(t)\}=F(s)$ and $\mathscr{L}\{g(t)\}=G(s)$, then $\mathscr{L}^{-1}\{F(s) G(s)\}=f(t) g(t)$.

  \item $\mathscr{L}\left\{e^{-7 t}\right\}=$ $\qquad$

  \item $\mathscr{L}\left\{t e^{-7 \pi}\right\}=$

  \item $\mathscr{L}\{\sin 2 t\}=$ $\qquad$

  \item $\mathscr{L}\left\{e^{-3 t} \sin 2 t\right\}=$ $\qquad$

  \item $\mathscr{L}\{t \sin 2 t\}=$ $\qquad$

  \item $\mathscr{L}\{\sin 2 t \mathscr{U}(t-\pi)\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{20}{s^{6}}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{1}{3 s-1}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{1}{(s-5)^{3}}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{1}{s^{2}-5}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{s}{s^{2}-10 s+29}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{e^{-5 s}}{s^{2}}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{s+\pi}{s^{2}+\pi^{2}} e^{-s}\right\}=$ $\qquad$

  \item $\mathscr{L}^{-1}\left\{\frac{1}{L^{2} s^{2}+n^{2} \pi^{2}}\right\}=$ $\qquad$

  \item $\mathscr{L}\left\{e^{-5 t}\right\}$ exists for $s>$ $\qquad$ .

  \item If $\mathscr{L}\{f(t)\}=F(s)$, then $\mathscr{L}\left\{t e^{8 t} f(t)\right\}=$ $\qquad$ .

  \item If $\mathscr{L}\{f(t)\}=F(s)$ and $k>0$, then $\mathscr{L}\left\{e^{a(t-k)} f(t-k) \mathscr{U}(t-k)\right\}=$ $\qquad$ .

  \item $1 * 1=$ $\qquad$\\
In Problems 25-28, (a) express $f$ in terms of unit step functions, (b) find $\mathscr{L}\{f(t)\}$, and (c) find $\mathscr{L}\left\{e^{t} f(t)\right\}$.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-358}
\end{center}

Figure 7.56

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-358(1)}
\end{center}

Figure 7.57

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-358(3)}
\end{center}

Figure 7.58\\
28. $f(t)$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-358(2)}
\end{center}

Figure 7.59

In Problems 29-36 use the Laplace transform to solve the given equation.

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $y^{\prime \prime}-2 y^{\prime}+y=e^{t}, \quad y(0)=0, y^{\prime}(0)=5$

  \item $y^{\prime \prime}-8 y^{\prime}+20 y=t e^{t}, \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}-4 y^{\prime}+6 y=30 U(t-\pi), \quad y(0)=0, y^{\prime}(0)=0$

  \item $y^{\prime \prime}+6 y^{\prime}+5 y=t-t थ(t-2), \quad y(0)=1, y^{\prime}(0)=0$

  \item $y^{\prime}-5 y=f(t)$, where $f(t)=\left\{\begin{array}{ll}t^{2}, & 0 \leq t<1 \\ 0, & t \geq 1\end{array} \quad y(0)=1\right.$

  \item $f(t)=1-2 \int_{0}^{t} e^{-3 \tau} f(t-\tau) d \tau$

  \item $y^{\prime}(t)=\cos t+\int_{0}^{t} y(\tau) \cos (t-\tau) d \tau, \quad y(0)=1$

  \item $\int_{0}^{t} f(\tau) f(t-\tau) d \tau=6 t^{3}$

  \item The current $i(t)$ in an $R$ - $C$ series circuit can be determined from the integral equation

\end{enumerate}

$$
R i+\frac{1}{C} \int_{0}^{t} i(\tau) d \tau=E(t)
$$

where $E(t)$ is the impressed voltage. Determine $i(t)$ when $R=10$ ohms, $C=0.5$ farad, and $E(t)=2\left(t^{2}+t\right)$.

\begin{enumerate}
  \setcounter{enumi}{37}
  \item A series circuit contains an inductor, a resistor, and a capacitor for which $L=\frac{1}{2}$ henry, $R=10$ ohms, and $C=0.01$ farad, respectively. The voltage
\end{enumerate}

$$
E(t)=\left\{\begin{array}{lr}
10, & 0 \leq t<5 \\
0, & t \geq 5
\end{array}\right.
$$

is applied to the circuit. Determine the instantaneous charge $q(t)$ on the capacitor for $t>0$ if $q(0)=0$ and $q^{\prime}(0)=0$.

\begin{enumerate}
  \setcounter{enumi}{38}
  \item A uniform cantilever beam of length $L$ is embedded at its left end $(x=0)$ and free at its right end. Find the deflection $y(x)$ if the load per unit length is given by
\end{enumerate}

$$
w(x)=\frac{2 w_{0}}{L}\left[\frac{L}{2}-x+\left(x-\frac{L}{2}\right) \mathscr{U}\left(x-\frac{L}{2}\right)\right]
$$

\begin{enumerate}
  \setcounter{enumi}{39}
  \item When a uniform beam is supported by an elastic foundation, the differential equation for its deflection $y(x)$ is
\end{enumerate}

$$
\frac{d^{4} y}{d x^{4}}+4 a^{4} y=\frac{w(x)}{E I}
$$

where $a$ is a constant. In the case when $a=1$, find the deflection $y(x)$ of an elastically supported beam of length $\pi$ that is embedded in concrete at both ends when a concentrated load $w_{0}$ is applied at $x=\pi / 2$. [Hint: Use the table of Laplace transforms in Appendix II.]

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-360}
\end{center}

\section*{SYSTEMS OF LINEAR DIFFERENTIAL EQUATIONS}
8.1 Operator Method

8.2 Laplace Transform Method

8.3 Systems of Linear First-Order Equations

8.4 Introduction to Matrices

8.5 Matrices and Systems of Linear First-Order Equations

8.6 Homogeneous Linear Systems

8.7 Undetermined Coefficients

8.8 Variation of Parameters

8.9 Matrix Exponential

Chapter 8 Review

Chapter 8 Review Exercises

In applications considered in previous chapters, a physical system could be described by a single differential equation. For example, in Chapter 5 we saw that the mathematical model for the motion of a mass attached to a spring or for the response of a series electrical circuit was a relatively simple differential equation of the form $a y^{\prime \prime}+b y^{\prime}+c y=f(t)$. However, if we attached two (or more) springs together or formed a parallel circuit or network, as shown in the accompanying figures, we would need two (or more) coupled, or simultaneous, differential equations to describe the motion of the masses or the response of the network.

In this chapter we confine our attention to the theory and solution of systems of simultaneous linear differential equations or, simply, linear systems in which all the coefficients are constants.\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-360(1)}

\subsection*{8.1 OPERATOR METHOD}
Simultaneous ordinary differential equations involve two or more equations that contain derivatives of two or more unknown functions of a single independent variable. If $x, y$, and $z$ are functions of the variable $t$, then

$$
\begin{aligned}
& 4 \frac{d^{2} x}{d t^{2}}=-5 x+y \quad x^{\prime}-3 x+y^{\prime}+z^{\prime}=5
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-361}
\end{center}

are two examples of systems of simultaneous differential equations.

Solution of a System A solution of a system of differential equations is a set of differentiable functions $x=f(t), y=g(t), z=h(t)$, and so on, that satisfies each equation of the system on some interval $I$.

Systematic Elimination The first technique we shall consider for solving systems is based on the fundamental principle of systematic algebraic elimination of variables. We shall see that the analogue of multiplying an algebraic equation by a constant is operating on a differential equation with some combination of derivatives. Recall that a linear differential equation

$$
a_{n} y^{(n)}+a_{n-1} y^{(n-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=g(t)
$$

where the $a_{i}, i=0,1, \ldots, n$ are constants, can be written in terms of differential operators as

$$
\left(a_{n} D^{n}+a_{n-1} D^{n-1}+\cdots+a_{1} D+a_{0}\right) y=g(t)
$$

\section*{EXAMPLE 1 A System in Operator Notation}
Write the system of differential equations

$$
\begin{aligned}
x^{\prime \prime}+2 x^{\prime}+y^{\prime \prime} & =x+3 y+\sin t \\
x^{\prime}+y^{\prime} & =-4 x+2 y+e^{-t}
\end{aligned}
$$

in operator notation.

Solution Rewrite the given system as

$$
\begin{aligned}
& x^{\prime \prime}+2 x^{\prime}-x+y^{\prime \prime}-3 y=\sin t \\
& x^{\prime}+4 x+y^{\prime}-2 y=e^{-t} \\
& \text { so that } \\
& \begin{aligned}
\left(D^{2}+2 D-1\right) x+\left(D^{2}-3\right) y & =\sin t \\
(D+4) x+(D-2) y & =e^{-t}
\end{aligned}
\end{aligned}
$$

Method of Solution Consider the simple system of linear first-order equations


\begin{align*}
& D y=2 x \\
& D x=3 y \tag{1}
\end{align*}


or, equivalently,


\begin{align*}
& 2 x-D y=0 \\
& D x-3 y=0 \tag{2}
\end{align*}


Operating on the first equation in (2) by $D$ while multiplying the second by 2 and then subtracting eliminates $x$ from the system. It follows that

$$
-D^{2} y+6 y=0 \text { or } \quad D^{2} y-6 y=0
$$

Since the roots of the auxiliary equation are $m_{1}=\sqrt{6}$ and $m_{2}=-\sqrt{6}$, we obtain


\begin{equation*}
y(t)=c_{1} e^{\sqrt{6} t}+c_{2} e^{-\sqrt{6} t} \tag{3}
\end{equation*}


Multiplying the first equation by -3 while operating on the second by $D$ and then adding gives the differential equation for $x, D^{2} x-6 x=0$. It follows immediately that


\begin{equation*}
x(t)=c_{3} e^{\sqrt{6} t}+c_{4} e^{-\sqrt{6} t} \tag{4}
\end{equation*}


Now (3) and (4) do not satisfy the system (1) for every choice of $c_{1}, c_{2}, c_{3}$, and $c_{4}$. Substituting $x(t)$ and $y(t)$ into the first equation of the original system (1) gives, after we simplify,

$$
\left(\sqrt{6} c_{1}-2 c_{3}\right) e^{\sqrt{6} t}+\left(-\sqrt{6} c_{2}-2 c_{4}\right) e^{-\sqrt{6} t}=0
$$

Since the latter expression is to be zero for all values of $t$, we must have

or


\begin{gather*}
\sqrt{6} c_{1}-2 c_{3}=0 \quad \text { and } \quad-\sqrt{6} c_{2}-2 c_{4}=0 \\
c_{3}=\frac{\sqrt{6}}{2} c_{1}, \quad c_{4}=-\frac{\sqrt{6}}{2} c_{2} . \tag{5}
\end{gather*}


Hence we conclude that a solution of the system must be

$$
x(t)=\frac{\sqrt{6}}{2} c_{1} e^{\sqrt{6} t}-\frac{\sqrt{6}}{2} c_{2} e^{-\sqrt{6} t}, \quad y(t)=c_{1} e^{\sqrt{6} t}+c_{2} e^{-\sqrt{6} t}
$$

You are urged to substitute (3) and (4) into the second equation of (1) and verify that the same relationship (5) holds between the constants.

\section*{EXAMPLE 2 Solving a System by Elimination}
Solve


\begin{align*}
D x+(D+2) y & =0 \\
(D-3) x-\quad 2 y & =0 \tag{6}
\end{align*}


Solution Operating on the first equation by $D-3$ and on the second by $D$ and subtracting eliminates $x$ from the system. It follows that the differential equation for $y$ is

$$
[(D-3)(D+2)+2 D] y=0 \quad \text { or } \quad\left(D^{2}+D-6\right) y=0
$$

Since the characteristic equation of this last differential equation is $m^{2}+m-6=(m-2)(m+3)=0$, we obtain the solution


\begin{equation*}
y(t)=c_{1} e^{2 t}+c_{2} e^{-3 t} \tag{7}
\end{equation*}


Eliminating $y$ in a similar manner yields $\left(D^{2}+D-6\right) x=0$, from which we find


\begin{equation*}
x(t)=c_{3} e^{2 t}+c_{4} e^{-3 t} \tag{8}
\end{equation*}


As we noted in the foregoing discussion, a solution of (6) does not contain four independent constants since the system itself puts a constraint on the actual number that can be chosen arbitrarily. Substituting (7) and (8) into the first equation of (6) gives

$$
\left(4 c_{1}+2 c_{3}\right) e^{2 t}+\left(-c_{2}-3 c_{4}\right) e^{-3 t}=0
$$

and so

Therefore

$$
\begin{array}{rlrlr}
4 c_{1}+2 c_{3} & =0 & \text { and } & -c_{2}-3 c_{4} & =0 . \\
c_{3} & =-2 c_{1} & \text { and } & c_{4} & =-\frac{1}{3} c_{2} .
\end{array}
$$

Accordingly, a solution of the system is

$$
x(t)=-2 c_{1} e^{2 t}-\frac{1}{3} c_{2} e^{-3 t}, \quad y(t)=c_{1} e^{2 t}+c_{2} e^{-3 t}
$$

Since we could just as easily solve for $c_{3}$ and $c_{4}$ in terms of $c_{1}$ and $c_{2}$, the solution in Example 2 can be written in the alternative form

$$
x(t)=c_{3} e^{2 t}+c_{4} e^{-3 t}, \quad y(t)=-\frac{1}{2} c_{3} e^{2 t}-3 c_{4} e^{-3 t}
$$

Also, it sometimes pays to keep one's eyes open when solving systems. Had we solved for $x$ first, then $y$ could be found, along with the relationship between the constants, by simply using the last equation of (6):

or

$$
\begin{aligned}
& y=\frac{1}{2}(D x-3 x)=\frac{1}{2}\left[2 c_{3} e^{2 t}-3 c_{4} e^{-3 t}-3 c_{3} e^{2 t}-3 c_{4} e^{-3 t}\right] \\
& y=-\frac{1}{2} c_{3} e^{2 t}-3 c_{4} e^{-3 t}
\end{aligned}
$$

\section*{EXAMPLE 3 Solving a System by Elimination}
Solve


\begin{align*}
& x^{\prime}-4 x+y^{\prime \prime}=t^{2}  \tag{9}\\
& x^{\prime}+x+y^{\prime}=0
\end{align*}


Solution First we write the system in differential operator notation:


\begin{align*}
& (D-4) x+D^{2} y=t^{2}  \tag{10}\\
& (D+1) x+D y=0
\end{align*}


Then, by eliminating $x$, we obtain

$$
\left[(D+1) D^{2}-(D-4) D\right] y=(D+1) t^{2}-(D-4) 0
$$

or

$$
\left(D^{3}+4 D\right) y=t^{2}+2 t
$$

Since the roots of the auxiliary equation $m\left(m^{2}+4\right)=0$ are $m_{1}=0, m_{2}=2 i$, and $m_{3}=-2 i$, the complementary function is

$$
y_{c}=c_{1}+c_{2} \cos 2 t+c_{3} \sin 2 t
$$

To determine the particular solution $y_{p}$ we use undetermined coefficients by assuming $y_{p}=A t^{3}+B t^{2}+C t$. Therefore

$$
\begin{gathered}
y_{p}^{\prime}=3 A t^{2}+2 B t+C, \quad y_{p}^{\prime \prime}=6 A t+2 B, \quad y_{p}^{\prime \prime \prime}=6 A \\
y_{p}^{\prime \prime \prime}+4 y_{p}^{\prime}=12 A t^{2}+8 B t+6 A+4 C=t^{2}+2 t
\end{gathered}
$$

The last equality implies

$$
12 A=1, \quad 8 B=2, \quad 6 A+4 C=0
$$

and hence $A=\frac{1}{12}, B=\frac{1}{4}, C=-\frac{1}{8}$. Thus


\begin{equation*}
y=y_{t}+y_{p}=c_{1}+c_{2} \cos 2 t+c_{3} \sin 2 t+\frac{1}{12} t^{3}+\frac{1}{4} t^{2}-\frac{1}{8} t \tag{11}
\end{equation*}


Eliminating $y$ from the system (10) leads to

$$
[(D-4)-D(D+1)] x=t^{2} \quad \text { or } \quad\left(D^{2}+4\right) x=-t^{2}
$$

It should be obvious that $x_{c}=c_{4} \cos 2 t+c_{5} \sin 2 t$ and that undetermined coefficients can be applied to obtain a particular solution of the form $x_{p}=A t^{2}+B t+C$. In this case the usual differentiations and algebra yield $x_{p}=-\frac{1}{4} t^{2}+\frac{1}{8}$ and so


\begin{equation*}
x=x_{c}+x_{p}=c_{4} \cos 2 t+c_{5} \sin 2 t-\frac{1}{4} t^{2}+\frac{1}{8} \tag{12}
\end{equation*}


Now $c_{4}$ and $c_{5}$ can be expressed in terms of $c_{2}$ and $c_{3}$ by substituting (11) and (12) into either equation of (9). By using the second equation, we find, after combining terms,

so

$$
\begin{gathered}
\left(c_{5}-2 c_{4}-2 c_{2}\right) \sin 2 t+\left(2 c_{5}+c_{4}+2 c_{3}\right) \cos 2 t=0 \\
c_{5}-2 c_{4}-2 c_{2}=0 \quad \text { and } \quad 2 c_{5}+c_{4}+2 c_{3}=0
\end{gathered}
$$

Solving for $c_{4}$ and $c_{5}$ in terms of $c_{2}$ and $c_{3}$ gives

$$
c_{4}=-\frac{1}{5}\left(4 c_{2}+2 c_{3}\right) \quad \text { and } \quad c_{5}=\frac{1}{5}\left(2 c_{2}-4 c_{3}\right)
$$

Finally, a solution of (9) is found to be

$$
\begin{aligned}
& x(t)=-\frac{1}{5}\left(4 c_{2}+2 c_{3}\right) \cos 2 t+\frac{1}{5}\left(2 c_{2}-4 c_{3}\right) \sin 2 t-\frac{1}{4} t^{2}+\frac{1}{8} \\
& y(t)=c_{1}+c_{2} \cos 2 t+c_{3} \sin 2 t+\frac{1}{12} t^{3}+\frac{1}{4} t^{2}-\frac{1}{8} t
\end{aligned}
$$

Use of Determinants Symbolically, if $L_{1}, L_{2}, L_{3}$, and $L_{4}$ denote linear differential operators with constant coefficients, then a system of linear differential equations in two variables $x$ and $y$ can be written as


\begin{align*}
& L_{1} x+L_{2} y=g_{1}(t)  \tag{13}\\
& L_{3} x+L_{4} y=g_{2}(t)
\end{align*}


Eliminating variables, as we would for algebraic equations, leads to


\begin{equation*}
\left(L_{1} L_{4}-L_{2} L_{3}\right) x=f_{1}(t) \text { and }\left(L_{1} L_{4}-L_{2} L_{3}\right) y=f_{2}(t) \tag{14}
\end{equation*}


where

$$
f_{1}(t)=L_{4} g_{1}(t)-L_{2} g_{2}(t) \text { and } f_{2}(t)=L_{1} g_{2}(t)-L_{3} g_{1}(t)
$$

Formally the results in (14) can be written in terms of determinants similar to those used in Cramer's rule:

\[
\left|\begin{array}{ll}
L_{1} & L_{2}  \tag{15}\\
L_{3} & L_{4}
\end{array}\right| x=\left|\begin{array}{ll}
g_{1} & L_{2} \\
g_{2} & L_{4}
\end{array}\right| \text { and }\left|\begin{array}{ll}
L_{1} & L_{2} \\
L_{3} & L_{4}
\end{array}\right| y=\left|\begin{array}{ll}
L_{1} & g_{1} \\
L_{3} & g_{2}
\end{array}\right|
\]

The left-hand determinant in each equation in (15) can be expanded in the usual algebraic sense, with the result then operating on the functions $x(t)$ and $y(t)$. However, some care should be exercised in the expansion of the right-hand determinants in (15). We must expand these determinants in the sense of the internal differential operators actually operating upon the functions $g_{1}(t)$ and $g_{2}(t)$.

If

$$
\left|\begin{array}{ll}
L_{1} & L_{2} \\
L_{3} & L_{4}
\end{array}\right| \neq 0
$$

in (15) and is a differential operator of order $n$, then

\begin{itemize}
  \item The system (13) can be uncoupled into two $n$ th-order differential equations in $x$ and $y$.
  \item The characteristic equation and hence the complementary function of each of these differential equations are the same.
  \item Since $x$ and $y$ both contain $n$ constants, there are a total of $2 n$ constants appearing.
  \item The total number of independent constants in the solution of the system is $n$.
\end{itemize}

If

$$
\left|\begin{array}{ll}
L_{1} & L_{2} \\
L_{3} & L_{4}
\end{array}\right|=0
$$

in (13), then the system may have a solution containing any number of independent constants or may have no solution at all. Similar remarks hold for systems larger than indicated in (13).

\section*{EXAMPLE 4 Solving a System Using Determinants}
Solve


\begin{align*}
& x^{\prime}=3 x-y-1 \\
& y^{\prime}=x+y+4 e^{t} \tag{16}
\end{align*}


Solution Write the system in terms of differential operators,

$$
\begin{aligned}
(D-3) x+y & =-1 \\
-x+(D-1) y & =4 e^{t}
\end{aligned}
$$

and then use determinants:

$$
\begin{aligned}
& \left|\begin{array}{cc}
D-3 & 1 \\
-1 & D-1
\end{array}\right| x=\left|\begin{array}{cc}
-1 & 1 \\
4 e^{t} & D-1
\end{array}\right| \\
& \left|\begin{array}{cc}
D-3 & 1 \\
-1 & D-1
\end{array}\right| y=\left|\begin{array}{cc}
D-3 & -1 \\
-1 & 4 e^{t}
\end{array}\right|
\end{aligned}
$$

After expanding, we find that

$$
\begin{aligned}
& (D-2)^{2} x=1-4 e^{t} \\
& (D-2)^{2} y=-1-8 e^{t}
\end{aligned}
$$

By the usual methods it follows that


\begin{align*}
& x=x_{c}+x_{p}=c_{1} e^{2 t}+c_{2} t e^{2 t}+\frac{1}{4}-4 e^{t}  \tag{17}\\
& y=y_{c}+y_{p}=c_{3} e^{2 t}+c_{4} t e^{2 t}-\frac{1}{4}-8 e^{t} \tag{18}
\end{align*}


Substituting (17) and (18) into the second equation of (16) gives

$$
\left(c_{3}-c_{1}+c_{4}\right) e^{2 t}+\left(c_{4}-c_{2}\right) t e^{2 t}=0
$$

which then implies

$$
c_{4}=c_{2} \quad \text { and } \quad c_{3}=c_{1}-c_{4}=c_{1}-c_{2}
$$

Thus a solution of (16) is

$$
x(t)=c_{1} e^{2 t}+c_{2} t e^{2 t}+\frac{1}{4}-4 e^{t}, \quad y(t)=\left(c_{1}-c_{2}\right) e^{2 t}+c_{2} t e^{2 t}-\frac{1}{4}-8 e^{t}
$$

\section*{EXAMPLE 5 Using Determinants}
Given the system

$$
\begin{aligned}
D x+D z & =t^{2} \\
2 x+D^{2} y & =e^{t} \\
-2 D x-2 y+(D+1) z & =0
\end{aligned}
$$

find the differential equation for the variable $y$.

Solution With determinants we can write

$$
\left|\begin{array}{ccc}
D & 0 & D \\
2 & D^{2} & 0 \\
-2 D & -2 & D+1
\end{array}\right| y=\left|\begin{array}{ccc}
D & t^{2} & D \\
2 & e^{t} & 0 \\
-2 D & 0 & D+1
\end{array}\right|
$$

In turn, expanding each determinant by cofactors of the first row gives

$$
\begin{aligned}
&\left(D\left|\begin{array}{cc}
D^{2} & 0 \\
-2 & D+1
\end{array}\right|+D\left|\begin{array}{cc}
2 & D^{2} \\
-2 D & -2
\end{array}\right|\right) y=D\left|\begin{array}{cc}
e^{t} & 0 \\
0 & D+1
\end{array}\right|-\left|\begin{array}{cc}
2 & 0 \\
-2 D & D+1
\end{array}\right| t^{2}+D\left|\begin{array}{cc}
2 & e^{t} \\
-2 D & 0
\end{array}\right| \\
& \text { or } D\left(3 D^{3}+D^{2}-4\right) y=4 e^{t}-2 t^{2}-4 t .
\end{aligned}
$$

Again we remind you that the $D$ symbol on the left-hand side is to be treated as an algebraic quantity, but this is not the case on the right-hand side.

\section*{EXERCISES 8.1}
Answers to odd-numbered problems begin on page A-18.

In Problems 1-22 solve, if possible, the given system of differential equations by either systematic elimination or determinants.

\begin{enumerate}
  \item $\frac{d x}{d t}=2 x-y$
  \item $\frac{d x}{d t}=4 x+7 y$\\
$\frac{d y}{d t}=x$\\
$\frac{d y}{d t}=x-2 y$
  \item $\frac{d x}{d t}=-y+t$
  \item $\frac{d x}{d t}-4 y=1$\\
$\frac{d y}{d t}=x-t$\\
$x+\frac{d y}{d t}=2$
  \item $\left(D^{2}+5\right) x-\quad 2 y=0$
  \item $(D+1) x+(D-1) y=2$
\end{enumerate}

$-2 x+\left(D^{2}+2\right) y=0$

$3 x+(D+2) y=-1$\\
7. $\frac{d^{2} x}{d t^{2}}=4 y+e^{t}$\\
8. $\frac{d^{2} x}{d t^{2}}+\frac{d y}{d t}=-5 x$

$\frac{d^{2} y}{d t^{2}}=4 x-e^{t}$

$$
\frac{d x}{d t}+\frac{d y}{d t}=-x+4 y
$$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item $D x+D^{2} y=e^{3 t}$
\end{enumerate}

$$
(D+1) x+(D-1) y=4 e^{3 t}
$$

\begin{enumerate}
  \setcounter{enumi}{9}
  \item $\begin{aligned} D^{2} x-\quad y & =t \\ (D+3) x+(D+3) y & =2\end{aligned}$
  \item $\left(D^{2}-1\right) x-y=0$
\end{enumerate}

$(D-1) x+D y=0$\\
12. $\left(2 D^{2}-D-1\right) x-(2 D+1) y=1$

$$
(D-1) x+\quad D y=-1
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $2 \frac{d x}{d t}-5 x+\frac{d y}{d t}=e^{t}$
  \item $\frac{d x}{d t}+\frac{d y}{d t} \quad=e^{t}$
\end{enumerate}

$\frac{d x}{d t}-x+\frac{d y}{d t}=5 e^{t}$

$-\frac{d^{2} x}{d t^{2}}+\frac{d x}{d t}+x+y=0$\\
15. $(D-1) x+\left(D^{2}+1\right) y=1$\\
16. $D^{2} x-2\left(D^{2}+D\right) y=\sin t$

$$
\left(D^{2}-1\right) x+(D+1) y=2
$$

$x+\quad D y=0$\\
17. $D x=y$\\
18. $D x+\quad z=e^{t}$

$D y=z$

$$
D z=x
$$

$(D-1) x+D y+D z=0$

$x+2 y+D z=e^{t}$\\
19. $\frac{d x}{d t}-6 y=0$\\
20. $\frac{d x}{d t}=-x+z$

$x-\frac{d y}{d t}+z=0$

$\frac{d y}{d t}=-y+z$

$x+y-\frac{d z}{d t}=0$

$\frac{d z}{d t}=-x+y$\\
21. $\begin{aligned} 2 D x+(D-1) y & =t \\ D x+\quad D y & =t^{2}\end{aligned}$\\
22. $D x-2 D y=t^{2}$

$(D+1) x-2(D+1) y=1$

In Problems 23 and 24 solve the given system subject to the indicated initial conditions.\\
23. $\frac{d x}{d t}=-5 x-y$\\
24. $\frac{d x}{d t}=y-1$\\
$\frac{d y}{d t}=4 x-y$\\
$\frac{d y}{d t}=-3 x+2 y$\\
$x(1)=0, y(1)=1$\\
$x(0)=0, y(0)=0$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item Determine, if possible, a system of differential equations having
\end{enumerate}

$$
x(t)=c_{1}+c_{2} e^{2 t}, \quad y(t)=-c_{1}+c_{2} e^{2 t}
$$

as its solution.

\subsection*{8.2 LAPLACE TRANSFORM METHOD \\
 - Reduction to algebraic system $\cdot$ Application}
When initial conditions are specified, the Laplace transform reduces a system of linear differential equations with constant coefficients to a set of simultaneous algebraic equations in the transformed functions.

\section*{EXAMPLE 1 System of DEs Transformed into an Algebraic System}
Solve


\begin{align*}
2 x^{\prime}+y^{\prime}-y & =t  \tag{1}\\
x^{\prime}+y^{\prime} & =t^{2}
\end{align*}


subject to $x(0)=1, y(0)=0$.

Solution If $X(s)=\mathscr{L}\{x(t)\}$ and $Y(s)=\mathscr{L}\{y(t)\}$, then after transforming each equation we obtain


\begin{gather*}
2[s X(s)-x(0)]+s Y(s)-y(0)-Y(s)=\frac{1}{s^{2}} \\
s X(s)-x(0)+s Y(s)-y(0)=\frac{2}{s^{3}} \\
2 s X(s)+(s-1) Y(s)=2+\frac{1}{s^{2}}  \tag{2}\\
s X(s)+\quad s Y(s)=1+\frac{2}{s^{3}} .
\end{gather*}


or

Multiplying the second equation of (2) by 2 and subtracting yields


\begin{equation*}
(-s-1) Y(s)=\frac{1}{s^{2}}-\frac{4}{s^{3}} \quad \text { or } \quad Y(s)=\frac{4-s}{s^{3}(s+1)} \tag{3}
\end{equation*}


Now by partial fractions

$$
\frac{4-s}{s^{3}(s+1)}=\frac{A}{s}+\frac{B}{s^{2}}+\frac{C}{s^{3}}+\frac{D}{s+1}
$$

so

$$
4-s=A s^{2}(s+1)+B s(s+1)+C(s+1)+D s^{3}
$$

Setting $s=0$ and $s=-1$ in the last line gives $C=4$ and $D=-5$, respectively, whereas equating the coefficients of $s^{3}$ and $s^{2}$ on each side of the equality yields

$$
A+D=0 \quad \text { and } \quad A+B=0
$$

It follows that $A=5, B=-5$. Thus (3) becomes

$$
Y(s)=\frac{5}{s}-\frac{5}{s^{2}}+\frac{4}{s^{3}}-\frac{5}{s+1}
$$

and so

$$
\begin{aligned}
y(t) & =5 \mathscr{L}^{-1}\left\{\frac{1}{s}\right\}-5 \mathscr{L}^{-1}\left\{\frac{1}{s^{2}}\right\}+2 \mathscr{L}^{-1}\left\{\frac{2!}{s^{3}}\right\}-5 \mathscr{L}^{-1}\left\{\frac{1}{s+1}\right\} \\
& =5-5 t+2 t^{2}-5 e^{-t}
\end{aligned}
$$

By the second equation of (2),

$$
X(s)=-Y(s)+\frac{1}{s}+\frac{2}{s^{4}}
$$

from which it follows that

$$
\begin{aligned}
x(t) & =-\mathscr{L}^{-1}\{Y(s)\}+\mathscr{L}^{-1}\left\{\frac{1}{s}\right\}+\frac{2}{3!} \mathscr{L}^{-1}\left\{\frac{3!}{s^{4}}\right\} \\
& =-4+5 t-2 t^{2}+\frac{1}{3} t^{3}+5 e^{-t}
\end{aligned}
$$

Hence we conclude that the solution of the given system (1) is


\begin{equation*}
x(t)=-4+5 t-2 t^{2}+\frac{1}{3} t^{3}+5 e^{-t}, \quad y(t)=5-5 t+2 t^{2}-5 e^{-t} \tag{4}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-369}
\end{center}

Figure 8.I\\
Applications Let us turn now to some elementary applications involving systems of differential equations. The solutions of the problems that we shall consider can be obtained either by the method of the preceding section or through the use of the Laplace transform.

Coupled Springs Two masses $m_{1}$ and $m_{2}$ are connected to two springs $A$ and $B$ of negligible mass having spring constants $k_{1}$ and $k_{2}$, respectively. In turn, the two springs are attached as shown in Figure 8.1. Let $x_{1}(t)$ and $x_{2}(t)$ denote the vertical displacements of the masses from their equilibrium positions. When the system is in motion, spring $B$ is subject to both an elongation and a compression; hence its net elongation is $x_{2}-x_{1}$. Therefore it follows from Hooke's law that springs $A$ and $B$ exert forces

$$
-k_{1} x_{1} \quad \text { and } \quad k_{2}\left(x_{2}-x_{1}\right)
$$

respectively, on $m_{1}$. If no external force is impressed on the system and if no damping force is present, then the net force on $m_{1}$ is $-k_{1} x_{1}+k_{2}\left(x_{2}-x_{1}\right)$. By Newton's second law we can write

$$
m_{1} \frac{d^{2} x_{1}}{d t^{2}}=-k_{1} x_{1}+k_{2}\left(x_{2}-x_{1}\right)
$$

Similarly, the net force exerted on mass $m_{2}$ is due solely to the net elongation of $B$; that is, $-k_{2}\left(x_{2}-x_{1}\right)$. Thus it follows that

$$
m_{2} \frac{d^{2} x_{2}}{d t^{2}}=-k_{2}\left(x_{2}-x_{1}\right)
$$

In other words, the motion of the coupled system is represented by the system of simultaneous second-order differential equations


\begin{align*}
& m_{1} x_{1}^{\prime \prime}=-k_{1} x_{1}+k_{2}\left(x_{2}-x_{1}\right) \\
& m_{2} x_{2}^{\prime \prime}=-k_{2}\left(x_{2}-x_{1}\right) \tag{5}
\end{align*}


In the next example we shall solve (5) under the assumptions that

$$
k_{1}=6, \quad k_{2}=4, \quad m_{1}=1, \quad m_{2}=1
$$

and that the masses start from their equilibrium positions with opposite unit velocities.

\section*{EXAMPLE 2 Coupled Springs}
Solve

\[
\begin{array}{r}
x_{1}^{\prime \prime}+10 x_{1}-4 x_{2}=0  \tag{6}\\
-4 x_{1}+x_{2}^{\prime \prime}+4 x_{2}=0
\end{array}
\]

subject to $x_{1}(0)=0, x_{1}^{\prime}(0)=1, x_{2}(0)=0, x_{2}^{\prime}(0)=-1$.

Solution The Laplace transform of each equation is

$$
\begin{aligned}
& s^{2} X_{1}(s)-s x_{1}(0)-x_{1}^{\prime}(0)+10 X_{1}(s)-4 X_{2}(s)=0 \\
& -4 X_{1}(s)+s^{2} X_{2}(s)-s x_{2}(0)-x_{2}^{\prime}(0)+4 X_{2}(s)=0
\end{aligned}
$$

where $X_{1}(s)=\mathscr{L}\left\{x_{1}(t)\right\}$ and $X_{2}(s)=\mathscr{L}\left\{x_{2}(t)\right\}$. The preceding system is the same as


\begin{align*}
\left(s^{2}+10\right) X_{1}(s)-\quad 4 X_{2}(s) & =1  \tag{7}\\
-4 X_{1}(s)+\left(s^{2}+4\right) X_{2}(s) & =-1
\end{align*}


Eliminating $X_{2}$ gives

$$
X_{1}(s)=\frac{s^{2}}{\left(s^{2}+2\right)\left(s^{2}+12\right)}
$$

By partial fractions we can write

$$
\frac{s^{2}}{\left(s^{2}+2\right)\left(s^{2}+12\right)}=\frac{A s+B}{s^{2}+2}+\frac{C s+D}{s^{2}+12}
$$

and

$$
s^{2}=(A s+B)\left(s^{2}+12\right)+(C s+D)\left(s^{2}+2\right)
$$

Comparing the coefficients of $s$ on each side of the last equality gives

$$
A+C=0, \quad B+D=1, \quad 12 A+2 C=0, \quad 12 B+2 D=0
$$

so $A=0, C=0, B=-\frac{1}{5}$, and $D=\frac{6}{5}$. Hence

$$
X_{1}(s)=-\frac{1 / 5}{s^{2}+2}+\frac{6 / 5}{s^{2}+12}
$$

and therefore

$$
\begin{aligned}
x_{1}(t) & =-\frac{1}{5 \sqrt{2}} \mathscr{L}^{-1}\left\{\frac{\sqrt{2}}{s^{2}+2}\right\}+\frac{6}{5 \sqrt{12}} \mathscr{L}^{-1}\left\{\frac{\sqrt{12}}{s^{2}+12}\right\} \\
& =-\frac{\sqrt{2}}{10} \sin \sqrt{2} t+\frac{\sqrt{3}}{5} \sin 2 \sqrt{3} t
\end{aligned}
$$

From the first equation of (7) it follows that

$$
X_{2}(s)=-\frac{s^{2}+6}{\left(s^{2}+2\right)\left(s^{2}+12\right)}
$$

Proceeding as before with partial fractions, we obtain

$$
X_{2}(s)=-\frac{2 / 5}{s^{2}+2}-\frac{3 / 5}{s^{2}+12}
$$

and

$$
\begin{aligned}
x_{2}(t) & =-\frac{2}{5 \sqrt{2}} \mathscr{L}^{-1}\left\{\frac{\sqrt{2}}{s^{2}+2}\right\}-\frac{3}{5 \sqrt{12}} \mathscr{L}^{-1}\left\{\frac{\sqrt{12}}{s^{2}+12}\right\} \\
& =-\frac{\sqrt{2}}{5} \sin \sqrt{2} t-\frac{\sqrt{3}}{10} \sin 2 \sqrt{3} t
\end{aligned}
$$

Finally, the solution to the given system (6) is


\begin{align*}
& x_{1}(t)=-\frac{\sqrt{2}}{10} \sin \sqrt{2} t+\frac{\sqrt{3}}{5} \sin 2 \sqrt{3} t  \tag{8}\\
& x_{2}(t)=-\frac{\sqrt{2}}{5} \sin \sqrt{2} t-\frac{\sqrt{3}}{10} \sin 2 \sqrt{3} t
\end{align*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-371}
\end{center}

Figure 8.2

Networks An electrical network having more than one loop also gives rise to simultaneous differential equations. As shown in Figure 8.2, the current $i_{1}(t)$ splits in the directions shown at point $B_{1}$, called a branch point of the network. By Kirchhoff's first law we can write


\begin{equation*}
i_{1}(t)=i_{2}(t)+i_{3}(t) \tag{9}
\end{equation*}


In addition we can also apply Kirchhoff's second law to each loop. For loop $A_{1} B_{1} B_{2} A_{2} A_{1}$, summing the voltage drops across each part of the loop gives


\begin{equation*}
E(t)=i_{1} R_{1}+L_{1} \frac{d i_{2}}{d t}+i_{2} R_{2} \tag{10}
\end{equation*}


Similarly, for loop $A_{1} B_{1} C_{1} C_{2} B_{2} A_{2} A_{1}$ we find


\begin{equation*}
E(t)=i_{1} R_{1}+L_{2} \frac{d i_{3}}{d t} \tag{11}
\end{equation*}


Using (9) to eliminate $i_{1}$ in (10) and (11) yields two first-order equations for the currents $i_{2}(t)$ and $i_{3}(t)$ :


\begin{align*}
& L_{1} \frac{d i_{2}}{d t}+\left(R_{1}+R_{2}\right) i_{2}+R_{1} i_{3}=E(t) \\
& L_{2} \frac{d i_{3}}{d t}+\quad R_{1} i_{2}+R_{1} i_{3}=E(t) \tag{12}
\end{align*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-372}
\end{center}

Figure 8.3\\
Given the natural initial conditions $i_{2}(0)=0, i_{3}(0)=0$, the system (12) is amenable to solution by the Laplace transform.

We leave it as an exercise (see Problem 18) to show that the system of differential equations describing the currents $i_{1}(t)$ and $i_{2}(t)$ in the network shown in Figure 8.3 containing a resistor, an inductor, and a capacitor is


\begin{align*}
L \frac{d i_{1}}{d t}+R i_{2} & =E(t)  \tag{13}\\
R C \frac{d i_{2}}{d t}+i_{2}-i_{1} & =0
\end{align*}


\section*{EXAMPLE 3 An Electrical Network}
Solve the system (13) under the conditions $E=60$ volts, $L=1$ henry, $R=50$ ohms, $C=10^{-4}$ farad, and $i_{1}$ and $i_{2}$ are initially zero.

Solution We must solve

$$
\begin{aligned}
\frac{d i_{1}}{d t}+50 i_{2} & =60 \\
50\left(10^{-4}\right) \frac{d i_{2}}{d t}+i_{2}-i_{1} & =0
\end{aligned}
$$

subject to $i_{1}(0)=0, i_{2}(0)=0$.

Applying the Laplace transform to each equation of the system and simplifying gives

$$
\begin{aligned}
s I_{1}(s)+\quad I_{2}(s) & =\frac{60}{s} \\
-200 I_{1}(s)+(s+200) I_{2}(s) & =0
\end{aligned}
$$

where $I_{1}(s)=\mathscr{L}\left\{i_{1}(t)\right\}$ and $I_{2}(s)=\mathscr{L}\left\{i_{2}(t)\right\}$. Solving the system for $I_{1}$ and $I_{2}$ yields

$$
I_{1}(s)=\frac{60 s+12,000}{s(s+100)^{2}} \quad \text { and } \quad I_{2}(s)=\frac{12,000}{s(s+100)^{2}}
$$

By partial fractions we can write

$$
\begin{aligned}
& I_{1}(s)=\frac{6 / 5}{s}-\frac{6 / 5}{s+100}-\frac{60}{(s+100)^{2}} \\
& I_{2}(s)=\frac{6 / 5}{s}-\frac{6 / 5}{s+100}-\frac{120}{(s+100)^{2}}
\end{aligned}
$$

from which it follows that

$$
i_{1}(t)=\frac{6}{5}-\frac{6}{5} e^{-100 t}-60 t e^{-100 t}, \quad i_{2}(t)=\frac{6}{5}-\frac{6}{5} e^{-100 t}-120 t e^{-100 t}
$$

Note that both $i_{1}(t)$ and $i_{2}(t)$ in Example 3 tend toward the value $E / R=\frac{6}{5}$ as $t \rightarrow \infty$. Furthermore since the current through the capacitor is $i_{3}(t)=i_{1}(t)-i_{2}(t)=60 t e^{-100 t}$, we observe that $i_{3}(t) \rightarrow 0$ as $t \rightarrow \infty$.

\section*{EXERCISES 8.2}
Answers to odd-numbered problems begin on page A-18.

In Problems 1-12 use the Laplace transform to solve the given system of differential equations.

\begin{enumerate}
  \item $\frac{d x}{d t}=-x+y$
  \item $\frac{d x}{d t}=2 y+e^{t}$
\end{enumerate}

$\frac{d y}{d t}=2 x$

$\frac{d y}{d t}=8 x-t$

$x(0)=0, y(0)=1$

$x(0)=1, y(0)=1$\\
3. $\frac{d x}{d t}=x-2 y$\\
4. $\frac{d x}{d t}+3 x+\frac{d y}{d t}=1$

$\frac{d y}{d t}=5 x-y$

$\frac{d x}{d t}-x+\frac{d y}{d t}-y=e^{t}$

$x(0)=-1, y(0)=2$

$x(0)=0, y(0)=0$\\
5. $2 \frac{d x}{d t}+\frac{d y}{d t}-2 x=1$\\
6. $\frac{d x}{d t}+x-\frac{d y}{d t}+y=0$

$\frac{d x}{d t}+\frac{d y}{d t}-3 x-3 y=2$

$\frac{d x}{d t}+\frac{d y}{d t}+2 y=0$

$x(0)=0, y(0)=0$

$x(0)=0, y(0)=1$\\
7. $\frac{d^{2} x}{d t^{2}}+x-y=0$\\
8. $\frac{d^{2} x}{d t^{2}}+\frac{d x}{d t}+\frac{d y}{d t}=0$

$\frac{d^{2} y}{d t^{2}}+y-x=0$

$\frac{d^{2} y}{d t^{2}}+\frac{d y}{d t}-4 \frac{d x}{d t}=0$

$x(0)=0, x^{\prime}(0)=-2$,

$x(0)=1, x^{\prime}(0)=0$,

$y(0)=0, y^{\prime}(0)=1$

$y(0)=-1, y^{\prime}(0)=5$\\
9. $\frac{d^{2} x}{d t^{2}}+\frac{d^{2} y}{d t^{2}}=t^{2}$\\
10. $\frac{d x}{d t}-4 x+\frac{d^{3} y}{d t^{3}}=6 \sin t$

$\frac{d^{2} x}{d t^{2}}-\frac{d^{2} y}{d t^{2}}=4 t$

$\frac{d x}{d t}+2 x-2 \frac{d^{3} y}{d t^{3}}=0$

$x(0)=8, x^{\prime}(0)=0$,

$x(0)=0, y(0)=0$,

$y(0)=0, y^{\prime}(0)=0$

$y^{\prime}(0)=0, y^{\prime \prime}(0)=0$\\
11. $\frac{d^{2} x}{d t^{2}}+3 \frac{d y}{d t}+3 y=0$\\
12. $\frac{d x}{d t}=4 x-2 y+2 U(t-1)$

$\frac{d^{2} x}{d t^{2}} \quad+3 y=t e^{-t}$\\
$x(0)=0, x^{\prime}(0)=2, y(0)=0$

$\frac{d y}{d t}=3 x-y+थ(t-1)$

$x(0)=0, y(0)=\frac{1}{2}$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Solve system (5) when $k_{1}=3, k_{2}=2, m_{1}=1, m_{2}=1, x_{1}(0)=0$, $x_{1}^{\prime}(0)=1, x_{2}(0)=1$, and $x_{2}^{\prime}(0)=0$.
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-374(2)}
\end{center}

Figure 8.4

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-374}
\end{center}

Figure 8.5

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-374(1)}
\end{center}

Figure 8.6

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-374(3)}
\end{center}

Figure 8.7\\
14. Derive the system of differential equations describing the straight-line vertical motion of the coupled springs shown in Figure 8.4. Use the Laplace transform to solve the system when $k_{1}=1, k_{2}=1, k_{3}=1, m_{1}=1, m_{2}=1$, $x_{1}(0)=0, x_{1}^{\prime}(0)=-1, x_{2}(0)=0$, and $x_{2}^{\prime}(0)=1$.

\begin{enumerate}
  \setcounter{enumi}{14}
  \item (a) Show that the system of differential equations for the currents $i_{2}(t)$ and $i_{3}(t)$ in the electrical network shown in Figure 8.5 is
\end{enumerate}

$$
\begin{aligned}
& L_{1} \frac{d i_{2}}{d t}+R i_{2}+R i_{3}=E(t) \\
& L_{2} \frac{d i_{3}}{d t}+R i_{2}+R i_{3}=E(t)
\end{aligned}
$$

(b) Solve the system in part (a) if $R=5$ ohms, $L_{1}=0.01$ henry, $L_{2}=0.0125$ henry, $E=100$ volts, $i_{2}(0)=0$, and $i_{3}(0)=0$.

(c) Determine the current $i_{1}(t)$.

\begin{enumerate}
  \setcounter{enumi}{15}
  \item (a) Show that the system of differential equations for the currents $i_{2}(t)$ and $i_{3}(t)$ in the electrical network shown in Figure 8.6 is
\end{enumerate}

$$
\begin{aligned}
L \frac{d i_{2}}{d t}+L \frac{d i_{3}}{d t}+R_{1} i_{2} & =E(t) \\
-R_{1} \frac{d i_{2}}{d t}+R_{2} \frac{d i_{3}}{d t}+\frac{1}{C} i_{3} & =0
\end{aligned}
$$

(b) Solve the system in part (a) if $R_{1}=10$ ohms, $R_{2}=5$ ohms, $L=1$ henry, $C=0.2$ farad,

$$
E(t)=\left\{\begin{array}{lr}
120, & 0 \leq t<2 \\
0, & t \geq 2
\end{array}\right.
$$

$$
i_{2}(0)=0 \text {, and } i_{3}(0)=0
$$

(c) Determine the current $i_{1}(t)$.

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Solve the system given in (12) when $R_{1}=6$ ohms, $R_{2}=5$ ohms, $L_{1}=1$ henry, $L_{2}=1$ henry, and $E(t)=50 \sin t$ volts.

  \item Derive the system of equations (13).

  \item Solve (13) when $E=60$ volts, $L=\frac{1}{2}$ henry, $R=50$ ohms, $C=10^{-4}$ farad, $i_{1}(0)=0$, and $i_{2}(0)=0$.

  \item Solve (13) when $E=60$ volts, $L=2$ henrys, $R=50$ ohms, $C=10^{-4}$ farad, $i_{1}(0)=0$, and $i_{2}(0)=0$.

  \item (a) Show that the system of differential equations for the charge on the capacitor $q(t)$ and the current $i_{3}(t)$ in the electrical network shown in Figure 8.7 is

\end{enumerate}

$$
\begin{aligned}
R_{1} \frac{d q}{d t}+\frac{1}{C} q+R_{1} i_{3} & =E(t) \\
L \frac{d i_{3}}{d t}+R_{2} i_{3}-\frac{1}{C} q & =0
\end{aligned}
$$

(b) Find the charge on the capacitor when $L=1$ henry, $R_{1}=1$ ohm, $R_{2}=1$ ohm, $C=1$ farad,

$$
E(t)=\left\{\begin{array}{lr}
0, & 0<t<1 \\
50 e^{-t}, & t \geq 1
\end{array}\right.
$$

$i_{3}(0)=0$, and $q(0)=0$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-375}
\end{center}

Figure 8.8\\
22. A double pendulum oscillates in a vertical plane under the influence of gravity (see Figure 8.8). For small displacements $\theta_{1}(t)$ and $\theta_{2}(t)$, it can be shown that the differential equations of motion are

$$
\begin{aligned}
\left(m_{1}+m_{2}\right) l_{1}^{2} \theta_{1}^{\prime \prime}+m_{2} l_{1} l_{2} \theta_{2}^{\prime \prime}+\left(m_{1}+m_{2}\right) l_{1} g \theta_{1} & =0 \\
m_{2} l_{2}^{2} \theta_{2}^{\prime \prime}+m_{2} l_{1} l_{2} \theta_{1}^{\prime \prime}+m_{2} l_{2} g \theta_{2} & =0 .
\end{aligned}
$$

Use the Laplace transform to solve the system when $m_{1}=3, m_{2}=1$, $l_{1}=l_{2}=16, \theta_{1}(0)=1, \theta_{2}(0)=-1, \theta_{1}^{\prime}(0)=0$ and $\theta_{2}^{\prime}(0)=0$.

\subsection*{8.3 SYSTEMS OF LINEAR FIRST-ORDER EQUATIONS}
In the preceding two sections we dealt with linear systems that were of the form


\begin{gather*}
P_{11}(D) x_{1}+P_{12}(D) x_{2}+\cdots+P_{1 n}(D) x_{n}=b_{1}(t) \\
P_{21}(D) x_{1}+P_{22}(D) x_{2}+\cdots+P_{2 n}(D) x_{n}=b_{2}(t)  \tag{1}\\
\vdots \\
P_{n 1}(D) x_{1}+P_{n 2}(D) x_{2}+\cdots+P_{n n}(D) x_{n}=b_{n}(t)
\end{gather*}


where the $P_{i j}$ were polynomials in the differential operator $D$. However, the study of systems of first-order differential equations


\begin{align*}
\frac{d x_{1}}{d t} & =g_{1}\left(t, x_{1}, x_{2}, \ldots, x_{n}\right) \\
\frac{d x_{2}}{d t} & =g_{2}\left(t, x_{1}, x_{2}, \ldots, x_{n}\right)  \tag{2}\\
& \vdots \\
\frac{d x_{n}}{d t} & =g_{n}\left(t, x_{1}, x_{2}, \ldots, x_{n}\right)
\end{align*}


is particularly important in advanced mathematics since every $n$ th-order differential equation

$$
y^{(n)}=F\left(t, y, y^{\prime}, \ldots, y^{(n-1)}\right)
$$

as well as most systems of differential equations, can be reduced to form (2). System (2) of $n$ first-order equations is called an $\boldsymbol{n}$ th-order system.

Linear Normal Form Of course, a system such as (2) need not be linear and need not have constant coefficients. Consequently, the system may not be readily solvable, if at all. In the remaining sections of this chapter we shall be inter-\\
ested only in a particular, but important, case of (2)—namely, those systems having the linear normal, or canonical, form


\begin{align*}
\frac{d x_{1}}{d t} & =a_{11}(t) x_{1}+a_{12}(t) x_{2}+\cdots+a_{1 n}(t) x_{n}+f_{1}(t) \\
\frac{d x_{2}}{d t} & =a_{21}(t) x_{1}+a_{22}(t) x_{2}+\cdots+a_{2 n}(t) x_{n}+f_{2}(t)  \tag{3}\\
& \vdots \\
\frac{d x_{n}}{d t} & =a_{n 1}(t) x_{1}+a_{n 2}(t) x_{2}+\cdots+a_{n n}(t) x_{n}+f_{n}(t)
\end{align*}


where the coefficients $a_{i j}$ and the functions $f_{i}$ are continuous on a common interval $I$. When $f_{i}(t)=0, i=1,2, \ldots, n$, the system (3) is said to be homogeneous; otherwise it is called nonhomogeneous.

We shall now show that every linear $n$ th-order differential equation can be reduced to a linear system having the normal form (3).

Equation to a System Suppose a linear $n$ th-order differential equation is first written as


\begin{equation*}
\frac{d^{n} y}{d t^{n}}=-\frac{a_{0}}{a_{n}} y-\frac{a_{1}}{a_{n}} y^{\prime}-\cdots-\frac{a_{n-1}}{a_{n}} y^{(n-1)}+f(t) \tag{4}
\end{equation*}


If we then introduce the variables


\begin{equation*}
y=x_{1}, \quad y^{\prime}=x_{2}, \quad y^{\prime \prime}=x_{3}, \ldots, \quad y^{(n-1)}=x_{n} \tag{5}
\end{equation*}


it follows that $y^{\prime}=x_{1}^{\prime}=x_{2}, y^{\prime \prime}=x_{2}^{\prime}=x_{3}, \ldots, y^{(n-1)}=x_{n-1}^{\prime}=x_{n}$, and $y^{(n)}=x_{n}^{\prime}$. Hence from (4) and (5) we find that a linear $n$ th-order differential equation can be expressed as an $n$ th-order system:


\begin{align*}
x_{1}^{\prime} & =x_{2} \\
x_{2}^{\prime} & =x_{3} \\
x_{3}^{\prime} & =x_{4} \\
& \vdots  \tag{6}\\
x_{n-1}^{\prime} & =x_{n} \\
x_{n}^{\prime} & =-\frac{a_{0}}{a_{n}} x_{1}-\frac{a_{1}}{a_{n}} x_{2}-\cdots-\frac{a_{n-1}}{a_{n}} x_{n}+f(t) .
\end{align*}


Inspection of (6) reveals that it has the same form as (3).

\section*{EXAMPLE 1 Writing a DE as a System}
Reduce the third-order equation $2 y^{\prime \prime \prime}-6 y^{\prime \prime}+4 y^{\prime}+y=\sin t$ to the normal form (3).

Solution Write the differential equation as

$$
y^{\prime \prime \prime}=-\frac{1}{2} y-2 y^{\prime}+3 y^{\prime \prime}+\frac{1}{2} \sin t
$$

and then let $y=x_{1}, y^{\prime}=x_{2}, y^{\prime \prime}=x_{3}$. Since

$$
x_{1}^{\prime}=y^{\prime}=x_{2}, \quad x_{2}^{\prime}=y^{\prime \prime}=x_{3}, \quad \text { and } \quad x_{3}^{\prime}=y^{\prime \prime \prime}
$$

we find

$$
\begin{aligned}
& x_{1}^{\prime}=x_{2} \\
& x_{2}^{\prime}=x_{3} \\
& x_{3}^{\prime}=-\frac{1}{2} x_{1}-2 x_{2}+3 x_{3}+\frac{1}{2} \sin t
\end{aligned}
$$

Systems Reduced to Normal Form Using a procedure similar to that just outlined, we can reduce most systems of the linear form (1) to the linear normal form (3). To accomplish this it is necessary to first solve the system for the highest-order derivative of each dependent variable. As we shall see, this may not always be possible.

\section*{EXAMPLE 2 Writing a System as a System of First-Order DEs}
Reduce

$$
\begin{aligned}
\left(D^{2}-D+5\right) x+2 D^{2} y & =e^{t} \\
-2 x+\left(D^{2}+2\right) y & =3 t^{2}
\end{aligned}
$$

to the normal form (3).

Solution Write the system as

$$
\begin{aligned}
D^{2} x+2 D^{2} y & =e^{t}-5 x+D x \\
D^{2} y & =3 t^{2}+2 x-2 y
\end{aligned}
$$

and then eliminate $D^{2} y$ by multiplying the second equation by 2 and subtracting. We have

$$
D^{2} x=e^{t}-6 t^{2}-9 x+4 y+D x
$$

Since the second equation of the system already expresses the highest-order derivative of $y$ in terms of the remaining functions, we are now in a position to introduce new variables. If we let

$$
D x=u \quad \text { and } \quad D y=v
$$

the expressions for $D^{2} x$ and $D^{2} y$ become, respectively,

$$
\begin{aligned}
& D u=e^{t}-6 t^{2}-9 x+4 y+u \\
& D v=3 t^{2}+2 x-2 y
\end{aligned}
$$

Thus the original system can be written in the normal form

$$
\begin{aligned}
& D x=u \\
& D y=v \\
& D u=-9 x+4 y+u+e^{t}-6 t^{2} \\
& D v=2 x-2 y+3 t^{2}
\end{aligned}
$$

Degenerate Systems Those systems of differential equations of form (1) that cannot be reduced to a linear system in normal form are said to be degenerate.

For example, it is a straightforward matter to show that it is impossible to solve the system

\[
\begin{array}{r}
(D+1) x+(D+1) y=0  \tag{7}\\
2 D x+(2 D+1) y=0
\end{array}
\]

for the highest derivative of each variable, and hence the system is degenerate.*

You may be wondering why anyone would want to convert a single differential equation to a system of equations, or for that matter a system of differential equations to an even larger system. While we are not in a position to completely justify their importance, suffice it to say that these procedures are more than a theoretical exercise. There are times when it is actually desirable to work with a system rather than with one equation. In the numerical analysis of differential equations, almost all computational algorithms are established for firstorder equations. Since these algorithms can be generalized directly to systems, to compute numerically, say, a second-order equation, we could reduce it to a system of two first-order equations (see Chapter 9).

A linear system such as (3) also arises naturally in some physical applications. The following example illustrates a homogeneous system in two dependent variables.

\section*{EXAMPLE 3 Two-Container Mixture Model}
Tank $A$ contains 50 gallons of water in which 25 pounds of salt are dissolved. A second tank, $B$, contains 50 gallons of pure water. Liquid is pumped in and out of the tanks at the rates shown in Figure 8.9. Derive the differential equations that describe the number of pounds $x_{1}(t)$ and $x_{2}(t)$ of salt at any time in tanks $A$ and $B$, respectively.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-378}
\end{center}

Figure 8.9

Solution By an analysis similar to that used in Section 3.2, we see that the net rate of change in $x_{1}(t) \mathrm{in} \mathrm{lb} / \mathrm{min}$ is

$$
\begin{aligned}
\frac{d x_{1}}{d t} & =\overbrace{(3 \mathrm{gal} / \mathrm{min}) \cdot(0 \mathrm{lb} / \mathrm{gal})+(1 \mathrm{gal} / \mathrm{min}) \cdot\left(\frac{x_{2}}{50} \mathrm{lb} / \mathrm{gal}\right)}^{\text {input }}-\overbrace{(4 \mathrm{gal} / \mathrm{min}) \cdot\left(\frac{x_{1}}{50} \mathrm{lb} / \mathrm{gal}\right)}^{\text {output }} \\
& =-\frac{2}{25} x_{1}+\frac{1}{50} x_{2} .
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item This does not mean that the system does not have a solution (see Problem 21).
\end{itemize}
}

In addition we find that the net rate of change in $x_{2}(t)$ is

$$
\begin{aligned}
\frac{d x_{2}}{d t} & =4 \cdot \frac{x_{1}}{50}-3 \cdot \frac{x_{2}}{50}-1 \cdot \frac{x_{2}}{50} \\
& =\frac{2}{25} x_{1}-\frac{2}{25} x_{2}
\end{aligned}
$$

Thus we obtain the first-order system


\begin{align*}
\frac{d x_{1}}{d t} & =-\frac{2}{25} x_{1}+\frac{1}{50} x_{2} \\
\frac{d x_{2}}{d t} & =\frac{2}{25} x_{1}-\frac{2}{25} x_{2} \tag{8}
\end{align*}


Observe that the foregoing system is accompanied by the initial conditions $x_{1}(0)=25, x_{2}(0)=0$.

It is left as an exercise to solve (8) by the Laplace transform. See Problem 17.

\section*{EXERCISES 8.3}
Answers to odd-numbered problems begin on page A-18.

In Problems 1-8 rewrite the given differential equation as a system in normal form (3).

\begin{enumerate}
  \item $y^{\prime \prime}-3 y^{\prime}+4 y=\sin 3 t$
  \item $2 \frac{d^{2} y}{d t^{2}}+4 \frac{d y}{d t}-5 y=0$
  \item $y^{\prime \prime \prime}-3 y^{\prime \prime}+6 y^{\prime}-10 y=t^{2}+1$
  \item $4 y^{\prime \prime \prime}+y=e^{t}$
  \item $\frac{d^{4} y}{d t^{4}}-2 \frac{d^{2} y}{d t^{2}}+4 \frac{d y}{d t}+y=t$
  \item $2 \frac{d^{4} y}{d t^{4}}+\frac{d^{3} y}{d t^{3}}-8 y=10$
  \item $(t+1) y^{\prime \prime}=t y$
  \item $t^{2} y^{\prime \prime}+t y^{\prime}+\left(t^{2}-4\right) y=0$
\end{enumerate}

In Problems 9-16 rewrite, if possible, the given system in the normal form (3).\\
9. $x^{\prime}+4 x-y^{\prime}=7 t$\\
10. $x^{\prime \prime}+y^{\prime}=1$\\
$x^{\prime}+\quad y^{\prime}-2 y=3 t$\\
$x^{\prime \prime}+y^{\prime}=-1$\\
11. $(D-1) x-D y=t^{2}$\\
12. $x^{\prime \prime}-2 y^{\prime \prime}=\sin t$

$$
x+D y=5 t-2
$$

$$
x^{\prime \prime}+y^{\prime \prime}=\cos t
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $(2 D+1) x-2 D y=4$

  \item $m_{1} x_{1}^{\prime \prime}=-k_{1} x_{1}+k_{2}\left(x_{2}-x_{1}\right)$\\
$D x-D y=e^{t}$\\
$m_{2} x_{2}^{\prime \prime}=-k_{2}\left(x_{2}-x_{1}\right)$

  \item $\frac{d^{3} x}{d t^{3}}=4 x-3 \frac{d^{2} x}{d t^{2}}+4 \frac{d y}{d t}$

  \item $D^{2} x+\quad D y=4 t$\\
$\frac{d^{2} y}{d t^{2}}=10 t^{2}-4 \frac{d x}{d t}+3 \frac{d y}{d t}$\\
$-D^{2} x+(D+1) y=6 t^{2}+10$

  \item Use the Laplace transform to solve system (8) subject to $x_{1}(0)=25$ and $x_{2}(0)=0$.

  \item Consider two tanks $A$ and $B$ with liquid being pumped in and out at the same rates as given in Example 3. What is the system of differential equations if, instead of pure water, a brine solution containing 2 lb of salt per gallon is pumped into tank $A$ ?

  \item Using the information given in Figure 8.10, derive the system of differential equations describing the numbers of pounds of salt $x_{1}, x_{2}$, and $x_{3}$ at any time in tanks $A, B$, and $C$, respectively.

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-380}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Consider the first-order system
\end{enumerate}

$$
\begin{aligned}
& \left(a_{1} D-b_{1}\right) x+\left(a_{2} D-b_{2}\right) y=0 \\
& \left(a_{3} D-b_{3}\right) x+\left(a_{4} D-b_{4}\right) y=0
\end{aligned}
$$

where the $a_{i}$ are nonzero constants. Determine a condition on the $a_{i}$ such that the system is degenerate.

\begin{enumerate}
  \setcounter{enumi}{20}
  \item Verify that the degenerate system (7) possesses the solution $x(t)=c_{1} e^{-t}$, $y(t)=-2 c_{1} e^{-t}$.
\end{enumerate}

\section*{8.4 INTRODUCTION TO MATRICES }
\textbackslash author\{

\begin{itemize}
  \item Matrix - Multiplicative inverse $\bullet$ Nonsingular matrix ・ Singular matrix \\
 - Augmented matrix - Elementary row operations - Gaussian elimination \\
 - Gauss-Jordan elimination - Reduced row-echelon form - Eigenvalue \\
 - Eigenvector \\
 - Characteristic equation\\
\}
\end{itemize}

\subsection*{8.4.1 BASIC DEFINITIONS AND THEORY}
Before examining a systematic procedure for solving linear first-order systems in normal form, we need the new and useful concept of a matrix.

\section*{DEFINITION 8.1 Matrix}
A matrix $\mathbf{A}$ is any rectangular array of numbers or functions:

\[
\mathbf{A}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n}  \tag{1}\\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & & & \vdots \\
a_{m 1} & a_{m 2} & \cdots & a_{m n}
\end{array}\right)
\]

If a matrix has $m$ rows and $n$ columns, we say that its size is $m$ by $n$ (written $m \times n$ ). An $n \times n$ matrix is called a square matrix of order $n$.

The element, or entry, in the $i$ th row and $j$ th column of an $m \times n$ matrix $\mathbf{A}$ is written $a_{i j}$. An $m \times n$ matrix $\mathbf{A}$ is then abbreviated as $\mathbf{A}=\left(a_{i j}\right)_{m \times n}$, or simply $\mathbf{A}=\left(a_{i j}\right)$. A $1 \times 1$ matrix is one constant or function.

DEFINITION 8.2 Equality of Matrices

Two $m \times n$ matrices $\mathbf{A}$ and $\mathbf{B}$ are equal if $a_{i j}=b_{i j}$ for each $i$ and $j$.

DEFINITION 8.3 Column Matrix

A column matrix $\mathbf{X}$ is any matrix having $n$ rows and one column:

$$
\mathbf{X}=\left(\begin{array}{c}
b_{11} \\
b_{21} \\
\vdots \\
b_{n 1}
\end{array}\right)=\left(b_{i 1}\right)_{n \times 1}
$$

A column matrix is also called a column vector or simply a vector.

DEFINITION 8.4

Multiples of Matrices

A multiple of a matrix $\mathbf{A}$ is defined to be

$$
k \mathbf{A}=\left(\begin{array}{cccc}
k a_{11} & k a_{12} & \cdots & k a_{1 n} \\
k a_{21} & k a_{22} & \cdots & k a_{2 n} \\
\vdots & & & \vdots \\
k a_{m 1} & k a_{m 2} & \cdots & k a_{m n}
\end{array}\right)=\left(k a_{i j}\right)_{m \times n}
$$

where $k$ is a constant or a function.

\section*{EXAMPLE 1 Multiples of Matrices}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-381}
\end{center}

We note in passing that for any matrix $\mathbf{A}$, the product $k \mathbf{A}$ is the same as $\mathbf{A} k$. For example,

$$
e^{-3 t}\binom{2}{5}=\binom{2 e^{-3 t}}{5 e^{-3 t}}=\binom{2}{5} e^{-3 t}
$$

\section*{DEFINITION 8.5 Addition of Matrices}
The sum of two $m \times n$ matrices $\mathbf{A}$ and $\mathbf{B}$ is defined to be the matrix

$$
\mathbf{A}+\mathbf{B}=\left(a_{i j}+b_{i j}\right)_{m \times n}
$$

In other words, when adding two matrices of the same size, we add the corresponding elements.

\section*{EXAMPLE 2 Matrix Addition}
$$
\begin{gathered}
\text { The sum of } \mathbf{A}=\left(\begin{array}{rrr}
2 & -1 & 3 \\
0 & 4 & 6 \\
-6 & 10 & -5
\end{array}\right) \text { and } \mathbf{B}=\left(\begin{array}{rrr}
4 & 7 & -8 \\
9 & 3 & 5 \\
1 & -1 & 2
\end{array}\right) \text { is } \\
\mathbf{A}+\mathbf{B}=\left(\begin{array}{rcc}
2+4 & -1+7 & 3+(-8) \\
0+9 & 4+3 & 6+5 \\
-6+1 & 10+(-1) & -5+2
\end{array}\right)=\left(\begin{array}{rrr}
6 & 6 & -5 \\
9 & 7 & 11 \\
-5 & 9 & -3
\end{array}\right)
\end{gathered}
$$

EXAMPLE 3 Matrix Written as a Sum of Column Matrices

The single matrix $\left(\begin{array}{c}3 t^{2}-2 e^{t} \\ t^{2}+7 t \\ 5 t\end{array}\right)$ can be written as the sum of three column vectors:

$$
\left(\begin{array}{c}
3 t^{2}-2 e^{t} \\
t^{2}+7 t \\
5 t
\end{array}\right)=\left(\begin{array}{c}
3 t^{2} \\
t^{2} \\
0
\end{array}\right)+\left(\begin{array}{c}
0 \\
7 t \\
5 t
\end{array}\right)+\left(\begin{array}{c}
-2 e^{t} \\
0 \\
0
\end{array}\right)=\left(\begin{array}{l}
3 \\
1 \\
0
\end{array}\right) t^{2}+\left(\begin{array}{l}
0 \\
7 \\
5
\end{array}\right) t+\left(\begin{array}{r}
-2 \\
0 \\
0
\end{array}\right) e^{t}
$$

The difference of two $m \times n$ matrices is defined in the usual manner: $\mathbf{A}-\mathbf{B}=\mathbf{A}+(-\mathbf{B})$, where $-\mathbf{B}=(-1) \mathbf{B}$.

\section*{DEFINITION 8.6 Multiplication of Matrices}
Let $\mathbf{A}$ be a matrix having $m$ rows and $n$ columns and $\mathbf{B}$ be a matrix having $n$ rows and $p$ columns. We define the product $\mathbf{A B}$ to be the $m \times p$ matrix

$$
\begin{aligned}
& \mathbf{A B}=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
\hline a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & & & \vdots \\
a_{m 1} & a_{m 2} & \cdots & a_{m n}
\end{array}\right)\left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 p} \\
b_{21} \\
b_{22} & \cdots & b_{2 p} \\
\vdots \\
b_{n 1}
\end{array}\right]
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-382}
\end{center}

$$
\begin{aligned}
& =\left(\sum_{k=1}^{n} a_{i k} b_{k j}\right)_{m \times p}
\end{aligned}
$$

Note carefully in Definition 8.6 that the product $\mathbf{A B}=\mathbf{C}$ is defined only when the number of columns in the matrix $\mathbf{A}$ is the same as the number of rows in $\mathbf{B}$. The size of the product can be determined from

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-383}
\end{center}

Also, you might recognize that the entries in, say, the $i$ th row of the final matrix $\mathbf{A B}$ are formed by using the component definition of the inner or dot product of the $i$ th row of $\mathbf{A}$ with each of the columns of $\mathbf{B}$.

\section*{EXAMPLE 4 Multiplication of Matrices}
(a) For $\mathbf{A}=\left(\begin{array}{ll}4 & 7 \\ 3 & 5\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}9 & -2 \\ 6 & 8\end{array}\right)$,

$$
\begin{aligned}
\mathbf{A B} & =\left(\begin{array}{ll}
4 \cdot 9+7 \cdot 6 & 4 \cdot(-2)+7 \cdot 8 \\
3 \cdot 9+5 \cdot 6 & 3 \cdot(-2)+5 \cdot 8
\end{array}\right) \\
& =\left(\begin{array}{ll}
78 & 48 \\
57 & 34
\end{array}\right) .
\end{aligned}
$$

(b) For $\mathbf{A}=\left(\begin{array}{ll}5 & 8 \\ 1 & 0 \\ 2 & 7\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}-4 & -3 \\ 2 & 0\end{array}\right)$,

$$
\begin{aligned}
\mathbf{A B} & =\left(\begin{array}{rl}
5 \cdot(-4)+8 \cdot 2 & 5 \cdot(-3)+8 \cdot 0 \\
1 \cdot(-4)+0 \cdot 2 & 1 \cdot(-3)+0 \cdot 0 \\
2 \cdot(-4)+7 \cdot 2 & 2 \cdot(-3)+7 \cdot 0
\end{array}\right) \\
& =\left(\begin{array}{rr}
-4 & -15 \\
-4 & -3 \\
6 & -6
\end{array}\right)
\end{aligned}
$$

In general, matrix multiplication is not commutative; that is, $\mathbf{A B} \neq \mathbf{B A}$. Observe in part (a) of Example 4 that $\mathbf{B A}=\left(\begin{array}{ll}30 & 53 \\ 48 & 82\end{array}\right)$, whereas in part (b) the product $\mathbf{B A}$ is not defined since Definition 8.6 requires that the first matrix (in this case $\mathbf{B}$ ) have the same number of columns as the second matrix has rows.

We are particularly interested in the product of a square matrix and a column vector.

\section*{EXAMPLE 5 Multiplication of Matrices}
$$
\begin{aligned}
& \text { (a) }\left(\begin{array}{rrr}
2 & -1 & 3 \\
0 & 4 & 5 \\
1 & -7 & 9
\end{array}\right)\left(\begin{array}{r}
-3 \\
6 \\
4
\end{array}\right)=\left(\begin{array}{l}
2 \cdot(-3)+(-1) \cdot 6+3 \cdot 4 \\
0 \cdot(-3)+4 \cdot 6+5 \cdot 4 \\
1 \cdot(-3)+(-7) \cdot 6+9 \cdot 4
\end{array}\right)=\left(\begin{array}{r}
0 \\
44 \\
-9
\end{array}\right) \\
& \text { (b) }\left(\begin{array}{rr}
-4 & 2 \\
3 & 8
\end{array}\right)\binom{x}{y}=\binom{-4 x+2 y}{3 x+8 y}
\end{aligned}
$$

Multiplicative Identity For a given positive integer $n$, the $n \times n$ matrix

$$
\mathbf{I}=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
\vdots & & & & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{array}\right)
$$

is called the multiplicative identity matrix. It follows from Definition 8.6 that for any $n \times n$ matrix $\mathbf{A}$,

$$
\mathbf{A I}=\mathbf{I A}=\mathbf{A}
$$

Also, it is readily verified that if $\mathbf{X}$ is an $n \times 1$ column matrix, then $\mathbf{I} \mathbf{X}=\mathbf{X}$.

Zero Matrix A matrix consisting of all zero entries is called a zero matrix and is denoted by $\mathbf{0}$. For example,

$$
\mathbf{0}=\binom{0}{0}, \quad \mathbf{0}=\left(\begin{array}{ll}
0 & 0 \\
0 & 0
\end{array}\right), \quad \mathbf{o}=\left(\begin{array}{ll}
0 & 0 \\
0 & 0 \\
0 & 0
\end{array}\right)
$$

and so on. If $\mathbf{A}$ and $\mathbf{0}$ are $m \times n$ matrices, then

$$
\mathbf{A}+\mathbf{0}=\mathbf{0}+\mathbf{A}=\mathbf{A}
$$

Associative Law Although we shall not prove it, matrix multiplication is associative. If $\mathbf{A}$ is an $m \times p$ matrix, $\mathbf{B}$ a $p \times r$ matrix, and $\mathbf{C}$ an $r \times n$ matrix, then

$$
\mathbf{A}(\mathbf{B C})=(\mathbf{A B}) \mathbf{C}
$$

is an $m \times n$ matrix.

Distributive Law If $\mathbf{B}$ and $\mathbf{C}$ are $r \times n$ matrices and $\mathbf{A}$ is an $m \times r$ matrix, then the distributive law is

$$
\mathbf{A}(\mathbf{B}+\mathbf{C})=\mathbf{A B}+\mathbf{A} \mathbf{C}
$$

Furthermore, if the product $(\mathbf{B}+\mathbf{C}) \mathbf{A}$ is defined, then

$$
(\mathbf{B}+\mathbf{C}) \mathbf{A}=\mathbf{B} \mathbf{A}+\mathbf{C} \mathbf{A}
$$

Determinant of a Matrix Associated with every square matrix A of constants, there is a number called the determinant of the matrix, which is denoted by det $\mathbf{A}$ or $|\mathbf{A}|$.

\section*{EXAMPLE 6 Determinant of a Square Matrix}
$$
\begin{gathered}
\text { For } \mathbf{A}=\left(\begin{array}{rrr}
3 & 6 & 2 \\
2 & 5 & 1 \\
-1 & 2 & 4
\end{array}\right) \text { we expand det } \mathbf{A} \text { by cofactors of the first row: } \\
\begin{aligned}
& \operatorname{det} \mathbf{A}=\left|\begin{array}{rrr}
3 & 6 & 2 \\
2 & 5 & 1 \\
-1 & 2 & 4
\end{array}\right|=3\left|\begin{array}{ll}
5 & 1 \\
2 & 4
\end{array}\right|-6\left|\begin{array}{rr}
2 & 1 \\
-1 & 4
\end{array}\right|+2\left|\begin{array}{rr}
2 & 5 \\
-1 & 2
\end{array}\right| \\
&=3(20-2)-6(8+1)+2(4+5)=18
\end{aligned}
\end{gathered}
$$

See Appendix III for a brief review of the properties of determinants.

\section*{DEFINITION 8.7 Transpose of a Matrix}
The transpose of the $m \times n$ matrix (1) is the $n \times m$ matrix $\mathbf{A}^{T}$ given by

$$
\mathbf{A}^{T}=\left(\begin{array}{cccc}
a_{11} & a_{21} & \ldots & a_{m 1} \\
a_{12} & a_{22} & \ldots & a_{m 2} \\
\vdots & & & \vdots \\
a_{1 n} & a_{2 n} & \ldots & a_{m n}
\end{array}\right)
$$

In other words, the rows of a matrix $\mathbf{A}$ become the columns of its transpose $\mathbf{A}^{T}$.

\section*{EXAMPLE 7 Transpose of a Matrix}
(a) The transpose of matrix $\mathbf{A}$ in Example 6 is

$$
\mathbf{A}^{T}=\left(\begin{array}{rrr}
3 & 2 & -1 \\
6 & 5 & 2 \\
2 & 1 & 4
\end{array}\right)
$$

(b) If $\mathbf{X}=\left(\begin{array}{l}5 \\ 0 \\ 3\end{array}\right)$, then $\mathbf{X}^{T}=\left(\begin{array}{lll}5 & 0 & 3\end{array}\right)$.

DEFINITION 8.8 Multiplicative Inverse of a Matrix

Let $\mathbf{A}$ be an $n \times n$ matrix. If there exists an $n \times n$ matrix $\mathbf{B}$ such that

$$
\mathbf{A B}=\mathbf{B} \mathbf{A}=\mathbf{I}
$$

where $\mathbf{I}$ is the multiplicative identity, then $\mathbf{B}$ is said to be the multiplicative inverse of $\mathbf{A}$ and is denoted by $\mathbf{B}=\mathbf{A}^{-1}$.

DEFINITION 8.9 Nonsingular/Singular Matrices

Let $\mathbf{A}$ be an $n \times n$ matrix. If $\operatorname{det} \mathbf{A} \neq 0$, then $\mathbf{A}$ is said to be nonsingular. If $\operatorname{det} \mathbf{A}=0$, then $\mathbf{A}$ is said to be singular.

The following gives a necessary and sufficient condition for a square matrix to have a multiplicative inverse.

\section*{THEOREM 8.1 Nonsingularity Implies A Has an Inverse}
An $n \times n$ matrix $\mathbf{A}$ has a multiplicative inverse $\mathbf{A}^{-1}$ if and only if $\mathbf{A}$ is nonsingular.

The following theorem gives one way of finding the multiplicative inverse for a nonsingular matrix.

\section*{THEOREM 8.2 A Formula for the Inverse of a Matrix}
Let $\mathbf{A}$ be an $n \times n$ nonsingular matrix and let $C_{i j}=(-1)^{i+j} M_{i j}$, where $M_{i j}$ is the determinant of the $(n-1) \times(n-1)$ matrix obtained by deleting the $i$ th row and $j$ th column from $\mathbf{A}$. Then


\begin{equation*}
\mathbf{A}^{-1}=\frac{1}{\operatorname{det} \mathbf{A}}\left(C_{i j}\right)^{T} \tag{2}
\end{equation*}


Each $C_{i j}$ in Theorem 8.2 is simply the cofactor (signed minor) of the corresponding entry $a_{i j}$ in $\mathbf{A}$. Note that the transpose is utilized in formula (2).

For future reference we observe in the case of a $2 \times 2$ nonsingular matrix

$$
\mathbf{A}=\left(\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right)
$$

that $C_{11}=a_{22}, C_{12}=-a_{21}, C_{21}=-a_{12}$, and $C_{22}=a_{11}$. Thus

\[
\mathbf{A}^{-1}=\frac{1}{\operatorname{det} \mathbf{A}}\left(\begin{array}{rr}
a_{22} & -a_{21}  \tag{3}\\
-a_{12} & a_{11}
\end{array}\right)^{T}=\frac{1}{\operatorname{det} \mathbf{A}}\left(\begin{array}{rr}
a_{22} & -a_{12} \\
-a_{21} & a_{11}
\end{array}\right)
\]

For a $3 \times 3$ nonsingular matrix

$$
\begin{aligned}
& \mathbf{A}=\left(\begin{array}{lll}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{array}\right) \\
& C_{11}=\left|\begin{array}{ll}
a_{22} & a_{23} \\
a_{32} & a_{33}
\end{array}\right|, \quad C_{12}=-\left|\begin{array}{ll}
a_{21} & a_{23} \\
a_{31} & a_{33}
\end{array}\right|, \quad C_{13}=\left|\begin{array}{ll}
a_{21} & a_{22} \\
a_{31} & a_{32}
\end{array}\right|,
\end{aligned}
$$

and so on. Carrying out the transposition gives

\[
\mathbf{A}^{-1}=\frac{1}{\operatorname{det} \mathbf{A}}\left(\begin{array}{lll}
C_{11} & C_{21} & C_{31}  \tag{4}\\
C_{12} & C_{22} & C_{32} \\
C_{13} & C_{23} & C_{33}
\end{array}\right)
\]

\section*{EXAMPLE 8 Inverse of a $2 \times 2$ Matrix}
Find the multiplicative inverse for $\mathbf{A}=\left(\begin{array}{rr}1 & 4 \\ 2 & 10\end{array}\right)$.

Solution Since det $\mathbf{A}=10-8=2 \neq 0, \mathbf{A}$ is nonsingular. It follows from Theorem 8.1 that $\mathbf{A}^{-1}$ exists. From (3) we find

$$
\mathbf{A}^{-1}=\frac{1}{2}\left(\begin{array}{rr}
10 & -4 \\
-2 & 1
\end{array}\right)=\left(\begin{array}{rr}
5 & -2 \\
-1 & \frac{1}{2}
\end{array}\right)
$$

\section*{EXAMPLE 9 Matrix with No Inverse}
The matrix $\mathbf{A}=\left(\begin{array}{ll}2 & 2 \\ 3 & 3\end{array}\right)$ is singular since $\operatorname{det} \mathbf{A}=2(3)-2(3)=0$. We conclude that $\mathbf{A}^{-1}$ does not exist.

\section*{EXAMPLE 10 Inverse of a $\mathbf{3} \times \mathbf{3}$ Matrix}
Find the multiplicative inverse for $\mathbf{A}=\left(\begin{array}{rrr}2 & 2 & 0 \\ -2 & 1 & 1 \\ 3 & 0 & 1\end{array}\right)$

Solution Since det $\mathbf{A}=12 \neq 0$, the given matrix is nonsingular. The cofactors corresponding to the entries in each row of $\operatorname{det} \mathbf{A}$ are

$$
\begin{array}{lll}
C_{11}=\left|\begin{array}{ll}
1 & 1 \\
0 & 1
\end{array}\right|=1 & C_{12}=-\left|\begin{array}{rr}
-2 & 1 \\
3 & 1
\end{array}\right|=5 & C_{13}=\left|\begin{array}{rr}
-2 & 1 \\
3 & 0
\end{array}\right|=-3 \\
C_{21}=-\left|\begin{array}{ll}
2 & 0 \\
0 & 1
\end{array}\right|=-2 & C_{22}=\left|\begin{array}{ll}
2 & 0 \\
3 & 1
\end{array}\right|=2 & C_{23}=-\left|\begin{array}{ll}
2 & 2 \\
3 & 0
\end{array}\right|=6 \\
C_{31}=\left|\begin{array}{ll}
2 & 0 \\
1 & 1
\end{array}\right|=2 & C_{32}=-\left|\begin{array}{rr}
2 & 0 \\
-2 & 1
\end{array}\right|=-2 & C_{33}=\left|\begin{array}{rr}
2 & 2 \\
-2 & 1
\end{array}\right|=6
\end{array}
$$

It follows from (4) that

$$
\mathbf{A}^{-1}=\frac{1}{12}\left(\begin{array}{rrr}
1 & -2 & 2 \\
5 & 2 & -2 \\
-3 & 6 & 6
\end{array}\right)=\left(\begin{array}{rrr}
\frac{1}{12} & -\frac{1}{6} & \frac{1}{6} \\
\frac{5}{12} & \frac{1}{6} & -\frac{1}{6} \\
-\frac{1}{4} & \frac{1}{2} & \frac{1}{2}
\end{array}\right)
$$

You are urged to verify that $\mathbf{A}^{-1} \mathbf{A}=\mathbf{A A}^{-1}=\mathbf{I}$.

Formula (2) presents obvious difficulties for nonsingular matrices larger than $3 \times 3$. For example, to apply (2) to a $4 \times 4$ matrix we would have to calculate\\
sixteen $3 \times 3$ determinants. ${ }^{*}$ In the case of a large matrix, there are more efficient ways of finding $\mathbf{A}^{-1}$. The curious reader is referred to any text in linear algebra.

Since our goal is to apply the concept of a matrix to systems of linear differential equations in normal form, we need the following definitions.

DEFINITION 8.10 Derivative of a Matrix of Functions

If $\mathbf{A}(t)=\left(a_{i j}(t)\right)_{m \times n}$ is a matrix whose entries are functions differentiable on a common interval, then

$$
\frac{d \mathbf{A}}{d t}=\left(\frac{d}{d t} a_{i j}\right)_{m \times n}
$$

DEFINITION 8.11 Integral of a Matrix of Functions

If $\mathbf{A}(t)=\left(a_{i j}(t)\right)_{m \times n}$ is a matrix whose entries are functions continuous on a common interval containing $t$ and $t_{0}$, then

$$
\int_{t_{0}}^{t} \mathbf{A}(s) d s=\left(\int_{t_{0}}^{t} a_{i j}(s) d s\right)_{m \times n}
$$

To differentiate (integrate) a matrix of functions we simply differentiate (integrate) each entry. The derivative of a matrix is also denoted by $\mathbf{A}^{\prime}(t)$.

\section*{EXAMPLE 11 Derivative/Integral of a Matrix}
$$
\text { If } \quad \mathbf{X}(t)=\left(\begin{array}{c}
\sin 2 t \\
e^{3 t} \\
8 t-1
\end{array}\right) \text {, then } \quad \mathbf{X}^{\prime}(t)=\left(\begin{array}{c}
\frac{d}{d t} \sin 2 t \\
\frac{d}{d t} e^{3 t} \\
\frac{d}{d t}(8 t-1)
\end{array}\right)=\left(\begin{array}{c}
2 \cos 2 t \\
3 e^{3 t} \\
8
\end{array}\right)
$$

and

$$
\int_{0}^{t} \mathbf{X}(s) d s=\left(\begin{array}{c}
\int_{0}^{t} \sin 2 s d s \\
\int_{0}^{t} e^{3 s} d s \\
\int_{0}^{t}(8 s-1) d s
\end{array}\right)=\left(\begin{array}{c}
-\frac{1}{2} \cos 2 t+\frac{1}{2} \\
\frac{1}{3} e^{3 t}-\frac{1}{3} \\
4 t^{2}-t
\end{array}\right)
$$
\footnotetext{\begin{itemize}
  \item Strictly speaking, a determinant is a number, but it is sometimes convenient to refer to a determinant as if it were an array.
\end{itemize}
}

\subsection*{8.4.2 Gaussian and Gauss-Jordan Elimination Methods}
In preparation for Section 8.6, we need to know more about solving algebraic systems of $n$ linear equations in $n$ unknowns


\begin{align*}
a_{11} x_{1}+a_{12} x_{2}+\cdots+a_{1 n} x_{n} & =b_{1} \\
a_{21} x_{1}+a_{22} x_{2}+\cdots+a_{2 n} x_{n} & =b_{2}  \tag{5}\\
& \vdots \\
a_{n 1} x_{1}+a_{n} x_{2}+\cdots+a_{n n} x_{n} & =b_{n} .
\end{align*}


If A denotes the matrix of coefficients in (5), we know that Cramer's rule (see Appendix III) could be used to solve the system whenever $\operatorname{det} \mathbf{A} \neq 0$. However, that rule requires a herculean effort if $\mathbf{A}$ is larger than $3 \times 3$. The procedure that we shall now consider has the distinct advantage of being not only an efficient way of handling large systems but also a means of solving consistent systems (5) in which $\operatorname{det} \mathbf{A}=0$ and a means of solving $m$ linear equations in $n$ unknowns.

\section*{DEFINITION 8.12}
\section*{Augmented Matrix}
The augmented matrix of the system (5) is the $n \times(n+1)$ matrix

$$
\left(\begin{array}{cccc|c}
a_{11} & a_{12} & \cdots & a_{1 n} & b_{1} \\
a_{21} & a_{22} & \cdots & a_{2 n} & b_{2} \\
\vdots & & & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n} & b_{n}
\end{array}\right)
$$

If $\mathbf{B}$ is the column matrix of the $b_{i}, i=1,2, \ldots, n$, the augmented matrix of (5) is denoted by $(\mathbf{A} \mid \mathbf{B})$.

Elementary Row Operations Recall from algebra that we can transform an algebraic system of equations into an equivalent system (that is, one having the same solution) by multiplying an equation by a nonzero constant, interchanging the positions of any two equations in the system, and adding a nonzero constant multiple of an equation to another equation. These operations on equations in a system are, in turn, equivalent to elementary row operations on an augmented matrix:

(i) Multiply a row by a nonzero constant.

(ii) Interchange any two rows.

(iii) Add a nonzero constant multiple of one row to any other row.

Elimination Methods To solve a system such as (5) using an augmented matrix we use either Gaussian elimination or the Gauss-Jordan elimination\\
method.* In the former method we carry out a succession of elementary row operations until we arrive at an augmented matrix in row-echelon form:

(i) The first nonzero entry in a nonzero row is 1 .

(ii) In consecutive nonzero rows, the first entry 1 in the lower row appears to the right of the first 1 in the higher row.

(iii) Rows consisting of all 0 's are at the bottom of the matrix.

In the Gauss-Jordan method the row operations are continued until we obtain an augmented matrix that is in reduced row-echelon form. A reduced rowechelon matrix has the same three properties listed above in addition to

(iv) A column containing a first entry 1 has 0 's everywhere else.

\section*{EXAMPLE 12 Row Echelon/Reduced Row-Echelon Form}
(a) The augmented matrices

$$
\left(\begin{array}{lll|r}
1 & 5 & 0 & 2 \\
0 & 1 & 0 & -1 \\
0 & 0 & 0 & 0
\end{array}\right) \text { and }\left(\begin{array}{rrrrr|r}
0 & 0 & 1 & -6 & 2 & 2 \\
0 & 0 & 0 & 0 & 1 & 4
\end{array}\right)
$$

are in row-echelon form. You should verify that the three criteria are satisfied.
\footnotetext{\begin{itemize}
  \item KARL FREIDRICH GAUSS (I777-I855) Gauss was the first of a new breed of precise and demanding mathematicians-the "rigorists." As a child, Gauss was a prodigy in mathematics. As an adult he often remarked that he could calculate or "reckon" before he could talk. However, as a college student, Gauss was torn between two loves: philology and mathematics. But he was inspired by some original mathematical achievements as a teenager and encouraged by the mathematician Wolfgang Bolyai, so the choice was not too difficult. At the age of twenty Gauss settled on a career in mathematics. At the age of twenty-two he completed a book on number theory, Disquisitiones Arithmeticae. Published in 1801, this text was recognized as a masterpiece, and even today remains a classic in its field. Gauss's doctoral dissertation of 1799 also remains a memorable document. Using the theory of functions of a complex variable, he was the first to prove the so-called fundamental theorem of algebra: Every polynomial equation has at least one root.
\end{itemize}

Although Gauss was certainly recognized and respected as an outstanding mathematician during his lifetime, the full extent of his genius was not realized until the publication of his scientific diary in 1898 , forty-four years after his death. Much to the chagrin of some nineteenth-century mathematicians, the diary revealed that Gauss had foreseen, sometimes by decades, many of their discoveries or, perhaps more accurately, rediscoveries. He was oblivious to fame; his mathematical researches were often pursued, like a child playing on a beach, simply for pleasure and self-satisfaction and not for the instruction that could be given to others through publication.

On any list of "Greatest Mathematicians Who Ever Lived," Karl Friedrich Gauss must surely rank near or at the top. For his profound impact on so many branches of mathematics, Gauss is sometimes referred to as "the prince of mathematicians."

WILHELM JORDAN (1842-1899) Jordan, a German engineer, used this method to solve linear systems in his 1888 text, Handbook of Geodesy.
}
(b) The augmented matrices

$$
\left(\begin{array}{lll|r}
1 & 0 & 0 & 7 \\
0 & 1 & 0 & -1 \\
0 & 0 & 0 & 0
\end{array}\right) \text { and }\left(\begin{array}{lllll|r}
0 & 0 & 1 & -6 & 0 & -6 \\
0 & 0 & 0 & 0 & 1 & 4
\end{array}\right)
$$

are in reduced row-echelon form. Note that the remaining entries in the columns containing a leading entry 1 are all 0 's.

It should be noted that in Gaussian elimination we stop once we have obtained an augmented matrix in row-echelon form. In other words, by using different sequences of row operations we may arrive at different row-echelon forms. This method then requires the use of back-substitution. In Gauss-Jordan elimination we stop when we have obtained the augmented matrix in reduced row-echelon form. Any sequence of row operations will lead to the same augmented matrix in reduced row-echelon form. This method does not require back-substitution; the solution of the system will be apparent by inspection of the final matrix. In terms of the equations of the original system, our goal in both methods is simply to make the coefficient of $x_{1}$ in the first equation* equal to 1 and then use multiples of that equation to eliminate $x_{1}$ from other equations. The process is repeated on the other variables.

To keep track of the row operations on an augmented matrix, we utilize the following notation:

\section*{Symbol Meaning}
$$
\begin{array}{ll}
R_{i j} & \text { Interchange rows } i \text { and } j \\
c R_{i} & \text { Multiply the } i \text { th row by the nonzero constant } c \\
c R_{i}+R_{j} & \text { Multiply the } i \text { th row by } c \text { and add to the } j \text { th row }
\end{array}
$$

\section*{EXAMPLE 13 Solution by Elimination}
Solve

$$
\begin{aligned}
2 x_{1}+6 x_{2}+x_{3} & =7 \\
x_{1}+2 x_{2}-x_{3} & =-1 \\
5 x_{1}+7 x_{2}-4 x_{3} & =9
\end{aligned}
$$

using (a) Gaussian elimination and (b) Gauss-Jordan elimination.

\section*{Solution}
(a) Using row operations on the augmented matrix of the system, we obtain

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-391}
\end{center}

$$
\begin{aligned}
& \xrightarrow{\frac{1}{2} R_{12}}\left(\begin{array}{rrr|r}
1 & 2 & -1 & -1 \\
0 & 1 & \frac{3}{2} & \frac{9}{2} \\
0 & -3 & 1 & 14
\end{array}\right) \xrightarrow{3 R_{2}+R_{3}}\left(\begin{array}{rrr|r}
1 & 2 & -1 & -1 \\
0 & 1 & \frac{3}{2} & \frac{9}{2} \\
0 & 0 & \frac{11}{2} & \frac{55}{2}
\end{array}\right) \xrightarrow{\frac{2}{11} R_{3}}\left(\begin{array}{rrr|r}
1 & 2 & -1 & -1 \\
0 & 1 & \frac{3}{2} & \frac{9}{2} \\
0 & 0 & 1 & 5
\end{array}\right) .
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item We can always interchange equations so that the first equation contains the variable $x_{1}$.
\end{itemize}
}

The last matrix is in row-echelon form and represents the system

$$
\begin{aligned}
x_{1}+2 x_{2}-x_{3} & =-1 \\
x_{2}+\frac{3}{2} x_{3} & =\frac{9}{2} \\
x_{3} & =5
\end{aligned}
$$

Substituting $x_{3}=5$ into the second equation then gives $x_{2}=-3$. Substituting both these values back into the first equation finally yields $x_{1}=10$.

(b) We start with the last matrix above. Since the first entries in the second and third rows are 1's, we must, in turn, make the remaining entries in the second and third columns 0 's:

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-392(1)}
\end{center}

The last matrix is now in reduced row-echelon form. Because of what the matrix means in terms of equations, it evident that the solution of the system is $x_{1}=10, x_{2}=-3, x_{3}=5$.

\section*{EXAMPLE 14 Gauss-Jordan Elimination}
Use Gauss-Jordan elimination to solve

$$
\begin{aligned}
x+3 y-2 z & =-7 \\
4 x+y+3 z & =5 \\
2 x-5 y+7 z & =19
\end{aligned}
$$

Solution We solve the system using Gauss-Jordan elimination:

$$
\begin{aligned}
& \left(\begin{array}{rrr|r}
1 & 3 & -2 & -7 \\
4 & 1 & 3 & 5 \\
2 & -5 & 7 & 19
\end{array}\right) \xrightarrow{-4 R_{1}+R_{2}+R_{3}}\left(\begin{array}{rrr|r}
1 & 3 & -2 & -7 \\
0 & -11 & 11 & 33 \\
0 & -11 & 11 & 33
\end{array}\right)
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-392}
\end{center}

In this case the last matrix in reduced row-echelon form implies that the original system of three equations in three unknowns is really equivalent to two equations in three unknowns. Since only $z$ is common to both equations (the nonzero rows), we can assign its values arbitrarily. If we let $z=t$, where $t$ represents any real number, then we see that the system has infinitely many solutions: $x=2-t, y=-3+t, z=t$. Geometrically, these equations are the parametric equations for the line of intersection of the planes $x+0 y+z=2$ and $0 x+y-z=-3$.

\subsection*{8.4.3 The Eigenvalue Problem}
Eigenvalues and Eigenvectors Gauss-Jordan elimination can be used to find the eigenvectors for a square matrix.

DEFINITION 8.13 Eigenvalues and Eigenvectors

Let $\mathbf{A}$ be an $n \times n$ matrix. A number $\lambda$ is said to be an eigenvalue of $\mathbf{A}$ if there exists a nonzero solution vector $\mathbf{K}$ of the linear system


\begin{equation*}
\mathbf{A K}=\lambda \mathbf{K} \tag{6}
\end{equation*}


The solution vector $\mathbf{K}$ is said to be an eigenvector corresponding to the eigenvalue $\lambda$.

The word eigenvalue is a combination of German and English terms adapted from the German word eigenwert, which, translated literally, is "proper value." Eigenvalues and eigenvectors are also called characteristic values and characteristic vectors, respectively.

\section*{EXAMPLE 15 Eigenvector of a Matrix}
Verify that $\mathbf{K}=\left(\begin{array}{r}1 \\ -1 \\ 1\end{array}\right)$ is an eigenvector of the matrix $\mathbf{A}=\left(\begin{array}{rrr}0 & -1 & -3 \\ 2 & 3 & 3 \\ -2 & 1 & 1\end{array}\right)$.

Solution By carrying out the multiplication AK, we see that

$$
\mathbf{A K}=\left(\begin{array}{rrr}
0 & -1 & -3 \\
2 & 3 & 3 \\
-2 & 1 & 1
\end{array}\right)\left(\begin{array}{r}
1 \\
-1 \\
1
\end{array}\right)=\left(\begin{array}{r}
-2 \\
2 \\
-2
\end{array}\right)=(-2)\left(\begin{array}{r}
1 \\
-1 \\
1
\end{array}\right)=\underset{(-2) \mathbf{K} .}{\downarrow}
$$

We see from the preceding line and Definition 8.13 that $\lambda=-2$ is an eigenvalue of $\mathbf{A}$.

Using properties of matrix algebra, we can write (6) in the alternative form


\begin{equation*}
(\mathbf{A}-\lambda \mathbf{I}) \mathbf{K}=\mathbf{0} \tag{7}
\end{equation*}


where $\mathbf{I}$ is the multiplicative identity. If we let

$$
\mathbf{K}=\left(\begin{array}{c}
k_{1} \\
k_{2} \\
\vdots \\
k_{n}
\end{array}\right)
$$

then (7) is the same as


\begin{align*}
& \left(a_{11}-\lambda\right) k_{1}+\quad a_{12} k_{2}+\cdots+\quad a_{1 n} k_{n}=0 \\
& a_{21} k_{1}+\left(a_{22}-\lambda\right) k_{2}+\cdots+\quad a_{2 n} k_{n}=0  \tag{8}\\
& a_{n 1} k_{1}+a_{n 2} k_{2}+\cdots+\left(a_{n n}-\lambda\right) k_{n}=0 .
\end{align*}


Although an obvious solution of (8) is $k_{1}=0, k_{2}=0, \ldots, k_{n}=0$, we are seeking only nontrivial solutions. Now it is known that a homogeneous system of $n$ linear equations in $n$ unknowns (that is, $b_{i}=0, i=1,2, \ldots, n$ in (5)) has a nontrivial solution if and only if the determinant of the coefficient matrix is equal to zero. Thus to find a nonzero solution $\mathbf{K}$ for (7), we must have


\begin{equation*}
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=0 \tag{9}
\end{equation*}


Inspection of (8) shows that the expansion of $\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})$ by cofactors results in an $n$ th-degree polynomial in $\lambda$. The equation (9) is called the characteristic equation of $\mathbf{A}$. Thus the eigenvalues of $\mathbf{A}$ are the roots of the characteristic equation. To find an eigenvector corresponding to an eigenvalue $\lambda$ we simply solve the system of equations $(\mathbf{A}-\lambda \mathbf{I}) \mathbf{K}=\mathbf{0}$ by applying Gauss-Jordan elimination to the augmented matrix $(\mathbf{A}-\lambda \mathbf{I} \mid \mathbf{0})$.

\section*{EXAMPLE 16 Eigenvalues/Eigenvectors}
Find the eigenvalues and eigenvectors of $\mathbf{A}=\left(\begin{array}{rrr}1 & 2 & 1 \\ 6 & -1 & 0 \\ -1 & -2 & -1\end{array}\right)$.

Solution To expand the determinant in the characteristic equation we use the cofactors of the second row:

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{ccc}
1-\lambda & 2 & 1 \\
6 & -1-\lambda & 0 \\
-1 & -2 & -1-\lambda
\end{array}\right|=-\lambda^{3}-\lambda^{2}+12 \lambda=0
$$

From $-\lambda^{3}-\lambda^{2}+12 \lambda=-\lambda(\lambda+4)(\lambda-3)=0$ we see that the eigenvalues are $\lambda_{1}=0, \lambda_{2}=-4$, and $\lambda_{3}=3$. To find the eigenvectors we must now reduce

$(\mathbf{A}-\lambda \mathbf{I} \mid \mathbf{0})$ three times corresponding to the three distinct eigenvalues.

For $\lambda_{1}=0$ we have

$$
\begin{aligned}
& (\mathbf{A}-0 \mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}
1 & 2 & 1 & 0 \\
6 & -1 & 0 & 0 \\
-1 & -2 & -1 & 0
\end{array}\right) \xrightarrow{\substack{6 R_{1}+R_{2} \\
R_{1}+R_{3}}}\left(\begin{array}{rrr|r}
1 & 2 & 1 & 0 \\
0 & -13 & -6 & 0 \\
0 & 0 & 0 & 0
\end{array}\right)
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-394}
\end{center}

Thus we see that $k_{1}=-\frac{1}{13} k_{3}$ and $k_{2}=-\frac{6}{13} k_{3}$. Choosing $k_{3}=-13$, we get the eigenvector*

$$
\mathbf{K}_{1}=\left(\begin{array}{r}
1 \\
6 \\
-13
\end{array}\right)
$$

For $\lambda_{2}=-4$,

$$
\begin{aligned}
& (\mathbf{A}+4 \mathbf{I} \mid 0)=\left(\begin{array}{rrr|r}
5 & 2 & 1 & 0 \\
6 & 3 & 0 & 0 \\
-1 & -2 & 3 & 0
\end{array}\right) \xrightarrow{-R_{3}}\left(\begin{array}{rrr|r}
1 & 2 & -3 & 0 \\
6 & 3 & 0 & 0 \\
5 & 2 & 1 & 0
\end{array}\right)
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-395}
\end{center}

implies $k_{1}=-k_{3}$ and $k_{2}=2 k_{3}$. Choosing $k_{3}=1$ then yields the second eigenvector

$$
\mathbf{K}_{2}=\left(\begin{array}{r}
-1 \\
2 \\
1
\end{array}\right)
$$

Finally, for $\lambda_{3}=3$ Gauss-Jordan elimination gives

$$
(\mathbf{A}-\mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}
-2 & 2 & 1 & 0 \\
6 & -4 & 0 & 0 \\
-1 & -2 & -4 & 0
\end{array}\right) \xrightarrow{\text { operations }}\left(\begin{array}{lll|l}
1 & 0 & 1 & 0 \\
0 & 1 & \frac{3}{2} & 0 \\
0 & 0 & 0 & 0
\end{array}\right)
$$

and so $k_{1}=-k_{3}$ and $k_{2}=-\frac{3}{2} k_{3}$. The choice of $k_{3}=-2$ leads to the third eigenvector:

$$
\mathbf{K}_{3}=\left(\begin{array}{r}
2 \\
3 \\
-2
\end{array}\right)
$$

When an $n \times n$ matrix $\mathbf{A}$ possesses $n$ distinct eigenvalues $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$, it can be proved that a set of $n$ linearly independent ${ }^{\dagger}$ eigenvectors $\mathbf{K}_{1}, \mathbf{K}_{2}, \ldots, \mathbf{K}_{n}$ can be found. However, when the characteristic equation has repeated roots, it may not be possible to find $n$ linearly independent eigenvectors for $\mathbf{A}$.

\section*{EXAMPLE 17 Eigenvalues/Eigenvectors}
Find the eigenvalues and eigenvectors of $\mathbf{A}=\left(\begin{array}{rr}3 & 4 \\ -1 & 7\end{array}\right)$.
\footnotetext{\begin{itemize}
  \item Of course $k_{3}$ could be chosen as any nonzero number. In other words, a nonzero constant multiple of an eigenvector is also an eigenvector.
\end{itemize}

$\dagger$ Linear independence of column vectors is defined in exactly the same manner as for functions.
}

Solution From the characteristic equation

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
3-\lambda & 4 \\
-1 & 7-\lambda
\end{array}\right|=(\lambda-5)^{2}=0
$$

we see that $\lambda_{1}=\lambda_{2}=5$ is an eigenvalue of multiplicity two. In the case of a $2 \times 2$ matrix there is no need to use Gauss-Jordan elimination. To find the eigenvector(s) corresponding to $\lambda_{1}=5$ we resort to the system $(\mathbf{A}-5 \mathbf{I} \mid \mathbf{0})$ in its equivalent form

$$
\begin{aligned}
-2 k_{1}+4 k_{2} & =0 \\
-k_{1}+2 k_{2} & =0
\end{aligned}
$$

It is apparent from this system that $k_{1}=2 k_{2}$. Thus if we choose $k_{2}=1$, we find the single eigenvector

$$
\mathbf{K}_{1}=\binom{2}{1}
$$

\section*{EXAMPLE 18 Eigenvalues/Eigenvectors}
Find the eigenvalues and eigenvectors of $\mathbf{A}=\left(\begin{array}{lll}9 & 1 & 1 \\ 1 & 9 & 1 \\ 1 & 1 & 9\end{array}\right)$.

Solution The characteristic equation

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{ccc}
9-\lambda & 1 & 1 \\
1 & 9-\lambda & 1 \\
1 & 1 & 9-\lambda
\end{array}\right|=-(\lambda-11)(\lambda-8)^{2}=0
$$

shows that $\lambda_{1}=11$ and that $\lambda_{2}=\lambda_{3}=8$ is an eigenvalue of multiplicity two.

For $\lambda_{1}=11$ Gauss-Jordan elimination gives

$$
(\mathbf{A}-11 \mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}
-2 & 1 & 1 & 0 \\
1 & -2 & 1 & 0 \\
1 & 1 & -2 & 0
\end{array}\right) \xrightarrow{\text { operawions }}\left(\begin{array}{rrr|r}
1 & 0 & -1 & 0 \\
0 & 1 & -1 & 0 \\
0 & 0 & 0 & 0
\end{array}\right)
$$

Hence $k_{1}=k_{3}$ and $k_{2}=k_{3}$. If $k_{3}=1$, then

$$
\mathbf{K}_{1}=\left(\begin{array}{l}
1 \\
1 \\
1
\end{array}\right)
$$

Now for $\lambda_{2}=8$ we have

$$
(\mathbf{A}-\mathbf{8} \mid \mathbf{0})=\left(\begin{array}{lll|l}
1 & 1 & 1 & 0 \\
1 & 1 & 1 & 0 \\
1 & 1 & 1 & 0
\end{array}\right) \xrightarrow{\text { operations }}\left(\begin{array}{lll|l}
1 & 1 & 1 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{array}\right)
$$

In the equation $k_{1}+k_{2}+k_{3}=0$, we are free to select two of the variables arbitrarily. Choosing, on the one hand, $k_{2}=1, k_{3}=0$ and, on the other, $k_{2}=0, k_{3}=1$, we obtain two linearly independent eigenvectors

$$
\mathbf{K}_{2}=\left(\begin{array}{r}
-1 \\
1 \\
0
\end{array}\right) \quad \text { and } \quad \mathbf{K}_{3}=\left(\begin{array}{r}
-1 \\
0 \\
1
\end{array}\right)
$$

corresponding to a single eigenvalue.

\section*{EXERCISES 8.4}
Answers to odd-numbered problems begin on page A-19.

\subsection*{8.4.I Basic Definitions and Theory}
\begin{enumerate}
  \item If $\mathbf{A}=\left(\begin{array}{rr}4 & 5 \\ -6 & 9\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}-2 & 6 \\ 8 & -10\end{array}\right)$, find (a) $\mathbf{A}+\mathbf{B},(\mathbf{b}) \mathbf{B}-\mathbf{A}$, (c) $2 \mathbf{A}+3 \mathbf{B}$.

  \item If $\mathbf{A}=\left(\begin{array}{rr}-2 & 0 \\ 4 & 1 \\ 7 & 3\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}3 & -1 \\ 0 & 2 \\ -4 & -2\end{array}\right)$,

\end{enumerate}

find (a) $\mathbf{A}-\mathbf{B}$, (b) $\mathbf{B}-\mathbf{A}$, (c) $2(\mathbf{A}+\mathbf{B})$.

\begin{enumerate}
  \setcounter{enumi}{2}
  \item If
\end{enumerate}

$$
\mathbf{A}=\left(\begin{array}{rr}
2 & -3 \\
-5 & 4
\end{array}\right) \quad \text { and } \quad \mathbf{B}=\left(\begin{array}{rr}
-1 & 6 \\
3 & 2
\end{array}\right)
$$

find (a) $\mathbf{A B}$, (b) $\mathbf{B A}$, (c) $\mathbf{A}^{2}=\mathbf{A A}$, (d) $\mathbf{B}^{2}=\mathbf{B B}$.

\begin{enumerate}
  \setcounter{enumi}{3}
  \item If $\mathbf{A}=\left(\begin{array}{rr}1 & 4 \\ 5 & 10 \\ 8 & 12\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rrr}-4 & 6 & -3 \\ 1 & -3 & 2\end{array}\right)$.
\end{enumerate}

find (a) $\mathbf{A B}$, (b) $\mathbf{B A}$.

\begin{enumerate}
  \setcounter{enumi}{4}
  \item If $\mathbf{A}=\left(\begin{array}{rr}1 & -2 \\ -2 & 4\end{array}\right), \quad \mathbf{B}=\left(\begin{array}{ll}6 & 3 \\ 2 & 1\end{array}\right)$, and $\quad \mathbf{C}=\left(\begin{array}{ll}0 & 2 \\ 3 & 4\end{array}\right)$,
\end{enumerate}

find (a) $\mathbf{B C}$, (b) $\mathbf{A}(\mathbf{B C})$, (c) $\mathbf{C}(\mathbf{B A})$, (d) $\mathbf{A}(\mathbf{B}+\mathbf{C})$.

\begin{enumerate}
  \setcounter{enumi}{5}
  \item If $\mathbf{A}=\left(\begin{array}{lll}5 & -6 & 7\end{array}\right), \quad \mathbf{B}=\left(\begin{array}{r}3 \\ 4 \\ -1\end{array}\right)$, and $\mathbf{C}=\left(\begin{array}{rrr}1 & 2 & 4 \\ 0 & 1 & -1 \\ 3 & 2 & 1\end{array}\right)$, find (a) $\mathbf{A B},(\mathbf{b}) \mathbf{B A}$, (c) $(\mathbf{B A}) \mathbf{C}$, (d) $(\mathbf{A B}) \mathbf{C}$.

  \item If $\mathbf{A}=\left(\begin{array}{r}4 \\ 8 \\ -10\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{lll}2 & 4 & 5\end{array}\right)$, find (a) $\mathbf{A}^{T} \mathbf{A}$, (b) $\mathbf{B}^{T} \mathbf{B}$, (c) $\mathbf{A}+\mathbf{B}^{T}$.

  \item If $\mathbf{A}=\left(\begin{array}{ll}1 & 2 \\ 2 & 4\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}-2 & 3 \\ 5 & 7\end{array}\right)$, find (a) $\mathbf{A}+\mathbf{B}^{T}$, (b) $2 \mathbf{A}^{T}-\mathbf{B}^{T}$, (c) $\mathbf{A}^{T}(\mathbf{A}-\mathbf{B})$.

  \item If $\mathbf{A}=\left(\begin{array}{ll}3 & 4 \\ 8 & 1\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}5 & 10 \\ -2 & -5\end{array}\right)$, find (a) $(\mathbf{A B})^{T}$, (b) $\mathbf{B}^{T} \mathbf{A}^{T}$.

  \item If $\mathbf{A}=\left(\begin{array}{rr}5 & 9 \\ -4 & 6\end{array}\right)$ and $\mathbf{B}=\left(\begin{array}{rr}-3 & 11 \\ -7 & 2\end{array}\right)$, find (a) $\mathbf{A}^{T}+\mathbf{B}^{T}$, (b) $(\mathbf{A}+\mathbf{B})^{T}$.

\end{enumerate}

In Problems 11-14 write the given sum as a single column matrix.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $4\binom{-1}{2}-2\binom{2}{8}+3\binom{-2}{3}$

  \item $3 t\left(\begin{array}{r}2 \\ t \\ -1\end{array}\right)+(t-1)\left(\begin{array}{r}-1 \\ -t \\ 3\end{array}\right)-2\left(\begin{array}{r}3 t \\ 4 \\ -5 t\end{array}\right)$

  \item $\left(\begin{array}{rr}2 & -3 \\ 1 & 4\end{array}\right)\binom{-2}{5}-\left(\begin{array}{ll}-1 & 6 \\ -2 & 3\end{array}\right)\binom{-7}{2}$

  \item $\left(\begin{array}{rrr}1 & -3 & 4 \\ 2 & 5 & -1 \\ 0 & -4 & -2\end{array}\right)\left(\begin{array}{c}t \\ 2 t-1 \\ -t\end{array}\right)+\left(\begin{array}{r}-t \\ 1 \\ 4\end{array}\right)-\left(\begin{array}{r}2 \\ 8 \\ -6\end{array}\right)$

\end{enumerate}

In Problems 15-22 determine whether the given matrix is singular or nonsingular. If it is nonsingular, find $\mathbf{A}^{-1}$.\\
15. $\mathbf{A}=\left(\begin{array}{ll}-3 & 6 \\ -2 & 4\end{array}\right)$\\
16. $\mathbf{A}=\left(\begin{array}{ll}2 & 5 \\ 1 & 4\end{array}\right)$\\
17. $\mathbf{A}=\left(\begin{array}{rr}4 & 8 \\ -3 & -5\end{array}\right)$\\
18. $\mathbf{A}=\left(\begin{array}{rr}7 & 10 \\ 2 & 2\end{array}\right)$\\
19. $\mathbf{A}=\left(\begin{array}{rrr}2 & 1 & 0 \\ -1 & 2 & 1 \\ 1 & 2 & 1\end{array}\right)$\\
20. $\mathbf{A}=\left(\begin{array}{rrr}3 & 2 & 1 \\ 4 & 1 & 0 \\ -2 & 5 & -1\end{array}\right)$\\
21. $\mathbf{A}=\left(\begin{array}{rrr}2 & 1 & 1 \\ 1 & -2 & -3 \\ 3 & 2 & 4\end{array}\right)$\\
22. $\mathbf{A}=\left(\begin{array}{rrr}4 & 1 & -1 \\ 6 & 2 & -3 \\ -2 & -1 & 2\end{array}\right)$

In Problems 23 and 24 show that the given matrix is nonsingular for every real value of $t$. Find $\mathbf{A}^{-1}(t)$.

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $\mathbf{A}(t)=\left(\begin{array}{rr}2 e^{-t} & e^{4 t} \\ 4 e^{-t} & 3 e^{4 t}\end{array}\right) \quad$ 24. $\mathbf{A}(t)=\left(\begin{array}{rr}2 e^{t} \sin t & -2 e^{t} \cos t \\ e^{t} \cos t & e^{t} \sin t\end{array}\right)$
\end{enumerate}

In Problems 25-28 find $d \mathbf{X} / d t$.\\
25. $\mathbf{X}=\left(\begin{array}{r}5 e^{-t} \\ 2 e^{-t} \\ -7 e^{-t}\end{array}\right)$\\
26. $\mathbf{X}=\binom{\frac{1}{2} \sin 2 t-4 \cos 2 t}{-3 \sin 2 t+5 \cos 2 t}$\\
27. $\mathbf{X}=2\binom{1}{-1} e^{2 t}+4\binom{2}{1} e^{-3 t}$\\
28. $\mathbf{X}=\binom{5 t e^{2 t}}{t \sin 3 t}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item Let $\mathbf{A}(t)=\left(\begin{array}{ll}e^{4 t} & \cos \pi t \\ 2 t & 3 t^{2}-1\end{array}\right)$.
\end{enumerate}

Find (a) $\frac{d \mathbf{A}}{d t}$, (b) $\int_{0}^{2} \mathbf{A}(t) d t$, (c) $\int_{0}^{t} \mathbf{A}(s) d s$.

\begin{enumerate}
  \setcounter{enumi}{29}
  \item Let $\mathbf{A}(t)=\left(\begin{array}{cc}\frac{1}{t^{2}+1} & 3 t \\ t^{2} & t\end{array}\right)$ and $\mathbf{B}(t)=\left(\begin{array}{cc}6 t & 2 \\ 1 / t & 4 t\end{array}\right)$.
\end{enumerate}

Find (a) $\frac{d \mathbf{A}}{d t}$, (b) $\frac{d \mathbf{B}}{d t}$, (c) $\int_{0}^{1} \mathbf{A}(t) d t$, (d) $\int_{1}^{2} \mathbf{B}(t) d t$, (e) $\mathbf{A}(t) \mathbf{B}(t)$, (f) $\frac{d}{d t} \mathbf{A}(t) \mathbf{B}(t),(\mathbf{g}) \int_{1}^{t} \mathbf{A}(s) \mathbf{B}(s) d s$.

\subsection*{8.4.2 Gaussian and Gauss-Jordan Elimination Methods}
In Problems 31-38 solve the given system of equations by either Gaussian elimination or Gauss-Jordan elimination.\\
31. $x+y-2 z=14$\\
32. $5 x-2 y+4 z=10$\\
$2 x-y+z=0$\\
$x+y+z=9$\\
$6 x+3 y+4 z=1$\\
$4 x-3 y+3 z=1$\\
33. $\begin{aligned} y+z & =-5 \\ 5 x+4 y-16 z & =-10 \\ x-y-5 z & =7\end{aligned}$\\
34. $3 x+y+z=4$\\
$4 x+2 y-z=7$\\
35. $2 x+y+z=4$\\
36. $x+2 z=8$\\
$10 x-2 y+2 z=-1$\\
$x+2 y-2 z=4$\\
$6 x-2 y+4 z=8$\\
$2 x+5 y-6 z=6$\\
37. $x_{1}+x_{2}-x_{3}-x_{4}=-1$\\
$x_{1}+x_{2}+x_{3}+x_{4}=3$\\
$x_{1}-x_{2}+x_{3}-x_{4}=3$\\
$4 x_{1}+x_{2}-2 x_{3}+x_{4}=0$\\
38. $2 x_{1}+x_{2}+x_{3}=0$\\
$x_{1}+3 x_{2}+x_{3}=0$\\
$7 x_{1}+x_{2}+3 x_{3}=0$

In Problems 39 and 40 use Gauss-Jordan elimination to demonstrate that the given system of equations has no solution.

$$
\text { 39. } \begin{aligned}
x+2 y+4 z & =2 \\
2 x+4 y+3 z & =1 \\
x+2 y-z & =7
\end{aligned}
$$

$$
\text { 40. } \begin{aligned}
x_{1}+x_{2}-x_{3}+3 x_{4} & =1 \\
x_{2}-x_{3}-4 x_{4} & =0 \\
x_{1}+2 x_{2}-2 x_{3}-x_{4} & =6 \\
4 x_{1}+7 x_{2}-7 x_{3} & =9
\end{aligned}
$$

\subsection*{8.4.3 The Eigenvalue Problem}
In Problems 41-48 find the eigenvalues and eigenvectors of the given matrix.\\
41. $\left(\begin{array}{ll}-1 & 2 \\ -7 & 8\end{array}\right)$\\
42. $\left(\begin{array}{ll}2 & 1 \\ 2 & 1\end{array}\right)$\\
43. $\left(\begin{array}{rr}-8 & -1 \\ 16 & 0\end{array}\right)$\\
44. $\left(\begin{array}{ll}1 & 1 \\ \frac{1}{4} & 1\end{array}\right)$\\
45. $\left(\begin{array}{rrr}5 & -1 & 0 \\ 0 & -5 & 9 \\ 5 & -1 & 0\end{array}\right)$\\
46. $\left(\begin{array}{lll}3 & 0 & 0 \\ 0 & 2 & 0 \\ 4 & 0 & 1\end{array}\right)$\\
47. $\left(\begin{array}{rrr}0 & 4 & 0 \\ -1 & -4 & 0 \\ 0 & 0 & -2\end{array}\right) \quad$ 48. $\left(\begin{array}{lll}1 & 6 & 0 \\ 0 & 2 & 1 \\ 0 & 1 & 2\end{array}\right)$

In Problems 49 and 50 show that the given matrix has complex eigenvalues. Find the eigenvectors of the matrix.\\
49. $\left(\begin{array}{ll}-1 & 2 \\ -5 & 1\end{array}\right)$\\
50. $\left(\begin{array}{rrr}2 & -1 & 0 \\ 5 & 2 & 4 \\ 0 & 1 & 2\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item If $\mathbf{A}(t)$ is a $2 \times 2$ matrix of differentiable functions and $\mathbf{X}(t)$ is a $2 \times 1$ column matrix of differentiable functions, prove the product rule
\end{enumerate}

$$
\frac{d}{d t}[\mathbf{A}(t) \mathbf{X}(t)]=\mathbf{A}(t) \mathbf{X}^{\prime}(t)+\mathbf{A}^{\prime}(t) \mathbf{X}(t)
$$

\begin{enumerate}
  \setcounter{enumi}{51}
  \item Derive formula (3). [Hint: Find a matrix $\mathbf{B}=\left(\begin{array}{ll}b_{11} & b_{12} \\ b_{21} & b_{22}\end{array}\right)$ for which $\mathbf{A B}=\mathbf{I}$. Solve for $b_{11}, b_{12}, b_{21}$, and $b_{22}$. Then show that $\mathbf{B A}=\mathbf{I}$.]

  \item If $\mathbf{A}$ is nonsingular and $\mathbf{A B}=\mathbf{A C}$, show that $\mathbf{B}=\mathbf{C}$.

  \item If $\mathbf{A}$ and $\mathbf{B}$ are nonsingular, show that $(\mathbf{A B})^{-1}=\mathbf{B}^{-1} \mathbf{A}^{-1}$.

  \item Let $\mathbf{A}$ and $\mathbf{B}$ be $n \times n$ matrices. In general, is

\end{enumerate}

$$
(\mathbf{A}+\mathbf{B})^{2}=\mathbf{A}^{2}+2 \mathbf{A B}+\mathbf{B}^{2} ?
$$

\subsection*{8.5 MATRICES AND SYSTEMS OF LINEAR FIRST-ORDER EQUATIONS}
\begin{itemize}
  \item Solution vector
  \item Superposition principle
  \item Linear dependence
  \item Linear independence
\end{itemize}

Wronskian

\begin{itemize}
  \item Fundamental set
  \item General solution
  \item Fundamental matrix
\end{itemize}

\subsection*{8.5.1 PRELIMINARY THEORY}
Matrix Form of a System If $\mathbf{X}, \mathbf{A}(t)$, and $\mathbf{F}(t)$ denote the respective matrices

$$
\mathbf{X}=\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right), \quad \mathbf{A}(t)=\left(\begin{array}{cccc}
a_{11}(t) & a_{12}(t) & \cdots & a_{1 n}(t) \\
a_{21}(t) & a_{22}(t) & \cdots & a_{2 n}(t) \\
\vdots & & & \vdots \\
a_{n 1}(t) & a_{n 2}(t) & \cdots & a_{n n}(t)
\end{array}\right), \quad \mathbf{F}(t)=\left(\begin{array}{c}
f_{1}(t) \\
f_{2}(t) \\
\vdots \\
f_{n}(t)
\end{array}\right)
$$

then the system of linear first-order differential equations


\begin{align*}
\frac{d x_{1}}{d t} & =a_{11}(t) x_{1}+a_{12}(t) x_{2}+\cdots+a_{1 n}(t) x_{n}+f_{1}(t) \\
\frac{d x_{2}}{d t} & =a_{21}(t) x_{1}+a_{22}(t) x_{2}+\cdots+a_{2 n}(t) x_{n}+f_{2}(t)  \tag{1}\\
& \vdots \\
\frac{d x_{n}}{d t} & =a_{n 1}(t) x_{1}+a_{n 2}(t) x_{2}+\cdots+a_{n n}(t) x_{n}+f_{n}(t)
\end{align*}


can be written as

$$
\frac{d}{d t}\left(\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right)=\left(\begin{array}{cccc}
a_{11}(t) & a_{12}(t) & \ldots & a_{1 n}(t) \\
a_{21}(t) & a_{22}(t) & \ldots & a_{2 n}(t) \\
\vdots & & & \vdots \\
a_{n 1}(t) & a_{n 2}(t) & \ldots & a_{n n}(t)
\end{array}\right)\left(\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right)+\left(\begin{array}{c}
f_{1}(t) \\
f_{2}(t) \\
\vdots \\
f_{n}(t)
\end{array}\right)
$$

or simply


\begin{equation*}
\frac{d \mathbf{X}}{d t}=\mathbf{A}(t) \mathbf{X}+\mathbf{F}(t) \tag{2}
\end{equation*}


If the system is homogeneous, (2) becomes


\begin{equation*}
\frac{d \mathbf{X}}{d t}=\mathbf{A}(t) \mathbf{X} \tag{3}
\end{equation*}


Equations (2) and (3) are also written as $\mathbf{X}^{\prime}=\mathbf{A X}+\mathbf{F}$ and $\mathbf{X}^{\prime}=\mathbf{A X}$, respectively.

\section*{EXAMPLE 1 Systems Written in Matrix Notation}
In matrix terms the nonhomogeneous system

$$
\begin{aligned}
& \frac{d x}{d t}=-2 x+5 y+e^{t}-2 t \\
& \frac{d y}{d t}=4 x-3 y+10 t
\end{aligned}
$$

can be written as

$$
\begin{aligned}
& \frac{d \mathbf{X}}{d t}=\left(\begin{array}{rr}
-2 & 5 \\
4 & -3
\end{array}\right) \mathbf{X}+\binom{e^{t}-2 t}{10 t} \\
& \mathbf{X}^{\prime}=\left(\begin{array}{rr}
-2 & 5 \\
4 & -3
\end{array}\right) \mathbf{X}+\binom{1}{0} e^{t}+\binom{-2}{10} t
\end{aligned}
$$

where $\mathbf{X}=\binom{x}{y}$.

\section*{EXAMPLE 2 Systems Written in Matrix Notation}
The matrix form of the homogeneous system

$$
\begin{aligned}
& \frac{d x}{d t}=2 x-3 y \\
& \frac{d y}{d t}=6 x+5 y
\end{aligned} \quad \text { is } \quad \frac{d \mathbf{X}}{d t}=\left(\begin{array}{rr}
2 & -3 \\
6 & 5
\end{array}\right) \mathbf{X}
$$

where $\mathbf{X}=\binom{x}{y}$.

DEFINITION 8.14 Solution Vector

A solution vector on an interval $I$ is any column matrix

$$
\mathbf{X}=\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right)
$$

whose entries are differentiable functions satisfying the system (2) on the interval.

\section*{EXAMPLE 3 Verification of Solutions}
Verify that

$$
\mathbf{X}_{1}=\binom{1}{-1} e^{-2 t}=\binom{e^{-2 t}}{-e^{-2 t}} \text { and } \quad \mathbf{X}_{2}=\binom{3}{5} e^{6 t}=\binom{3 e^{6 t}}{5 e^{6 t}}
$$

are solutions of

\[
\mathbf{X}^{\prime}=\left(\begin{array}{ll}
1 & 3  \tag{4}\\
5 & 3
\end{array}\right) \mathbf{X}
\]

on the interval $(-\infty, \infty)$.

Solution We have $\quad \mathbf{X}_{1}^{\prime}=\binom{-2 e^{-2 t}}{2 e^{-2 t}}$

and $\quad \mathbf{A} \mathbf{X}_{1}=\left(\begin{array}{ll}1 & 3 \\ 5 & 3\end{array}\right)\binom{e^{-2 t}}{-e^{-2 t}}=\binom{e^{-2 t}-3 e^{-2 t}}{5 e^{-2 t}-3 e^{-2 t}}=\binom{-2 e^{-2 t}}{2 e^{-2 t}}=\mathbf{X}_{1}^{\prime}$.

Now

$$
\mathbf{X}_{2}^{\prime}=\binom{18 e^{6 t}}{30 e^{5 t}}
$$

and

$$
\mathbf{A} \mathbf{X}_{2}=\left(\begin{array}{ll}
1 & 3 \\
5 & 3
\end{array}\right)\binom{3 e^{6 t}}{5 e^{6 t}}=\binom{3 e^{6 t}+15 e^{6 t}}{15 e^{6 t}+15 e^{6 t}}=\binom{18 e^{6 t}}{30 e^{6 t}}=\mathbf{X}_{2}^{\prime}
$$

Much of the theory of systems of $n$ linear first-order differential equations is similar to that of linear $n$ th-order differential equations.

Initial-Value Problem Let $t_{0}$ denote a point on an interval $I$ and

$$
\mathbf{X}\left(t_{0}\right)=\left(\begin{array}{c}
x_{1}\left(t_{0}\right) \\
x_{2}\left(t_{0}\right) \\
\vdots \\
x_{n}\left(t_{0}\right)
\end{array}\right) \quad \text { and } \quad \mathbf{X}_{0}=\left(\begin{array}{c}
\gamma_{1} \\
\gamma_{2} \\
\vdots \\
\gamma_{n}
\end{array}\right)
$$

where the $\gamma_{i}, i=1,2, \ldots, n$ are given constants. Then the problem

$$
\text { Solve: } \quad \frac{d \mathbf{X}}{d t}=\mathbf{A}(t) \mathbf{X}+\mathbf{F}(t)
$$

Subject to: $\quad \mathbf{X}\left(t_{0}\right)=\mathbf{X}_{0}$

is an initial-value problem on the interval.

\section*{THEOREM 8.3 Existence of a Unique Solution}
Let the entries of the matrices $\mathbf{A}(t)$ and $\mathbf{F}(t)$ be functions continuous on a common interval $I$ that contains the point $t_{0}$. Then there exists a unique solution of the initial-value problem (5) on the interval.

Homogeneous Systems In the next several definitions and theorems, we are concerned only with homogeneous systems. Without stating it, we shall always assume that the $a_{i j}$ and the $f_{i}$ are continuous functions of $t$ on some common interval $I$.

Superposition Principle The following result is a superposition principle for solutions of linear systems.

\section*{THEOREM 8.4 Superposition Principle}
Let $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{k}$ be a set of solution vectors of the homogeneous system (3) on an interval $I$. Then the linear combination

$$
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{k} \mathbf{X}_{k}
$$

where the $c_{i}, i=1,2, \ldots, k$ are arbitrary constants, is also a solution on the interval.

It follows from Theorem 8.4 that a constant multiple of any solution vector of a homogeneous system of linear first-order differential equations is also a solution.

\section*{EXAMPLE 4 Constant Multiple of a Solution Is a Solution}
One solution of the system

is


\begin{align*}
& \mathbf{X}^{\prime}=\left(\begin{array}{rrr}
1 & 0 & 1 \\
1 & 1 & 0 \\
-2 & 0 & -1
\end{array}\right) \mathbf{X}  \tag{6}\\
& \mathbf{X}_{1}=\left(\begin{array}{c}
\cos t \\
-\frac{1}{2} \cos t+\frac{1}{2} \sin t \\
-\cos t-\sin t
\end{array}\right)
\end{align*}


For any constant $c_{1}$ the vector $\mathbf{X}=c_{1} \mathbf{X}_{1}$ is also a solution since

$$
\frac{d \mathbf{X}}{d t}=\left(\begin{array}{c}
-c_{1} \sin t \\
\frac{1}{2} c_{1} \sin t+\frac{1}{2} c_{1} \cos t \\
c_{1} \sin t-c_{1} \cos t
\end{array}\right)
$$

and

$$
\begin{aligned}
\mathbf{A X} & =\left(\begin{array}{rrr}
1 & 0 & 1 \\
1 & 1 & 0 \\
-2 & 0 & -1
\end{array}\right)\left(\begin{array}{c}
-c_{1} \cos t \\
-\frac{1}{2} c_{1} \cos t+\frac{1}{2} c_{1} \sin t \\
-c_{1} \cos t-c_{1} \sin t
\end{array}\right) \\
& =\left(\begin{array}{c}
-c_{1} \sin t \\
\frac{1}{2} c_{1} \cos t+\frac{1}{2} c_{1} \sin t \\
-c_{1} \cos t+c_{1} \sin t
\end{array}\right)
\end{aligned}
$$

Inspection of the resulting matrices shows that $\mathbf{X}^{\prime}=\mathbf{A X}$.

\section*{EXAMPLE 5 Using the Superposition Principle}
Consider the system (6) of Example 4. If

and

$$
\begin{gathered}
\mathbf{X}_{2}=\left(\begin{array}{c}
0 \\
e^{t} \\
0
\end{array}\right), \text { then } \mathbf{X}_{2}^{\prime}=\left(\begin{array}{c}
0 \\
e^{t} \\
0
\end{array}\right) \\
\mathbf{A} \mathbf{X}_{2}=\left(\begin{array}{rrr}
1 & 0 & 1 \\
1 & 1 & 0 \\
-2 & 0 & -1
\end{array}\right)\left(\begin{array}{l}
0 \\
e^{t} \\
0
\end{array}\right)=\left(\begin{array}{l}
0 \\
e^{t} \\
0
\end{array}\right)=\mathbf{X}_{2}^{\prime}
\end{gathered}
$$

Thus we see that $\mathbf{X}_{2}$ is also a solution vector of (6). By the superposition principle the linear combination

$$
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}=c_{1}\left(\begin{array}{c}
\cos t \\
-\frac{1}{2} \cos t+\frac{1}{2} \sin t \\
-\cos t-\sin t
\end{array}\right)+c_{2}\left(\begin{array}{l}
0 \\
e^{t} \\
0
\end{array}\right)
$$

is yet another solution of the system.

Linear Independence We are primarily interested in linearly independent solutions of the homogeneous system (3).

\section*{DEFINITION 8.15 Linear Dependence/Independence}
Let $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{k}$ be a set of solution vectors of the homogeneous system (3) on an interval $I$. We say that the set is linearly dependent on the interval if there exist constants $c_{1}, c_{2}, \ldots, c_{k}$, not all zero, such that

$$
c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{k} \mathbf{X}_{k}=\mathbf{0}
$$

for every $t$ in the interval. If the set of vectors is not linearly dependent on the interval, it is said to be linearly independent.

The case when $k=2$ should be clear; two solution vectors $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ are linearly dependent if one is a constant multiple of the other, and conversely. For\\
$k>2$ a set of solution vectors is linearly dependent if we can express at least one solution vector as a linear combination of the remaining vectors.

\section*{EXAMPLE 6 Linearly Independent Solutions}
 It can be verified that $\mathbf{X}_{1}=\binom{3}{1} e^{t}$ and $\mathbf{X}_{2}=\binom{1}{1} e^{-t}$ are solution vectors of thesystem

\[
\mathbf{X}^{\prime}=\left(\begin{array}{ll}
2 & -3  \tag{7}\\
1 & -2
\end{array}\right) \mathbf{X}
\]

Now $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ are linearly independent on the interval $(-\infty, \infty)$ since

$$
c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}=0 \quad \text { or } \quad c_{1}\binom{3}{1} e^{t}+c_{2}\binom{1}{1} e^{-t}=\binom{0}{0}
$$

is equivalent to

$$
\begin{aligned}
3 c_{1} e^{t}+c_{2} e^{-t} & =0 \\
c_{1} e^{t}+c_{2} e^{-t} & =0
\end{aligned}
$$

Solving this system for $c_{1}$ and $c_{2}$ immediately yields $c_{1}=0$ and $c_{2}=0$.

\section*{EXAMPLE 7 Linearly Dependent Solutions}
The vector $\mathbf{X}_{3}=\binom{e^{t}+\cosh t}{\cosh t}$ is also a solution of the system (7) given in Example 6. However, $\mathbf{X}_{1}, \mathbf{X}_{2}$, and $\mathbf{X}_{3}$ are linearly dependent since

$$
\mathbf{X}_{3}=\frac{1}{2} \mathbf{X}_{1}+\frac{1}{2} \mathbf{X}_{2}
$$

Wronskian As in our earlier consideration of the theory of a single ordinary differential equation, we can introduce the concept of the Wronskian determinant as a test for linear independence. We state the following theorem without proof.

\section*{THEOREM 8.5 Criterion for Linearly Independent Solutions}
Let $\quad \mathbf{X}_{1}=\left(\begin{array}{c}x_{11} \\ x_{21} \\ \vdots \\ x_{n 1}\end{array}\right), \quad \mathbf{X}_{2}=\left(\begin{array}{c}x_{12} \\ x_{22} \\ \vdots \\ x_{n 2}\end{array}\right), \quad \ldots, \quad \mathbf{X}_{n}=\left(\begin{array}{c}x_{1 n} \\ x_{2 n} \\ \vdots \\ x_{n n}\end{array}\right)$

be $n$ solution vectors of the homogeneous system (3) on an interval $I$. A necessary and sufficient condition that the set of solutions be linearly independent is that the Wronskian

\[
W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}\right)=\left|\begin{array}{cccc}
x_{11} & x_{12} & \cdots & x_{1 n}  \tag{8}\\
x_{21} & x_{22} & \cdots & x_{2 n} \\
\vdots & & & \vdots \\
x_{n 1} & x_{n 2} & \cdots & x_{n n}
\end{array}\right| \neq 0
\]

for every $t$ in $I$

In fact, it can be shown that if $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}$ are solution vectors of (3), then either $W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}\right) \neq 0$ for every $t$ in $I$ or $W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}\right)=0$ for every $t$ in the interval. Thus if we can show that $W \neq 0$ for some $t_{0}$ in $I$, then $W \neq 0$ for every $t$ and hence the solutions are linearly independent on the interval.

Notice that, unlike our previous definition of the Wronskian, the determinant (8) does not involve differentiation.

\section*{EXAMPLE 8 Using the Wronskian}
In Example 3 we saw that

$$
\mathbf{X}_{1}=\binom{1}{-1} e^{-2 t} \quad \text { and } \quad \mathbf{X}_{2}=\binom{3}{5} e^{6 t}
$$

are solutions of the system (4). Clearly, $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ are linearly independent on $(-\infty, \infty)$ since neither vector is a constant multiple of the other. In addition, we have

$$
W\left(\mathbf{X}_{1}, \mathbf{X}_{2}\right)=\left|\begin{array}{rr}
e^{-2 t} & 3 e^{6 t} \\
-e^{-2 t} & 5 e^{6 t}
\end{array}\right|=8 e^{4 t} \neq 0
$$

for all real values of $t$.

\section*{Fundamental Set of Solutions}
\section*{DEFINITION 8.16 Fundamental Set of Solutions}
Any set $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}$ of $n$ linearly independent solution vectors of the homogeneous system (3) on an interval $I$ is said to be a fundamental set of solutions on the interval.

\section*{THEOREM 8.6 Existence of a Fundamental Set}
There exists a fundamental set of solutions for the homogeneous system (3) on an interval $I$.

\section*{DEFINITION 8.17 General Solution-Homogeneous Systems}
Let $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}$ be a fundamental set of solutions of the homogeneous system (3) on an interval $I$. The general solution of the system on the interval is defined to be

$$
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{n} \mathbf{X}_{n}
$$

where the $c_{i}, i=1,2, \ldots, n$ are arbitrary constants.

Although we shall not give the proof, it can be shown that, for appropriate choices of the constants $c_{1}, c_{2}, \ldots, c_{n}$, any solution of (3) on the interval $I$ can be obtained from the general solution.

\section*{EXAMPLE 9 General Solution}
From Example 8 we know that

$$
\mathbf{X}_{1}=\binom{1}{-1} e^{-2 t} \quad \text { and } \quad \mathbf{X}_{2}=\binom{3}{5} e^{6 t}
$$

are linearly independent solutions of (4) on ( $-\infty, \infty$ ). Hence $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ form a fundamental set of solutions on the interval. The general solution of the system on the interval is then


\begin{equation*}
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}=c_{1}\binom{1}{-1} e^{-2 t}+c^{2}\binom{3}{5} e^{6 t} \tag{9}
\end{equation*}


\section*{EXAMPLE 10 General Solution}
The vectors

$$
\mathbf{X}_{1}=\left(\begin{array}{c}
\cos t \\
-\frac{1}{2} \cos t+\frac{1}{2} \sin t \\
-\cos t-\sin t
\end{array}\right), \quad \mathbf{X}_{2}=\left(\begin{array}{l}
0 \\
1 \\
0
\end{array}\right) e^{t}, \quad \mathbf{X}_{3}=\left(\begin{array}{c}
\sin t \\
-\frac{1}{2} \sin t-\frac{1}{2} \cos t \\
-\sin t+\cos t
\end{array}\right)
$$

are solutions of the system (6)* in Example 4. Now

$$
\begin{aligned}
W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \mathbf{X}_{3}\right) & =\left|\begin{array}{ccc}
\cos t & 0 & \sin t \\
-\frac{1}{2} \cos t+\frac{1}{2} \sin t & e^{t} & -\frac{1}{2} \sin t-\frac{1}{2} \cos t \\
-\cos t-\sin t & 0 & -\sin t+\cos t
\end{array}\right| \\
& =e^{t}\left|\begin{array}{cc}
\cos t & \sin t \\
-\cos t-\sin t & -\sin t+\cos t
\end{array}\right|=e^{t} \neq 0
\end{aligned}
$$

for all real values of $t$. We conclude that $\mathbf{X}_{1}, \mathbf{X}_{2}$, and $\mathbf{X}_{3}$ form a fundamental set of solutions on $(-\infty, \infty)$. Thus the general solution of the system on the interval is

$$
\begin{aligned}
\mathbf{X} & =c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+c_{3} \mathbf{X}_{3} \\
& =c_{1}\left(\begin{array}{c}
\cos t \\
-\frac{1}{2} \cos t+\frac{1}{2} \sin t \\
-\cos t-\sin t
\end{array}\right)+c_{2}\left(\begin{array}{l}
0 \\
1 \\
0
\end{array}\right) e^{t}+c_{3}\left(\begin{array}{c}
\sin t \\
-\frac{1}{2} \sin t-\frac{1}{2} \cos t \\
-\sin t+\cos t
\end{array}\right)
\end{aligned}
$$

Nonhomogeneous Systems For nonhomogeneous systems a particular solution $\mathbf{X}_{p}$ on an interval $I$ is any vector, free of arbitrary parameters, whose entries are functions that satisfy the system (2).
\footnotetext{\begin{itemize}
  \item On pages 378 and 379 it was verified that $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ are solutions; it is left as an exercise to demonstrate that $\mathbf{X}_{3}$ is also a solution. See Problem 16.
\end{itemize}
}

\section*{EXAMPLE 11 Particular Solution}
Verify that the vector $\mathbf{X}_{p}=\binom{3 t-4}{-5 t+6}$ is a particular solution of the nonhomogeneous system

\[
\mathbf{X}^{\prime}=\left(\begin{array}{ll}
1 & 3  \tag{10}\\
5 & 3
\end{array}\right) \mathbf{X}+\binom{12 t-11}{-3}
\]

on the interval $(-\infty, \infty)$.

Solution We have $\mathbf{X}_{p}^{\prime}=\binom{3}{-5}$ and

$$
\begin{aligned}
\left(\begin{array}{ll}
1 & 3 \\
5 & 3
\end{array}\right) \mathbf{X}_{p}+\binom{12 t-11}{-3} & =\left(\begin{array}{ll}
1 & 3 \\
5 & 3
\end{array}\right)\binom{3 t-4}{-5 t+6}+\binom{12 t-11}{-3} \\
& =\binom{(3 t-4)+3(-5 t+6)}{5(3 t-4)+3(-5 t+6)}+\binom{12 t-11}{-3} \\
& =\binom{-12 t+14}{-2}+\binom{12 t-11}{-3}=\binom{3}{-5}=\mathbf{X}_{p}^{\prime}
\end{aligned}
$$

\section*{THEOREM 8.7}
Let $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{k}$ be a set of solution vectors of the homogeneous system (3) on an interval $I$ and let $\mathbf{X}_{p}$ be any solution vector of the nonhomogeneous system (2) on the same interval. Then

$$
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{k} \mathbf{X}_{k}+\mathbf{X}_{p}
$$

is also a solution of the nonhomogeneous system on the interval for any constants $c_{1}, c_{2}, \ldots, c_{k}$.

DEFINITION 8.18 General Solution-Nonhomogeneous Systems

Let $\mathbf{X}_{p}$ be a given solution of the nonhomogeneous system (2) on an interval $I$, and let

$$
\mathbf{X}_{c}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{n} \mathbf{X}_{n}
$$

denote the general solution on the same interval of the associated homogeneous system (3). The general solution of the nonhomogeneous system on the interval is defined to be

$$
\mathbf{X}=\mathbf{X}_{c}+\mathbf{X}_{p}
$$

The general solution $\mathbf{X}_{c}$ of the homogeneous system (3) is called the complementary function of the nonhomogeneous system (2).

\section*{EXAMPLE 12 General Solution}
In Example 11 it was verified that a particular solution of the nonhomogeneous system (10) on $(-\infty, \infty)$ is

$$
\mathbf{X}_{p}=\binom{3 t-5}{-5 t+6}
$$

The complementary function of (10) on the same interval, or the general solution of

$$
\mathbf{X}^{\prime}=\left(\begin{array}{ll}
1 & 3 \\
5 & 3
\end{array}\right) \mathbf{X}
$$

was seen in Example 9 to be

$$
\mathbf{X}_{c}=c_{1}\binom{1}{-1} e^{-2 t}+c_{2}\binom{3}{5} e^{6 t}
$$

Hence by Definition 8.18 ,

$$
\mathbf{X}=\mathbf{X}_{c}+\mathbf{X}_{p}=c_{1}\binom{1}{-1} e^{-2 t}+c_{2}\binom{3}{5} e^{6 t}+\binom{3 t-4}{-5 t+6}
$$

is the general solution of $(10)$ on $(-\infty, \infty)$.

As one might expect, if $\mathbf{X}$ is any solution of the nonhomogeneous system (2) on an interval $I$, then it is always possible to find appropriate constants $c_{1}, c_{2}, \ldots, c_{n}$ so that $\mathbf{X}$ can be obtained from the general solution.

\subsection*{8.5.2 A Fundamental Matrix}
If $\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}$ is a fundamental set of solutions of the homogeneous system (3) on an interval $I$, then its general solution on the interval is


\begin{align*}
\mathbf{X} & =c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+\cdots+c_{n} \mathbf{X}_{n} \\
& =c_{1}\left(\begin{array}{c}
x_{11} \\
x_{21} \\
\vdots \\
x_{n 1}
\end{array}\right)+c_{2}\left(\begin{array}{c}
x_{12} \\
x_{22} \\
\vdots \\
x_{n 2}
\end{array}\right)+\cdots+c_{n}\left(\begin{array}{c}
x_{1 n} \\
x_{2 n} \\
\vdots \\
x_{n n}
\end{array}\right)=\left(\begin{array}{c}
c_{1} x_{11}+c_{2} x_{12}+\cdots+c_{n} x_{1 n} \\
c_{1} x_{21}+c_{2} x_{22}+\cdots+c_{n} x_{2 n} \\
\vdots \\
c_{1} x_{n 1}+c_{2} x_{n 2}+\cdots+c_{n} x_{n n}
\end{array}\right) \tag{11}
\end{align*}


Observe that (11) can be written as the matrix product

\[
\mathbf{X}=\left(\begin{array}{cccc}
x_{11} & x_{12} & \cdots & x_{1 n}  \tag{12}\\
x_{21} & x_{22} & \cdots & x_{2 n} \\
\vdots & & & \vdots \\
x_{n 1} & x_{n 2} & \cdots & x_{n n}
\end{array}\right)\left(\begin{array}{c}
c_{1} \\
c_{2} \\
\vdots \\
c_{n}
\end{array}\right)
\]

We are led to the following definition.

\section*{DEFINITION 8.19 Fundamental Matrix}
Let $\quad \mathbf{X}_{1}=\left(\begin{array}{c}x_{11} \\ x_{21} \\ \vdots \\ x_{n 1}\end{array}\right), \quad \mathbf{X}_{2}=\left(\begin{array}{c}x_{12} \\ x_{22} \\ \vdots \\ x_{n 2}\end{array}\right), \quad \ldots, \quad \mathbf{X}_{n}=\left(\begin{array}{c}x_{1 n} \\ x_{2 n} \\ \vdots \\ x_{n n}\end{array}\right)$

be a fundamental set of $n$ solution vectors of the homogeneous system (3) on an interval $I$. The matrix

$$
\Phi(t)=\left(\begin{array}{cccc}
x_{11} & x_{12} & \cdots & x_{1 n} \\
x_{21} & x_{22} & \cdots & x_{2 n} \\
\vdots & & & \vdots \\
x_{n 1} & x_{n 2} & \cdots & x_{n n}
\end{array}\right)
$$

is said to be a fundamental matrix of the system on the interval.

\section*{EXAMPLE 13 A Fundamental Matrix}
The vectors

$$
\mathbf{X}_{1}=\binom{1}{-1} e^{-2 t}=\binom{e^{-2 t}}{-e^{-2 t}} \text { and } \quad \mathbf{X}_{2}=\binom{3}{5} e^{6 t}=\binom{3 e^{6 t}}{5 e^{6 t}}
$$

have been shown to form a fundamental set of solutions of the system (4) on $(-\infty, \infty)$. A fundamental matrix of the system on the interval is then

\[
\Phi(t)=\left(\begin{array}{rr}
e^{-2 t} & 3 e^{6 t}  \tag{13}\\
-e^{-2 t} & 5 e^{6 t}
\end{array}\right)
\]

The result given in (12) states that the general solution of any homogeneous system $\mathbf{X}^{\prime}=\mathbf{A}(t) \mathbf{X}$ can always be written in terms of a fundamental matrix of the system: $\mathbf{X}=\boldsymbol{\Phi}(t) \mathbf{C}$, where $\mathbf{C}$ is an $n \times 1$ column vector of arbitrary constants.

\section*{EXAMPLE 14 General Solution Using a Fundamental Matrix}
The general solution given in (9) can be written as

$$
\mathbf{X}=\left(\begin{array}{rr}
e^{-2 t} & 3 e^{6 t} \\
-e^{-2 t} & 5 e^{6 t}
\end{array}\right)\binom{c_{1}}{c_{2}}
$$

Furthermore, to say that $\mathbf{X}=\Phi(t) \mathbf{C}$ is a solution of $\mathbf{X}^{\prime}=\mathbf{A}(t) \mathbf{X}$ means

$$
\Phi^{\prime}(t) \mathbf{C}=\mathbf{A}(t) \Phi(t) \mathbf{C}
$$

or $\left(\boldsymbol{\Phi}^{\prime}(t)-\mathbf{A}(t) \boldsymbol{\Phi}(t)\right) \mathbf{C}=\mathbf{0}$. Since the last equation is to hold for every $t$ in the interval $I$ and for every possible column matrix of constants $\mathbf{C}$, we must have $\Phi^{\prime}(t)-\mathbf{A}(t) \Phi(t)=\mathbf{0}$ or


\begin{equation*}
\Phi^{\prime}(t)=\mathbf{A}(t) \Phi(t) \tag{14}
\end{equation*}


This result will be useful in Section 8.8.

Fundamental Matrix Is Nonsingular Comparison of Theorem 8.5 and Definition 8.19 shows that $\operatorname{det} \Phi(t)$ is the same as the Wronskian $W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{n}\right)$.* Hence the linear independence of the columns of $\Phi(t)$ on an interval $I$ guarantees that det $\Phi(t) \neq 0$ for every $t$ in the interval; that is, $\Phi(t)$ is nonsingular on the interval.

\section*{THEOREM 8.8 A Fundamental Matrix Has an Inverse}
Let $\Phi(t)$ be a fundamental matrix of the homogeneous system (3) on an interval $I$. Then $\boldsymbol{\Phi}^{-1}(t)$ exists for every value of $t$ in the interval.

\section*{EXAMPLE 15 Inverse of a Fundamental Matrix}
For the fundamental matrix given in (13) we see that det $\Phi(t)=8 e^{4 t}$. It then follows from (3) of Section 8.4 that

$$
\Phi^{-1}(t)=\frac{1}{8 e^{4 t}}\left(\begin{array}{cc}
5 e^{6 t} & -3 e^{6 t} \\
e^{-2 t} & e^{-2 t}
\end{array}\right)=\left(\begin{array}{cc}
\frac{5}{8} e^{2 t} & -\frac{3}{8} e^{2 t} \\
\frac{1}{8} e^{-6 t} & \frac{1}{8} e^{-6 t}
\end{array}\right)
$$

Special Matrix In some instances it is convenient to form another special $n \times n$ matrix, a matrix in which the column vectors $\mathbf{V}_{i}$ are solutions of $\mathbf{X}^{\prime}=\mathbf{A}(t) \mathbf{X}$ that satisfy the conditions

\[
\mathbf{V}_{1}\left(t_{0}\right)=\left(\begin{array}{c}
1  \tag{15}\\
0 \\
\vdots \\
0
\end{array}\right), \quad \mathbf{V}_{2}\left(t_{0}\right)=\left(\begin{array}{c}
0 \\
1 \\
\vdots \\
0
\end{array}\right), \quad \ldots, \quad \mathbf{V}_{n}\left(t_{0}\right)=\left(\begin{array}{c}
0 \\
0 \\
\vdots \\
1
\end{array}\right)
\]

Here $t_{0}$ is an arbitrarily chosen point in the interval on which the general solution of the system is defined. We denote this special matrix by the symbol $\Psi(t)$. Observe that $\Psi(t)$ has the property

\[
\Psi\left(t_{0}\right)=\left(\begin{array}{ccccc}
1 & 0 & 0 & \cdots & 0  \tag{1}\\
0 & 1 & 0 & \cdots & 0 \\
\vdots & & & & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{array}\right)=\mathbf{I}
\]

where $\mathbf{I}$ is the $n \times n$ multiplicative identity.
\footnotetext{\begin{itemize}
  \item For this reason some texts call $\boldsymbol{\Phi}(t)$ a Wronski matrix.
\end{itemize}
}

\section*{EXAMPLE 16 Finding $\Psi(t)$}
Find the matrix $\Psi(t)$ satisfying $\Psi(0)=\mathbf{I}$ for the system given in (4).

Solution From (9) we know that the general solution of (4) is given by

$$
\mathbf{X}=c_{1}\binom{1}{-1} e^{-2 t}+c_{2}\binom{3}{5} e^{6 t}
$$

When $t=0$, we first solve for constants $c_{1}$ and $c_{2}$ such that

$$
c_{1}\binom{1}{-1}+c_{2}\binom{3}{5}=\binom{1}{0} \text { or } \begin{aligned}
c_{1}+3 c_{2} & =1 \\
-c_{1}+5 c_{2} & =0
\end{aligned}
$$

We find that $c_{1}=\frac{5}{8}$ and $c_{2}=\frac{1}{8}$. Hence we define the vector $\mathbf{V}_{1}$ to be the linear combination

$$
\mathbf{V}_{1}=\frac{5}{8}\binom{1}{-1} e^{-2 t}+\frac{1}{8}\binom{3}{5} e^{6 t}
$$

Again when $t=0$ we wish to find another pair of constants $c_{1}$ and $c_{2}$ for which

$$
c_{1}\binom{1}{-1}+c_{2}\binom{3}{5}=\binom{0}{1} \text { or } \quad \begin{aligned}
c_{1}+3 c_{2} & =0 \\
-c_{1}+5 c_{2} & =1
\end{aligned}
$$

In this case we find $c_{1}=-\frac{3}{8}$ and $c_{2}=\frac{1}{8}$. We then define

Hence


\begin{gather*}
\mathbf{V}_{2}=-\frac{3}{8}\binom{1}{-1} e^{-2 t}+\frac{1}{8}\binom{3}{5} e^{6 t} \\
\Psi(t)=\left(\begin{array}{rr}
\frac{5}{8} e^{-2 t}+\frac{3}{8} e^{6 t} & -\frac{3}{8} e^{-2 t}+\frac{3}{8} e^{6 t} \\
-\frac{5}{8} e^{-2 t}+\frac{5}{8} e^{6 t} & \frac{3}{8} e^{-2 t}+\frac{5}{8} e^{6 t}
\end{array}\right) \tag{17}
\end{gather*}


Observe that $\Psi(0)=\left(\begin{array}{ll}1 & 0 \\ 0 & 1\end{array}\right)=\mathbf{I}$.

Note in Example 16 that since the columns of $\Psi(t)$ are linear combinations of the solutions $\Psi$ of $\mathbf{X}^{\prime}=\mathbf{A}(t) \mathbf{X}$, we know from the superposition principle that each column is a solution of the system.

$\Psi(t)$ Is a Fundamental Matrix From (16) it is seen that det $\Psi\left(t_{0}\right) \neq 0$, and hence we conclude from Theorem 8.5 that the columns of $\Psi(t)$ are linearly independent on the interval under consideration. Therefore $\Psi(t)$ is a fundamental matrix. Also, it follows from Theorem 8.3 that $\Psi(t)$ is the unique matrix that satisfies the condition $\Psi\left(t_{0}\right)=\mathbf{I}$. Last, the fundamental matrices $\Phi(t)$ and $\Psi(t)$ are related by


\begin{equation*}
\Psi(t)=\Phi(t) \Phi^{-1}\left(t_{0}\right) \tag{18}
\end{equation*}


Equation (18) provides an alternative method for determining $\Psi(t)$ (see Problem 37 ).

The answer to why anyone would want to form an obviously complicated looking fundamental matrix such as (17) will be answered in Sections 8.8 and 8.9.

\section*{EXERCISES 8.5}
Answers to odd-numbered problems begin on page A-19.

\subsection*{8.5.I Preliminary Theory}
In Problems 1-6 write the given system in matrix form.

\begin{enumerate}
  \item $\frac{d x}{d t}=3 x-5 y$
  \item $\frac{d x}{d t}=4 x-7 y$\\
$\frac{d y}{d t}=4 x+8 y$\\
$\frac{d y}{d t}=5 x$
  \item $\frac{d x}{d t}=-3 x+4 y-9 z$
  \item $\frac{d x}{d t}=x-y$\\
$\frac{d y}{d t}=6 x-y$\\
$\frac{d y}{d t}=x+2 z$\\
$\frac{d z}{d t}=10 x+4 y+3 z$\\
$\frac{d z}{d t}=-x+z$
  \item $\frac{d x}{d t}=x-y+z+t-1$
  \item $\frac{d x}{d t}=-3 x+4 y+e^{-t} \sin 2 t$\\
$\frac{d y}{d t}=2 x+y-z-3 t^{2}$\\
$\frac{d y}{d t}=5 x+9 y+4 e^{-t} \cos 2 t$\\
$\frac{d z}{d t}=x+y+z+t^{2}-t+2$
\end{enumerate}

In Problems 7-10 write the given system without the use of matrices.\\
7. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}4 & 2 \\ -1 & 3\end{array}\right) \mathbf{X}+\binom{1}{-1} e^{t}$\\
8. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}7 & 5 & -9 \\ 4 & 1 & 1 \\ 0 & -2 & 3\end{array}\right) \mathbf{X}+\left(\begin{array}{l}0 \\ 2 \\ 1\end{array}\right) e^{5 t}-\left(\begin{array}{l}8 \\ 0 \\ 3\end{array}\right) e^{-2 t}$\\
9. $\frac{d}{d t}\left(\begin{array}{l}x \\ y \\ z\end{array}\right)=\left(\begin{array}{rrr}1 & -1 & 2 \\ 3 & -4 & 1 \\ -2 & 5 & 6\end{array}\right)\left(\begin{array}{l}x \\ y \\ z\end{array}\right)+\left(\begin{array}{l}1 \\ 2 \\ 2\end{array}\right) e^{-t}-\left(\begin{array}{r}3 \\ -1 \\ 1\end{array}\right) t$\\
10. $\frac{d}{d t}\binom{x}{y}=\left(\begin{array}{rr}3 & -7 \\ 1 & 1\end{array}\right)\binom{x}{y}+\binom{4}{8} \sin t+\binom{t-4}{2 t+1} e^{4 t}$

In Problems 11-16 verify that the vector $\mathbf{X}$ is a solution of the given system.\\
11. $\frac{d x}{d t}=3 x-4 y$

$$
\frac{d y}{d t}=4 x-7 y ; \quad \mathbf{X}=\binom{1}{2} e^{-5 t}
$$

\begin{enumerate}
  \setcounter{enumi}{11}
  \item $\frac{d x}{d t}=-2 x+5 y$
\end{enumerate}

$$
\frac{d y}{d t}=-2 x+4 y ; \quad \mathbf{X}=\binom{5 \cos t}{3 \cos t-\sin t} e^{t}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}-1 & \frac{1}{4} \\ 1 & -1\end{array}\right) \mathbf{X} ; \quad \mathbf{X}=\binom{-1}{2} e^{-3 / / 2}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & 1 \\ -1 & 0\end{array}\right) \mathbf{X} ; \quad \mathbf{X}=\binom{1}{3} e^{t}+\binom{4}{-4} t e^{t}$
  \item $\frac{d \mathbf{X}}{d t}=\left(\begin{array}{rrr}1 & 2 & 1 \\ 6 & -1 & 0 \\ -1 & -2 & -1\end{array}\right) \mathbf{X} ; \quad \mathbf{X}=\left(\begin{array}{r}1 \\ 6 \\ -13\end{array}\right)$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & 0 & 1 \\ 1 & 1 & 0 \\ -2 & 0 & -1\end{array}\right) \mathbf{X} ; \quad \mathbf{X}=\left(\begin{array}{c}\sin t \\ -\frac{1}{2} \sin t-\frac{1}{2} \cos t \\ -\sin t+\cos t\end{array}\right)$
\end{enumerate}

In Problems 17-20 the given vectors are solutions of a system $\mathbf{X}^{\prime}=\mathbf{A X}$.

Determine whether the vectors form a fundamental set on $(-\infty, \infty)$.\\
17. $\mathbf{X}_{1}=\binom{1}{1} e^{-2 t}, \mathbf{X}_{2}=\binom{1}{-1} e^{-6 t}$\\
18. $\mathbf{X}_{1}=\binom{1}{-1} e^{t}, \mathbf{X}_{2}=\binom{2}{6} e^{t}+\binom{8}{-8} t e^{t}$\\
19. $\mathbf{X}_{1}=\left(\begin{array}{r}1 \\ -2 \\ 4\end{array}\right)+t\left(\begin{array}{l}1 \\ 2 \\ 2\end{array}\right), \mathbf{X}_{2}=\left(\begin{array}{r}1 \\ -2 \\ 4\end{array}\right), \mathbf{X}_{3}=\left(\begin{array}{r}3 \\ -6 \\ 12\end{array}\right)+t\left(\begin{array}{l}2 \\ 4 \\ 4\end{array}\right)$\\
20. $\mathbf{X}_{1}=\left(\begin{array}{r}1 \\ 6 \\ -13\end{array}\right), \mathbf{X}_{2}=\left(\begin{array}{r}1 \\ -2 \\ -1\end{array}\right) e^{-4 t}, \mathbf{X}_{3}=\left(\begin{array}{r}2 \\ 3 \\ -2\end{array}\right) e^{3 t}$

In Problems 21-24 verify that the vector $\mathbf{X}_{p}$ is a particular solution of the given system.\\
21. $\frac{d x}{d t}=x+4 y+2 t-7$

$$
\frac{d y}{d t}=3 x+2 y-4 t-18 ; \quad \mathbf{X}_{p}=\binom{2}{-1} t+\binom{5}{1}
$$

\begin{enumerate}
  \setcounter{enumi}{21}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & 1 \\ 1 & -1\end{array}\right) \mathbf{X}+\binom{-5}{2} ; \quad \mathbf{X}_{p}=\binom{1}{3}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}2 & 1 \\ 3 & 4\end{array}\right) \mathbf{X}-\binom{1}{7} e^{t} ; \quad \mathbf{X}_{p}=\binom{1}{1} e^{t}+\binom{1}{-1} t e^{t}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & 2 & 3 \\ -4 & 2 & 0 \\ -6 & 1 & 0\end{array}\right) \mathbf{X}+\left(\begin{array}{r}-1 \\ 4 \\ 3\end{array}\right) \sin 3 t ; \quad \mathbf{X}_{p}=\left(\begin{array}{c}\sin 3 t \\ 0 \\ \cos 3 t\end{array}\right)$

  \item Prove that the general solution of

\end{enumerate}

$$
\mathbf{X}^{\prime}=\left(\begin{array}{lll}
0 & 6 & 0 \\
1 & 0 & 1 \\
1 & 1 & 0
\end{array}\right) \mathbf{x}
$$

on the interval $(-\infty, \infty)$ is

$$
\mathbf{X}=c_{1}\left(\begin{array}{r}
6 \\
-1 \\
-5
\end{array}\right) e^{-t}+c_{2}\left(\begin{array}{r}
-3 \\
1 \\
1
\end{array}\right) e^{-2 t}+c_{3}\left(\begin{array}{l}
2 \\
1 \\
1
\end{array}\right) e^{3 t}
$$

\begin{enumerate}
  \setcounter{enumi}{25}
  \item Prove that the general solution of
\end{enumerate}

$$
\mathbf{X}^{\prime}=\left(\begin{array}{rr}
-1 & -1 \\
-1 & 1
\end{array}\right) \mathbf{X}+\binom{1}{1} t^{2}+\binom{4}{-6} t+\binom{-1}{5}
$$

on the interval $(-\infty, \infty)$ is

$\mathbf{X}=c_{1}\binom{1}{-1-\sqrt{2}} e^{\sqrt{2} t}+c_{2}\binom{1}{-1+\sqrt{2}} e^{-\sqrt{2} t}+\binom{1}{0} t^{2}+\binom{-2}{4} t+\binom{1}{0}$.

\subsection*{8.5.2 A Fundamental Matrix}
In Problems 27-30 the indicated column vectors form a fundamental set of solutions for the given system on $(-\infty, \infty)$. Form a fundamental matrix $\Phi(t)$ and compute $\Phi^{-1}(t)$.\\
27. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}4 & 1 \\ 6 & 5\end{array}\right) \mathbf{X} ; \quad \mathbf{X}_{1}=\binom{1}{-2} e^{2 t}, \mathbf{X}_{2}=\binom{1}{3} e^{7 t}$\\
28. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}2 & 3 \\ 3 & 2\end{array}\right) \mathbf{X} ; \quad \mathbf{X}_{1}=\binom{-1}{1} e^{-t}, \mathbf{X}_{2}=\binom{1}{1} e^{5 t}$\\
29. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}4 & 1 \\ -9 & -2\end{array}\right) \mathbf{X} ; \quad \mathbf{X}_{1}=\binom{-1}{3} e^{t}, \mathbf{X}_{2}=\binom{-1}{3} t e^{t}+\binom{0}{-1} e^{t}$\\
30. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}3 & -2 \\ 5 & -3\end{array}\right) \mathbf{X} ; \quad \mathbf{X}_{1}=\binom{2 \cos t}{3 \cos t+\sin t}, \mathbf{X}_{2}=\binom{-2 \sin t}{\cos t-3 \sin t}$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item Find the fundamental matrix $\Psi(t)$ satisfying $\Psi(0)=$ I for the system given in Problem 27.

  \item Find the fundamental matrix $\Psi(t)$ satisfying $\Psi(0)=\mathbf{I}$ for the system given in Problem 28

  \item Find the fundamental matrix $\Psi(t)$ satisfying $\Psi(0)=\mathbf{I}$ for the system given in Problem 29.

  \item Find the fundamental matrix $\Psi(t)$ satisfying $\Psi(\pi / 2)=\mathrm{I}$ for the system given in Problem 30.

  \item If $\mathbf{X}=\boldsymbol{\Phi}(t) \mathbf{C}$ is the general solution of $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}$, show that the solution of the initial-value problem $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}, \mathbf{X}\left(t_{0}\right)=\mathbf{X}_{0}$ is $\mathbf{X}=\boldsymbol{\Phi}(t) \boldsymbol{\Phi}^{-1}\left(t_{0}\right) \mathbf{X}_{0}$.

  \item Show that the solution of the initial-value problem given in Problem 35 is also given by $\mathbf{X}=\Psi(t) \mathbf{X}_{0}$.

  \item Show that $\Psi(t)=\Phi(t) \Phi^{-1}\left(t_{0}\right)$. [Hint: Compare Problems 35 and 36.]

\end{enumerate}

\subsection*{8.6 HOMOGENEOUS LINEAR SYSTEMS \\
 - Eigenvalues \\
 - Eigenvectors \\
 - General solutions}
\subsection*{8.6.1 Distinct REAL EIGENVALUES}
For the remainder of this chapter we shall be concerned only with linear systems with real constant coefficients.

We saw in Example 9 of Section 8.5 that the general solution of the homogeneous system

is

$$
\begin{gathered}
\frac{d x}{d t}=x+3 y \\
\frac{d y}{d t}=5 x+3 y \\
\mathbf{X}=c_{1}\binom{1}{-1} e^{-2 t}+c_{2}\binom{3}{5} e^{6 t}
\end{gathered}
$$

Since both solution vectors have the basic form

$$
\mathbf{X}_{i}=\binom{k_{1}}{k_{2}} e^{\lambda, t}, \quad i=1,2
$$

$k_{1}$ and $k_{2}$ constants, we are prompted to ask whether we can always find a solution of the form

\[
\mathbf{X}=\left(\begin{array}{c}
k_{1}  \tag{1}\\
k_{2} \\
\vdots \\
k_{n}
\end{array}\right) e^{\lambda t}=\mathbf{K} e^{\lambda t}
\]

for the general homogeneous linear first-order system


\begin{equation*}
\mathbf{X}^{\prime}=\mathbf{A X} \tag{2}
\end{equation*}


where $\mathbf{A}$ is an $n \times n$ matrix of constants.

Eigenvalues and Eigenvectors If (1) is to be a solution vector of (2), then $\mathbf{X}^{\prime}=\mathbf{K} \lambda e^{\lambda t}$ so the system becomes

$$
\mathbf{K} \lambda e^{\lambda t}=\mathbf{A} \mathbf{K} e^{\lambda t}
$$

After dividing out $e^{\lambda t}$ and rearranging, we obtain $\mathbf{A K}=\lambda \mathbf{K}$ or


\begin{equation*}
(\mathbf{A}-\lambda \mathbf{I}) \mathbf{K}=\mathbf{0} \tag{3}
\end{equation*}


Equation (3) is equivalent to the simultaneous algebraic equations (8) of Section 8.4. To find a nontrivial solution $\mathbf{X}$ of (2) we must find a nontrivial vector $\mathbf{K}$ satisfying (3). But in order for (3) to have nontrivial solutions we must have

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=0
$$

The latter equation is recognized as the characteristic equation of the matrix $\mathbf{A}$. In other words, $\mathbf{X}=\mathbf{K} e^{\lambda t}$ will be a solution of the system of differential equations (2) if and only if $\lambda$ is an eigenvalue of $\mathbf{A}$ and $\mathbf{K}$ is an eigenvector corresponding to $\lambda$.

When the $n \times n$ matrix $\mathbf{A}$ possesses $n$ distinct real eigenvalues $\lambda_{1}$, $\lambda_{2}, \ldots, \lambda_{n}$, then a set of $n$ linearly independent eigenvectors $\mathbf{K}_{1}, \mathbf{K}_{2}, \ldots, \mathbf{K}_{n}$ can always be found and

$$
\mathbf{X}_{1}=\mathbf{K}_{1} e^{\lambda_{1} t}, \quad \mathbf{X}_{2}=\mathbf{K}_{2} e^{\lambda_{2} t}, \quad \ldots, \quad \mathbf{X}_{n}=\mathbf{K}_{n} e^{\lambda_{n} t}
$$

is a fundamental set of solutions of (2) on $(-\infty, \infty)$.

\section*{THEOREM 8.9 General Solution-Homogeneous Systems}
Let $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ be $n$ distinct real eigenvalues of the coefficient matrix $\mathbf{A}$ of the homogeneous system (2) and let $\mathbf{K}_{1}, \mathbf{K}_{2}, \ldots, \mathbf{K}_{n}$ be the corresponding eigenvectors. Then the general solution of (2) on the interval $(-\infty, \infty)$ is given by

$$
\mathbf{X}=c_{1} \mathbf{K}_{1} e^{\lambda_{1} t}+c_{2} \mathbf{K}_{2} e^{\lambda_{2} t}+\cdots+c_{n} \mathbf{K}_{n} e^{\lambda_{n} t}
$$

\section*{EXAMPLE 1 Distinct Eigenvalues}
Solve


\begin{align*}
& \frac{d x}{d t}=2 x+3 y \\
& \frac{d y}{d t}=2 x+y \tag{4}
\end{align*}


Solution We first find the eigenvalues and eigenvectors of the matrix of coefficients.

The characteristic equation is

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
2-\lambda & 3 \\
2 & 1-\lambda
\end{array}\right|=\lambda^{2}-3 \lambda-4=0
$$

Since $\lambda^{2}-3 \lambda-4=(\lambda+1)(\lambda-4)$, we see that the eigenvalues are $\lambda_{1}=-1$ and $\lambda_{2}=4$.

Now for $\lambda_{1}=-1,(3)$ is equivalent to

$$
\begin{aligned}
& 3 k_{1}+3 k_{2}=0 \\
& 2 k_{1}+2 k_{2}=0
\end{aligned}
$$

Thus $k_{1}=-k_{2}$. When $k_{2}=-1$, the related eigenvector is

$$
\begin{gathered}
\mathbf{K}_{1}=\binom{1}{-1} \\
-2 k_{1}+3 k_{2}=0 \\
2 k_{1}-3 k_{2}=0
\end{gathered}
$$

For $\lambda_{2}=4$ we have

so $k_{1}=3 k_{2} / 2$, and therefore with $k_{2}=2$ the corresponding eigenvector is

$$
\mathbf{K}_{2}=\binom{3}{2}
$$

Since the matrix of coefficients $\mathbf{A}$ is a $2 \times 2$ matrix and since we have found two linearly independent solutions of (4),

$$
\mathbf{X}_{1}=\binom{1}{-1} e^{-t} \quad \text { and } \quad \mathbf{X}_{2}=\binom{3}{2} e^{4 t}
$$

we conclude that the general solution of the system is


\begin{equation*}
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}=c_{1}\binom{1}{-1} e^{-t}+c_{2}\binom{3}{2} e^{4 t} \tag{5}
\end{equation*}


For the sake of review, you should keep firmly in mind that a solution of a system of first-order differential equations, when written in terms of matrices, is simply an alternative to the method that we employed in Section 8.1-namely, listing the individual functions and the relationships between the constants. By adding the vectors given in (5), we obtain

$$
\binom{x(t)}{y(t)}=\binom{c_{1} e^{-t}+3 c_{2} e^{4 t}}{-c_{1} e^{-t}+2 c_{2} e^{4 t}}
$$

and this in turn yields the more familiar statement

$$
x(t)=c_{1} e^{-t}+3 c_{2} e^{4 t}, \quad y(t)=-c_{1} e^{-t}+2 c_{2} e^{4 t}
$$

\section*{EXAMPLE 2 Distinct Eigenvalues}
Solve


\begin{align*}
& \frac{d x}{d t}=-4 x+y+z \\
& \frac{d y}{d y}=\quad x+5 y-z  \tag{6}\\
& \frac{d z}{d t}=\quad y-3 z
\end{align*}


Solution Using the cofactors of the third row, we find

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{ccc}
-4-\lambda & 1 & 1 \\
1 & 5-\lambda & -1 \\
0 & 1 & -3-\lambda
\end{array}\right|=-(\lambda+3)(\lambda+4)(\lambda-5)=0
$$

and so the eigenvalues are $\lambda_{1}=-3, \lambda_{2}=-4, \lambda_{3}=5$.

Now for $\lambda_{1}=-3$ Gauss-Jordan elimination gives

$(\mathbf{A}+3 \mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}-1 & 1 & 1 & 0 \\ 1 & 8 & -1 & 0 \\ 0 & 1 & 0 & 0\end{array}\right) \xrightarrow{\text { operations }}\left(\begin{array}{rrr|r}1 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0\end{array}\right)$.

Therefore $k_{1}=k_{3}, k_{2}=0$. The choice $k_{3}=1$ gives the eigenvector

\[
\mathbf{K}_{1}=\left(\begin{array}{l}
1  \tag{7}\\
0 \\
1
\end{array}\right)
\]

Similarly, for $\lambda_{2}=-4$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-419}
\end{center}

implies $k_{1}=10 k_{3}, k_{2}=-k_{3}$. Choosing $k_{3}=1$, we get the second eigenvector

\[
\mathbf{K}_{2}=\left(\begin{array}{r}
10  \tag{8}\\
-1 \\
1
\end{array}\right)
\]

Finally, when $\lambda_{3}=5$, the augmented matrices


\begin{align*}
& (\mathbf{A}-5 \mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}
-9 & 1 & 1 & 0 \\
1 & 0 & -1 & 0 \\
0 & 1 & -8 & 0
\end{array}\right) \xrightarrow{\text { row }}\left(\begin{array}{rrr|r}
1 & 0 & -1 & 0 \\
0 & 1 & -8 & 0 \\
0 & 0 & 0 & 0
\end{array}\right) \\
& \text { yierations } \\
& \mathbf{K}_{3}=\left(\begin{array}{l}
1 \\
8 \\
1
\end{array}\right) . \tag{9}
\end{align*}


Multiplying the vectors (7), (8), and (9) by $e^{-3 t}, e^{-4 t}$, and $e^{5 t}$, respectively, gives three solutions of (6):

$$
\mathbf{X}_{1}=\left(\begin{array}{l}
1 \\
0 \\
1
\end{array}\right) e^{-3 t}, \quad \mathbf{X}_{2}=\left(\begin{array}{r}
10 \\
-1 \\
1
\end{array}\right) e^{-4 t}, \quad \mathbf{X}_{3}=\left(\begin{array}{l}
1 \\
8 \\
1
\end{array}\right) e^{5 t}
$$

The general solution of the system is then

$$
\mathbf{X}=c_{1}\left(\begin{array}{l}
1 \\
0 \\
1
\end{array}\right) e^{-3 t}+c_{2}\left(\begin{array}{r}
10 \\
-1 \\
1
\end{array}\right) e^{-4 t}+c_{3}\left(\begin{array}{l}
1 \\
8 \\
1
\end{array}\right) e^{5 t}
$$

\subsection*{8.6.2 CompleX EigenVALUES}
If

$$
\lambda_{1}=\alpha+i \beta \quad \text { and } \quad \lambda_{2}=\alpha-i \beta, \quad i^{2}=-1, \beta>0
$$

are complex eigenvalues of the coefficient matrix $\mathbf{A}$, we can then certainly expect their corresponding eigenvectors to also have complex entries.*

For example, the characteristic equation of the system


\begin{align*}
& \frac{d x}{d t}=6 x-y  \tag{10}\\
& \frac{d y}{d t}=5 x+4 y
\end{align*}

\footnotetext{\begin{itemize}
  \item When the characteristic equation has real coefficients, complex eigenvalues always appear in conjugate pairs.
\end{itemize}
}
is

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
6-\lambda & -1 \\
5 & 4-\lambda
\end{array}\right|=\lambda^{2}-10 \lambda+29=0
$$

From the quadratic formula we find $\lambda_{1}=5+2 i, \lambda_{2}=5-2 i$.

Now for $\lambda_{1}=5+2 i$ we must solve

$$
\begin{aligned}
(1-2 i) k_{1}-\quad k_{2} & =0 \\
5 k_{1}-(1+2 i) k_{2} & =0
\end{aligned}
$$

Since $k_{2}=(1-2 i) k_{1}, *$ it follows, after we choose $k_{1}=1$, that one eigenvector is

$$
\mathbf{K}_{1}=\binom{1}{1-2 i}
$$

Similarly, for $\lambda_{2}=5-2 i$ we find the other eigenvector to be

$$
\mathbf{K}_{2}=\binom{1}{1+2 i}
$$

Consequently two solutions of (10) are

$$
\mathbf{X}_{1}=\binom{1}{1-2 i} e^{(5+2 i) t} \quad \text { and } \quad \mathbf{X}_{2}=\binom{1}{1+2 i} e^{(5-2) t}
$$

By the superposition principle another solution is


\begin{equation*}
\mathbf{X}=c_{1}\binom{1}{1-2 i} e^{(5+2 i) t}+c_{2}\binom{1}{1+2 i} e^{(5-2 i) t} \tag{11}
\end{equation*}


Note that the entries in $\mathbf{K}_{2}$ corresponding to $\lambda_{2}$ are the conjugates of the entries in $\mathbf{K}_{1}$ corresponding to $\lambda_{1}$. The conjugate of $\lambda_{1}$ is, of course, $\lambda_{2}$. We write this as $\lambda_{2}=\bar{\lambda}_{1}$ and $\mathbf{K}_{2}=\overline{\mathbf{K}}_{1}$. We have illustrated the following general result.

\section*{THEOREM 8.10 Solutions Corresponding to a Complex Eigenvalue}
Let $\mathbf{A}$ be the coefficient matrix having real entries of the homogeneous system (2), and let $\mathbf{K}$ be an eigenvector corresponding to the complex eigenvalue $\lambda_{1}=\alpha+i \beta, \alpha$ and $\beta$ real. Then

$$
\mathbf{K}_{1} e^{\lambda_{1} t} \text { and } \overline{\mathbf{K}}_{1} e^{\bar{\lambda}_{1} t}
$$

are solutions of (2).

It is desirable and relatively easy to rewrite a solution such as (11) in terms of real functions. Since

$$
\begin{aligned}
& x=c_{1} e^{(5+2 i) t}+c_{2} e^{(5-2 i) t} \\
& y=c_{1}(1-2 i) e^{(5+2 i) t}+c_{2}(1+2 i) e^{(5-2 i) t}
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item Note that the second equation is simply $1+2 i$ times the first.
\end{itemize}
}
it follows from Euler's formula that

$$
\begin{aligned}
x & =e^{5 t}\left[c_{1} e^{2 i t}+c_{2} e^{-2 i t}\right] \\
& =e^{5 t}\left[\left(c_{1}+c_{2}\right) \cos 2 t+\left(c_{1} i-c_{2} i\right) \sin 2 t\right] \\
y & =e^{5 t}\left[\left(c_{1}(1-2 i)+c_{2}(1+2 i)\right) \cos 2 t+\left(c_{1} i(1-2 i)-c_{2} i(1+2 i)\right) \sin 2 t\right] \\
& =e^{5 t}\left[\left(c_{1}+c_{2}\right)-2\left(c_{1} i-c_{2} i\right)\right] \cos 2 t+e^{5 t}\left[2\left(c_{1}+c_{2}\right)+\left(c_{1} i-c_{2} i\right)\right] \sin 2 t
\end{aligned}
$$

If we replace $c_{1}+c_{2}$ by $C_{1}$ and $c_{1} i-c_{2} i$ by $C_{2}$, then

$$
\begin{aligned}
& x=e^{5 t}\left[C_{1} \cos 2 t+C_{2} \sin 2 t\right] \\
& y=e^{5 t}\left[C_{1}-2 C_{2}\right] \cos 2 t+e^{5 t}\left[2 C_{1}+C_{2}\right] \sin 2 t
\end{aligned}
$$

or, in terms of vectors,


\begin{equation*}
\mathbf{X}=\binom{x}{y}=C_{1}\binom{\cos 2 t}{\cos 2 t+2 \sin 2 t} e^{5 t}+C_{2}\binom{\sin 2 t}{-2 \cos 2 t+\sin 2 t} e^{5 t} \tag{12}
\end{equation*}


Here, of course, it can be verified that each vector in (12) is a solution of (10). In addition, the solutions are linearly independent on the interval $(-\infty, \infty)$. We may further assume that $C_{1}$ and $C_{2}$ are completely arbitrary and real. Thus (12) is the general solution of (10).

The foregoing process can be generalized. Let $\mathbf{K}_{1}$ be an eigenvector of the matrix $\mathbf{A}$ corresponding to the complex eigenvalue $\lambda_{1}=\alpha+i \beta$. Then $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ in Theorem 8.10 can be written as

$$
\begin{aligned}
& \mathbf{K}_{1} e^{\lambda_{1} t}=\mathbf{K}_{1} e^{\alpha} e^{i \beta t}=\mathbf{K}_{1} e^{\alpha t}(\cos \beta t+i \sin \beta t) \\
& \overline{\mathbf{K}}_{1} e^{\overline{1}_{1} t}=\overline{\mathbf{K}}_{1} e^{\alpha t} e^{-i \beta t}=\overline{\mathbf{K}}_{1} e^{\alpha t}(\cos \beta t-i \sin \beta t) .
\end{aligned}
$$

The foregoing equations then yield

$$
\begin{aligned}
\frac{1}{2}\left(\mathbf{K}_{1} e^{\lambda_{1} t}+\overline{\mathbf{K}}_{1} e^{\bar{\lambda}_{1} t}\right) & =\frac{1}{2}\left(\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right) e^{\alpha t} \cos \beta t-\frac{i}{2}\left(-\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right) e^{\alpha t} \sin \beta t \\
\frac{i}{2}\left(-\mathbf{K}_{1} e^{\lambda_{1} t}+\overline{\mathbf{K}}_{1} e^{\bar{\lambda}_{1} t}\right) & =\frac{i}{2}\left(-\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right) e^{\alpha t} \cos \beta t+\frac{1}{2}\left(\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right) e^{\alpha t} \sin \beta t .
\end{aligned}
$$

For any complex number $z=a+i b$, we note that $\frac{1}{2}(z+\bar{z})=a$ and $(i / 2)(-z+\bar{z})=b$ are real numbers. Therefore, the entries in the column vectors $\frac{1}{2}\left(\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right)$ and (i/2) ( $\left.-\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right)$ are real numbers. By defining


\begin{equation*}
\mathbf{B}_{1}=\frac{1}{2}\left[\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right] \quad \text { and } \quad \mathbf{B}_{2}=\frac{i}{2}\left[-\mathbf{K}_{1}+\overline{\mathbf{K}}_{1}\right] \tag{13}
\end{equation*}


we are led to the following theorem.

\section*{THEOREM 8.11 Real Solutions Corresponding to a Complex Eigenvalue}
Let $\lambda_{1}=\alpha+i \beta$ be a complex eigenvalue of the coefficient matrix $\mathbf{A}$ in the homogeneous system (2) and let $\mathbf{B}_{1}$ and $\mathbf{B}_{2}$ denote the column vectors defined in (13). Then


\begin{align*}
& \mathbf{X}_{1}=\left(\mathbf{B}_{1} \cos \beta t-\mathbf{B}_{2} \sin \beta t\right) e^{a t} \\
& \mathbf{X}_{2}=\left(\mathbf{B}_{2} \cos \beta t+\mathbf{B}_{1} \sin \beta t\right) e^{a t} \tag{14}
\end{align*}


are linearly independent solutions of (2) on $(-\infty, \infty)$.

The matrices $\mathbf{B}_{1}$ and $\mathbf{B}_{2}$ in (13) are often denoted by


\begin{equation*}
\mathbf{B}_{1}=\operatorname{Re}\left(\mathbf{K}_{1}\right) \quad \text { and } \quad \mathbf{B}_{2}=\operatorname{Im}\left(\mathbf{K}_{1}\right) \tag{15}
\end{equation*}


since these vectors are, in turn, the real and imaginary parts of the eigenvector $\mathbf{K}_{1}$. For example, (12) follows from (14) with

$$
\begin{aligned}
\mathbf{K}_{1}=\binom{1}{1-2 i}=\binom{1}{1}+i\binom{0}{-2} \\
\mathbf{B}_{1}=\operatorname{Re}\left(\mathbf{K}_{1}\right)=\binom{1}{1} \text { and } \mathbf{B}_{2}=\operatorname{Im}\left(\mathbf{K}_{1}\right)=\binom{0}{-2}
\end{aligned}
$$

\section*{EXAMPLE 3 Complex Eigenvalues}
Solve $\mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & 8 \\ -1 & -2\end{array}\right) \mathbf{X}$.

Solution First we obtain the eigenvalues from

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
2-\lambda & 8 \\
-1 & -2-\lambda
\end{array}\right|=\lambda^{2}+4=0
$$

Thus the eigenvalues are $\lambda_{1}=2 i$ and $\lambda_{2}=\bar{\lambda}_{1}=-2 i$. For $\lambda_{1}$ we see that the system

$$
\begin{aligned}
(2-2 i) k_{1}+8 k_{2} & =0 \\
-k_{1}+(-2-2 i) k_{2} & =0
\end{aligned}
$$

gives $k_{1}=-(2+2 i) k_{2}$. By choosing $k_{2}=-1$, we get

$$
\mathbf{K}_{1}=\binom{2+2 i}{-1}=\binom{2}{-1}+i\binom{2}{0}
$$

Now from (15) we form

$$
\mathbf{B}_{1}=\operatorname{Re}\left(\mathbf{K}_{1}\right)=\binom{2}{-1} \quad \text { and } \quad \mathbf{B}_{2}=\operatorname{Im}\left(\mathbf{K}_{1}\right)=\binom{2}{0}
$$

Since $\alpha=0$, it follows from (14) that the general solution of the system is

$$
\begin{aligned}
\mathbf{X} & =c_{1}\left[\binom{2}{-1} \cos 2 t-\binom{2}{0} \sin 2 t\right]+c_{2}\left[\binom{2}{0} \cos 2 t+\binom{2}{-1} \sin 2 t\right] \\
& =c_{1}\binom{2 \cos 2 t-2 \sin 2 t}{-\cos 2 t}+c_{2}\binom{2 \cos 2 t+2 \sin 2 t}{-\sin 2 t} .
\end{aligned}
$$

\section*{EXAMPLE 4 Complex Eigenvalues}
$$
\text { Solve } \mathbf{X}^{\prime}=\left(\begin{array}{rr}
1 & 2 \\
-\frac{1}{2} & 1
\end{array}\right) \mathbf{X}
$$

Solution The solutions of the characteristic equation

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
1-\lambda & 2 \\
-\frac{1}{2} & 1-\lambda
\end{array}\right|=\lambda^{2}-2 \lambda+2=0
$$

are $\lambda_{1}=1+i$ and $\lambda_{2}=\bar{\lambda}_{1}=1-i$. Now an eigenvector associated with $\lambda_{1}$ is

$$
\mathbf{K}_{1}=\binom{2}{i}=\binom{2}{0}+i\binom{0}{1}
$$

From (15) we find $\mathbf{B}_{1}=\binom{2}{0}$ and $\mathbf{B}_{2}=\binom{0}{1}$. Thus (14) gives

$$
\begin{aligned}
\mathbf{X} & =c_{1}\left[\binom{2}{0} \cos t-\binom{0}{1} \sin t\right] e^{t}+c_{2}\left[\binom{0}{1} \cos t+\binom{2}{0} \sin t\right] e^{t} \\
& =c_{1}\binom{2 \cos t}{-\sin t} e^{t}+c_{2}\binom{2 \sin t}{\cos t} e^{t}
\end{aligned}
$$

Alternative Method When $\mathbf{A}$ is a $2 \times 2$ matrix having a complex eigenvalue $\lambda=\alpha+i \beta$, the general solution of the system can also be obtained from the assumption

$$
\mathbf{X}=\binom{c_{1}}{c_{2}} e^{\alpha t} \sin \beta t+\binom{c_{3}}{c_{4}} e^{\alpha t} \cos \beta t
$$

and then the substitution of $x(t)$ and $y(t)$ into one of the equations of the original system. This procedure is basically that of Section 8.1.

\subsection*{8.6.3 RepeAted EigenVALues}
Up to this point we have not considered the case in which some of the $n$ eigenvalues $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ of an $n \times n$ matrix are repeated. For example, the characteristic equation of the coefficient matrix in

\[
\mathbf{X}^{\prime}=\left(\begin{array}{rr}
3 & -18  \tag{1}\\
2 & -9
\end{array}\right) \mathbf{X}
\]

is readily shown to be $(\lambda+3)^{2}=0$, and therefore $\lambda_{1}=\lambda_{2}=-3$ is a root of multiplicity two. Now for this value we find the single eigenvector

$$
\mathbf{K}_{1}=\binom{3}{1}
$$

and so one solution of (16) is


\begin{equation*}
\mathbf{X}_{1}=\binom{3}{1} e^{-3 t} \tag{17}
\end{equation*}


But since we are obviously interested in forming the general solution of the system, we need to pursue the question of finding a second solution.

In general, if $m$ is a positive integer and $\left(\lambda-\lambda_{1}\right)^{m}$ is a factor of the characteristic equation, while $\left(\lambda-\lambda_{1}\right)^{m+1}$ is not a factor, then $\lambda_{1}$ is said to be an eigenvalue of multiplicity $\boldsymbol{m}$. The next three examples illustrate the following cases:

(i) For some $n \times n$ matrices $\mathbf{A}$ it may be possible to find $m$ linearly independent eigenvectors $\mathbf{K}_{1}, \mathbf{K}_{2}, \ldots, \mathbf{K}_{m}$ corresponding to an eigenvalue\\
$\lambda_{1}$ of multiplicity $m \leq n$. In this case the general solution of the system contains the linear combination

$$
c_{1} \mathbf{K}_{1} e^{\lambda_{1} t}+c_{2} \mathbf{K}_{2} e^{\lambda_{1} t}+\cdots+c_{m} \mathbf{K}_{m} e^{\lambda_{1} t} .
$$

(ii) If there is only one eigenvector corresponding to the eigenvalue $\lambda_{1}$ of multiplicity $m$, then $m$ linearly independent solutions of the form

$$
\begin{aligned}
\mathbf{X}_{1} & =\mathbf{K}_{11} e^{\lambda_{1} t} \\
\mathbf{X}_{2} & =\mathbf{K}_{21} t e^{\lambda_{1} t}+\mathbf{K}_{22} e^{\lambda_{1} t} \\
& \vdots \\
\mathbf{X}_{m} & =\mathbf{K}_{m 1} \frac{t^{m-1}}{(m-1)!} e^{\lambda_{1} t}+\mathbf{K}_{m 2} \frac{t^{m-2}}{(m-2)!} e^{\lambda_{1} t}+\cdots+\mathbf{K}_{m m} e^{\lambda_{1} t},
\end{aligned}
$$

where $\mathbf{K}_{i j}$ are column vectors, can always be found.

Eigenvalue of Multiplicity Two We begin by considering eigenvalues of multiplicity two. In the first example we illustrate a matrix for which we can find two distinct eigenvectors corresponding to a double eigenvalue.

\section*{EXAMPLE 5 Repeated Eigenvalues}
Solve $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & -2 & 2 \\ -2 & 1 & -2 \\ 2 & -2 & 1\end{array}\right) \mathbf{X}$

Solution Expanding the determinant in the characteristic equation

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{ccc}
1-\lambda & -2 & 2 \\
-2 & 1-\lambda & -2 \\
2 & -2 & 1-\lambda
\end{array}\right|=0
$$

yields $-(\lambda+1)^{2}(\lambda-5)=0$. We see that $\lambda_{1}=\lambda_{2}=-1$ and $\lambda_{3}=5$.

For $\lambda_{1}=-1$ Gauss-Jordan elimination gives immediately

$(\mathbf{A}+\mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}2 & -2 & 2 & 0 \\ -2 & 2 & -2 & 0 \\ 2 & -2 & 2 & 0\end{array}\right) \xrightarrow{\text { operations }}\left(\begin{array}{rrr|r}1 & -1 & 1 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0\end{array}\right)$.

The first row of the last matrix means $k_{1}-k_{2}+k_{3}=0$ or $k_{1}=k_{2}-k_{3}$. The choices $k_{2}=1, k_{3}=0$ and $k_{2}=1, k_{3}=1$ yield, in turn, $k_{1}=1$ and $k_{1}=0$. Thus two eigenvectors corresponding to $\lambda_{1}=-1$ are

$$
\mathbf{K}_{1}=\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right) \quad \text { and } \quad \mathbf{K}_{2}=\left(\begin{array}{l}
0 \\
1 \\
1
\end{array}\right)
$$

Since neither eigenvector is a constant multiple of the other, we have found, corresponding to the same eigenvalue, two linearly independent solutions

$$
\mathbf{X}_{1}=\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right) e^{-t} \text { and } \quad \mathbf{X}_{2}=\left(\begin{array}{l}
0 \\
1 \\
1
\end{array}\right) e^{-t}
$$

Last, for $\lambda_{3}=5$ the reduction

$$
(\mathbf{A}+5 \mathbf{I} \mid \mathbf{0})=\left(\begin{array}{rrr|r}
-4 & -2 & 2 & 0 \\
-2 & -4 & -2 & 0 \\
2 & -2 & -4 & 0
\end{array}\right) \xrightarrow{\substack{\text { row } \\
\text { operations }}}\left(\begin{array}{rrr|r}
1 & 0 & -1 & 0 \\
0 & 1 & 1 & 0 \\
0 & 0 & 0 & 0
\end{array}\right)
$$

implies $k_{1}=k_{3}$ and $k_{2}=-k_{3}$. Picking $k_{3}=1$ gives $k_{1}=1, k_{2}=-1$, and thus a third eigenvector is

$$
\mathbf{K}_{3}=\left(\begin{array}{r}
1 \\
-1 \\
1
\end{array}\right)
$$

We conclude that the general solution of the system is

$$
\mathbf{X}=c_{1}\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right) e^{-t}+c_{2}\left(\begin{array}{l}
0 \\
1 \\
1
\end{array}\right) e^{-t}+c_{3}\left(\begin{array}{r}
1 \\
-1 \\
1
\end{array}\right) e^{5 t}
$$

Second Solution Now suppose $\lambda_{1}$ is an eigenvalue of multiplicity two and there is only one eigenvector associated with this value. A second solution can be found of the form

where


\begin{gather*}
\mathbf{X}_{2}=\mathbf{K} t e^{\lambda_{1} \mathrm{t}}+\mathbf{P} e^{\lambda_{1} \mathrm{t}}  \tag{18}\\
\mathbf{K}=\left(\begin{array}{c}
k_{1} \\
k_{2} \\
\vdots \\
k_{n}
\end{array}\right) \quad \text { and } \quad \mathbf{P}=\left(\begin{array}{c}
p_{1} \\
p_{2} \\
\vdots \\
p_{n}
\end{array}\right)
\end{gather*}


To see this we substitute (18) into the system $\mathbf{X}^{\prime}=\mathbf{A X}$ and simplify:

$$
\left(\mathbf{A K}-\lambda_{1} \mathbf{K}\right) t e^{\lambda_{1} t}+\left(\mathbf{A P}-\lambda_{1} \mathbf{P}-\mathbf{K}\right) e^{\lambda_{1} t}=\mathbf{0} .
$$

Since this last equation is to hold for all values of $t$, we must have


\begin{equation*}
\left(\mathbf{A}-\lambda_{1} \mathbf{I}\right) \mathbf{K}=\mathbf{0} \tag{19}
\end{equation*}


and


\begin{equation*}
\left(\mathbf{A}-\lambda_{1} \mathbf{I}\right) \mathbf{P}=\mathbf{K} \tag{20}
\end{equation*}


Equation (19) simply states that $\mathbf{K}$ must be an eigenvector of $\mathbf{A}$ associated with $\lambda_{1}$. By solving (19), we find one solution, $\mathbf{X}_{1}=\mathbf{K} e^{\lambda_{1} t}$. To find the second solution $\mathbf{X}_{2}$ we need only solve the additional system (20) for the vector $\mathbf{P}$.

\section*{EXAMPLE 6 Repeated Eigenvalues}
Find the general solution of the system given in (16).

Solution From (17) we know that $\lambda_{1}=-3$ and that one solution is $\mathbf{X}_{1}=\binom{3}{1} e^{-3 t}$. Identifying $\mathbf{K}=\binom{3}{1}$ and $\mathbf{P}=\binom{p_{1}}{p_{2}}$, we find from (20) that we must now solve

$$
(\mathbf{A}+3 \mathbf{I}) \mathbf{P}=\mathbf{K} \quad \text { or } \quad \begin{aligned}
& 6 p_{1}-18 p_{2}=3 \\
& 2 p_{1}-6 p_{2}=1
\end{aligned}
$$

Since this system is obviously equivalent to one equation, we have an infinite number of choices for $p_{1}$ and $p_{2}$. For example, by choosing $p_{1}=1$, we find $p_{2}=\frac{1}{6}$. However, for simplicity, we shall choose $p_{1}=\frac{1}{2}$ so that $p_{2}=0$. Hence $\mathbf{P}=\binom{\frac{1}{2}}{0}$. Thus from (18) we find

$$
\mathbf{X}_{2}=\binom{3}{1} t e^{-3 t}+\binom{\frac{1}{2}}{0} e^{-3 t}
$$

The general solution of (16) is then

$$
\mathbf{X}=c_{1}\binom{3}{1} e^{-3 t}+c_{2}\left[\binom{3}{1} t e^{-3 t}+\binom{\frac{1}{2}}{0} e^{-3 t}\right]
$$

Eigenvalues of Multiplicity Three When a matrix A has only one eigenvector associated with an eigenvalue $\lambda_{1}$ of multiplicity three, we can find a second solution of form (18) and a third solution of the form


\begin{equation*}
\mathbf{X}_{3}=\mathbf{K} \frac{t^{2}}{2} e^{\lambda_{1} t}+\mathbf{P} t e^{\lambda_{1} t}+\mathbf{Q} e^{\lambda_{1} t} \tag{21}
\end{equation*}


where $\quad \mathbf{K}=\left(\begin{array}{c}k_{1} \\ k_{2} \\ \vdots \\ k_{n}\end{array}\right), \quad \mathbf{P}=\left(\begin{array}{c}p_{1} \\ p_{2} \\ \vdots \\ p_{n}\end{array}\right)$, and $\mathbf{Q}=\left(\begin{array}{c}q_{1} \\ q_{2} \\ \vdots \\ q_{n}\end{array}\right)$.

By substituting (21) into the system $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}$, we find that the column vectors $\mathbf{K}, \mathbf{P}$, and $\mathbf{Q}$ must satisfy

and


\begin{align*}
& \left(\mathbf{A}-\lambda_{1} \mathbf{I}\right) \mathbf{K}=\mathbf{0}  \tag{22}\\
& \left(\mathbf{A}-\lambda_{1} \mathbf{I}\right) \mathbf{P}=\mathbf{K}  \tag{23}\\
& \left(\mathbf{A}-\lambda_{1} \mathbf{I}\right) \mathbf{Q}=\mathbf{P} \tag{24}
\end{align*}


Of course, the solutions of (22) and (23) can be utilized in the formulation of the solutions $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$.

\section*{EXAMPLE 7 Repeated Eigenvalues}
$$
\text { Solve } \mathbf{X}^{\prime}=\left(\begin{array}{lll}
2 & 1 & 6 \\
0 & 2 & 5 \\
0 & 0 & 2
\end{array}\right) \mathbf{X}
$$

Solution The characteristic equation $(\lambda-2)^{3}=0$ shows that $\lambda_{1}=2$ is an eigenvalue of multiplicity three. In succession we find that a solution of

$$
(\mathbf{A}-2 \mathbf{I}) \mathbf{K}=\mathbf{0} \quad \text { is } \quad \mathbf{K}=\left(\begin{array}{l}
1 \\
0 \\
0
\end{array}\right)
$$

a solution of

$$
(\mathbf{A}-2 \mathbf{I}) \mathbf{P}=\mathbf{K} \text { is } \quad \mathbf{P}=\left(\begin{array}{l}
0 \\
1 \\
0
\end{array}\right)
$$

and finally a solution of

$$
(\mathbf{A}-2 \mathbf{I}) \mathbf{Q}=\mathbf{P} \quad \text { is } \quad \mathbf{Q}=\left(\begin{array}{r}
0 \\
-\frac{6}{5} \\
\frac{1}{5}
\end{array}\right)
$$

We see from (18) and (21) that the general solution of the system is

$$
\mathbf{X}=c_{1}\left(\begin{array}{l}
1 \\
0 \\
0
\end{array}\right) e^{2 t}+c^{2}\left[\left(\begin{array}{l}
1 \\
0 \\
0
\end{array}\right) t e^{2 t}+\left(\begin{array}{l}
0 \\
1 \\
0
\end{array}\right) e^{2 t}\right]+c^{3}\left[\left(\begin{array}{l}
1 \\
0 \\
0
\end{array}\right) \frac{t^{2}}{2} e^{2 t}+\left(\begin{array}{l}
0 \\
1 \\
0
\end{array}\right) t e^{2 t}+\left(\begin{array}{c}
0 \\
-\frac{6}{5} \\
\frac{1}{5}
\end{array}\right) e^{2 t}\right]
$$

Remarks When an eigenvalue $\lambda_{1}$ has multiplicity $m$, either we can find $m$ linearly independent eigenvectors or the number of corresponding eigenvectors is less than $m$. Hence the two cases listed on pages 398-399 are not all the possibilities under which a repeated eigenvalue can occur. It could happen, say, that a $5 \times 5$ matrix has an eigenvalue of multiplicity five and there exist three linearly independent eigenvectors.

\section*{EXERCISES 8.6}
Answers to odd-numbered problems begin on page A-21.

\subsection*{8.6. I Distinct Real Eigenvalues}
In Problems 1-12 find the general solution of the given system.

\begin{enumerate}
  \item $\frac{d x}{d t}=x+2 y$
  \item $\frac{d x}{d t}=2 y$\\
$\frac{d y}{d t}=4 x+3 y$
\end{enumerate}

$$
\frac{d y}{d t}=8 x
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $\frac{d x}{d t}=-4 x+2 y$
  \item $\frac{d x}{d t}=\frac{1}{2} x+9 y$\\
$\frac{d y}{d t}=-\frac{5}{2} x+2 y$\\
$\frac{d y}{d t}=\frac{1}{2} x+2 y$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}10 & -5 \\ 8 & -12\end{array}\right) \mathbf{X}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}-6 & 2 \\ -3 & 1\end{array}\right) \mathbf{X}$
  \item $\frac{d x}{d t}=x+y-z$
  \item $\frac{d x}{d t}=2 x-7 y$\\
$\frac{d y}{d t}=2 y$\\
$\frac{d y}{d t}=5 x+10 y+4 z$\\
$\frac{d z}{d t}=\quad y-z$\\
$\frac{d z}{d t}=\quad 5 y+2 z$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}-1 & 1 & 0 \\ 1 & 2 & 1 \\ 0 & 3 & -1\end{array}\right) \mathbf{X}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{lll}1 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 1\end{array}\right) \mathbf{X}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}-1 & -1 & 0 \\ \frac{3}{4} & -\frac{3}{2} & 3 \\ \frac{1}{8} & \frac{1}{4} & -\frac{1}{2}\end{array}\right) \mathbf{X}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}-1 & 4 & 2 \\ 4 & -1 & -2 \\ 0 & 0 & 6\end{array}\right) \mathbf{X}$
\end{enumerate}

In Problems 13 and 14 solve the given system subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}\frac{1}{2} & 0 \\ 1 & -\frac{1}{2}\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\binom{3}{5}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{lll}1 & 1 & 4 \\ 0 & 2 & 0 \\ 1 & 1 & 1\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\left(\begin{array}{l}1 \\ 3 \\ 0\end{array}\right)$

\end{enumerate}

\subsection*{8.6.2 Complex Eigenvalues}
In Problems 15-26 find the general solution of the given system.\\
15. $\frac{d x}{d t}=6 x-y$\\
16. $\frac{d x}{d t}=x+y$\\
$\frac{d y}{d t}=5 x+2 y$\\
$\frac{d y}{d t}=-2 x-y$\\
17. $\frac{d x}{d t}=5 x+y$\\
18. $\frac{d x}{d t}=4 x+5 y$\\
$\frac{d y}{d t}=-2 x+3 y$\\
$\frac{d y}{d t}=-2 x+6 y$\\
19. $X^{\prime}=\left(\begin{array}{ll}4 & -5 \\ 5 & -4\end{array}\right) \mathbf{X}$\\
20. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}1 & -8 \\ 1 & -3\end{array}\right) \mathbf{X}$\\
21. $\frac{d x}{d t}=z$\\
22. $\frac{d x}{d t}=2 x+y+2 z$

$\frac{d y}{d t}=-z$

$\frac{d z}{d t}=y$\\
23. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & -1 & 2 \\ -1 & 1 & 0 \\ -1 & 0 & 1\end{array}\right) \mathbf{X}$\\
25. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}2 & 5 & 1 \\ -5 & -6 & 4 \\ 0 & 0 & 2\end{array}\right) \mathbf{X}$

In Problems 27 and 28 solve the given system subject to the indicated initial condition.\\
27. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & -12 & -14 \\ 1 & 2 & -3 \\ 1 & 1 & -2\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\left(\begin{array}{r}4 \\ 6 \\ -7\end{array}\right)$\\
28. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}6 & -1 \\ 5 & 4\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\binom{-2}{8}$

\subsection*{8.6.3 Repeated Eigenvalues}
In Problems 29-38 find the general solution of the given system.\\
29. $\frac{d x}{d t}=3 x-y$\\
30. $\frac{d x}{d t}=-6 x+5 y$\\
$\frac{d y}{d t}=9 x-3 y$\\
$\frac{d y}{d t}=-5 x+4 y$\\
31. $\frac{d x}{d t}=-x+3 y$\\
32. $\frac{d x}{d t}=12 x-9 y$\\
$\frac{d y}{d t}=-3 x+5 y$\\
$\frac{d y}{d t}=4 x$\\
33. $\frac{d x}{d t}=3 x-y-z$\\
34. $\frac{d x}{d t}=3 x+2 y+4 z$\\
$\frac{d y}{d t}=x+y-z$\\
$\frac{d y}{d t}=2 x \quad+2 z$\\
$\frac{d z}{d t}=x-y+z$\\
$\frac{d z}{d t}=4 x+2 y+3 z$\\
35. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}5 & -4 & 0 \\ 1 & 0 & 2 \\ 0 & 2 & 5\end{array}\right) \mathbf{X}$\\
36. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & 0 & 0 \\ 0 & 3 & 1 \\ 0 & -1 & 1\end{array}\right) \mathbf{X}$\\
37. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & 0 & 0 \\ 2 & 2 & -1 \\ 0 & 1 & 0\end{array}\right) \mathbf{X}$\\
38. $\mathbf{X}^{\prime}=\left(\begin{array}{lll}4 & 1 & 0 \\ 0 & 4 & 1 \\ 0 & 0 & 4\end{array}\right) \mathbf{X}$

In Problems 39 and 40 solve the given system subject to the indicated initial condition\\
39. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & 4 \\ -1 & 6\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\binom{-1}{6}$\\
40. $\mathbf{X}^{\prime}=\left(\begin{array}{lll}0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\left(\begin{array}{l}1 \\ 2 \\ 5\end{array}\right)$

\section*{Miscellaneous Problems}
If $\Phi(t)$ is a fundamental matrix of the system, the initial-value problem $\mathbf{X}^{\prime}=\mathbf{A X}, \mathbf{X}\left(t_{0}\right)=\mathbf{X}_{0}$ has the solution $\mathbf{X}=\boldsymbol{\Phi}(t) \Phi^{-1}\left(t_{0}\right) \mathbf{X}_{0}$ (see Problem 35, Exercises 8.5). In Problems 41 and 42 use this result to solve the given system subject to the indicated initial condition.\\
41. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}4 & 3 \\ 3 & -4\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\binom{1}{1}$\\
42. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}-\frac{2}{25} & \frac{1}{50} \\ \frac{2}{25} & -\frac{2}{25}\end{array}\right) \mathbf{X}, \quad \mathbf{X}(0)=\binom{25}{0}$

In Problems 43 and 44 find a solution of the given system of the form $\mathbf{X}=t^{\lambda} \mathbf{K}, t>0$, where $\mathbf{K}$ is a column vector of constants.\\
43. $t \mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & 3 \\ -1 & 5\end{array}\right) \mathbf{X}$\\
44. $t \mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & -2 \\ 2 & 7\end{array}\right) \mathbf{X}$

\section*{8.7* UNDETERMINED COEFFICIENTS - Undetermined coefficients}
The methods of undetermined coefficients and variation of parameters can both be adapted to the solution of a nonhomogeneous linear system $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}+\mathbf{F}(t)$. Of these two methods, variation of parameters is the more powerful technique. However, there are a few instances when the method of undetermined coefficients gives a quick means of finding a particular solution $\mathbf{X}_{p}$.

EXAMPLE 1 Undetermined Coefficients

Solve the system $\mathbf{X}^{\prime}=\left(\begin{array}{ll}-1 & 2 \\ -1 & 1\end{array}\right) \mathbf{X}+\binom{-8}{3}$ on $(-\infty, \infty)$.
\footnotetext{\begin{itemize}
  \item This section is an optional section.
\end{itemize}
}

Solution We first solve the homogeneous system

$$
\mathbf{X}^{\prime}=\left(\begin{array}{ll}
-1 & 2 \\
-1 & 1
\end{array}\right) \mathbf{X}
$$

The characteristic equation

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
-1-\lambda & 2 \\
-1 & 1-\lambda
\end{array}\right|=\lambda^{2}+1=0
$$

yields the complex eigenvalues $\lambda_{1}=i$ and $\lambda_{2}=\bar{\lambda}_{1}=-i$. By the procedures of the last section, we find

$$
\mathbf{X}_{c}=c_{1}\binom{\cos t+\sin t}{\cos t}+c_{2}\binom{\cos t-\sin t}{-\sin t}
$$

Now since $\mathbf{F}(t)$ is a constant vector, we assume a constant particular solution vector $\mathbf{X}_{p}=\binom{a_{1}}{b_{1}}$. Substituting this latter assumption into the original system leads to

$$
\begin{aligned}
& 0=-a_{1}+2 b_{1}-8 \\
& 0=-a_{1}+b_{1}+3
\end{aligned}
$$

Solving this system of algebraic equations gives $a_{1}=14$ and $b_{1}=11$, and so $\mathbf{X}_{p}=\binom{14}{11}$. The general solution of the system is

$$
\mathbf{X}=c_{1}\binom{\cos t+\sin t}{\cos t}+c_{2}\binom{\cos t-\sin t}{-\sin t}+\binom{14}{11}
$$

\section*{EXAMPLE 2 Undetermined Coefficients}
Solve the system

$$
\begin{aligned}
& \frac{d x}{d t}=6 x+y+6 t \\
& \frac{d y}{d t}=4 x+3 y-10 t+4
\end{aligned}
$$

on $(-\infty, \infty)$.

Solution We first solve the homogeneous system

$$
\begin{aligned}
& \frac{d x}{d t}=6 x+y \\
& \frac{d y}{d t}=4 x+3 y
\end{aligned}
$$

by the method of Section 8.6. The eigenvalues are determined from

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
6-\lambda & 1 \\
4 & 3-\lambda
\end{array}\right|=\lambda^{2}-9 \lambda+14=0
$$

Since $\lambda^{2}-9 \lambda+14=(\lambda-2)(\lambda-7)$, we have $\lambda_{1}=2$ and $\lambda_{2}=7$. It is then easily verified that the respective eigenvectors of the coefficient matrix are

$$
\mathbf{K}_{1}=\binom{1}{-4} \quad \text { and } \quad \mathbf{K}_{2}=\binom{1}{1}
$$

Consequently the complementary function is

$$
\mathbf{X}_{c}=c_{1}\binom{1}{-4} e^{2 t}+c_{2}\binom{1}{1} e^{\pi t}
$$

Because $\mathbf{F}(t)$ can be written as

$$
\mathbf{F}(t)=\binom{6}{-10} t+\binom{0}{4}
$$

we shall try to find a particular solution of the system possessing the same form:

$$
\mathbf{X}_{p}=\binom{a_{2}}{b_{2}} t+\binom{a_{1}}{b_{1}}
$$

In matrix terms we must have

$$
\begin{gathered}
\mathbf{X}_{p}^{\prime}=\left(\begin{array}{ll}
6 & 1 \\
4 & 3
\end{array}\right) \mathbf{X}_{p}+\binom{6}{-10} t+\binom{0}{4} \\
\binom{a_{2}}{b_{2}}=\left(\begin{array}{ll}
6 & 1 \\
4 & 3
\end{array}\right)\left[\binom{a_{2}}{b_{2}} t+\binom{a_{1}}{b_{1}}\right]+\binom{6}{-10} t+\binom{0}{4} \\
\binom{0}{0}=\binom{\left(6 a_{2}+b_{2}+6\right) t+6 a_{1}+b_{1}-a_{2}}{\left(4 a_{2}+3 b_{2}-10\right) t+4 a_{1}+3 b_{1}-b_{2}+4}
\end{gathered}
$$

From this last identity we conclude that

$$
\begin{array}{lr}
6 a_{2}+b_{2}+6=0 \\
4 a_{2}+3 b_{2}-10=0
\end{array} \quad \text { and } \quad \begin{aligned}
6 a_{1}+b_{1}-a_{2}=0 \\
4 a_{1}+3 b_{1}-b_{2}+4=0
\end{aligned}
$$

Solving the first two equations simultaneously yields $a_{2}=-2$ and $b_{2}=6$. Substituting these values into the last two equations and solving for $a_{1}$ and $b_{1}$ gives $a_{1}=-\frac{4}{7}, b_{1}=\frac{10}{7}$. It follows, therefore, that a particular solution vector is

$$
\mathbf{X}_{p}=\binom{-2}{6} t+\binom{-\frac{4}{7}}{\frac{10}{7}}
$$

and so the general solution of the system on $(-\infty, \infty)$ is

$$
\begin{aligned}
\mathbf{X} & =\mathbf{X}_{c}+\mathbf{X}_{p} \\
& =c_{1}\binom{1}{-4} e^{2 t}+c_{2}\binom{1}{1} e^{7 t}+\binom{-2}{6} t+\binom{-\frac{4}{7}}{\frac{10}{7}}
\end{aligned}
$$

\section*{EXAMPLE 3 Form of a Particular Solution}
Determine the form of the particular solution vector $\mathbf{X}_{p}$ for

$$
\begin{aligned}
& \frac{d x}{d t}=5 x+3 y-2 e^{-t}+1 \\
& \frac{d y}{d t}=-x+y+e^{-t}-5 t+7
\end{aligned}
$$

Solution Proceeding in the usual manner, we find

Now since

$$
\begin{gathered}
\mathbf{X}_{c}=c_{1}\binom{1}{-1} e^{2 t}+c_{2}\binom{3}{-1} e^{4 t} \\
\mathbf{F}(t)=\binom{-2}{1} e^{-t}+\binom{0}{-5} t+\binom{1}{7}
\end{gathered}
$$

we assume a particular solution of the form

$$
\mathbf{X}_{p}=\binom{a_{3}}{b_{3}} e^{-t}+\binom{a_{2}}{b_{2}} t+\binom{a_{1}}{b_{1}}
$$

Remarks The method of undetermined coefficients is not as simple as the last three examples seem to indicate. As in Section 4.4, the method can be applied only when the entries in the matrix $\mathbf{F}(t)$ are constants, polynomials, exponential functions, sines and cosines, or finite sums and products of these functions. There are further difficulties. The assumption for $\mathbf{X}_{p}$ is actually predicated on a prior knowledge of the complementary function $\mathbf{X}_{c}$. For example, if $\mathbf{F}(t)$ is a constant vector and $\lambda=0$ is an eigenvalue, then $\mathbf{X}_{c}$ contains a constant vector. In this case $\mathbf{X}_{p}$ is not a constant vector as in Example 1 but rather

$$
\mathbf{X}_{p}=\binom{a_{2}}{b_{2}} t+\binom{a_{1}}{b_{1}}
$$

See Problem 11

Similarly, in Example 3, if we replace $e^{-t}$ in $\mathbf{F}(t)$ by $e^{2 t}(\lambda=2$ is an eigenvalue), then the correct form of the particular solution is

$$
\mathbf{X}_{p}=\binom{a_{4}}{b_{4}} t e^{2 t}+\binom{a_{3}}{b_{3}} e^{2 t}+\binom{a_{2}}{b_{2}} t+\binom{a_{1}}{b_{1}}
$$

Rather than pursue these difficulties, we turn our attention now to the method of variation of parameters.

\section*{EXERCISES 8.7}
Answers to odd-numbered problems begin on page A-21.

In Problems 1-8 use the method of undetermined coefficients to solve the given system on $(-\infty, \infty)$.

$$
\begin{aligned}
& \text { 1. } \frac{d x}{d t}=2 x+3 y-7 \\
& \text { 2. } \frac{d x}{d t}=5 x+9 y+2 \\
& \frac{d y}{d t}=-x-2 y+5 \\
& \frac{d y}{d t}=-x+11 y+6
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-434}
\end{center}

Figure 8.11 $\begin{aligned} \text { 3. } \frac{d x}{d t} & =x+3 y-2 t^{2} & \text { 4. } \frac{d x}{d t} & =x-4 y+4 t+9 e^{6 t} \\ \frac{d y}{d t} & =3 x+y+t+5 & \frac{d y}{d t} & =4 x+y-t+e^{6 t}\end{aligned}$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{cc}4 & \frac{1}{3} \\ 9 & 6\end{array}\right) \mathbf{X}+\binom{-3}{10} e^{t}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{cc}-1 & 5 \\ -1 & 1\end{array}\right) \mathbf{X}+\binom{\sin t}{-2 \cos t}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{lll}1 & 1 & 1 \\ 0 & 2 & 3 \\ 0 & 0 & 5\end{array}\right) \mathbf{X}+\left(\begin{array}{r}1 \\ -1 \\ 2\end{array}\right) e^{4 t}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{lll}0 & 0 & 5 \\ 0 & 5 & 0 \\ 5 & 0 & 0\end{array}\right) \mathbf{X}+\left(\begin{array}{r}5 \\ -10 \\ 40\end{array}\right)$

  \item Solve $\mathbf{X}^{\prime}=\left(\begin{array}{rr}-1 & -2 \\ 3 & 4\end{array}\right) \mathbf{X}+\binom{3}{3}$ subject to $\mathbf{X}(0)=\binom{-4}{5}$.

  \item (a) Show that the system of differential equations for the currents $i_{2}(t)$ and $i_{3}(t)$ in the electrical network shown in Figure 8.11 is

\end{enumerate}

$$
\frac{d}{d t}\binom{i_{2}}{i_{3}}=\left(\begin{array}{cc}
-R_{1} / L_{1} & -R_{1} / L_{1} \\
-R_{1} / L_{2} & -\left(R_{1}+R_{2}\right) / L_{2}
\end{array}\right)\binom{i_{2}}{i_{3}}+\binom{E / L_{1}}{E / L_{2}}
$$

(b) Solve the system in part (a) if $R_{1}=2$ ohms, $R_{2}=3$ ohms, $L_{1}=1$ henry, $L_{2}=1$ henry, $E=60$ volts, $i_{2}(0)=0$, and $i_{3}(0)=0$.

(c) Determine the current $i_{1}(t)$.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item Solve the system $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & -1 \\ -1 & 1\end{array}\right) \mathbf{X}+\binom{3}{-5}$ on $(-\infty, \infty)$.
\end{enumerate}

[Hint: A particular solution may not be unique.]

\subsection*{8.8 VARIATION OF PARAMETERS - Variation of parameters $\cdot$ Particular solution}
In Section 8.5 we saw that the general solution of a homogeneous system $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}$ can be written as the product

$$
\mathbf{X}=\Phi(t) \mathbf{C}
$$

where $\Phi(t)$ is a fundamental matrix of the system and $\mathbf{C}$ is an $n \times 1$ column vector of constants. As in the procedure of Section 4.5, we ask whether it is possible to replace $\mathbf{C}$ by a column matrix of functions

\[
\mathbf{U}(t)=\left(\begin{array}{c}
u_{1}(t)  \tag{1}\\
u_{2}(t) \\
\vdots \\
u_{n}(t)
\end{array}\right) \quad \text { so that } \quad \mathbf{X}_{p}=\Phi(t) \mathbf{U}(t)
\]

is a particular solution of the nonhomogeneous system


\begin{equation*}
\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}+\mathbf{F}(t) \tag{2}
\end{equation*}


By the product rule* the derivative of (1) is


\begin{equation*}
\mathbf{X}_{p}^{\prime}=\Phi(t) \mathbf{U}^{\prime}(t)+\Phi^{\prime}(t) \mathbf{U}(t) \tag{3}
\end{equation*}


Substituting (3) and (1) into (2) gives


\begin{equation*}
\Phi(t) \mathbf{U}^{\prime}(t)+\Phi^{\prime}(t) \mathbf{U}(t)=\mathbf{A} \Phi(t) \mathbf{U}(t)+\mathbf{F}(t) \tag{4}
\end{equation*}


Now recall from (14) of Section 8.5 that $\Phi^{\prime}(t)=\mathbf{A} \Phi(t)$. Thus (4) becomes

$$
\Phi(t) \mathbf{U}^{\prime}(t)+\mathbf{A} \boldsymbol{\Phi}(t) \mathbf{U}(t)=\mathbf{A} \boldsymbol{\Phi}(t) \mathbf{U}(t)+\mathbf{F}(t)
$$

or


\begin{equation*}
\Phi(t) \mathbf{U}^{\prime}(t)=\mathbf{F}(t) \tag{5}
\end{equation*}


Multiplying both sides of equation (5) by $\Phi^{-1}(t)$ gives

$$
\mathbf{U}^{\prime}(t)=\Phi^{-1}(t) \mathbf{F}(t) \quad \text { or } \quad \mathbf{U}(t)=\int \Phi^{-1}(t) \mathbf{F}(t) d t
$$

Hence by assumption (1) we conclude that a particular solution of (2) is given by


\begin{equation*}
\mathbf{X}_{p}=\Phi(t) \int \Phi^{-1}(t) \mathbf{F}(t) d t \tag{6}
\end{equation*}


To calculate the indefinite integral of the column matrix $\Phi^{-1}(t) \mathbf{F}(t)$ in (6) we integrate each entry. Thus the general solution of the system (2) is $\mathbf{X}=\mathbf{X}_{c}+\mathbf{X}_{p}$ or


\begin{equation*}
\mathbf{X}=\Phi(t) \mathbf{C}+\Phi(t) \int \Phi^{-1}(t) \mathbf{F}(t) d t \tag{7}
\end{equation*}


\section*{EXAMPLE 1 Variation of Parameters}
Find the general solution of the nonhomogeneous system

\[
\mathbf{X}^{\prime}=\left(\begin{array}{rr}
-3 & 1  \tag{8}\\
2 & -4
\end{array}\right) \mathbf{X}+\binom{3 t}{e^{-t}}
\]

on the interval $(-\infty, \infty)$.

Solution We first solve the homogeneous system

\[
\mathbf{X}^{\prime}=\left(\begin{array}{rr}
-3 & 2  \tag{9}\\
1 & -4
\end{array}\right) \mathbf{X}
\]

The characteristic equation of the coefficient matrix is

$$
\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=\left|\begin{array}{cc}
-3-\lambda & 1 \\
2 & -4-\lambda
\end{array}\right|=(\lambda+2)(\lambda+5)=0
$$
\footnotetext{\begin{itemize}
  \item See Problem 51, Exercises 8.4. Note that the order of the products is very important. Since $\mathbf{U}(t)$ is a column matrix, the products $\mathbf{U}^{\prime}(t) \Phi(t)$ and $\mathbf{U}(t) \Phi^{\prime}(t)$ are not defined.
\end{itemize}
}
and so the eigenvalues are $\lambda_{1}=-2$ and $\lambda_{2}=-5$. By the usual method we find that the eigenvectors corresponding to $\lambda_{1}$ and $\lambda_{2}$ are, respectively,

$$
\binom{1}{1} \text { and }\binom{1}{-2}
$$

The solution vectors of the system (9) are then

$$
\mathbf{X}_{1}=\binom{1}{1} e^{-2 t} \quad \text { and } \quad \mathbf{X}_{2}=\binom{1}{-2} e^{-5 t}
$$

Next we form

$$
\boldsymbol{\Phi}(t)=\left(\begin{array}{rr}
e^{-2 t} & e^{-2 t} \\
e^{-5 t} & -2 e^{-5 t}
\end{array}\right) \text { and } \quad \boldsymbol{\Phi}^{-1}(t)=\left(\begin{array}{cc}
\frac{2}{3} e^{2 t} & \frac{1}{3} e^{2 t} \\
\frac{1}{3} e^{5 t} & -\frac{1}{3} e^{5 t}
\end{array}\right)
$$

From (6) we then obtain

$$
\begin{aligned}
\mathbf{X}_{p}=\boldsymbol{\Phi}(t) \int \boldsymbol{\Phi}^{-1}(t) \mathbf{F}(t) d t & =\left(\begin{array}{rr}
e^{-2 t} & e^{-5 t} \\
e^{-2 t} & -2 e^{-5 t}
\end{array}\right) \int\left(\begin{array}{cc}
\frac{2}{3} e^{2 t} & \frac{1}{3} e^{2 t} \\
\frac{1}{3} e^{5 t} & -\frac{1}{3} e^{5 t}
\end{array}\right)\binom{3 t}{e^{-t}} d t \\
& =\left(\begin{array}{cc}
e^{-2 t} & e^{-5 t} \\
e^{-2 t} & -2 e^{-5 t}
\end{array}\right) \int\binom{2 t e^{2 t}+\frac{1}{3} e^{t}}{t e^{5 t}-\frac{1}{3} e^{4 t}} d t \\
& =\left(\begin{array}{cr}
e^{-2 t} & e^{-5 t} \\
e^{-2 t} & -2 e^{-5 t}
\end{array}\right)\binom{t e^{2 t}-\frac{1}{2} e^{2 t}+\frac{1}{3} e^{t}}{\frac{1}{5} t e^{5 t}-\frac{1}{25} e^{5 t}-\frac{1}{12} e^{4 t}} \\
& =\binom{\frac{6}{5} t-\frac{27}{50}+\frac{1}{4} e^{-t}}{\frac{3}{5} t-\frac{21}{50}+\frac{1}{2} e^{-t}} .
\end{aligned}
$$

Hence from (7) the general solution of (8) on the interval is

$$
\begin{aligned}
\mathbf{X} & =\left(\begin{array}{lr}
e^{-2 t} & e^{-5 t} \\
e^{-2 t} & -2 e^{-5 t}
\end{array}\right)\binom{c_{1}}{c_{2}}+\binom{\frac{6}{5} t-\frac{27}{50}+\frac{1}{4} e^{-t}}{\frac{3}{5} t-\frac{21}{50}+\frac{1}{2} e^{-t}} \\
& =c_{1}\binom{1}{1} e^{-2 t}+c_{2}\binom{1}{-2} e^{-5 t}+\binom{\frac{6}{5}}{\frac{3}{5}} t-\binom{\frac{27}{50}}{\frac{21}{50}}+\binom{\frac{1}{4}}{\frac{1}{2}} e^{-t}
\end{aligned}
$$

The general solution of (2) on an interval can be written in the alternative manner


\begin{equation*}
\mathbf{X}=\boldsymbol{\Phi}(t) \mathbf{C}+\boldsymbol{\Phi}(t) \int_{t_{0}}^{\prime} \boldsymbol{\Phi}^{-1}(s) \mathbf{F}(s) d s \tag{10}
\end{equation*}


where $t$ and $t_{0}$ are points in the interval. This last form is useful in solving (2) subject to an initial condition $\mathbf{X}\left(t_{0}\right)=\mathbf{X}_{0}$. Substituting $t=t_{0}$ in (10) yields

$$
\mathbf{X}_{0}=\Phi\left(t_{0}\right) \mathbf{C}
$$

from which we see immediately that

$$
\mathbf{C}=\boldsymbol{\Phi}^{-1}\left(t_{0}\right) \mathbf{X}_{0}
$$

We conclude that the solution of the initial-value problem is given by


\begin{equation*}
\mathbf{X}=\boldsymbol{\Phi}(t) \boldsymbol{\Phi}^{-1}\left(t_{0}\right) \mathbf{X}_{0}+\boldsymbol{\Phi}(t) \int_{t_{0}}^{\prime} \boldsymbol{\Phi}^{-1}(s) \mathbf{F}(s) d s \tag{11}
\end{equation*}


Recall from Section 8.5 that an alternative way of forming a fundamental matrix is to choose its column vectors $\mathbf{V}_{i}$ in such a manner that

\[
\mathbf{V}_{1}\left(t_{0}\right)=\left(\begin{array}{c}
1  \tag{12}\\
0 \\
\vdots \\
0
\end{array}\right), \quad \mathbf{V}_{2}\left(t_{0}\right)=\left(\begin{array}{c}
0 \\
1 \\
\vdots \\
0
\end{array}\right), \quad \ldots, \quad \mathbf{V}_{n}\left(t_{0}\right)=\left(\begin{array}{c}
0 \\
0 \\
\vdots \\
1
\end{array}\right)
\]

This fundamental matrix is denoted by $\Psi(t)$. As a consequence of (12) we know that $\Psi(t)$ has the property


\begin{equation*}
\Psi\left(t_{0}\right)=\mathbf{I} \tag{13}
\end{equation*}


But since $\Psi(t)$ is nonsingular for all values of $t$ in an interval, (13) implies


\begin{equation*}
\Psi^{-1}\left(t_{0}\right)=\mathbf{I} \tag{14}
\end{equation*}


Thus when $\Psi(t)$ is used rather than $\Phi(t)$, it follows from (14) that (11) can be written


\begin{equation*}
\mathbf{X}=\boldsymbol{\Psi}(t) \mathbf{X}_{0}+\Psi(t) \int_{t_{0}}^{\prime} \boldsymbol{\Psi}^{-1}(s) \mathbf{F}(s) d s \tag{15}
\end{equation*}


\section*{EXERCISES 8.8}
Answers to odd-numbered problems begin on page A-22.

In Problems I-20 use variation of parameters to solve the given system.

\begin{enumerate}
  \item $\frac{d x}{d t}=3 x-3 y+4$
  \item $\frac{d x}{d t}=2 x-y$\\
$\frac{d y}{d t}=2 x-2 y-1$\\
$\frac{d y}{d t}=3 x-2 y+4 t$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}3 & -5 \\ \frac{3}{4} & -1\end{array}\right) \mathbf{X}+\binom{1}{-1} e^{1 / 2}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}2 & -1 \\ 4 & 2\end{array}\right) \mathbf{X}+\binom{\sin 2 t}{2 \cos 2 t} e^{2 t}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}0 & 2 \\ -1 & 3\end{array}\right) \mathbf{X}+\binom{1}{-1} e^{t}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}0 & 2 \\ -1 & 3\end{array}\right) \mathbf{X}+\binom{2}{e^{-3 t}}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & 8 \\ 1 & -1\end{array}\right) \mathbf{X}+\binom{12}{12} t$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & 8 \\ 1 & -1\end{array}\right) \mathbf{X}+\binom{e^{-t}}{t e^{t}}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}3 & 2 \\ -2 & -1\end{array}\right) \mathbf{X}+\binom{2 e^{-t}}{e^{-t}}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}3 & 2 \\ -2 & -1\end{array}\right) \mathbf{X}+\binom{1}{1}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}0 & -1 \\ 1 & 0\end{array}\right) \mathbf{X}+\binom{\sec t}{0}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & -1 \\ 1 & 1\end{array}\right) \mathbf{X}+\binom{3}{3} e^{\prime}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & -1 \\ 1 & 1\end{array}\right) \mathbf{X}+\binom{\cos t}{\sin t} e^{t}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}2 & -2 \\ 8 & -6\end{array}\right) \mathbf{X}+\binom{1}{3} \frac{e^{-2 t}}{t}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}0 & 1 \\ -1 & 0\end{array}\right) \mathbf{X}+\binom{0}{\sec t \tan t}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}0 & 1 \\ -1 & 0\end{array}\right) \mathbf{X}+\binom{\mathrm{I}}{\cot t}$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-438}
\end{center}

Figure 8.12\\
17. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & 2 \\ -\frac{1}{2} & 1\end{array}\right) \mathbf{X}+\binom{\csc t}{\sec t} e^{t} \quad$ 18. $\mathbf{X}^{\prime}=\left(\begin{array}{cc}1 & -2 \\ 1 & -1\end{array}\right) \mathbf{X}+\binom{\tan t}{1}$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{lll}1 & 1 & 0 \\ 1 & 1 & 0 \\ 0 & 0 & 3\end{array}\right) \mathbf{X}+\left(\begin{array}{c}e^{t} \\ e^{2 t} \\ t e^{3 t}\end{array}\right)$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}3 & -1 & -1 \\ 1 & 1 & -1 \\ 1 & -1 & 1\end{array}\right) \mathbf{X}+\left(\begin{array}{c}0 \\ t \\ 2 e^{t}\end{array}\right)$

\end{enumerate}

In Problems 21 and 22 use (11) to solve the given system subject to the indicated initial condition.

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}3 & -1 \\ -1 & 3\end{array}\right) \mathbf{X}+\binom{4 e^{2 t}}{4 e^{4 t}}, \quad \mathbf{X}(0)=\binom{1}{1}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}1 & -1 \\ 1 & -1\end{array}\right) \mathbf{X}+\binom{1 / t}{1 / t}, \quad \mathbf{X}(1)=\binom{2}{-1}$

\end{enumerate}

In Problems 23 and 24 use (15) to solve the given system subject to the indicated initial condition. Use the results of Problems 31 and 34 in Exercises 8.5.

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}4 & 1 \\ 6 & 5\end{array}\right) \mathbf{X}+\binom{50 e^{7 t}}{0}, \quad \mathbf{X}(0)=\binom{5}{-5}$

  \item $\mathbf{X}^{\prime}=\left(\begin{array}{ll}3 & -2 \\ 5 & -3\end{array}\right) \mathbf{X}+\binom{2}{3}, \quad \mathbf{X}(\pi / 2)=\binom{0}{0}$

  \item (a) Show that the system of differential equations for the currents $i_{1}(t)$ and $i_{2}(t)$ in the electrical network shown in Figure 8.12 is

\end{enumerate}

$$
\frac{d}{d t}\binom{i_{1}}{i_{2}}=\left(\begin{array}{cc}
-\left(R_{1}+R_{2}\right) / L_{2} & R_{2} / L_{2} \\
R_{2} / L_{1} & -R_{2} / L_{1}
\end{array}\right)\binom{i_{1}}{i_{2}}+\binom{E / L_{2}}{0}
$$

(b) Solve the system in part (a) if $R_{1}=8$ ohms, $R_{2}=3$ ohms, $L_{1}=1$ henry, $L_{2}=1$ henry, $E(t)=100 \sin t$ volts, $i_{1}(0)=0$, and $i_{2}(0)=0$.

\section*{8.9* MATRIX EXPONENTIAL \\
 - Matrix exponential - Solution of linear systems}
Matrices can be utilized in an entirely different manner to solve a homogeneous system of linear first-order differential equations.

Recall that the simple linear first-order differential equation $x^{\prime}=a x$, where $a$ is a constant, has the general solution $x=c e^{a t}$. It seems natural then
\footnotetext{\begin{itemize}
  \item This section is an optional section.
\end{itemize}
}
to ask whether we can define a matrix exponential $e^{t \mathrm{~A}}$ so that the homogeneous system $\mathbf{X}^{\prime}=\mathbf{A X}$, where $\mathbf{A}$ is an $n \times n$ matrix of constants, has a solution


\begin{equation*}
\mathbf{X}=e^{t \lambda} \mathbf{C} \tag{1}
\end{equation*}


Since $\mathbf{C}$ is to be an $n \times 1$ column vector of arbitrary constants, we want $e^{\boldsymbol{t A}}$ to be an $n \times n$ matrix. While the complete development of the meaning of the matrix exponential would necessitate a more thorough investigation of matrix algebra, one means of computing $e^{t A}$ is given in the following definition.

\section*{DEFINITION 8.20}
Matrix Exponential

For any $n \times n$ matrix $\mathbf{A}$,


\begin{equation*}
e^{t \mathbf{A}}=\sum_{n=0}^{\infty} \frac{(t \mathbf{A})^{n}}{n!}=\mathbf{I}+t \mathbf{A}+\frac{t^{2}}{2!} \mathbf{A}^{2}+\frac{t^{2}}{3!} \mathbf{A}^{3}+\cdots \tag{2}
\end{equation*}


It can be shown that the series given in (2) converges to an $n \times n$ matrix for every value of $t$. Also, $\mathbf{A}^{2}=\mathbf{A A}, \mathbf{A}^{3}=\mathbf{A}\left(\mathbf{A}^{2}\right)$, and so on.

Now the general solution of the single differential equation

$$
x^{\prime}=a x+f(t)
$$

where $a$ is a constant, can be expressed as

$$
x=x_{c}+x_{p}=c e^{a t}+e^{a t} \int_{t_{0}}^{t} e^{-a s} f(s) d s
$$

For systems of linear first-order differential equations, it can be shown that the general solution of

$$
\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}+\mathbf{F}(t)
$$

where $\mathbf{A}$ is an $n \times n$ matrix of constants, is


\begin{equation*}
\mathbf{X}=\mathbf{X}_{c}+\mathbf{X}_{p}=e^{t \boldsymbol{A}} \mathbf{C}+e^{t \boldsymbol{A}} \int_{t_{0}}^{t} e^{-s \boldsymbol{A}} \mathbf{F}(s) d s \tag{3}
\end{equation*}


The matrix exponential $e^{t \mathrm{~A}}$ is always nonsingular and $e^{-s \mathrm{~A}}=\left(e^{s \mathrm{~A}}\right)^{-1}$. In practice, $e^{-s \mathrm{~A}}$ can be obtained from $e^{t \mathrm{~A}}$ by replacing $t$ by $-s$.

Additional Properties From (2) it is seen that


\begin{equation*}
e^{0}=\mathbf{I} \tag{4}
\end{equation*}


Also, formal termwise differentiation of (2) shows that


\begin{equation*}
\frac{d}{d t} e^{t \mathbf{A}}=\mathbf{A} e^{t \mathbf{A}} \tag{5}
\end{equation*}


If we denote the matrix exponential by $\Psi(t)$, then (5) and (4) are equivalent to


\begin{equation*}
\Psi^{\prime}(t)=\mathbf{A} \Psi(t) \tag{6}
\end{equation*}



\begin{equation*}
\Psi(0)=\mathbf{I} \tag{7}
\end{equation*}


respectively. The notation here is chosen deliberately. Comparing (6) with (14) of Section 8.5 reveals that $e^{\prime \mathbf{A}}$ is a fundamental matrix of the system $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}$. It is precisely this formulation of the fundamental matrix that was discussed on page 386 of Section 8.5.

By multiplying the series defining $e^{\prime \mathbf{A}}$ and $e^{-s \mathbf{A}}$, we can prove that

$$
e^{(\mathbf{A} A} e^{-s \mathbf{A}}=e^{(t-s) \mathbf{A}} \quad \text { or, equivalently, } \quad \boldsymbol{\Psi}(t) \Psi^{-1}(s)=\boldsymbol{\Psi}(t-s) . *
$$

This last result enables us to relate (3) to (10) of the preceding section:


\begin{align*}
\mathbf{X} & =e^{t \mathbf{A}} \mathbf{C}+\int_{t_{0}}^{t} e^{t \mathbf{A}} e^{-s \mathbf{A}} \mathbf{F}(s) d s \\
& =e^{t \mathbf{A}} \mathbf{C}+\int_{t_{0}}^{t} e^{(t-s) \mathbf{A}} \mathbf{F}(s) d s  \tag{8}\\
\mathbf{X} & =\Psi(t) \mathbf{C}+\int_{t_{0}}^{t} \Psi(t-s) \mathbf{F}(s) d s \tag{9}
\end{align*}


Equation (9) possesses a form simpler than (10) of Section 8.8. In other words, there is no need to compute $\Psi^{-1}$; we need only replace $t$ by $t-s$ in $\Psi(t)$.

\section*{EXERCISES 8.9}
Answers to odd-numbered problems begin on page A-22.

In Problems 1 and 2 use (2) to compute $e^{\tau \mathbf{A}}$ and $e^{-\mathrm{IA}}$.

\begin{enumerate}
  \item $\mathbf{A}=\left(\begin{array}{ll}0 & 1 \\ 1 & 0\end{array}\right)$
  \item $\mathbf{A}=\left(\begin{array}{ll}1 & 0 \\ 0 & 2\end{array}\right)$
\end{enumerate}

In Problems 3 and 4 use (1) to find the general solution of each system.\\
3. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}0 & 1 \\ 1 & 0\end{array}\right) \mathbf{X}$\\
4. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}1 & 0 \\ 0 & 2\end{array}\right) \mathbf{X}$

In Problems 5-8 use (3) to find the general solution of each system.\\
5. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}0 & 1 \\ 1 & 0\end{array}\right) \mathbf{X}+\binom{1}{1}$\\
6. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}0 & 1 \\ 1 & 0\end{array}\right) \mathbf{X}+\binom{\cosh t}{\sinh t}$\\
7. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}1 & 0 \\ 0 & 2\end{array}\right) \mathbf{X}+\binom{t}{e^{4 t}}$\\
8. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}1 & 0 \\ 0 & 2\end{array}\right) \mathbf{X}+\binom{3}{-1}$
\footnotetext{\begin{itemize}
  \item Although $e^{t \mathbf{A}} e^{-s \mathbf{A}}=e^{(t-s) \mathbf{A}}$, it is interesting to note that $e^{\mathbf{A}} e^{\mathbf{B}}$ is, in general, not the same as $e^{\mathbf{A}+\mathbf{B}}$ for $n \times n$ matrices $\mathbf{A}$ and $\mathbf{B}$
\end{itemize}
}

\section*{Miscellaneous Problems}
Let $\mathbf{P}$ denote a matrix whose columns are eigenvectors $\mathbf{K}_{1}, \mathbf{K}_{2}, \ldots, \mathbf{K}_{n}$ responding to distinct eigenvalues $\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n}$ of an $n \times n$ matrix $\mathbf{A}$. Then it can be shown that $\mathbf{A}=\mathbf{P D P}^{-1}$, where $\mathbf{D}$ is defined by

\[
\mathbf{D}=\left(\begin{array}{cccc}
\lambda_{1} & 0 & \cdots & 0  \tag{10}\\
0 & \lambda_{2} & \cdots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \cdots & \lambda_{n}
\end{array}\right)
\]

In Problems 9 and 10 verify the above result for the given matrix.\\
9. $\mathbf{A}=\left(\begin{array}{rr}2 & 1 \\ -3 & 6\end{array}\right)$\\
10. $\mathbf{A}=\left(\begin{array}{ll}2 & 1 \\ 1 & 2\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item Suppose $\mathbf{A}=\mathbf{P D P} \mathbf{P}^{-1}$, where $\mathbf{D}$ is defined in (10). Use (2) to show that $e^{t \mathbf{A}}=\mathbf{P} e^{t \mathrm{D}} \mathbf{P}^{-1}$.

  \item Use (2) to show that

\end{enumerate}

$$
e^{t \mathbf{D}}=\left(\begin{array}{cccc}
e^{\lambda_{1} t} & 0 & \cdots & 0 \\
0 & e^{\lambda_{2} t} & \cdots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \cdots & e^{\lambda_{n} t}
\end{array}\right)
$$

where $\mathbf{D}$ is defined in (10).

In Problems 13 and 14 use the results of Problems 9-12 to solve the given system.\\
13. $X^{\prime}=\left(\begin{array}{rr}2 & 1 \\ -3 & 6\end{array}\right) \mathbf{X}$\\
14. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}2 & 1 \\ 1 & 2\end{array}\right) \mathbf{X}$

\section*{CHAPTER 8 REVIEW}
Throughout this chapter we have considered systems of linear differential equations.

For linear systems probably the most basic technique of solution consists of rewriting the entire system in operator notation and then using systematic elimination to obtain single differential equations in one dependent variable that can be solved by the usual procedures. Also, determinants can usually be utilized to accomplish the same result. Once all dependent variables have been determined, it is necessary to use the system itself to find various relationships between the parameters.

When initial conditions are specified, the Laplace transform can be used to reduce the system to simultaneous algebraic equations in the transformed functions.

A first-order system in normal form in two dependent variables is any system


\begin{align*}
& \frac{d x}{d t}=a_{11}(t) x+a_{12}(t) y+f_{1}(t) \\
& \frac{d y}{d t}=a_{21}(t) x+a_{22}(t) y+f_{2}(t) \tag{1}
\end{align*}


where the coefficients $a_{i j}(t), f_{1}(t)$, and $f_{2}(t)$ are continuous on some common interval $I$. When $f_{1}(t)=0, f_{2}(t)=0$, the system is said to be homogeneous;\\
otherwise it is nonhomogeneous. Any linear second-order differential equation can be expressed in this form.

Using matrices, we can write the system (1) compactly as


\begin{equation*}
\frac{d \mathbf{X}}{d t}=\mathbf{A}(t) \mathbf{X}+\mathbf{F}(t) \tag{2}
\end{equation*}


where

$$
\mathbf{X}=\binom{x}{y}, \quad \mathbf{A}(t)=\left(\begin{array}{ll}
a_{11}(t) & a_{12}(t) \\
a_{21}(t) & a_{22}(t)
\end{array}\right), \quad \text { and } \quad \mathbf{F}(t)=\binom{f_{1}(t)}{f_{2}(t)}
$$

The general solution of the homogeneous system in two dependent variables


\begin{equation*}
\frac{d \mathbf{X}}{d t}=\mathbf{A}(t) \mathbf{X} \tag{3}
\end{equation*}


is defined to be the linear combination


\begin{equation*}
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2} \tag{4}
\end{equation*}


where $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ form a fundamental set of solutions of (3) on $I$. The general solution of the nonhomogeneous system (2) is defined to be

$$
\mathbf{X}=\mathbf{X}_{c}+\mathbf{X}_{p}
$$

where $\mathbf{X}_{c}$ is defined by (4) and $\mathbf{X}_{p}$ is any solution vector of (2).

To solve a homogeneous system (3) we determine the eigenvalues of the coefficient matrix $\mathbf{A}$ and then find the corresponding eigenvectors.

To solve a nonhomogeneous system we first solve the associated homogeneous system. A particular solution vector $\mathbf{X}_{p}$ of the nonhomogeneous system is found by either undetermined coefficients or variation of parameters.

A fundamental matrix of a homogeneous system (3) in two dependent variables is defined to be

\[
\Phi(t)=\left(\begin{array}{ll}
x_{1} & x_{2}  \tag{5}\\
y_{1} & y_{2}
\end{array}\right)
\]

The columns in (5) are obtained from two linearly independent solution vectors $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ of (3). In terms of matrices, the method of variation of parameters leads to a particular solution given by

$$
\mathbf{X}_{p}=\boldsymbol{\Phi}(t) \int \boldsymbol{\Phi}^{-1}(t) \mathbf{F}(t) d t
$$

The general solution of (2) on an interval is

$$
\mathbf{X}=\boldsymbol{\Phi}(t) \mathbf{C}+\boldsymbol{\Phi}(t) \int \boldsymbol{\Phi}^{-1}(t) \mathbf{F}(t) d t
$$

where $\mathbf{C}$ is a column matrix containing two arbitrary constants. The matrix $\Phi^{-1}(t)$ is called the multiplicative inverse of $\Phi(t)$; the multiplicative inverse satisfies $\Phi(t) \Phi^{-1}(t)=\Phi^{-1}(t) \Phi(t)=\mathbf{I}$, where $\mathbf{I}$ is the $2 \times 2$ multiplicative identity.

\section*{CHAPTER 8 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-22.

Answer Problems 1-12 without referring back to the text. Fill in the blank or answer true or false.

\begin{enumerate}
  \item Every second-order linear differential equation can be expressed as a system of two linear first-order differential equations. $\qquad$

  \item If $\mathbf{A}=\binom{1}{2}$ and $\mathbf{B}=\left(\begin{array}{ll}3 & 4\end{array}\right)$, then $\mathbf{A B}=$ $\qquad$ and $\mathbf{B A}=$ . $\qquad$

  \item If $\mathbf{A}=\left(\begin{array}{ll}1 & 2 \\ 3 & 4\end{array}\right)$, then $\mathbf{A}^{-1}=$ $\qquad$ .

  \item If $\mathbf{A}$ is a nonsingular matrix for which $\mathbf{A B}=\mathbf{A C}$, then $\mathbf{B}=\mathbf{C}$. $\qquad$

  \item If $\mathbf{X}_{1}$ is a solution of $\mathbf{X}^{\prime}=\mathbf{A}$ and $\mathbf{X}_{2}$ is a solution of $\mathbf{X}^{\prime}=\mathbf{A X}+\mathbf{F}$, then $\mathbf{X}=\mathbf{X}_{1}+\mathbf{X}_{2}$ is a solution of $\mathbf{X}^{\prime}=\mathbf{A X}+\mathbf{F}$. $\qquad$

  \item A fundamental matrix $\Phi$ of a system $\mathbf{X}^{\prime}=\mathbf{A X}$ is always nonsingular. $\qquad$

  \item Let $\mathbf{A}$ be an $n \times n$ matrix. The eigenvalues of $\mathbf{A}$ are the nonzero solutions of $\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})=0$. $\qquad$

  \item A nonzero constant multiple of an eigenvector is an eigenvector corresponding to the same eigenvalue. $\qquad$

  \item An $n \times 1$ column vector $\mathbf{K}$ with all zero entries is never an eigenvector of an $n \times n$ matrix $\mathbf{A}$. - $\qquad$

  \item Let $\mathbf{A}$ be an $n \times n$ matrix with real entries. If $\lambda$ is a complex eigenvalue, then $\bar{\lambda}$ is also an eigenvalue of $\mathbf{A}$. $\qquad$

  \item An $n \times n$ matrix $\mathbf{A}$ always possesses $n$ linearly independent eigenvectors. $\qquad$

  \item The augmented matrix

\end{enumerate}

$$
\left(\begin{array}{lll|l}
1 & 1 & 1 & 2 \\
0 & 1 & 0 & 3 \\
0 & 0 & 0 & 0
\end{array}\right)
$$

is in reduced row-echelon form. $\qquad$\\
In Problems 13-16 use systematic elimination or determinants to solve the given system.\\
13. $x^{\prime}+y^{\prime}=2 x+2 y+1$\\
14. $\frac{d x}{d t}=2 x+y+t-2$\\
$x^{\prime}+2 y^{\prime}=\quad y+3$\\
$\frac{d y}{d t}=3 x+4 y-4 t$\\
15. $(D-2) x-\quad y=-e^{t}$

$-3 x+(D-4) y=-7 e^{t}$\\
16. $(D+2) x+(D+1) y=\sin 2 t$

$5 x+(D+3) y=\cos 2 t$

In Problems 17 and 18 use the Laplace transform to solve each system.\\
17. $x^{\prime}+y=t$\\
18. $x^{\prime \prime}+y^{\prime \prime}=e^{2 t}$\\
$4 x+y^{\prime}=0$\\
$2 x^{\prime}+y^{\prime \prime}=-e^{2 t}$\\
$x(0)=1, y(0)=2$

$$
\begin{aligned}
& x(0)=0, y(0)=0 \\
& x^{\prime}(0)=0, y^{\prime}(0)=0
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item (a) Write as one column matrix $X$ :
\end{enumerate}

$$
\left(\begin{array}{rrr}
3 & 1 & 1 \\
-1 & 2 & -1 \\
0 & -2 & 4
\end{array}\right)\left(\begin{array}{c}
t \\
t^{2} \\
t^{3}
\end{array}\right)-\left(\begin{array}{r}
2 \\
-2 \\
-1
\end{array}\right)+2 t\left(\begin{array}{l}
1 \\
0 \\
4
\end{array}\right)+2 t^{2}\left(\begin{array}{r}
1 \\
-1 \\
7
\end{array}\right)
$$

(b) Find $d \mathbf{X} / d t$.

\begin{enumerate}
  \setcounter{enumi}{19}
  \item Write the differential equation
\end{enumerate}

$$
3 y^{(4)}-5 y^{\prime \prime}+9 y=6 e^{t}-2 t
$$

as a system of first-order equations in linear normal form.

\begin{enumerate}
  \setcounter{enumi}{20}
  \item Write the system
\end{enumerate}

$$
\begin{aligned}
\left(2 D^{2}+D\right) y-\quad D^{2} x & =\ln t \\
D^{2} y+(D+1) x & =5 t-2
\end{aligned}
$$

as a system of first-order equations in linear normal form.

\begin{enumerate}
  \setcounter{enumi}{21}
  \item Verify that the general solution of the system
\end{enumerate}

$$
\begin{aligned}
& \frac{d x}{d t}=y \\
& \frac{d y}{d t}=-x+2 y-2 \cos t
\end{aligned}
$$

on the interval $(-\infty, \infty)$ is

$$
\mathbf{X}=c_{1}\binom{1}{1} e^{t}+c_{2}\left[\binom{1}{1} t e^{t}+\binom{0}{1} e^{t}\right]+\binom{\sin t}{\cos t}
$$

In Problems 23-28 use the concept of eigenvalues and eigenvectors to solve each system.\\
23. $\frac{d x}{d t}=2 x+y$\\
24. $\frac{d x}{d t}=-4 x+2 y$\\
$\frac{d y}{d t}=-x$\\
$\frac{d y}{d t}=2 x-4 y$\\
25. $\mathbf{X}^{\prime}=\left(\begin{array}{rr}1 & 2 \\ -2 & 1\end{array}\right) \mathbf{X}$\\
26. $\mathbf{X}^{\prime}=\left(\begin{array}{ll}-2 & 5 \\ -2 & 4\end{array}\right) \mathbf{X}$\\
27. $\mathbf{X}^{\prime}=\left(\begin{array}{lll}1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1\end{array}\right) \mathbf{X}$\\
28. $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & -1 & 1 \\ 0 & 1 & 3 \\ 4 & 3 & 1\end{array}\right) \mathbf{X}$

In Problems 29-32 use either undetermined coefficients or variation of parameters to solve the given system.

$$
\begin{aligned}
& \text { 29. } \mathbf{X}^{\prime}=\left(\begin{array}{ll}
2 & 8 \\
0 & 4
\end{array}\right) \mathbf{X}+\binom{2}{16 t} \\
& \text { 30. } \frac{d x}{d t}=x+2 y \\
& \frac{d y}{d t}=-\frac{1}{2} x+y+e^{t} \tan t \\
& \text { 31. } \mathbf{X}^{\prime}=\left(\begin{array}{ll}
-1 & 1 \\
-2 & 1
\end{array}\right) \mathbf{X}+\binom{1}{\cot t} \\
& \text { 32. } \mathbf{X}^{\prime}=\left(\begin{array}{rr}
3 & 1 \\
-1 & 1
\end{array}\right) \mathbf{X}+\binom{-2}{1} e^{2 t}
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-446}
\end{center}

\section*{NUMERICAL METHODS FOR ORDINARY DIFFERENTIAL EQUATIONS}
9.1 Direction Fields

9.2 The Euler Methods

9.3 The Three-Term Taylor Method

9.4 The Runge-Kutta Method

9.5 Multistep Methods

9.6 Errors and Stability

9.7 Higher-Order Equations and Systems

9.8 Second-Order Boundary-Value Problems

Chapter 9 Review

Chapter 9 Review Exercises

INTRODUCTION

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-446(1)}
\end{center}

A differential equation does not have to have a solution, and even if a solution exists, we may not always be able to find (that is, exhibit) an explicit or implicit solution of the equation. In many instances, particularly in the study of nonlinear equations, we may have to be content with an approximation to the solution.

If a solution of a differential equation exists, it represents a locus of points (points connected by a smooth curve) in the Cartesian plane. Beginning in Section 9.2 we shall consider numerical procedures that utilize the differential equation to obtain a sequence of distinct points whose coordinates, as shown in the accompanying figure, approximate the coordinates of the points on the actual solution curve.

Our primary focus in this chapter is on first-order initial-value problems: $d y / d x=f(x, y), y\left(x_{0}\right)=y_{0}$. We shall see that the numerical procedures developed for first-order equations may be adapted to systems of first-order equations in a very natural manner. As a consequence, we can approximate solutions of higher-order initial-value problems by simply reducing the differential equation to a system of first-order equations (see Section 8.3). In Section 9.8 we shall turn our attention to a numerical procedure for linear second-order boundary-value problems.

We begin with the study of direction fields. Although it is not a numerical method, the concept of a direction field enables us to obtain a rough sketch of a solution of a first-order differential equation without actually solving it.

\subsection*{9.1 DIRECTION FIELDS \\
 - Lineal elements \\
 - Isocline \\
 - Slope field}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-447(1)}
\end{center}

Figure 9.1

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-447}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-447(3)}
\end{center}

(b)

Figure 9.2

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-447(2)}
\end{center}

Figure 9.3\\
Lineal Elements Suppose for the moment that we do not know the general solution of the simple equation $y^{\prime}=y$. Specifically, the differential equation implies that the slopes of tangent lines to a solution curve are given by the function $f(x, y)=y$. When $f(x, y)$ is held constant-that is, when


\begin{equation*}
y=c \tag{1}
\end{equation*}


where $c$ is any constant-we are in effect stating that the slope of the tangents to the solution curves is the same constant value along a horizontal line. For example, for $y=2$ let us draw a sequence of short line segments, or lineal elements, each having slope 2 and its midpoint on the line. As shown in Figure 9.1, the solution curves pass through this horizontal line at every point tangent to the lineal elements.

Isoclines and Direction Fields Equation (1) represents a one-parameter family of horizontal lines. In general, any member of the family $f(x, y)=c$ is called an isocline, which literally means a curve along which the inclination (of the tangents) is the same. As the parameter $c$ is varied, we obtain a collection of isoclines on which the lineal elements are judiciously constructed. The totality of these lineal elements is called a direction field, slope field, or lineal element field of the differential equation $y^{\prime}=f(x, y)$. As we see in Figure 9.2(a), the direction field suggests the "flow pattern" for the family of solution curves of the differential equation $y^{\prime}=y$. In particular, if we want the one solution that passes through the point $(0,1)$, then, as indicated in Figure 9.2(b), we construct a curve through this point and passing through the isoclines with the appropriate slopes.

\section*{EXAMPLE 1 Isoclines}
Determine the isoclines for the differential equation

$$
\frac{d y}{d x}=4 x^{2}+9 y^{2}
$$

Solution For $c>0$ the isoclines are the curves

$$
4 x^{2}+9 y^{2}=c
$$

As Figure 9.3 shows, the curves are a concentric family of ellipses with major axis along the $x$-axis.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-448}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-448(1)}
\end{center}

(b)

Figure 9.4

\section*{EXAMPLE 2 Direction Field}
Sketch the direction field and indicate several possible members of the family of solution curves for

$$
\frac{d y}{d x}=\frac{x}{y}
$$

Solution Before sketching the direction field corresponding to the isoclines $x / y=c$ or $y=x / c$, we note that the differential equation gives the following information:

(a) If a solution curve crosses the $x$-axis $(y=0)$, it does so tangent to a vertical lineal element at every point except possibly $(0,0)$.

(b) If a solution curve crosses the $y$-axis $(x=0)$, it does so tangent to a horizontal lineal element at every point except possibly $(0,0)$.

(c) The lineal elements corresponding to the isoclines $c=1$ and $c=-1$ are collinear with the lines $y=x$ and $y=-x$, respectively. Indeed, it is easily verified that these isoclines are both particular solutions of the given differential equation. However, it should be noted that in general isoclines are themselves not solutions to a differential equation. See Example 4.

Figure 9.4(a) shows the direction field and several possible solution curves. Remember that on any particular isocline all the lineal elements are parallel. Also, the lineal elements may be drawn in such a manner as to suggest the flow of a particular curve. In other words, imagine the isoclines so close together that if the lineal elements were connected, we would have a polygonal curve suggestive of the shape of a smooth curve. Alternatively, the lineal elements can be drawn uniformly spaced on their isoclines as shown in the computer-generated version of the same direction field given in Figure 9.4(b). Note, however, that the isoclines themselves are not drawn in part (b).

\section*{EXAMPLE 3 Approximate Solution Curve}
In Section 2.1 we indicated that the differential equation

$$
\frac{d y}{d x}=x^{2}+y^{2}
$$

cannot be solved in terms of elementary functions. Use a direction field to locate an approximate solution satisfying $y(0)=1$.

Solution The isoclines are concentric circles defined by

$$
x^{2}+y^{2}=c, \quad c>0
$$

By choosing $c=\frac{1}{4}, c=1, c=\frac{9}{4}$, and $c=4$, we obtain the circles with radii $\frac{1}{2}, 1, \frac{3}{2}$, and 2 shown in Figure 9.5(a). The lineal elements superimposed on each circle have slope corresponding to the particular value of $c$. It seems plausible from inspection of Figure 9.5(a) that a solution curve of the given initial-value problem might have the shape given in Figure 9.5(b).

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-449(1)}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-449}
\end{center}

(b)

Figure 9.5

The concept of the direction field is used primarily to establish the existence of, and possibly to locate an approximate solution curve for, a first-order differential equation that cannot be solved by the usual standard techniques. However, the preceding discussion is of little value in determining specific values of a solution $y(x)$ at given points. For example, if we want to know the approximate value of $y(0.5)$ for the solution of

$$
\frac{d y}{d x}=x^{2}+y^{2}, \quad y(0)=1
$$

then Figure $9.5(\mathrm{~b})$ can do nothing more than indicate that $y(0.5)$ may be in the same "ball park" as $y=2$.

When the isoclines are straight lines, it is easy to determine which, if any, of these isoclines are also particular solutions of the differential equation.

\section*{EXAMPLE 4 Solution of a DE}
The isoclines of the differential equation


\begin{equation*}
y^{\prime}=2 x+y \tag{2}
\end{equation*}


are the straight lines


\begin{equation*}
2 x+y=c \tag{3}
\end{equation*}


A line in this latter family will be a solution of the differential equation whenever its slope is the same as $c$. In other words, both the original equation and the line satisfy $y^{\prime}=c$. Since the slope of (3) is -2 if we choose $c=-2$, then $2 x+y=-2$ is a solution of $(2)$.

Remarks Sketching a direction field by hand is a straightforward but timeconsuming task. If available to you, computer software is recommended.

\section*{EXERCISES 9.1}
\section*{Answers to odd-numbered problems begin on page A-23.}
In Problems 1-4 use the given computer-generated direction field to sketch several possible solution curves for the indicated differential equation.

\begin{enumerate}
  \item $y^{\prime}=x y$
  \item $y^{\prime}=1-x y$\\
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-449(2)}
\end{enumerate}

Figure 9.6

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $y^{\prime}=y-x$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-450(1)}
\end{center}

Figure 9.8\\
4. $y^{\prime}=\cos x / \sin y$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-450}
\end{center}

Figure 9.9

In Problems 5-14 identify the isoclines for the given differential equation.\\
5. $\frac{d y}{d x}=x+4$\\
6. $\frac{d y}{d x}=2 x+y$\\
7. $\frac{d y}{d x}=x^{2}-y^{2}$\\
8. $\frac{d y}{d x}=y-x^{2}$\\
9. $y^{\prime}=\sqrt{x^{2}+y^{2}+2 y+1}$\\
10. $y^{\prime}=\left(x^{2}+y^{2}\right)^{-1}$\\
11. $\frac{d y}{d x}=y(x+y)$\\
12. $\frac{d y}{d x}=y+e^{x}$\\
13. $\frac{d y}{d x}=\frac{y-1}{x-2}$\\
14. $\frac{d y}{d x}=\frac{x-y}{x+y}$

In Problems 15-22 sketch-or use a computer to obtain-the direction field for the given differential equation. Indicate several possible solution curves.\\
15. $y^{\prime}=x$\\
16. $y^{\prime}=x+y$\\
17. $y \frac{d y}{d x}=-x$\\
18. $\frac{d y}{d x}=\frac{1}{y}$\\
19. $\frac{d y}{d x}=0.2 x^{2}+y$\\
20. $\frac{d y}{d x}=x e^{y}$\\
21. $y^{\prime}=y-\cos \frac{\pi}{2} x$\\
22. $y^{\prime}=1-\frac{y}{x}$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item Formally show that the isoclines for the differential equation
\end{enumerate}

$$
\frac{d y}{d x}=\frac{\alpha x+\beta y}{\gamma x+\delta y}
$$

are straight lines through the origin.

\begin{enumerate}
  \setcounter{enumi}{23}
  \item Show that $y=c x$ is a solution of the differential equation in Problem 23 if and only if $(\beta-\gamma)^{2}+4 \alpha \delta \geq 0$.
\end{enumerate}

In Problems 25-30 find those isoclines that are also solutions of the given differential equation. See Problems 23 and 24 and Example 4.\\
25. $y^{\prime}=3 x+2 y$\\
26. $y^{\prime}=6 x-2 y$\\
27. $y^{\prime}=\frac{2 x}{y}$\\
28. $y^{\prime}=\frac{2 y}{x+y}$\\
29. $\frac{d y}{d x}=\frac{4 x+3 y}{y}$\\
30. $\frac{d y}{d x}=\frac{5 x+10 y}{-4 x+3 y}$

\subsection*{9.2 THE EULER METHODS \\
 - Euler's method $\cdot$ Step size - Absolute error $\cdot$ Relative error \\
 - Percentage relative error - Improved Euler's method}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-451}
\end{center}

Figure 9.10

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-451(1)}
\end{center}

Figure 9.11\\
Euler's Method One of the simplest techniques for approximating solutions of differential equations is known as Euler's method, or the method of tangent lines. Suppose we wish to approximate the solution of the initial-value problem

$$
y^{\prime}=f(x, y), \quad y\left(x_{0}\right)=y_{0}
$$

If $h$ is a positive increment on the $x$-axis, then as Figure 9.10 shows, we can find a point $\left(x_{1}, y_{1}\right)=\left(x_{0}+h, y_{1}\right)$ on the line tangent to the unknown solution curve at $\left(x_{0}, y_{0}\right)$.

By the point-slope form of the equation of a line, we have

$$
\frac{y_{1}-y_{0}}{\left(x_{0}+h\right)-x_{0}}=y_{0}^{\prime} \quad \text { or } \quad y_{1}=y_{0}+h y_{0}^{\prime}
$$

where $y_{0}^{\prime}=f\left(x_{0}, y_{0}\right)$. If we label $x_{0}+h$ by $x_{1}$, then the point $\left(x_{1}, y_{1}\right)$ on the tangent line is an approximation to the point $\left(x_{1}, y\left(x_{1}\right)\right)$ on the solution curve; that is, $y_{1} \approx y\left(x_{1}\right)$. Of course the accuracy of the approximation depends heavily on the size of the increment $h$. Usually we must choose this step size to be "reasonably small."

Assuming a uniform (constant) value of $h$, we can obtain a succession of points $\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{n}, y_{n}\right)$, which we hope are close to the points $\left(x_{1}, y\left(x_{1}\right)\right),\left(x_{2}, y\left(x_{2}\right)\right), \ldots,\left(x_{n}, y\left(x_{n}\right)\right)$. See Figure 9.11. Now using $\left(x_{1}, y_{1}\right)$, we can obtain the value of $y_{2}$, which is the ordinate of a point on a new "tangent" line. We have

$$
\frac{y_{2}-y_{1}}{h}=y_{1}^{\prime} \quad \text { or } \quad y_{2}=y_{1}+h y_{1}^{\prime}=y_{1}+h f\left(x_{1}, y_{1}\right)
$$

In general it follows that


\begin{equation*}
y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right) \tag{1}
\end{equation*}


where $x_{n}=x_{0}+n h$.

As an example, suppose we try the iteration scheme (1) on a differential equation for which we know the explicit solution; in this way we can compare the estimated values $y_{n}$ and the true values $y\left(x_{n}\right)$.

Use Euler's method to obtain an approximation to $y(1.5)$ using first $h=0.1$ and then $h=0.05$.

Solution We first identify $f(x, y)=0.2 x y$ so that (1) becomes

$$
y_{n+1}=y_{n}+h\left(0.2 x_{n} y_{n}\right)
$$

Then for $h=0.1$ we find

$$
y_{1}=y_{0}+(0.1)\left(0.2 x_{0} y_{0}\right)=1+(0.1)[0.2(1)(1)]=1.02
$$

which is an estimate to the value of $y(1.1)$. However, if we use $h=0.05$, it takes two iterations to reach $x=1.1$. We have

$$
\begin{aligned}
& y_{1}=1+(0.05)[0.2(1)(1)]=1.01 \\
& y_{2}=1.01+(0.05)[0.2(1.05)(1.01)]=1.020605
\end{aligned}
$$

Here we note that $y_{1} \approx y(1.05)$ and $y_{2} \approx y(1.1)$. The remainder of the calculations are summarized in Tables 9.1 and 9.2. Each entry is rounded to four decimal places.

Table 9.1 Euler's Method with $h=0.1$

\begin{center}
\begin{tabular}{lllll}
\hline
$x_{n}$ & $y_{n}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
$\%$ Rel. \\
error \\
\end{tabular} \\
\hline
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.10 & 1.0200 & 1.0212 & 0.0012 & 0.12 \\
1.20 & 1.0424 & 1.0450 & 0.0025 & 0.24 \\
1.30 & 1.0675 & 1.0714 & 0.0040 & 0.37 \\
1.40 & 1.0952 & 1.1008 & 0.0055 & 0.50 \\
1.50 & 1.1259 & 1.1331 & 0.0073 & 0.64 \\
\hline
\end{tabular}
\end{center}

Table 9.2 Euler's Method with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
$\%$ Rel. \\
error \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.05 & 1.0100 & 1.0103 & 0.0003 & 0.03 \\
1.10 & 1.0206 & 1.0212 & 0.0006 & 0.06 \\
1.15 & 1.0318 & 1.0328 & 0.0009 & 0.09 \\
1.20 & 1.0437 & 1.0450 & 0.0013 & 0.12 \\
1.25 & 1.0562 & 1.0579 & 0.0016 & 0.16 \\
1.30 & 1.0694 & 1.0714 & 0.0020 & 0.19 \\
1.35 & 1.0833 & 1.0857 & 0.0024 & 0.22 \\
1.40 & 1.0980 & 1.1008 & 0.0028 & 0.25 \\
1.45 & 1.1133 & 1.1166 & 0.0032 & 0.29 \\
1.50 & 1.1295 & 1.1331 & 0.0037 & 0.32 \\
\hline
\end{tabular}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-452}
\end{center}

Figure 9.12\\
In Example 1 the true values were calculated from the known solution $y=e^{0.1\left(x^{2}-1\right)}$. Also, the absolute error is defined to be

$\mid$ true value - approximation $\mid$.

The relative error and the percentage relative error are, in turn,

$$
\begin{gathered}
\frac{\mid \text { true value }- \text { approximation } \mid}{\mid \text { true value } \mid} \\
\text { and } \frac{\mid \text { true value }- \text { approximation } \mid}{\mid \text { true value } \mid} \times 100=\frac{\text { absolute error }}{\mid \text { true value } \mid} \times 100 \text {. }
\end{gathered}
$$

Computer software enables us to examine approximations to the graph of the solution $y(x)$ of an initial-value problem by plotting straight lines through the points $\left(x_{n}, y_{n}\right)$ generated by Euler's method. In Figure 9.12 we have compared, on the interval $[1,3]$, the graph of the exact solution of the initial-value problem in Example 1 with the graphs obtained from Euler's method using the\\
step sizes $h=1, h=0.5$, and $h=0.1$. It is apparent from the figure that the approximation improves as the step size decreases.

Although we see that the percentage relative error in Tables 9.1 and 9.2 is growing, it does not appear to be that bad. But you should not be deceived by Example 1 and Figure 9.12. Watch what happens in the next example when we simply change the coefficient 0.2 of the differential equation in Example 1 to the number 2 .

\section*{EXAMPLE 2 Euler's Method}
Use Euler's method to obtain the approximate value of $y(1.5)$ for the solution of $y^{\prime}=2 x y, y(1)=1$.

Solution You should verify that the exact or analytic solution is now $y=e^{x^{2}-1}$. Proceeding as in Example 1, we obtain the following results.

Table 9.3 Euler's Method with $h=0.1$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
\% Rel. \\
error \\
\end{tabular} \\
\hline
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.10 & 1.2000 & 1.2337 & 0.0337 & 2.73 \\
1.20 & 1.4640 & 1.5527 & 0.0887 & 5.71 \\
1.30 & 1.8154 & 1.9937 & 0.1784 & 8.95 \\
1.40 & 2.2874 & 2.6117 & 0.3244 & 12.42 \\
1.50 & 2.9278 & 3.4904 & 0.5625 & 16.12 \\
\hline
\end{tabular}
\end{center}

Table 9.4 Euler's Method with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
\% Rel. \\
error \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.05 & 1.1000 & 1.1079 & 0.0079 & 0.72 \\
1.10 & 1.2155 & 1.2337 & 0.0182 & 1.47 \\
1.15 & 1.3492 & 1.3806 & 0.0314 & 2.27 \\
1.20 & 1.5044 & 1.5527 & 0.0483 & 3.11 \\
1.25 & 1.6849 & 1.7551 & 0.0702 & 4.00 \\
1.30 & 1.8955 & 1.9937 & 0.0982 & 4.93 \\
1.35 & 2.1419 & 2.2762 & 0.1343 & 5.90 \\
1.40 & 2.4311 & 2.6117 & 0.1806 & 6.92 \\
1.45 & 2.7714 & 3.0117 & 0.2403 & 7.98 \\
1.50 & 3.1733 & 3.4904 & 0.3171 & 9.08 \\
\hline
 &  &  &  &  \\
\hline
\end{tabular}
\end{center}

In this case, with a step size $h=0.1$, a $16 \%$ relative error in the calculation of the approximation to $y(1.5)$ is totally unacceptable. At the expense of doubling the number of calculations, a slight improvement in accuracy is obtained by halving the step size to $h=0.05$.

We will discuss the errors for Euler's method in detail in Section 9.6.

Of course in many instances we may not know the solution of a particular differential equation, or for that matter whether a solution of an initial-value problem actually exists. The following nonlinear equation does possess a solution in closed form, but we leave it as an exercise for you to find it. (See Problem 1.)

\section*{EXAMPLE 3 Euler's Method}
Use Euler's method to obtain the approximate value of $y(0.5)$ for the solution of $y^{\prime}=(x+y-1)^{2}, y(0)=2$.

Table 9.5 Euler's

Method with $h=0.1$

\begin{center}
\begin{tabular}{ll}
\hline
$x_{n}$ & $y_{\boldsymbol{n}}$ \\
\hline
0.00 & 2.0000 \\
0.10 & 2.1000 \\
0.20 & 2.2440 \\
0.30 & 2.4525 \\
0.40 & 2.7596 \\
0.50 & 3.2261 \\
\hline
\end{tabular}
\end{center}

Table 9.6 Euler's

Method with $h=0.05$

\begin{center}
\begin{tabular}{ll}
\hline
$x_{n}$ & $y_{n}$ \\
\hline
0.00 & 2.0000 \\
0.05 & 2.0500 \\
0.10 & 2.1105 \\
0.15 & 2.1838 \\
0.20 & 2.2727 \\
0.25 & 2.3812 \\
0.30 & 2.5142 \\
0.35 & 2.6788 \\
0.40 & 2.8845 \\
0.45 & 3.1455 \\
0.50 & 3.4823 \\
\hline
\end{tabular}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-454}
\end{center}

Figure 9.13\\
Solution For $n=0$ and $h=0.1$ we have

$$
y_{1}=y_{0}+(0.1)\left(x_{0}+y_{0}-1\right)^{2}=2+(0.1)(1)^{2}=2.1
$$

The remaining calculations are summarized in Tables 9.5 and 9.6 for $h=0.1$ and $h=0.05$, respectively.

We may want greater accuracy than that displayed, say, in Table 9.4, and so we could try a step size even smaller than $h=0.05$. However, rather than resorting to this extra labor, it probably would be more advantageous to employ an alternative numerical procedure. Euler's formula by itself, though attractive in its simplicity, is seldom used in serious calculations.

Improved Euler's Method The formula


\begin{gather*}
y_{n+1}=y_{n}+h \frac{f\left(x_{n}, y_{n}\right)+f\left(x_{n+1}, y_{n+1}^{*}\right)}{2} \\
y_{n+1}^{*}=y_{n}+h f\left(x_{n}, y_{n}\right) \tag{2}
\end{gather*}


where

is known as the improved Euler's formula, or Heun's formula. The values $f\left(x_{n}, y_{n}\right)$ and $f\left(x_{n+1}, y_{n+1}^{*}\right)$ are approximations to the slope of the curve at $\left(x_{n}, y\left(x_{n}\right)\right)$ and $\left(x_{n+1}, y\left(x_{n+1}\right)\right)$, and consequently the quotient

$$
\frac{f\left(x_{n}, y_{n}\right)+f\left(x_{n+1}, y_{n+1}^{*}\right)}{2}
$$

can be interpreted as an average slope on the interval between $x_{n}$ and $x_{n+1}$.

The equations in (2) can be readily visualized. In Figure 9.13 we show the case in which $n=0$. Note that

$$
f\left(x_{0}, y_{0}\right) \text { and } f\left(x_{1}, y_{1}^{*}\right)
$$

are slopes of the indicated straight lines passing through the points $\left(x_{0}, y_{0}\right)$ and $\left(x_{1}, y_{1}^{*}\right)$, respectively. By taking an average of these slopes, we obtain the slope of the dashed skew lines. Rather than advancing along the line with slope $m=f\left(x_{0}, y_{0}\right)$ to the point with ordinate $y_{1}^{*}$ obtained by the usual Euler's method, we advance along the line through $\left(x_{0}, y_{0}\right)$ with slope $m_{\text {ave }}$ until we reach $x_{1}$. It seems plausible from inspection of the figure that $y_{1}$ is an improvement over $y_{1}^{*}$. In fact, in Section 9.6 we will see that the improved Euler's method is more accurate than Euler's method.

We might also say that the value of

$$
y_{1}^{*}=y_{0}+h f\left(x_{0}, y_{0}\right)
$$

predicts a value of $y\left(x_{1}\right)$, whereas

$$
y_{1}=y_{0}+h \frac{f\left(x_{0}, y_{0}\right)+f\left(x_{1}, y_{1}^{*}\right)}{2}
$$

corrects this estimate.

\section*{EXAMPLE 4 Improved Euler's Method}
Use the improved Euler's formula to obtain the approximate value of $y(1.5)$ for the solution of the initial-value problem in Example 2. Compare the results for $h=0.1$ and $h=0.05$.

Solution $\quad$ For $n=0$ and $h=0.1$ we first compute

$$
y_{1}^{*}=y_{0}+(0.1)\left(2 x_{0} y_{0}\right)=1.2
$$

Then from (2)

$$
y_{1}=y_{0}+(0.1) \frac{2 x_{0} y_{0}+2 x_{1} y_{1}^{*}}{2}=1+(0.1) \frac{2(1)(1)+2(1.1)(1.2)}{2}=1.232
$$

The comparative values of the calculations for $h=0.1$ and $h=0.5$ are given in Tables 9.7 and 9.8 , respectively.

Table 9.7 Improved Euler's Method with $h=0.1$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
\% Rel. \\
error \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.10 & 1.2320 & 1.2337 & 0.0017 & 0.14 \\
1.20 & 1.5479 & 1.5527 & 0.0048 & 0.31 \\
1.30 & 1.9832 & 1.9937 & 0.0106 & 0.53 \\
1.40 & 2.5908 & 2.6117 & 0.0209 & 0.80 \\
1.50 & 3.4509 & 3.4904 & 0.0394 & 1.13 \\
\hline
\end{tabular}
\end{center}

Table 9.8 Improved Euler's Method with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
\% Rel. \\
error \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.05 & 1.1077 & 1.1079 & 0.0002 & 0.02 \\
1.10 & 1.2332 & 1.2337 & 0.0004 & 0.04 \\
1.15 & 1.3798 & 1.3806 & 0.0008 & 0.06 \\
1.20 & 1.5514 & 1.5527 & 0.0013 & 0.08 \\
1.25 & 1.7531 & 1.7551 & 0.0020 & 0.11 \\
1.30 & 1.9909 & 1.9937 & 0.0029 & 0.14 \\
1.35 & 2.2721 & 2.2762 & 0.0041 & 0.18 \\
1.40 & 2.6060 & 2.6117 & 0.0057 & 0.22 \\
1.45 & 3.0038 & 3.0117 & 0.0079 & 0.26 \\
1.50 & 3.4795 & 3.4904 & 0.0108 & 0.31 \\
\hline
\end{tabular}
\end{center}

A brief word of caution is in order here. We cannot compute all the values of $y_{n}^{*}$ first and then substitute these values in the first formula of (2). In other words, we cannot use the data in Table 9.3 to help construct the values in Table 9.7. Why not?

\section*{EXAMPLE 5 Improved Euler's Method}
Use the improved Euler's formula to obtain the approximate value of $y(0.5)$ for the solution of the initial-value problem in Example 3.

Table 9.9 Improved Euler's Method with $h=0.1$

\begin{center}
\begin{tabular}{ll}
\hline
$x_{n}$ & $y_{n}$ \\
\hline
0.00 & 2.0000 \\
0.10 & 2.1220 \\
0.20 & 2.3049 \\
0.30 & 2.5858 \\
0.40 & 3.0378 \\
0.50 & 3.8254 \\
\hline
\end{tabular}
\end{center}

Table 9.10 Improved Euler's Method with $h=0.05$

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 2.0000 \\
0.05 & 2.0553 \\
0.10 & 2.1228 \\
0.15 & 2.2056 \\
0.20 & 2.3075 \\
0.25 & 2.4342 \\
0.30 & 2.5931 \\
0.35 & 2.7953 \\
0.40 & 3.0574 \\
0.45 & 3.4057 \\
0.50 & 3.8840 \\
\hline
\end{tabular}
\end{center}

Solution $\quad$ For $n=0$ and $h=0.1$ we have

$$
\begin{gathered}
y_{1}^{*}=y_{0}+(0.1)\left(x_{0}+y_{0}-1\right)^{2}=2.1 \\
y_{1}=y_{0}+(0.1) \frac{\left(x_{0}+y_{0}-1\right)^{2}+\left(x_{1}+y_{1}^{*}-1\right)^{2}}{2} \\
=2+(0.1) \frac{1+1.44}{2}=2.122
\end{gathered}
$$

and so

The remaining calculations are summarized in Tables 9.9 and 9.10 for $h=0.1$ and $h=0.05$, respectively.

\section*{EXERCISES 9.2}
\section*{Answers to odd-numbered problems begin on page A-24.}
\begin{enumerate}
  \item Solve the initial-value problem
\end{enumerate}

$$
y^{\prime}=(x+y-1)^{2}, \quad y(0)=2
$$

in terms of elementary functions.

\begin{enumerate}
  \setcounter{enumi}{1}
  \item Let $y(x)$ be the solution of the initial-value problem given in Problem 1 . Round to four decimal places as you compute the exact values of $y(0.1)$, $y(0.2), y(0.3), y(0.4)$, and $y(0.5)$. Compare these values with the entries in Tables 9.5, 9.6, 9.9, and 9.10.
\end{enumerate}

Given the initial-value problems in Problems 3-12, use Euler's formula to obtain a four-decimal approximation to the indicated value. First use (a) $h=0.1$ and then (b) $h=0.05$.\\
3. $y^{\prime}=2 x-3 y+1, y(1)=5 ; \quad y(1.5)$\\
4. $y^{\prime}=4 x-2 y, y(0)=2 ; \quad y(0.5)$\\
5. $y^{\prime}=1+y^{2}, y(0)=0 ; \quad y(0.5)$\\
6. $y^{\prime}=x^{2}+y^{2}, y(0)=1 ; \quad y(0.5)$\\
7. $y^{\prime}=e^{-y}, y(0)=0 ; \quad y(0.5)$\\
8. $y^{\prime}=x+y^{2}, y(0)=0 ; \quad y(0.5)$\\
9. $y^{\prime}=(x-y)^{2}, y(0)=0.5 ; \quad y(0.5)$\\
10. $y^{\prime}=x y+\sqrt{y}, y(0)=1 ; \quad y(0.5)$\\
11. $y^{\prime}=x y^{2}-\frac{y}{x}, y(1)=1 ; \quad y(1.5)$\\
12. $y^{\prime}=y-y^{2}, y(0)=0.5 ; \quad y(0.5)$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item As parts (a)-(e) of this problem, repeat the calculations of Problems 3, $5,7,9$, and 11 using the improved Euler's formula.

  \item As parts (a)-(e) of this problem, repeat the calculations of Problems 4, $6,8,10$, and 12 using the improved Euler's formula.

  \item Although it may not be obvious from the differential equation, its solution could "behave badly" near a point $x$ at which we wish to approximate $y(x)$. Numerical procedures may then give widely differing results near this point. Let $y(x)$ be the solution of the initial-value problem

\end{enumerate}

$$
y^{\prime}=x^{2}+y^{3}, \quad y(1)=1
$$

Using the step size $h=0.1$, compare the results obtained from Euler's formula with the results from the improved Euler's formula in the approximation of $y(1.4)$.

\begin{enumerate}
  \setcounter{enumi}{15}
  \item Derive the basic Euler's formula by integrating both sides of the equation $y^{\prime}=f(x, y)$ on the interval $x_{n} \leq x \leq x_{n+1}$. Approximate the integral of the right side by replacing the function $f(x, y)$ by its value at the left endpoint of the interval of integration.

  \item By following the procedure outlined in Problem 16, derive the improved Euler's formula. [Hint: Replace the integrand of the right side by the average of its values at the endpoints of the interval of integration.]

\end{enumerate}

\subsection*{9.3 THE THREE-TERM TAYLOR METHOD \\
 - Taylor series expansion \\
 - Taylor's method}
The numerical method considered in this section, the three-term Taylor method, is more of theoretical interest than of practical importance since the results obtained using the following formula (5) do not differ substantially from those obtained using the improved Euler's method.

In this study of numerical solutions of differential equations, many computational algorithms can be derived from a Taylor series expansion. Recall from calculus that the form of this expansion centered at a point $x=a$ is


\begin{equation*}
y(x)=y(a)+y^{\prime}(a) \frac{(x-a)}{1!}+y^{\prime \prime}(a) \frac{(x-a)^{2}}{2!}+\cdots \tag{1}
\end{equation*}


It is understood that the function $y(x)$ possesses derivatives of all orders and that the series (1) converges in some interval defined by $|x-a|<R$. Notice, in particular, that if we set $a=x_{n}$ and $x=x_{n}+h$, then (1) becomes


\begin{equation*}
y\left(x_{n}+h\right)=y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) h+y^{\prime \prime}\left(x_{n}\right) \frac{h^{2}}{2}+\cdots \tag{2}
\end{equation*}


Euler's Method Revisited Furthermore, let us now assume that the function $y(x)$ is a solution of the first-order differential equation $y^{\prime}=f(x, y)$. If we then truncate the series (2) after, say, two terms, we obtain the approximation


\begin{equation*}
y\left(x_{n}+h\right) \approx y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) h \text { or } \quad y\left(x_{n}+h\right) \approx y\left(x_{n}\right)+f\left(x_{n}, y\left(x_{n}\right)\right) h \tag{3}
\end{equation*}


Observe that we can obtain Euler's formula


\begin{equation*}
y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right) \tag{4}
\end{equation*}


of the preceding section by replacing $y\left(x_{n}+h\right)$ and $y\left(x_{n}\right)$ in (3) by their approximations $y_{n+1}$ and $y_{n}$, respectively. The approximation symbol $\approx$ is replaced by an equality since we are defining the left side of (4) by the numbers obtained from the right-hand member.

Taylor's Method By retaining three terms in the series (2), we can write

$$
y\left(x_{n}+h\right) \approx y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) h+y^{\prime \prime}\left(x_{n}\right) \frac{h^{2}}{2}
$$

After the replacements noted in the preceding material, it follows that


\begin{equation*}
y_{n+1}=y_{n}+y_{n}^{\prime} h+y_{n}^{\prime \prime} \frac{h^{2}}{2} \tag{5}
\end{equation*}


The second derivative $y^{\prime \prime}$ can be obtained by differentiating $y^{\prime}=f(x, y)$.

At this point let us reexamine two initial-value problems from Section 9.2.

\section*{EXAMPLE 1 Taylor's Method}
Use the three-term Taylor formula to obtain the approximate value of $y(1.5)$ for the solution of $y^{\prime}=2 x y, y(1)=1$. Compare the results for $h=0.1$ and $h=0.05$.

Solution Since $y^{\prime}=2 x y$, it follows by the product rule that $y^{\prime \prime}=$ $2 x y^{\prime}+2 y$. Thus, for example, when $h=0.1, n=0$, we can first calculate

and then

$$
\begin{aligned}
& y_{0}^{\prime}=2 x_{0} y_{0}=2(1)(1)=2 \\
& y_{0}^{\prime \prime}=2 x_{0} y_{0}^{\prime}+2 y_{0}=2(1)(2)+2(1)=6
\end{aligned}
$$

Hence (5) becomes

$$
y_{1}=y_{0}+y_{0}^{\prime}(0.1)+y_{0}^{\prime \prime} \frac{(0.1)^{2}}{2}=1+2(0.1)+6(0.005)=1.23
$$

The results of the iteration, along with the comparative exact values, are summarized in Tables 9.11 and 9.12 .

Table 9.11 Three-Term Taylor Method with $h=0.1$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & True value & Abs. error & \% Rel. error \\
\hline
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.10 & 1.2300 & 1.2337 & 0.0037 & 0.30 \\
1.20 & 1.5427 & 1.5527 & 0.0100 & 0.65 \\
1.30 & 1.9728 & 1.9937 & 0.0210 & 1.05 \\
1.40 & 2.5721 & 2.6117 & 0.0396 & 1.52 \\
1.50 & 3.4188 & 3.4904 & 0.0715 & 2.05 \\
\hline
\end{tabular}
\end{center}

Table 9.13 ThreeTerm Taylor Method with $h=0.1$

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 2.0000 \\
0.10 & 2.1200 \\
0.20 & 2.2992 \\
0.30 & 2.5726 \\
0.40 & 3.0077 \\
0.50 & 3.7511 \\
\hline
\end{tabular}
\end{center}

Table 9.14 ThreeTerm Taylor Method with $h=0.05$

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 2.0000 \\
0.05 & 2.0550 \\
0.10 & 2.1222 \\
0.15 & 2.2045 \\
0.20 & 2.3058 \\
0.25 & 2.4315 \\
0.30 & 2.5890 \\
0.35 & 2.7889 \\
0.40 & 3.0475 \\
0.45 & 3.3898 \\
0.50 & 3.8574 \\
\hline
\end{tabular}
\end{center}

Table 9.12 Three-Term Taylor Method with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & True value & Abs. error & \% Rel. error \\
\hline
1.00 & 1.0000 & 1.0000 & 0.0000 &  \\
1.05 & 1.1075 & 1.1079 & 0.0004 & 0.00 \\
1.10 & 1.2327 & 1.2337 & 0.0010 & 0.08 \\
1.15 & 1.3788 & 1.3806 & 0.0018 & 0.13 \\
1.20 & 1.5499 & 1.5527 & 0.0028 & 0.18 \\
1.25 & 1.7509 & 1.7551 & 0.0041 & 0.23 \\
1.30 & 1.9879 & 1.9937 & 0.0059 & 0.29 \\
1.35 & 2.2681 & 2.2762 & 0.0081 & 0.36 \\
1.40 & 2.6006 & 2.6117 & 0.0111 & 0.43 \\
1.45 & 2.9967 & 3.0117 & 0.0150 & 0.50 \\
1.50 & 3.4702 & 3.4904 & 0.0202 & 0.58 \\
\hline
\end{tabular}
\end{center}

\section*{EXAMPLE 2 Taylor's Method}
Use the three-term Taylor formula to obtain the approximate value of $y(0.5)$ for the solution of $y^{\prime}=(x+y-1)^{2}, y(0)=2$.

Solution In this case we compute $y^{\prime \prime}$ by the power rule. We have

$$
y^{\prime \prime}=2(x+y-1)\left(1+y^{\prime}\right)
$$

The results are summarized in Tables 9.13 and 9.14 for $h=0.1$ and $h=0.05$, respectively.

A comparison of the last two examples with the corresponding results obtained from the improved Euler's method shows no startling dissimilarities. In fact, when $f(x, y)$ is linear in both variables $x$ and $y$, Taylor's method gives the same values of $y_{n}$ as the improved Euler's method for a given value of $h$. See Problems 12 and 13. In the error analysis given in Section 9.6 we will see that these two methods have the same accuracy.

\section*{EXERCISES 9.3}
\section*{Answers to odd-numbered problems begin on page A-25.}
Given the initial-value problems in Problems 1-10, use the three-term Taylor formula to obtain a four-decimal approximation to the indicated value. First use (a) $h=0.1$ and then (b) $h=0.05$.

\begin{enumerate}
  \item $y^{\prime}=2 x-3 y+1, y(1)=5 ; \quad y(1.5)$

  \item $y^{\prime}=4 x-2 y, y(0)=2 ; \quad y(0.5)$

  \item $y^{\prime}=1+y^{2}, y(0)=0 ; \quad y(0.5)$

  \item $y^{\prime}=x^{2}+y^{2}, y(0)=1 ; \quad y(0.5)$

  \item $y^{\prime}=e^{-y}, y(0)=0 ; \quad y(0.5)$

  \item $y^{\prime}=x+y^{2}, y(0)=0 ; \quad y(0.5)$

  \item $y^{\prime}=(x-y)^{2}, y(0)=0.5 ; \quad y(0.5)$

  \item $y^{\prime}=x y+\sqrt{y}, y(0)=1 ; \quad y(0.5)$

  \item $y^{\prime}=x y^{2}-\frac{y}{x}, y(1)=1 ; \quad y(1.5)$

  \item $y^{\prime}=y-y^{2}, y(0)=0.5 ; \quad y(0.5)$

  \item Let $y(x)$ be the solution of the initial-value problem

\end{enumerate}

$$
y^{\prime}=x^{2}+y^{3}, \quad y(1)=1
$$

Use $h=0.1$ and the three-term Taylor formula to obtain an approximation to $y$ (1.4). Compare your answer with the results obtained in Problem 15 of Exercises 9.2.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item Consider the differential equation $y^{\prime}=f(x, y)$, where $f$ is linear in $x$ and $y$. In this case prove that the improved Euler's formula is the same as the three-term Taylor formula. [Hint: Recall from calculus that a Taylor series for a function $g$ of two variables is
\end{enumerate}

$$
\begin{aligned}
g(a+h, b+k)= & g(a, b)+g_{x}(a, b) h+g_{y}(a, b) k \\
& +\left.\frac{1}{2}\left(h^{2} g_{x x}+2 h k g_{x y}+k^{2} g_{y y}\right)\right|_{(a, b)} \\
& + \text { terms involving higher-order derivatives. }
\end{aligned}
$$

Apply this result to $f\left(x_{n}+h, y_{n}+h f\left(x_{n}, y_{n}\right)\right)$ in the improved Euler's formula. Also use the fact that $y^{\prime \prime}(x)=(d / d x) y^{\prime}(x)=f_{x}+f_{y} y^{\prime}$.]

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Compare the approximate values of $y(1.5)$ for
\end{enumerate}

$$
y^{\prime}=x+y-1, \quad y(1)=5
$$

using the three-term Taylor method and the improved Euler's method with $h=0.1$. Solve the initial-value problem and compute the true values $y\left(x_{n}\right), n=0,1, \ldots, 5$.

\subsection*{9.4 THE RUNGE-KUTTA METHOD}
Probably one of the most popular as well as most accurate numerical procedures used in obtaining approximate solutions to differential equations is the fourthorder Runge-Kutta method.* As the name suggests, there are Runge-Kutta methods of different orders.
\footnotetext{\begin{itemize}
  \item CARL D. T. RUNGE (I856-1927) A German professor of applied mathematics at the University of Göttingen, Runge devised this numerical method around I895. (M. W. Kutta expanded on this work in 1901.) In mathematics Runge also did notable work in the field of Diophantine equations. In physics Runge is remembered for his work on the Zeeman effect (the spectral lines in the emission spectrum of an element are affected by the presence of a magnetic field).
\end{itemize}

MARTIN W. KUTTA (1867-1944) Also a German applied mathematician, Kutta made significant contributions to the field of aerodynamics.
}

For the moment let us consider a second-order procedure. This consists of finding constants $a, b, \alpha$, and $\beta$ such that the formula

where


\begin{align*}
y_{n+1} & =y_{n}+a k_{1}+b k_{2}  \tag{1}\\
k_{1} & =h f\left(x_{n}, y_{n}\right) \\
k_{2} & =h f\left(x_{n}+\alpha h, y_{n}+\beta k_{1}\right) \tag{2}
\end{align*}


agrees with a Taylor series expansion to as many terms as possible. The obvious purpose is to achieve the accuracy of the Taylor method without having to compute higher-order derivatives. Now it can be shown that whenever the constants satisfy $a+b=1, b \alpha=\frac{1}{2}, b \beta=\frac{1}{2}$, (1) agrees with a Taylor expansion out to the $h^{2}$, or third, term. It should be of interest to observe that when $a=\frac{1}{2}, b=\frac{1}{2}, \alpha=1, \beta=1$, then (1) reduces to the improved Euler's method. Thus we can conclude that the three-term Taylor formula is essentially equivalent to the improved Euler's formula. Also, the basic Euler's method is a first-order Runge-Kutta procedure.

Notice too that the sum $a k_{1}+b k_{2}, a+b=1$ in equation (1) is simply a weighted average of $k_{1}$ and $k_{2}$. The numbers $k_{1}$ and $k_{2}$ are multiples of approximations to the slope at two different points.

Fourth-Order Runge-Kutta Formula The fourth-order Runge-Kutta method consists of determining appropriate constants so that a formula such as

$$
y_{n+1}=y_{n}+a k_{1}+b k_{2}+c k_{3}+d k_{4}
$$

agrees with a Taylor expansion out to the $h^{4}$, or fifth, term. As in (2), the $k_{i}$ are constant multiples of $f(x, y)$ evaluated at select points. The derivation of the actual method is tedious, to say the least, so we state the results:


\begin{align*}
y_{n+1} & =y_{n}+\frac{1}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right) \\
k_{1} & =h f\left(x_{n}, y_{n}\right) \\
k_{2} & =h f\left(x_{n}+\frac{1}{2} h, y_{n}+\frac{1}{2} k_{1}\right)  \tag{3}\\
k_{3} & =h f\left(x_{n}+\frac{1}{2} h, y_{n}+\frac{1}{2} k_{2}\right) \\
k_{4} & =h f\left(x_{n}+h, y_{n}+k_{3}\right) .
\end{align*}


You are advised to look carefully at the formulas in (3); note that $k_{2}$ depends on $k_{1}, k_{3}$ depends on $k_{2}$, and so on. Also, $k_{2}$ and $k_{3}$ involve approximations to the slope at the midpoint of the interval between $x_{n}$ and $x_{n+1}=x_{n}+h$.

\section*{EXAMPLE 1 Fourth-Order Runge-Kutta Method}
Use the Runge-Kutta method with $h=0.1$ to obtain an approximation to $y(1.5)$ for the solution of $y^{\prime}=2 x y, y(1)=1$.

Solution For the sake of illustration let us compute the case when $n=0$. From (3) we find

$$
\begin{aligned}
k_{1} & =(0.1) f\left(x_{0}, y_{0}\right)=(0.1)\left(2 x_{0} y_{0}\right)=0.2 \\
k_{2} & =(0.1) f\left(x_{0}+\frac{1}{2}(0.1), y_{0}+\frac{1}{2}(0.2)\right) \\
& =(0.1) 2\left(x_{0}+\frac{1}{2}(0.1)\right)\left(y_{0}+\frac{1}{2}(0.2)\right)=0.231
\end{aligned}
$$

$$
\begin{aligned}
k_{3} & =(0.1) f\left(x_{0}+\frac{1}{2}(0.1), y_{0}+\frac{1}{2}(0.231)\right) \\
& =(0.1) 2\left(x_{0}+\frac{1}{2}(0.1)\right)\left(y_{0}+\frac{1}{2}(0.231)\right)=0.234255 \\
k_{4} & =(0.1) f\left(x_{0}+0.1, y_{0}+0.234255\right) \\
& =(0.1) 2\left(x_{0}+0.1\right)\left(y_{0}+0.234255\right)=0.2715361
\end{aligned}
$$

and therefore

$$
\begin{aligned}
y_{1} & =y_{0}+\frac{1}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right) \\
& =1+\frac{1}{6}(0.2+2(0.231)+2(0.234255)+0.2715361)=1.23367435
\end{aligned}
$$

Table 9.15, whose entries are rounded to four decimal places, should convince you why the Runge-Kutta method is so popular. Of course there is no need to use any smaller step size. The reason for the high accuracy of the RungeKutta method will be seen in Section 9.6.

Table 9.15 Runge-Kutta Method with $h=0.1$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & \begin{tabular}{l}
True \\
value \\
\end{tabular} & \begin{tabular}{l}
Abs. \\
error \\
\end{tabular} & \begin{tabular}{l}
\% Rel. \\
error \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 1.0000 & 1.0000 & 0.0000 & 0.00 \\
1.10 & 1.2337 & 1.2337 & 0.0000 & 0.00 \\
1.20 & 1.5527 & 1.5527 & 0.0000 & 0.00 \\
1.30 & 1.9937 & 1.9937 & 0.0000 & 0.00 \\
1.40 & 2.6116 & 2.6117 & 0.0001 & 0.00 \\
1.50 & 3.4902 & 3.4904 & 0.0001 & 0.00 \\
\hline
\end{tabular}
\end{center}

You might be interested in inspecting Tables 9.16 and 9.17 at this point.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{6}{|c|}{Comparison of Numerical Methods with $h=0.1$} & \multicolumn{6}{|c|}{Comparison of Numerical Methods with $h=0.05$} \\
\hline
$x_{n}$ & Euler's & \begin{tabular}{l}
Improved \\
Euler's \\
\end{tabular} & \begin{tabular}{l}
Three- \\
Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} & \begin{tabular}{l}
True \\
value \\
\end{tabular} & $x_{n}$ & Euler's & \begin{tabular}{l}
Improved \\
Euler's \\
\end{tabular} & \begin{tabular}{l}
Three- \\
Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} & \begin{tabular}{l}
True \\
value \\
\end{tabular} \\
\hline
1.00 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.00 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline
1.10 & 1.2000 & 1.2320 & 1.2300 & 1.2337 & 1.2337 & 1.05 & 1.1000 & 1.1077 & 1.1075 & 1.1079 & 1.1079 \\
\hline
1.20 & 1.4640 & 1.5479 & 1.5427 & 1.5527 & 1.5527 & 1.10 & 1.2155 & 1.2332 & 1.2327 & 1.2337 & 1.2337 \\
\hline
1.30 & 1.8154 & 1.9832 & 1.9728 & 1.9937 & 1.9937 & 1.15 & 1.3492 & 1.3798 & 1.3788 & 1.3806 & 1.3806 \\
\hline
1.40 & 2.2874 & 2.5908 & 2.5721 & 2.6116 & 2.6117 & 1.20 & 1.5044 & 1.5514 & 1.5499 & 1.5527 & 1.5527 \\
\hline
\multirow[t]{6}{*}{1.50} & 2.9278 & 3.4509 & 3.4188 & 3.4902 & 3.4904 & 1.25 & 1.6849 & 1.7531 & 1.7509 & 1.7551 & 1.7551 \\
\hline
 &  &  &  &  &  & 1.30 & 1.8955 & 1.9909 & 1.9879 & 1.9937 & 1.9937 \\
\hline
 &  &  &  &  &  & 1.35 & 2.1419 & 2.2721 & 2.2681 & 2.2762 & 2.2762 \\
\hline
 &  &  &  &  &  & 1.40 & 2.4311 & 2.6060 & 2.6006 & 2.6117 & 2.6117 \\
\hline
 &  &  &  &  &  & 1.45 & 2.7714 & 3.0038 & 2.9967 & 3.0117 & 3.0117 \\
\hline
 &  &  &  &  &  & 1.50 & 3.1733 & 3.4795 & 3.4702 & 3.4903 & 3.4904 \\
\hline
\end{tabular}
\end{center}

These tables compare the results obtained from applying the various formulas that we have examined to the two specific problems

$$
y^{\prime}=2 x y, \quad y(1)=1 \quad \text { and } \quad y^{\prime}=(x+y-1)^{2}, \quad y(0)=2
$$

that we have considered throughout the last three sections.

Table $9.16 \quad y^{\prime}=2 x y, y(1)=1$

Table 9.17 $y^{\prime}=(x+y-1)^{2}, y(0)=2$

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{6}{|c|}{Comparison of Numerical Methods with $h=0.1$} & \multicolumn{6}{|c|}{Comparison of Numerical Methods with $h=0.05$} \\
\hline
$x_{n}$ & Euler's & \begin{tabular}{l}
Improved \\
Euler's \\
\end{tabular} & \begin{tabular}{l}
Three- \\
Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} & \begin{tabular}{l}
True \\
value \\
\end{tabular} & $x_{n}$ & Euler's & \begin{tabular}{l}
Improved \\
Euler's \\
\end{tabular} & \begin{tabular}{l}
Three- \\
Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} & \begin{tabular}{l}
True \\
value \\
\end{tabular} \\
\hline
0.00 & 2.0000 & 2.0000 & 2.0000 & 2.0000 & 2.0000 & 0.00 & 2.0000 & 2.0000 & 2.0000 & 2.0000 & 2.0000 \\
\hline
0.10 & 2.1000 & 2.1220 & 2.1200 & 2.1230 & 2.1230 & 0.05 & 2.0500 & 2.0553 & 2.0550 & 2.0554 & 2.0554 \\
\hline
0.20 & 2.2440 & 2.3049 & 2.2992 & 2.3085 & 2.3085 & 0.10 & 2.1105 & 2.1228 & 2.1222 & 2.1230 & 2.1230 \\
\hline
0.30 & 2.4525 & 2.5858 & 2.5726 & 2.5958 & 2.5958 & 0.15 & 2.1838 & 2.2056 & 2.2045 & 2.2061 & 2.2061 \\
\hline
0.40 & 2.7596 & 3.0378 & 3.0077 & 3.0649 & 3.0650 & 0.20 & 2.2727 & 2.3075 & 2.3058 & 2.3085 & 2.3085 \\
\hline
\multirow[t]{6}{*}{0.50} & 3.2261 & 3.8254 & 3.7511 & 3.9078 & 3.9082 & 0.25 & 2.3812 & 2.4342 & 2.4315 & 2.4358 & 2.4358 \\
\hline
 &  &  &  &  &  & 0.30 & 2.5142 & 2.5931 & 2.5890 & 2.5958 & 2.5958 \\
\hline
 &  &  &  &  &  & 0.35 & 2.6788 & 2.7953 & 2.7889 & 2.7998 & 2.7997 \\
\hline
 &  &  &  &  &  & 0.40 & 2.8845 & 3.0574 & 3.0475 & 3.0650 & 3.0650 \\
\hline
 &  &  &  &  &  & 0.45 & 3.1455 & 3.4057 & 3.3898 & 3.4189 & 3.4189 \\
\hline
 &  &  &  &  &  & 0.50 & 3.4823 & 3.8840 & 3.8574 & 3.9082 & 3.9082 \\
\hline
\end{tabular}
\end{center}

EXERCISES 9.4

Answers to odd-numbered problems begin on page A-26.

Given the initial-value problems in Problems 1-10, use the Runge-Kutta method with $h=0.1$ to obtain a four-decimal approximation to the indicated value.

\begin{enumerate}
  \item $y^{\prime}=2 x-3 y+1, y(1)=5, \quad y(1.5)$

  \item $y^{\prime}=4 x-2 y, y(0)=2, \quad y(0.5)$

  \item $y^{\prime}=1+y^{2}, y(0)=0, \quad y(0.5)$

  \item $y^{\prime}=x^{2}+y^{2}, y(0)=1, \quad y(0.5)$

  \item $y^{\prime}=e^{-y}, y(0)=0, \quad y(0.5)$

  \item $y^{\prime}=x+y^{2}, y(0)=0, \quad y(0.5)$

  \item $y^{\prime}=(x-y)^{2}, y(0)=0.5, \quad y(0.5)$

  \item $y^{\prime}=x y+\sqrt{y}, y(0)=1, \quad y(0.5)$

  \item $y^{\prime}=x y^{2}-\frac{y}{x}, y(1)=1, \quad y(1.5)$

  \item $y^{\prime}=y-y^{2}, y(0)=0.5, \quad y(0.5)$

  \item If air resistance is proportional to the square of the instantaneous velocity, then the velocity $v$ of a mass $m$ dropped from a given height is determined from

\end{enumerate}

$$
m \frac{d v}{d t}=m g-k v^{2}, \quad k>0
$$

(see Problem 8, Chapter 3 Review Exercises). If $v(0)=0, k=0.125$, $m=5$ slugs, and $g=32 \mathrm{ft} / \mathrm{s}^{2}$, use the Runge-Kutta method to find an approximation to the velocity of the falling mass at $t=5$ seconds. Use $h=1$.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item Solve the initial-value problem in Problem 11 by one of the methods of Chapter 2. Find the true value of $v(5)$.

  \item A mathematical model for the area $A$ (in $\mathrm{cm}^{2}$ ) that a colony of bacteria (B. dendroides) occupies is given by*

\end{enumerate}

$$
\frac{d A}{d t}=A(2.128-0.0432 A)
$$

If $A(0)=0.24 \mathrm{~cm}^{2}$, use the Runge-Kutta method to complete the following table. Use $h=0.5$.

\begin{center}
\begin{tabular}{llllll}
\hline
$t$ (days) & 1 & 2 & 3 & 4 & 5 \\
\hline
$A$ (observed) & 2.78 & 13.53 & 36.30 & 47.50 & 49.40 \\
\hline
$A$ (approximated) &  &  &  &  &  \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{13}
  \item Solve the initial-value problem in Problem 13. Compute the values $A(1)$, $A(2), A(3), A(4)$, and $A(5)$. [Hint: See Section 3.3.]

  \item Let $y(x)$ be the solution of the initial-value problem

\end{enumerate}

$$
y^{\prime}=x^{2}+y^{3}, \quad y(1)=1
$$

Determine whether the Runge-Kutta formula can be used to obtain an approximation for $y(1.4)$. Use $h=0.1$.

\begin{enumerate}
  \setcounter{enumi}{15}
  \item Consider the differential equation $y^{\prime}=f(x)$. In this case show that the fourth-order Runge-Kutta method reduces to Simpson's rule for the integral of $f(x)$ on the interval $x_{n} \leq x \leq x_{n+1}$.
\end{enumerate}

\subsection*{9.5 MULTISTEP METHODS}
Adams-Bashforth/Adams-Moulton Method There are many additional formulas that can be applied to obtain approximations to solutions of differential equations. Although it is not our intention to survey the vast field of numerical methods, several additional formulas deserve mention. The Adams-Bashforth/ Adams-Moulton method, like the improved Euler formula, is a predictorcorrector method. By using the Adams-Bashforth formula


\begin{equation*}
y_{n+1}^{*}=y_{n}+\frac{h}{24}\left(55 y_{n}^{\prime}-59 y_{n-1}^{\prime}+37 y_{n-2}^{\prime}-9 y_{n-3}^{\prime}\right), \tag{1}
\end{equation*}


where

$$
\begin{aligned}
y_{n}^{\prime} & =f\left(x_{n}, y_{n}\right) \\
y_{n-1}^{\prime} & =f\left(x_{n-1}, y_{n-1}\right) \\
y_{n-2}^{\prime} & =f\left(x_{n-2}, y_{n-2}\right) \\
y_{n-3}^{\prime} & =f\left(x_{n-3}, y_{n-3}\right)
\end{aligned}
$$
\footnotetext{\begin{itemize}
  \item See V. A. Kostitzin, Mathematical Biology (London: Harrap, 1939).
\end{itemize}
}
for $n \geq 3$, as a predictor, we are able to substitute the value of $y_{n+1}^{*}$ into the Adams-Moulton corrector


\begin{gather*}
y_{n+1}=y_{n}+\frac{h}{24}\left(9 y_{n+1}^{\prime}+19 y_{n}^{\prime}-5 y_{n-1}^{\prime}+y_{n-2}^{\prime}\right)  \tag{2}\\
y_{n+1}^{\prime}=f\left(x_{n+1}, y_{n+1}^{*}\right)
\end{gather*}


Notice formula (1) requires that we know the values of $y_{0}, y_{1}, y_{2}$, and $y_{3}$ in order to obtain $y_{4}$. The value of $y_{0}$ is, of course, the given initial condition; the values of $y_{1}, y_{2}$, and $y_{3}$ are computed by an accurate method such as the RungeKutta formula.

Since the Adams-Bashforth/Adams-Moulton formulas demand that we know more than just $y_{n}$ to compute $y_{n+1}$, the procedure is called a multistep, or continuing, method. The Euler formulas, the three-term Taylor formula, and the Runge-Kutta formulas are examples of single-step, or starting, methods.

\section*{EXAMPLE 1 Adams-Bashforth/Adams-Moulton Method}
Use the Adams-Bashforth/Adams-Moulton method with $h=0.2$ to obtain an approximation to $y(0.8)$ for the solution of $y^{\prime}=x+y-1, y(0)=1$.

Solution With a step size of $h=0.2, y(0.8)$ will be approximated by $y_{4}$. To get started we use the Runge-Kutta method with $x_{0}=0, y_{0}=1$, and $h=0.2$ to obtain

$$
y_{1}=1.02140000, \quad y_{2}=1.09181796, \quad y_{3}=1.22210646
$$

Now with the identifications $x_{0}=0, x_{1}=0.2, x_{2}=0.4, x_{3}=0.6$, and $f(x, y)=$ $x+y-1$, we find

$$
\begin{aligned}
& y_{0}^{\prime}=f\left(x_{0}, y_{0}\right)=(0)+(1)-1=0 \\
& y_{1}^{\prime}=f\left(x_{1}, y_{1}\right)=(0.2)+(1.02140000)-1=0.22140000 \\
& y_{2}^{\prime}=f\left(x_{2}, y_{2}\right)=(0.4)+(1.09181796)-1=0.49181796 \\
& y_{3}^{\prime}=f\left(x_{3}, y_{3}\right)=(0.6)+(1.22210646)-1=0.82210646
\end{aligned}
$$

With the foregoing values the predictor (1) then gives

$$
y_{4}^{*}=y_{3}+\frac{0.2}{24}\left(55 y_{3}^{\prime}-59 y_{2}^{\prime}+37 y_{1}^{\prime}-9 y_{0}^{\prime}\right)=1.42535975
$$

To use the corrector (2) we first need

$$
y_{4}^{\prime}=f\left(x_{4}, y_{4}^{*}\right)=(0.8)+(1.42535975)-1=1.22535975 .
$$

Finally, (2) yields

$$
y_{4}=y_{3}+\frac{0.2}{24}\left(9 y_{4}^{\prime}+19 y_{3}^{\prime}-5 y_{2}^{\prime}+y_{1}^{\prime}\right)=1.42552788
$$

You should verify that the exact value of $y(0.8)$ in Example 1 is $y(0.8)=$ 1.42554093 .

Milne's Method Another multistep method, which admittedly has limited use (for a reason explained in Section 9.6), is called Milne's method. In this method the predictor is


\begin{equation*}
y_{n+1}^{*}=y_{n-3}+\frac{4 h}{3}\left(2 y_{n}^{\prime}-y_{n-1}^{\prime}+2 y_{n-2}^{\prime}\right) \text {, } \tag{3}
\end{equation*}


where

$$
\begin{aligned}
y_{n}^{\prime} & =f\left(x_{n}, y_{n}\right) \\
y_{n-1}^{\prime} & =f\left(x_{n-1}, y_{n-1}\right) \\
y_{n-2}^{\prime} & =f\left(x_{n-2}, y_{n-2}\right)
\end{aligned}
$$

for $n \geq 3$. The corrector for this formula, based on Simpson's rule of integration, is given by


\begin{equation*}
y_{n+1}=y_{n-1}+\frac{h}{3}\left(y_{n+1}^{\prime}+4 y_{n}^{\prime}+y_{n-1}^{\prime}\right) \tag{4}
\end{equation*}


where

As in the Adams-Bashforth/Adams-Moulton method, we generally use the Runge-Kutta method to compute $y_{1}, y_{2}$, and $y_{3}$.

Choice of Starting Methods As stated earlier in this section, a multistep method requires the use of a single-step method, or starting method. Some care should be taken in the selection of this latter method. In practice, starting methods are usually chosen to have the same accuracy as the multistep method with which they are used. By accuracy we mean the same order of error (see Section 9.6). Using a less accurate starting method with a highly accurate multistep method is not advisable because then the values used in the multistep method will be unreliable. On the other hand, a highly accurate starting method is complicated and expensive to calculate and this effort will be wasted if the multistep method is of low accuracy.

Advantages and Disadvantages of Multistep Methods Many considerations enter into the choice of a method to solve a differential equation numerically. Single-step methods, particularly the Runge-Kutta method, are often chosen because of their accuracy and the fact that they are easy to program. However, a major drawback to them is that the right-hand side of the differential equation must be evaluated many times at each step. For instance, the fourth-order Runge-Kutta method requires four function evaluations for each step. On the other hand, if the function evaluations in the previous step have been calculated and stored, a multistep method requires only one new function evaluation for each step. This can lead to a great savings in time and expense.

As an example, to solve $y^{\prime}=f(x, y), y\left(x_{0}\right)=y_{0}$ numerically using $n$ steps by the fourth-order Runge-Kutta method requires $4 n$ function evaluations. The Adams-Bashforth multistep method requires 16 function evaluations for the Runge-Kutta fourth-order starter and $n-4$ for the $n$ Adams-Bashforth steps, giving a total of $n+12$ function evaluations for this method. In general the Adams-Bashforth multistep method requires slightly more than a quarter of the number of function evaluations required for the fourth-order Runge-Kutta method. If the evaluation of $f(x, y)$ is complicated, the multistep method will be more efficient.

Another issue involved with multistep methods is how many times the corrector formula should be repeated in each step. Each time the corrector is used, another function evaluation is done, and so the accuracy is increased at the expense of losing an advantage of the multistep method. In practice, the corrector is calculated once, and if the value of $y_{n+1}$ is changed by a large amount, the entire problem is restarted using a smaller step size. This is often the basis of the variable step size methods, whose discussion is beyond the scope of this text.

\section*{EXERCISES 9.5}
Answers to odd-numbered problems begin on page A-27.

\begin{enumerate}
  \item Find the exact solution of the initial-value problem in Example 1. Compare the exact values of $y(0.2), y(0.4), y(0.6)$, and $y(0.8)$ with the approximations $y_{1}, y_{2}, y_{3}$, and $y_{4}$.

  \item Write a computer program for the Adams-Bashforth/Adams-Moulton method.

\end{enumerate}

In Problems 3 and 4 use the Adams-Bashforth/Adams-Moulton method to approximate $y(0.8)$, where $y(x)$ is the solution of the given initial-value problem. Use $h=0.2$ and the Runge-Kutta method to compute $y_{1}, y_{2}$, and $y_{3}$.

$$
\begin{array}{ll}
\text { 3. } y^{\prime}=2 x-3 y+1, y(0)=1 & \text { 4. } y^{\prime}=4 x-2 y, y(0)=2
\end{array}
$$

In Problems 5-8 use the Adams-Bashforth/Adams-Moulton method to approximate $y(1.0)$, where $y(x)$ is the solution of the given initial-value problem. Use $h=0.2$ and $h=0.1$ and the Runge-Kutta method to compute $y_{1}, y_{2}$, and $y_{3}$.

$$
\begin{array}{ll}
\text { 5. } y^{\prime}=1+y^{2}, y(0)=0 & \text { 6. } y^{\prime}=y+\cos x, y(0)=1 \\
\text { 7. } y^{\prime}=(x-y)^{2}, y(0)=0 & \text { 8. } y^{\prime}=x y+\sqrt{y}, y(0)=1
\end{array}
$$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item Use Milne's method to approximate the value of $y(0.4)$, where $y(x)$ is the solution of the initial-value problem in Example 1. Use $h=0.1$ and the Runge-Kutta method to compute $y_{1}, y_{2}$, and $y_{3}$.
\end{enumerate}

\subsection*{9.6 ERRORS AND STABILITY \\
 - Global truncation error}
Errors in Numerical Methods In choosing and using a numerical method for the solution of an initial-value problem, we must be aware of the various sources of errors. For some kinds of computation, the accumulation of errors might reduce the accuracy of an approximation to the point of being useless. On the other hand, depending upon the use to which a numerical solution may be put, extreme accuracy may not be worth the added expense and complication.

One source of error always present in calculations is round-off error. This is caused by the fact that any calculator or computer can compute to only, at\\
most, a finite number of decimal places. Suppose for the sake of illustration that we have a calculator that can display six digits while carrying eight digits internally. If we multiply two numbers, each having six decimals, then the product actually contains 12 decimal places. But the number that we see is rounded to six decimal places, while the machine has stored a number rounded to eight decimal places. In one calculation such as this, the round-off error may not be significant, but a problem could arise if many calculations are performed with rounded numbers. One way to reduce the effect of round-off error is to minimize the number of calculations. Another technique on a computer is to use double precision capabilities. Since round-off error is unpredictable and difficult to analyze, we will neglect it in the error analysis that follows. We will concentrate on investigating the error made by using a formula or algorithm to approximate the values of the solution.

\section*{Truncation Errors for Euler's Method When iterating Euler's formula}
$$
y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right)
$$

we obtain a sequence of values $y_{1}, y_{2}, y_{3}, \ldots$. The value $y_{1}$ will not agree with $y\left(x_{1}\right)$, the actual solution evaluated at $x_{1}$, because the algorithm gives only a straight-line approximation to the solution. See Figure 9.10 in Section 9.2. This error is called the local truncation error, formula error, or discretization error. It occurs at each step; that is, if we assume that $y_{n}$ is accurate, then $y_{n+1}$ will contain local truncation error.

To derive a formula for the local truncation error for Euler's method we will use Taylor's formula with remainder. This is very similar to the Taylor series expansion (1) in Section 9.3. If a function $y(x)$ possesses $k+1$ continuous derivatives on an open interval containing $x$ and $a$, then


\begin{equation*}
y(x)=y(a)+y^{\prime}(a) \frac{(x-a)}{1!}+\cdots+y^{(k)}(a) \frac{(x-a)^{k}}{k!}+y^{(k+1)}(c) \frac{(x-a)^{k+1}}{(k+1)!} \tag{1}
\end{equation*}


where $c$ is some point between $a$ and $x$. Setting $k=1, a=x_{n}$, and $x=x_{n+1}=$ $x_{n}+h$, we get

$$
y\left(x_{n+1}\right)=y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) \frac{h}{1!}+y^{\prime \prime}(c) \frac{h^{2}}{2!} \quad \text { or } \quad y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right)+y^{\prime \prime}(c) \frac{h^{2}}{2!}
$$

Euler's method is this formula without the last term; hence, the local truncation error in $y_{n+1}$ is

$$
y^{\prime \prime}(c) \frac{h^{2}}{2!}, \quad \text { where } \quad x_{n}<c<x_{n+1}
$$

Unfortunately, the value of $c$ is usually unknown (it exists theoretically) and so the exact error cannot be calculated, but an upper bound on the absolute value of the error is

$$
M \frac{h^{2}}{2}, \quad \text { where } \quad M=\max _{x_{n}<x<x_{n+1}}\left|y^{\prime \prime}(x)\right|
$$

The following terminology is used when discussing errors of numerical methods. A calculation is said to be of order $\alpha$, denoted $O\left(h^{\alpha}\right)$, if the error behaves like $C h^{\alpha}$, where $C$ is a constant. From this we see that if the step size is halved, then the new error should be approximately $C\left(h^{\alpha} / 2^{\alpha}\right)$; that is, the error is reduced by a factor of $1 / 2^{\alpha}$.

Using this definition, we see that the local truncation error for Euler's method is of order two, or $O\left(h^{2}\right)$.

\section*{EXAMPLE 1 Bound for Local Truncation Errors}
Find a bound for the local truncation errors for Euler's method applied to $y^{\prime}=2 x y, y(1)=1$.

Solution This differential equation was studied in Example 2 of Section 9.2, and its analytic solution is $y(x)=e^{x^{2}-1}$.

The local truncation error is

$$
y^{\prime \prime}(c) \frac{h^{2}}{2}=\left(2+4 c^{2}\right) e^{\left(c^{2}-1\right)} \frac{h^{2}}{2}
$$

where $c$ is between $x_{n}$ and $x_{n}+h$. In particular, for $h=0.1$ we can get an upper bound on the local truncation error for $y_{1}$ by replacing $c$ by 1.1 :

$$
\left[2+(4)(1.1)^{2}\right] e^{\left((1.1)^{2}-1\right)} \frac{(0.1)^{2}}{2}=0.0422
$$

From Table 9.3 we see that the error after the first step is 0.0337 , less than the value given by the bound.

Similarly, we can get a bound for the local truncation error for any of the five steps given in Table 9.3 by replacing $c$ by 1.5 (this value of $c$ gives the largest value of $y^{\prime \prime}(c)$ for any of the steps and may be too generous for the first few steps). Doing this gives


\begin{equation*}
\left[2+(4)(1.5)^{2}\right] e^{\left.(1.5)^{2}-1\right)} \frac{(0.1)^{2}}{2}=0.1920 \tag{2}
\end{equation*}


as an upper bound for the local truncation error in each step.

Note in Example 1 that if $h$ was halved to 0.05 , then the error bound (2) would be 0.0480 , about one fourth as much. This is expected since the local truncation error for Euler's method is $O\left(h^{2}\right)$.

In the above analysis we assumed in the calculation of $y_{n+1}$ that the value of $y_{n}$ was correct, but it is not because it contains local truncation errors from previous steps. The total error in $y_{n+1}$ is an accumulation of the errors in each of the previous steps. See Figure 9.11 in Section 9.2. This total error is called the global truncation error. A complete analysis of the global truncation error is beyond the scope of this text, but it can be shown that the global truncation error for Euler's method is $O(h)$.

We expect that for Euler's method if the step size was halved, then the error would be approximately halved as well. This is borne out in Example 2 of Section 9.2 , where the absolute error at $x=1.50$ with $h=0.1$ is 0.5625 and the absolute error with $h=0.05$ is 0.3171 , approximately half as large. See Tables 9.3 and 9.4 in Section 9.2.

In general it can be shown that if a method for the numerical solution of a differential equation has local truncation error $O\left(h^{\alpha+1}\right)$, then the global truncation error is $O\left(h^{\alpha}\right)$. Hence we can say that the order of global truncation error for any method is one less than the order of the local truncation error.

Truncation Errors for Other Methods The local and global truncation errors for the other methods we have studied can be analyzed similarly. For instance, it was pointed out in Section 9.4 that the improved Euler's method is a secondorder Runge-Kutta method and thus one condition it satisfies is that it agrees with the Taylor polynomial through $k=2$. Thus the local truncation error is

$$
y^{(3)}(c) \frac{h^{3}}{3!}
$$

The derivation of this result is left for you. (See Problem 1.)

Since the local truncation error is $O\left(h^{3}\right)$, we know that the global truncation error is $O\left(h^{2}\right)$. This can be seen in Tables 9.7 and 9.8 of Section 9.2; when the step size is halved from $h=0.1$ to $h=0.05$, the global truncation error at $x=1.50$ is reduced from 0.0394 to 0.0108 . This is a reduction of approximately one fourth.

Similarly, a condition in the derivation of the fourth-order Runge-Kutta method is that it should agree with the Taylor polynomial through $k=4$. Hence the local truncation error is

$$
y^{(5)}(c) \frac{h^{5}}{5!} \quad \text { or } \quad O\left(h^{5}\right)
$$

and the global truncation error is $O\left(h^{4}\right)$. It is now obvious why this is called the fourth-order Runge-Kutta method.

Table 9.18 Runge-Kutta Method

\begin{center}
\begin{tabular}{lcc}
\hline
$\boldsymbol{h}$ & Approximation & Error \\
\hline
0.1 & 3.49021064 & $1.323210889 \times 10^{-4}$ \\
\hline
0.05 & 3.49033382 & $9.137760898 \times 10^{-6}$ \\
\hline
\end{tabular}
\end{center}

Table 9.19 Orders of Error for Different Methods

\begin{center}
\begin{tabular}{lc}
\hline
Method & \begin{tabular}{l}
Order of global \\
truncation error \\
\end{tabular} \\
\hline
Euler & 1 \\
Improved Euler & 2 \\
Three-term Taylor & 2 \\
Fourth-order & 4 \\
$\quad$ Runge-Kutta &  \\
Adams-Bashforth & 4 \\
Adams-Moulton & 4 \\
Milne & 4 \\
\hline
\end{tabular}
\end{center}

\section*{EXAMPLE 2 Bound for Local/Global Truncation Errors}
Analyze the local and global truncation errors for the fourth-order Runge-Kutta method applied to $y^{\prime}=2 x y, y(1)=1$.

Solution By differentiating the known solution $y(x)=e^{x^{2}-1}$, we get


\begin{equation*}
y^{(5)}(c) \frac{h^{5}}{5!}=\left(120 c+160 c^{3}+32 c^{5}\right) e^{c^{2}-1} \frac{h^{5}}{5!} \tag{3}
\end{equation*}


Thus with $c=1.5$, (3) yields a bound of 0.00028 on the local discretization error for each of the five steps when $h=0.1$. Note that in Table 9.15 the error in $y_{1}$ is much less than this bound.

In Table 9.18 we summarize the approximations to the solution of the initial-value problem at $x=1.5$ given by the fourth-order Runge-Kutta method with $h=0.1$ and $h=0.05$. Because the method is so exact, many decimal places must be kept in the numerical solution to see the effect of halving the step size. Note that when we halve $h$, the error is divided by a factor of about $2^{4}=16$, as expected.

A similar analysis can be done for the errors in each of the methods we have studied. Table 9.19 gives the results.

Stability of Numerical Methods In accepting the results of a numerical method, a user should always be concerned with the stability of the method. Put simply, a method is stable if small changes in the data make only small changes in the results. This is important since the numbers used in a calculator or com-\\
puter are not exact. Also, in physical applications the data are often obtained by imprecise measurements. If a method is not stable, it is possible to have an error greater than would be expected from global truncation or round-off error. All single-step methods are stable if the step size taken is small enough; however, some multistep methods, particularly Milne's method, are not stable.

\section*{EXAMPLE 3 Milne's Method}
Consider the initial-value problem $y^{\prime}=-10 y+5, y(1)=1$. Use Milne's method to obtain an approximation to $y(2.0)$ using $h=0.1$.

Solution The instability of the method for this relatively simple problem is apparent from inspection of the results given in Table 9.20. The starting method is the fourth-order Runge-Kutta method, which is very accurate and stable, but nevertheless the very large errors at the end of the calculations make the approximation for $y(2.0)$ quite useless.

Table 9.20 Instability of Milne's Method

\begin{center}
\begin{tabular}{llrr}
\hline
$\boldsymbol{x}$ & Actual & \multicolumn{1}{l}{Milne} & \multicolumn{1}{c}{Error} \\
\hline
 &  &  &  \\
1.0 & 1.00000 & 1.00000 &  \\
1.1 & 0.68393 & 0.68750 & 0.00357 \\
1.2 & 0.56767 & 0.57031 & 0.00264 \\
1.3 & 0.52489 & 0.52637 & 0.00148 \\
1.4 & 0.50917 & 0.52344 & 0.01427 \\
1.5 & 0.50337 & 0.47266 & -0.03071 \\
1.6 & 0.50125 & 0.60417 & 0.10292 \\
1.7 & 0.50045 & 0.14963 & -0.35082 \\
1.8 & 0.50017 & 1.66956 & 1.16939 \\
1.9 & 0.50005 & -3.39111 & -3.89116 \\
2.0 & 0.50002 & 13.47418 & 12.97416 \\
\hline
\end{tabular}
\end{center}

Milne's method is the only numerical procedure we have studied that has serious stability problems, but stability must be considered when any numerical method is used.

\section*{EXERCISES 9.6}
\section*{Answers to odd-numbered problems begin on page A-27.}
\begin{enumerate}
  \item Use the Taylor polynomial with remainder (1) to find the formula for the local truncation error for the improved Euler's method (recall that it is a second-order Runge-Kutta method).

  \item Repeat Problem 1 for the three-term Taylor method.

  \item Repeat Problem 1 for the fourth-order Runge-Kutta method.

  \item Consider the initial-value problem $y^{\prime}=2 y, y(0)=1$. The analytic solution is $y(x)=e^{2 x}$.

\end{enumerate}

(a) Approximate $y(0.1)$ using one step and Euler's method.

(b) Find a bound for the local truncation error in $y_{1}$.

(c) Compare the actual error in $y_{1}$ with your error bound.

(d) Approximate $y(0.1)$ using two steps and Euler's method.

(e) Verify that the global truncation error for Euler's method is $O(h)$ by comparing the errors in parts (a) and (d).

\begin{enumerate}
  \setcounter{enumi}{4}
  \item Repeat Problem 4 using the improved Euler's method. Its global truncation error is $O\left(h^{2}\right)$.

  \item Repeat Problem 4 using the three-term Taylor method. Its global truncation error is $O\left(h^{2}\right)$.

  \item Repeat Problem 4 using the fourth-order Runge-Kutta method. Its global truncation error is $O\left(h^{4}\right)$. Keep eight or nine decimal places in your calculations.

\end{enumerate}

8.-11. Repeat Problems 4-7 using the initial-value problem $y^{\prime}=-2 y+x$, $y(0)=1$. The analytic solution is $y(x)=\frac{1}{2} x-\frac{1}{4}+\frac{5}{4} e^{-2 x}$.

\begin{enumerate}
  \setcounter{enumi}{11}
  \item Consider the initial-value problem $y^{\prime}=2 x-3 y+1, y(1)=5$. The analytic solution is $y(x)=\frac{1}{9}+\frac{2}{3} x+\frac{38}{9} e^{-3(x-1)}$.
\end{enumerate}

(a) Find a formula involving $c$ and $h$ for the local truncation error in the $n$th step if Euler's method is used.

(b) Find a bound for the local truncation error in each step if $h=0.1$ is used to approximate $y(1.5)$.

(c) Approximate $y(1.5)$ using $h=0.1$ and $h=0.05$ with Euler's method. See Problem 3, Exercises 9.2.

(d) Calculate the errors in part (c) and verify that the global truncation error of Euler's method is $O(h)$.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Repeat Problem 12 using the improved Euler's method, which has global truncation error $O\left(h^{2}\right)$. See Problem 13(a), Exercises 9.2. You may need to keep more than four decimal places to see the effect of reducing the order of error.

  \item Repeat Problem 12 using the three-term Taylor series method, which has global truncation error $O\left(h^{2}\right)$. See Problem 1, Exercises 9.3. You may need to keep more than four decimal places to see the effect of reducing the order of error.

  \item Repeat Problem 12 using the fourth-order Runge-Kutta method, which has global truncation error $O\left(h^{4}\right)$. See Problem 1, Exercise 9.4. You will need to keep more than six decimal places to see the effect of reducing the order of error.

\end{enumerate}

16.-19. Repeat Problems 12-15 for the initial-value problem $y^{\prime}=e^{-y}$, $y(0)=0$. The analytic solution is $y(x)=\ln (x+1)$. Approximate $y(0.5)$. See Problems 7 and 13(c) in Exercises 9.2, Problem 5 in Exercises 9.3, and Problem 5 in Exercises 9.4.

\subsection*{9.7 HIGHER-ORDER EQUATIONS AND SYSTEMS \\
 - Numerical methods applied to systems \\
 - Euler's method \\
 - Runge-Kutta method}
Second-Order Initial-Value Problem The numerical procedures we have discussed so far in this chapter applied to only a first-order equation $d y / d x=f(x, y)$ subject to an initial condition $y\left(x_{0}\right)=y_{0}$. To approximate the solution to, say, a second-order initial-value problem


\begin{equation*}
\frac{d^{2} y}{d x^{2}}=f\left(x, y, y^{\prime}\right), \quad y\left(x_{0}\right)=y_{0}, \quad y^{\prime}\left(x_{0}\right)=y_{0}^{\prime} \tag{1}
\end{equation*}


we reduce the second-order differential equation to a second-order system. (See Section 8.3.) If we let $y^{\prime}=u$, then the equation in (1) becomes


\begin{align*}
y^{\prime} & =u  \tag{2}\\
u^{\prime} & =f(x, y, u)
\end{align*}


We now apply a particular method to each equation in the resulting system. For example, the basic Euler's method for the system (2) would be


\begin{align*}
& y_{n+1}=y_{n}+h u_{n}  \tag{3}\\
& u_{n+1}=u_{n}+h f\left(x_{n}, y_{n}, u_{n}\right)
\end{align*}


\section*{EXAMPLE 1 Second-Order DE}
Use Euler's method to obtain the approximate value of $y(0.2)$, where $y(x)$ is the solution of the initial-value problem

$$
y^{\prime \prime}+x y^{\prime}+y=0, \quad y(0)=1, \quad y^{\prime}(0)=2
$$

Solution In terms of the substitution $y^{\prime}=u$, the equation is equivalent to the system

$$
\begin{aligned}
y^{\prime} & =u \\
u^{\prime} & =-x u-y
\end{aligned}
$$

Thus from (3) we obtain

$$
\begin{aligned}
& y_{n+1}=y_{n}+h u_{n} \\
& u_{n+1}=u_{n}+h\left[-x_{n} u_{n}-y_{n}\right]
\end{aligned}
$$

Using the step size $h=0.1$ and $y_{0}=1, u_{0}=2$, we find

$$
\begin{aligned}
& y_{1}=y_{0}+(0.1) u_{0}=1+(0.1) 2=1.2 \\
& u_{1}=u_{0}+(0.1)\left[-x_{0} u_{0}-y_{0}\right]=2+(0.1)[-(0)(2)-1]=1.9 \\
& y_{2}=y_{1}+(0.1) u_{1}=1.2+(0.1)(1.9)=1.39 \\
& u_{2}=u_{1}+(0.1)\left[-x_{1} u_{1}-y_{1}\right]=1.9+(0.1)[-(0.1)(1.9)-1.2]=1.761
\end{aligned}
$$

In other words, $y(0.2) \approx 1.39$ and $y^{\prime}(0.2) \approx 1.761$.

Systems An initial-value problem for a second-order system-that is, a system of two first-order differential equations-is


\begin{align*}
x^{\prime} & =f(t, x, y)  \tag{4}\\
y^{\prime} & =g(t, x, y) \\
x\left(t_{0}\right) & =x_{0}, \quad y\left(t_{0}\right)=y_{0}
\end{align*}


As we did in (3), to approximate a solution of this problem we apply a numerical method to each equation in (4). The fourth-order Runge-Kutta method looks like this:


\begin{align*}
& x_{n+1}=x_{n}+\frac{1}{6}\left(m_{1}+2 m_{2}+2 m_{3}+m_{4}\right)  \tag{5}\\
& y_{n+1}=y_{n}+\frac{1}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right)
\end{align*}


where

$$
\begin{array}{ll}
m_{1}=h f\left(t_{n}, x_{n}, y_{n}\right) & k_{1}=h g\left(t_{n}, x_{n}, y_{n}\right) \\
m_{2}=h f\left(t_{n}+\frac{1}{2} h, x_{n}+\frac{1}{2} m_{1}, y_{n}+\frac{1}{2} k_{1}\right) & k_{2}=h g\left(t_{n}+\frac{1}{2} h, x_{n}+\frac{1}{2} m_{1}, y_{n}+\frac{1}{2} k_{1}\right) \\
m_{3}=h f\left(t_{n}+\frac{1}{2} h, x_{n}+\frac{1}{2} m_{2}, y_{n}+\frac{1}{2} k_{2}\right) & k_{3}=h g\left(t_{n}+\frac{1}{2} h, x_{n}+\frac{1}{2} m_{2}, y_{n}+\frac{1}{2} k_{2}\right) \\
m_{4}=h f\left(t_{n}+h, x_{n}+m_{3}, y_{n}+k_{3}\right) & k_{4}=h g\left(t_{n}+h, x_{n}+m_{3}, y_{n}+k_{3}\right)
\end{array}
$$

\section*{EXAMPLE 2 Runge-Kutta Method Applied to a System}
Consider the initial-value problem

$$
\begin{aligned}
x^{\prime} & =2 x+4 y \\
y^{\prime} & =-x+6 y \\
x(0) & =-1, \quad y(0)=6
\end{aligned}
$$

Use the fourth-order Runge-Kutta method to approximate $x(0.6)$ and $y(0.6)$. Compare the results for $h=0.2$ and $h=0.1$.

Solution We illustrate the computations of $x_{1}$ and $y_{1}$ with the step size $h=0.2$. With the identifications $f(t, x, y)=2 x+4 y, g(t, x, y)=-x+6 y$, $t_{0}=0, x_{0}=-1$, and $y_{0}=6$, we see from (6) that

$$
\begin{aligned}
m_{1} & =h f\left(t_{0}, x_{0}, y_{0}\right)=0.2 f(0,-1,6)=0.2[2(-1)+4(6)]=4.4000 \\
k_{1} & =h g\left(t_{0}, x_{0}, y_{0}\right)=0.2 g(0,-1,6)=0.2[-1(-1)+6(6)]=7.4000 \\
m_{2} & =h f\left(t_{0}+\frac{1}{2} h, x_{0}+\frac{1}{2} m_{1}, y_{0}+\frac{1}{2} k_{1}\right)=0.2 f(0.1,1.2,9.7)=8.2400 \\
k_{2} & =h g\left(t_{0}+\frac{1}{2} h, x_{0}+\frac{1}{2} m_{1}, y_{0}+\frac{1}{2} k_{1}\right)=0.2 g(0.1,1.2,9.7)=11.4000 \\
m_{3} & =h f\left(t_{0}+\frac{1}{2} h, x_{0}+\frac{1}{2} m_{2}, y_{0}+\frac{1}{2} k_{2}\right)=0.2 f(0.1,3.12,11.7)=10.6080 \\
k_{3} & =h g\left(t_{0}+\frac{1}{2} h, x_{0}+\frac{1}{2} m_{2}, y_{0}+\frac{1}{2} k_{2}\right)=0.2 g(0.1,3.12,11.7)=13.4160 \\
m_{4} & =h f\left(t_{0}+h, x_{0}+m_{3}, y_{0}+k_{3}\right)=0.2 f(0.2,8,20.216)=19.3760 \\
k_{4} & =h g\left(t_{0}+h, x_{0}+m_{3}, y_{0}+k_{3}\right)=0.2 g(0.2,8,20.216)=21.3776
\end{aligned}
$$

Therefore, from (5) we get

$$
\begin{aligned}
x_{1} & =x_{0}+\frac{1}{6}\left(m_{1}+2 m_{2}+2 m_{3}+m_{4}\right) \\
& =-1+\frac{1}{6}(4.4+2(8.24)+2(10.608)+19.3760)=9.2453 \\
y_{1} & =y_{0}+\frac{1}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right) \\
& =6+\frac{1}{6}(7.4+2(11.4)+2(13.416)+21.3776)=19.0683
\end{aligned}
$$

where, as usual, the computed values are rounded to four decimal places. These numbers give us the approximations $x_{1} \approx x(0.2)$ and $y_{1} \approx y(0.2)$. The subsequent values, obtained with the aid of a computer, are summarized in Tables 9.21 and 9.22 .

Table 9.21 Runge-Kutta Method with $h=0.2$

\begin{center}
\begin{tabular}{rrrrrrrrrrr}
\hline
$m_{1}$ & \multicolumn{1}{c}{$m_{2}$} & \multicolumn{1}{c}{$m_{3}$} & $m_{4}$ & $\boldsymbol{k}_{1}$ & $\boldsymbol{k}_{2}$ & $\boldsymbol{k}_{3}$ & $\boldsymbol{k}_{4}$ & $\boldsymbol{t}_{\boldsymbol{n}}$ & $\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
 &  &  &  &  &  &  &  &  &  &  \\
 &  &  &  &  &  &  & 0.00 & -1.0000 & 6.0000 &  \\
4.4000 & 8.2400 & 10.6080 & 19.3760 & 7.4000 & 11.4000 & 13.4160 & 21.3776 & 0.20 & 9.2453 & 19.0683 \\
18.9527 & 31.1564 & 37.8870 & 63.6848 & 21.0329 & 31.7573 & 36.9716 & 57.8214 & 0.40 & 46.0327 & 55.1203 \\
62.5093 & 97.7863 & 116.0063 & 187.3669 & 56.9378 & 84.8495 & 98.0688 & 151.4191 & 0.60 & 158.9430 & 150.8192 \\
\hline
\end{tabular}
\end{center}

Table 9.22 Runge-Kutta Method with $h=0.1$

\begin{center}
\begin{tabular}{rrrrrrrrrrr}
\hline
$m_{1}$ & \multicolumn{1}{l}{$m_{2}$} & \multicolumn{1}{l}{$m_{3}$} & \multicolumn{1}{c}{$\boldsymbol{m}_{4}$} & $k_{1}$ & $k_{2}$ & $k_{3}$ & $k_{4}$ & $\boldsymbol{t}_{\boldsymbol{n}}$ & $\boldsymbol{x}_{n}$ &  \\
\hline
 &  &  &  &  &  &  &  &  &  &  \\
 &  &  &  &  &  &  & 0.00 & -1.0000 & 6.0000 &  \\
2.2000 & 3.1600 & 3.4560 & 4.8720 & 3.7000 & 4.7000 & 4.9520 & 6.3256 & 0.10 & 2.3840 & 10.8883 \\
4.8321 & 6.5742 & 7.0778 & 9.5870 & 6.2946 & 7.9413 & 8.3482 & 10.5957 & 0.20 & 9.3379 & 19.1332 \\
9.5208 & 12.5821 & 13.4258 & 17.7609 & 10.5461 & 13.2339 & 13.8872 & 17.5358 & 0.30 & 22.5541 & 32.8539 \\
17.6524 & 22.9090 & 24.3055 & 31.6554 & 17.4569 & 21.8114 & 22.8549 & 28.7393 & 0.40 & 46.5103 & 55.4420 \\
31.4788 & 40.3496 & 42.6387 & 54.9202 & 28.6141 & 35.6245 & 37.2840 & 46.7207 & 0.50 & 88.5729 & 93.3006 \\
54.6348 & 69.4029 & 73.1247 & 93.4107 & 46.5231 & 57.7482 & 60.3774 & 75.4370 & 0.60 & 160.7563 & 152.0025 \\
\hline
\end{tabular}
\end{center}

You should verify that the solution of the initial-value problem in Example 2 (see Problem 39, Exercises 8.6) is given by $x(t)=(26 t-1) e^{4 t}, y(t)=$ $(13 t+6) e^{4 t}$. From these equations we see that the exact values are $x(0.6)=160.9384$ and $y(0.6)=152.1198$.

In conclusion, we state Euler's method for the general system (4):

$$
\begin{aligned}
& x_{n+1}=x_{n}+h f\left(t_{n}, x_{n}, y_{n}\right) \\
& y_{n+1}=y_{n}+h g\left(t_{n}, x_{n}, y_{n}\right) .
\end{aligned}
$$

\section*{EXERCISES 9.7}
Answers to odd-numbered problems begin on page A-28.

\begin{enumerate}
  \item Use Euler's method to approximate $y(0.2)$, where $y(x)$ is the solution of the initial-value problem
\end{enumerate}

$$
y^{\prime \prime}-4 y^{\prime}+4 y=0, \quad y(0)=-2, \quad y^{\prime}(0)=1
$$

Use $h=0.1$. Find the exact solution of the problem and compare the exact value of $y(0.2)$ with $y_{2}$.

\begin{enumerate}
  \setcounter{enumi}{1}
  \item Use Euler's method to approximate $y(1.2)$, where $y(x)$ is the solution of the initial-value problem
\end{enumerate}

$$
x^{2} y^{\prime \prime}-2 x y^{\prime}+2 y=0, \quad y(1)=4, \quad y^{\prime}(1)=9,
$$

where $x>0$. Use $h=0.1$. Find the exact solution of the problem and compare the exact value of $y(1.2)$ with $y_{2}$.

\begin{enumerate}
  \setcounter{enumi}{2}
  \item Repeat Problem 1 using the Runge-Kutta method with $h=0.2$ and $h=0.1$.

  \item Repeat Problem 2 using the Runge-Kutta method with $h=0.2$ and $h=0.1$.

  \item Use the Runge-Kutta method to obtain the approximate value of $y(0.2)$, where $y(x)$ is a solution of the initial-value problem

\end{enumerate}

$$
y^{\prime \prime}-2 y^{\prime}+2 y=e^{t} \cos t, \quad y(0)=1, \quad y^{\prime}(0)=2
$$

Use $h=0.2$ and $h=0.1$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-476}
\end{center}

Figure 9.14

\begin{enumerate}
  \setcounter{enumi}{5}
  \item When $E=100$ volts, $R=10$ ohms, and $L=1$ henry, the system of differential equations for the currents $i_{1}(t)$ and $i_{3}(t)$ in the electrical network given in Figure 9.14 is
\end{enumerate}

$$
\frac{d i_{1}}{d t}=-20 i_{1}+10 i_{3}+100
$$

$$
\frac{d i_{3}}{d t}=10 i_{1}-20 i_{3}
$$

where $i_{1}(0)=0$ and $i_{3}(0)=0$. Use the Runge-Kutta method to approximate $i_{1}(t)$ and $i_{3}(t)$ at $t=0.1,0.2,0.3,0.4$, and 0.5 . Use $h=0.1$.

In Problems 7-10 use the Runge-Kutta method to approximate $x(0.2)$ and $y(0.2)$. Compare the results for $h=0.2$ and $h=0.1$.\\
7. $x^{\prime}=2 x-y$\\
8. $x^{\prime}=x+2 y$\\
$y^{\prime}=x$\\
$y^{\prime}=4 x+3 y$\\
$x(0)=6, y(0)=2$\\
$x(0)=1, y(0)=1$\\
9. $x^{\prime}=-y+t$\\
10. $x^{\prime}=6 x+y+6 t$\\
$y^{\prime}=x-t$\\
$y^{\prime}=4 x+3 y-10 t+4$\\
$x(0)=-3, y(0)=5$\\
$x(0)=0.5, y(0)=0.2$

\subsection*{9.8 SECOND-ORDER BOUNDARY-VALUE PROBLEMS \\
 - Difference quotient \\
 - Finite difference \\
 - Finite difference equation}
In Sections 9.2-9.5 we focused on techniques that yield an approximation to a solution of a first-order initial-value problem $y^{\prime}=f(x, y), y\left(x_{0}\right)=y_{0}$. In addition, we saw in Section 9.7 that we can adapt the approximation techniques to a second-order initial-value problem $y^{\prime \prime}=f\left(x, y, y^{\prime}\right), y\left(x_{0}\right)=y_{0}, y^{\prime}\left(x_{0}\right)=y_{0}^{\prime}$ by reducing the second-order differential equation to a system of first-order equations. In this section we are going to examine a method for approximating a solution to a second-order boundary-value problem $y^{\prime \prime}=f\left(x, y, y^{\prime}\right), y(a)=\alpha$, $y(b)=\beta$. We note at the outset that this method does not require reducing the second-order differential equation to a system of equations.

Finite Difference Approximations Recall from (2) of Section 9.3 that a Taylor series expansion of a function $y(x)$ can be written as


\begin{align*}
y(x+h) & =y(x)+y^{\prime}(x) h+y^{\prime \prime}(x) \frac{h^{2}}{2}+y^{\prime \prime \prime}(x) \frac{h^{3}}{6}+\cdots  \tag{1}\\
\text { and so } \quad y(x-h) & =y(x)-y^{\prime}(x) h+y^{\prime \prime}(x) \frac{h^{2}}{2}-y^{\prime \prime \prime}(x) \frac{h^{3}}{6}+\cdots \tag{2}
\end{align*}


If $h$ is small, we can ignore terms involving $h^{4}, h^{5}, \ldots$ since these values are negligible. Indeed, if we ignore all terms involving $h^{2}$ and higher, then (1) and (2) yield, in turn, the following approximations for the first derivative $y^{\prime}(x)$ :


\begin{align*}
& y^{\prime}(x) \approx \frac{1}{h}[y(x+h)-y(x)]  \tag{3}\\
& y^{\prime}(x) \approx \frac{1}{h}[y(x)-y(x-h)] \tag{4}
\end{align*}


Subtracting (1) and (2) also gives


\begin{equation*}
y^{\prime}(x) \approx \frac{1}{2 h}[y(x+h)-y(x-h)] \tag{5}
\end{equation*}


On the other hand, if we ignore terms involving $h^{3}$ and higher, then by adding (1) and (2) we obtain an approximation for the second derivative $y^{\prime \prime}(x)$ :


\begin{equation*}
y^{\prime \prime}(x) \approx \frac{1}{h^{2}}[y(x+h)-2 y(x)+y(x-h)] \tag{6}
\end{equation*}


The right sides of (3), (4), (5), and (6) are called difference quotients. The expressions

$$
\begin{aligned}
& y(x+h)-y(x) \quad y(x)-y(x-h) \\
& y(x+h)-y(x-h) \text { and } y(x+h)-2 y(x)+y(x-h)
\end{aligned}
$$

are called finite differences. Specifically, $y(x+h)-y(x)$ is called a forward difference, $y(x)-y(x-h)$ is a backward difference, and both $y(x+h)-y(x-h)$ and $y(x+h)-2 y(x)+y(x-h)$ are called central dif-\\
ferences. The results given in (5) and (6) are referred to as central difference approximations for the derivatives $y^{\prime}$ and $y^{\prime \prime}$.

Finite Difference Equation Consider now a linear second-order boundaryvalue problem


\begin{equation*}
y^{\prime \prime}+P(x) y^{\prime}+Q(x) y=f(x), \quad y(a)=\alpha, \quad y(b)=\beta \tag{7}
\end{equation*}


Suppose $a=x_{0}<x_{1}<x_{2}<\cdots<x_{n-1}<x_{n}=b$ represents a regular partition of the interval $[a, b]$; that is, $x_{i}=a+i h$, where $i=0,1,2, \ldots, n$ and $h=(b-a) / n$. The points

$$
x_{1}=a+h, \quad x_{2}=a+2 h, \quad \ldots, \quad x_{n-1}=a+(n-1) h
$$

are called interior mesh points of the interval $[a, b]$. If we let

$$
y_{i}=y\left(x_{i}\right), \quad P_{i}=P\left(x_{i}\right), \quad Q_{i}=Q\left(x_{i}\right), \quad \text { and } \quad f_{i}=f\left(x_{i}\right)
$$

and if $y^{\prime \prime}$ and $y^{\prime}$ in (7) are replaced by the central difference approximations (5) and (6), we get

$$
\frac{y_{i+1}-2 y_{i}+y_{i-1}}{h^{2}}+P_{i} \frac{y_{i+1}-y_{i-1}}{2 h}+Q_{i} y_{i}=f_{i}
$$

or, after simplifying,


\begin{equation*}
\left(1+\frac{h}{2} P_{i}\right) y_{i+1}+\left(-2+h^{2} Q_{i}\right) y_{i}+\left(1-\frac{h}{2} P_{i}\right) y_{i-1}=h^{2} f_{i} \tag{8}
\end{equation*}


The last equation, known as a finite difference equation, is an approximation to the differential equation. It enables us to approximate the solution $y(x)$ of (7) at the interior mesh points $x_{1}, x_{2}, \ldots, x_{n-1}$ of the interval $[a, b]$. By letting $i$ take on the values $1,2, \ldots, n-1$ in (8), we obtain $n-1$ equations in the $n-1$ unknowns $y_{1}, y_{2}, \ldots, y_{n-1}$. Bear in mind that we know $y_{0}$ and $y_{n}$ since these are the prescribed boundary conditions $y_{0}=y\left(x_{0}\right)=y(a)=\alpha$ and $y_{n}=y\left(x_{n}\right)=y(b)=\beta$.

In Example 1 we consider a boundary-value problem for which we can compare the approximate values found with the exact values of an explicit solution.

\section*{EXAMPLE 1 Finite Difference Method}
Use the difference equation (8) with $n=4$ to approximate the solution of the boundary-value problem $y^{\prime \prime}-4 y=0, y(0)=0, y(1)=5$.

Solution To use (8) we identify $P(x)=0, Q(x)=-4, \quad f(x)=0$, and $h=(1-0) / 4=\frac{1}{4}$. Hence the difference equation is


\begin{equation*}
y_{i+1}-2.25 y_{i}+y_{i-1}=0 \tag{9}
\end{equation*}


Now the interior points are $x_{1}=0+\frac{1}{4}, x_{2}=0+\frac{2}{4}, x_{3}=0+\frac{3}{4}$, and so for $i=1,2$, and 3 , (9) yields the following system for the corresponding $y_{1}, y_{2}$, and $y_{3}$ :

$$
\begin{aligned}
& y_{2}-2.25 y_{1}+y_{0}=0 \\
& y_{3}-2.25 y_{2}+y_{1}=0 \\
& y_{4}-2.25 y_{3}+y_{2}=0
\end{aligned}
$$

With the boundary conditions $y_{0}=0$ and $y_{4}=5$, the foregoing system becomes

$$
\begin{aligned}
-2.25 y_{1}+y_{2} & =0 \\
y_{1}-2.25 y_{2}+y_{3} & =0 \\
y_{2}-2.25 y_{3} & =-5
\end{aligned}
$$

Solving the system gives $y_{1}=0.7256, y_{2}=1.6327$, and $y_{3}=2.9479$.

Now the general solution of the given differential equation is $y=$ $c_{1} \cosh 2 x+c_{2} \sinh 2 x$. The condition $y(0)=0$ implies $c_{1}=0$. The other boundary condition gives $c_{2}$. In this way we see that an explicit solution of the boundary-value problem is $y(x)=(5 \sinh 2 x) / \sinh 2$. Thus the exact values (rounded to four decimal places) of this solution at the interior points are $y(0.25)=0.7184, y(0.5)=1.6201$, and $y(0.75)=2.9354$.

The accuracy of the approximations in Example 1 can be improved by using a smaller value of $h$. Of course, the trade-off here is that a smaller value of $h$ necessitates solving a larger system of equations. It is left as an exercise to show that with $h=\frac{1}{8}$, approximations to $y(0.25), y(0.5)$, and $y(0.75)$ are $0.7202,1.6233$, and 2.9386, respectively. See Problem 11.

\section*{EXAMPLE 2 Finite Difference Method}
Use the difference equation (8) with $n=10$ to approximate the solution of

$$
y^{\prime \prime}+3 y^{\prime}+2 y=4 x^{2}, \quad y(1)=1, y(2)=6
$$

Solution In this case we identify $P(x)=3, Q(x)=2, \quad f(x)=4 x^{2}$, and $h=(2-1) / 10=0.1$, and so (8) becomes


\begin{equation*}
1.15 y_{i+1}-1.98 y_{i}+0.85 y_{i-1}=0.04 x_{i}^{2} \tag{10}
\end{equation*}


Now the interior points are $x_{1}=1.1, x_{2}=1.2, x_{3}=1.3, x_{4}=1.4, x_{5}=1.5$, $x_{6}=1.6, x_{7}=1.7, x_{8}=1.8$, and $x_{9}=1.9$. Thus, for $i=1,2, \ldots, 9$ and $y_{0}=1, y_{10}=6,(10)$ gives a system of nine equations and nine unknowns:

$$
\begin{aligned}
1.15 y_{2}-1.98 y_{1} & =-0.8016 \\
1.15 y_{3}-1.98 y_{2}+0.85 y_{1} & =0.0576 \\
1.15 y_{4}-1.98 y_{3}+0.85 y_{2} & =0.0676 \\
1.15 y_{5}-1.98 y_{4}+0.85 y_{3} & =0.0784 \\
1.15 y_{6}-1.98 y_{5}+0.85 y_{4} & =0.0900 \\
1.15 y_{7}-1.98 y_{6}+0.85 y_{5} & =0.1024 \\
1.15 y_{8}-1.98 y_{7}+0.85 y_{6} & =0.1156 \\
1.15 y_{9}-1.98 y_{8}+0.85 y_{7} & =0.1296 \\
-1.98 y_{9}+0.85 y_{8} & =-6.7556 .
\end{aligned}
$$

We can solve this large system using Gaussian elimination or, with relative ease, by means of a computer algebra system such as Mathematica. The result is found to be $y_{1}=2.4047, y_{2}=3.4432, y_{3}=4.2010, y_{4}=4.7469, y_{5}=5.1359$, $y_{6}=5.4124, y_{7}=5.6117, y_{8}=5.7620$, and $y_{9}=5.8855$.

Remarks The approximation method that we have just considered can be extended to boundary-value problems in which the first derivative is specified at a boundary-for example, a problem such as $y^{\prime \prime}=f\left(x, y, y^{\prime}\right)$, $y^{\prime}(a)=\alpha, y(b)=\beta$. See Problem 13 .

\section*{EXERCISES 9.8}
\section*{Answers to odd-numbered problems begin on page A-28.}
In Problems 1-10 use the finite difference method and the indicated value of $n$ to approximate the solution of the given boundary-value problem.

\begin{enumerate}
  \item $y^{\prime \prime}+9 y=0, y(0)=4, y(2)=1 ; \quad n=4$

  \item $y^{\prime \prime}-y=x^{2}, y(0)=0, y(1)=0 ; \quad n=4$

  \item $y^{\prime \prime}+2 y^{\prime}+y=5 x, y(0)=0, y(1)=0 ; \quad n=5$

  \item $y^{\prime \prime}-10 y^{\prime}+25 y=1, y(0)=1, y(1)=0 ; \quad n=5$

  \item $y^{\prime \prime}-4 y^{\prime}+4 y=(x+1) e^{2 x}, y(0)=3, y(1)=0 ; \quad n=6$

  \item $y^{\prime \prime}+5 y^{\prime}=4 \sqrt{x}, y(1)=1, y(2)=-1 ; \quad n=6$

  \item $x^{2} y^{\prime \prime}+3 x y^{\prime}+3 y=0, y(1)=5, y(2)=0 ; \quad n=8$

  \item $x^{2} y^{\prime \prime}-x y^{\prime}+y=\ln x, y(1)=0, y(2)=-2 ; \quad n=8$

  \item $y^{\prime \prime}+(1-x) y^{\prime}+x y=x, y(0)=0, y(1)=2 ; \quad n=10$

  \item $y^{\prime \prime}+x y^{\prime}+y=x, y(0)=1, y(1)=0 ; \quad n=10$

  \item Rework Example 1 using $n=8$.

  \item The electrostatic potential $u$ between two concentric spheres of radius $r=1$ and $r=4$ is determined from

\end{enumerate}

$$
\frac{d^{2} u}{d r^{2}}+\frac{2}{r} \frac{d u}{d r}=0, \quad u(1)=50, \quad u(4)=100
$$

Use the method of this section with $n=6$ to approximate the solution of this boundary-value problem.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Consider the boundary-value problem $y^{\prime \prime}+x y=0, y^{\prime}(0)=1$, $y(1)=-1$.
\end{enumerate}

(a) Find the difference equation corresponding to the differential equation. Show that for $i=0,1,2, \ldots, n-1$ the difference equation yields $n$ equations in $n+1$ unknowns $y_{-1}, y_{0}, y_{1}, y_{2}, \ldots, y_{n-1}$. Here $y_{-1}$ and $y_{0}$ are unknowns since $y_{-1}$ represents an approximation to $y$ at the exterior point $x=-h$ and $y_{0}$ is not specified at $x=0$.

(b) Use the central difference approximation (5) to show that $y_{1}-y_{-1}=$ $2 h$. Use this equation to eliminate $y_{-1}$ from the system in part (a).

(c) Use $n=5$ and the system of equations found in parts (a) and (b) to approximate the solution of the original boundary-value problem.

\section*{CHAPTER 9 REVIEW}
A solution of a differential equation may exist and yet we may not be able to determine it in terms of the familiar elementary functions. A way of convincing oneself that a first-order equation $y^{\prime}=f(x, y)$ possesses a solution passing through a specific point $\left(x_{0}, y_{0}\right)$ is to sketch the direction field associated with the equation. The equation $f(x, y)=c$ determines the isoclines, or curves of constant inclination. This means that every solution curve that passes through a particular isocline does so with the same slope. The direction field is the totality of short line segments throughout two-dimensional space that have midpoints on the isoclines and that possess slope equal to the value of the parameter $c$. A carefully plotted sequence of these lineal elements can suggest the shape of a solution curve passing through the given point $\left(x_{0}, y_{0}\right)$.

At best, a direction field can give only the crudest form of an approximation to a numerical value of the solution $y(x)$ of the initial-value problem when $x$ is close to $x_{0}$.

To obtain the approximate values of $y(x)$, we used Euler's formula,

$$
y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right)
$$

the improved Euler's formula,

$$
\begin{gathered}
y_{n+1}=y_{n}+h \frac{f\left(x_{n}, y_{n}\right)+f\left(x_{n+1}, y_{n+1}^{*}\right)}{2} \\
y_{n+1}^{*}=y_{n}+h f\left(x_{n}, y_{n}\right)
\end{gathered}
$$

the three-term Taylor formula,

$$
y_{n+1}=y_{n}+y_{n}^{\prime} h+y_{n}^{\prime \prime} \frac{h^{2}}{2}
$$

the Runge-Kutta formula,

$$
y_{n+1}=y_{n}+\frac{1}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right)
$$

where

$$
\begin{aligned}
& k_{1}=h f\left(x_{n}, y_{n}\right) \\
& k_{2}=h f\left(x_{n}+\frac{1}{2} h, y_{n}+\frac{1}{2} k_{1}\right) \\
& k_{3}=h f\left(x_{n}+\frac{1}{2} h, y_{n}+\frac{1}{2} k_{2}\right) \\
& k_{4}=h f\left(x_{n}+h, y_{n}+k_{3}\right)
\end{aligned}
$$

and the Adams-Bashforth/Adams-Moulton formulas,

$$
\begin{gathered}
y_{n+1}^{*}=y_{n}+\frac{h}{24}\left(55 y_{n}^{\prime}-59 y_{n-1}^{\prime}+37 y_{n-2}^{\prime}-9 y_{n-3}^{\prime}\right) \\
y_{n+1}=y_{n}+\frac{h}{24}\left(9 y_{n+1}^{\prime}+19 y_{n}^{\prime}-5 y_{n-1}^{\prime}+y_{n-2}^{\prime}\right) \\
y_{n+1}^{\prime}=f\left(x_{n+1}, y_{n+1}^{*}\right)
\end{gathered}
$$

where

In each of the foregoing formulas, the number $h$ is the length of a uniform step. In other words, $x_{1}=x_{0}+h, x_{2}=x_{1}+h=x_{0}+2 h, \ldots, x_{n}=x_{n-1}+h=$ $x_{0}+n h$.

The first four methods are known as single-step, or starting, methods. The Adams-Bashforth/Adams-Moulton and Milne methods are examples of multistep, or continuing, methods. To use these multistep methods we need to first compute $y_{1}, y_{2}$, and $y_{3}$ by some starting method. The Adams-Bashforth/ Adams-Moulton and Milne methods are examples of a class of approximating formulas known as predictor-corrector formulas.

An important question in using numerical techniques is the size of error. The order of the global truncation error is a good way to measure the accuracy of a method,

To obtain numerical approximations to higher-order differential equations, we can reduce the differential equation to a system of first-order equations. We then apply a particular numerical technique to each equation of the system.

We can approximate a solution of a second-order boundary-value problem by replacing the differential equation by a finite difference equation.

\section*{CHAPTER 9 REVIEW EXERCISES}
Answers to odd-numbered problems begin on page A-29.

In Problems 1 and 2 sketch the direction field for the given differential equation. Indicate several possible solution curves.

$$
\begin{array}{ll}
\text { 1. } y d x-x d y=0 & \text { 2. } y^{\prime}=2 x-y
\end{array}
$$

In Problems 3-6 construct a table comparing the indicated values of $y(x)$ using Euler's, improved Euler's, three-term Taylor, and Runge-Kutta methods. Compute to four rounded decimal places. Use $h=0.1$ and $h=0.05$.\\
3. $y^{\prime}=2 \ln x y, y(1)=2$

$y(1.1), y(1.2), y(1.3), y(1.4), y(1.5)$\\
4. $y^{\prime}=\sin x^{2}+\cos y^{2}, y(0)=0$

$y(0.1), y(0.2), y(0.3), y(0.4), y(0.5)$\\
5. $y^{\prime}=\sqrt{x+y}, y(0.5)=0.5$

$y(0.6), y(0.7), y(0.8), y(0.9), y(1.0)$\\
6. $y^{\prime}=x y+y^{2}, y(1)=1$

$y(1.1), y(1.2), y(1.3), y(1.4), y(1.5)$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item Use Euler's method to obtain the approximate value of $y(0.2)$, where $y(x)$ is the solution of the initial-value problem
\end{enumerate}

$$
y^{\prime \prime}-(2 x+1) y=1, \quad y(0)=3, \quad y^{\prime}(0)=1
$$

First use one step with $h=0.2$ and then repeat the calculations using $h=0.1$.

\begin{enumerate}
  \setcounter{enumi}{7}
  \item Use the Adams-Bashforth/Adams-Moulton method to approximate the value of $y(0.4)$, where $y(x)$ is the solution of
\end{enumerate}

$$
y^{\prime}=4 x-2 y, \quad y(0)=2
$$

Use the Runge-Kutta formula and $h=0.1$ to obtain the values of $y_{1}, y_{2}$, and $y_{3}$.

\begin{enumerate}
  \setcounter{enumi}{8}
  \item Use Euler's method and $h=0.1$ to approximate the values of $x(0.2), y(0.2)$, where $x(t)$ and $y(t)$ are solutions of
\end{enumerate}

$$
\begin{gathered}
x^{\prime}=x+y \\
y^{\prime}=x-y \\
x(0)=1, \quad y(0)=2
\end{gathered}
$$

\begin{enumerate}
  \setcounter{enumi}{9}
  \item Use the finite difference method with $n=10$ to approximate the solution of the boundary-value problem
\end{enumerate}

$$
y^{\prime \prime}+6.55(1+x) y=1, \quad y(0)=0, \quad y(1)=0
$$

\section*{C. J. Knickerbocker}
Department of Mathematics, St. Lawrence University

\section*{NERVE IMPULSE MODELS}
Abiologically interesting and mathematically rich problem is the transmission of an electrical impulse down a nerve axon. The impulse, or action potential, is represented pictorially in Figure 9.15 as a voltage change over time at some point on the nerve axon.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-484(1)}
\end{center}

Figure 9.15

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-484}
\end{center}

$[\mathrm{Na}+]$

Figure 9.16 Nerve axon

Physically, a nerve axon can be thought of as a cylinder surrounded by a thin permeable membrane with sodium ions outside the axon membrane and potassium ions inside the membrane. See Figure 9.16.

Pretend we are standing at a point on the axon as a nerve impulse approaches. This "disturbance" induces a change in the voltage near us by having the sodium ions rush through the membrane, making the inside of the axon more positively charged. In Figure 9.15 this corresponds to the voltage rise at the left of the pulse. At this stage the potassium ions inside react to the voltage change by rushing out through the membrane, trying to re-equalize the potential across the membrane. This is seen as the voltage decline in Figure 9.15. But the potassium ions overcompensate and the charge becomes negative relative to the undisturbed case. A slow recovery period, the long tail in Figure 9.15, now occurs as the ions move back to their original sides of the membrane.

In about 1950, A. L. Hodgkin and A. F. Huxley developed a system of nonlinear partial differential equations that model the action potential in a nerve axon. The Hodgkin-Huxley system is similar to a nonlinear heat equation in\\
four dependent variables and two independent variables. In general, the solution to this type of equation is difficult, if not impossible, to find, and in particular the Hodgkin-Huxley equation cannot be solved analytically. Therefore, we need some alternatives to finding an analytical solution. The first possibility is to find an analytical solution to a simplified version of the Hodgkin-Huxley equation. Much research has been done on this idea, but in order to find an exact solution to the simplified equations the Hodgkin-Huxley equation must be reduced to the point where most of the interesting physical properties are lost. A second possibility is to find a numerical solution to a simplified Hodgkin-Huxley equation; that is, we approximate the Hodgkin-Huxley equation and then find a numerical solution to this approximate version. The simplified model we will consider is called the Fitzhugh-Nagumo equation, given by

$$
\begin{aligned}
\frac{\partial^{2} u}{\partial x^{2}} & =\frac{\partial u}{\partial t}+f(u)+z \\
\frac{\partial z}{\partial t} & =\varepsilon u \\
f(u) & =u(1-u)(a-u)
\end{aligned}
$$

where $\varepsilon$ is very small and $0 \leq a \leq 1$. The Hodgkin-Huxley equation is simplified by scaling variables, noting that two of the dependent variables are roughly time independent and that a certain nonlinear term can be simulated by a cubic function of the voltage. This equation was first described by Fitzhugh and was extensively studied by Nagumo. This simplified equation does not yield any real quantitative information about the action potential, but it is rich in the qualitative aspects of the physical problem.

We can make another simplification by noting that the action potential moves at a constant velocity $\theta$ and does not change its shape as it moves; that is, we can transfer the equation from an $x, t$-coordinate system to a traveling coordinate system in $\xi$ by assuming a solution of the form $u=u(\xi)=u(x-\theta t)$. This yields the following ordinary differential equation in $\xi$ :

$$
\begin{aligned}
\frac{d^{2} u}{d \xi^{2}}-\theta \frac{d u}{d \xi}-f(u)-z & =0 \\
\theta \frac{d z}{d \xi} & =\varepsilon u \\
f(u) & =u(1-u)(a-u)
\end{aligned}
$$

Some analytical results are known for this equation when specific values are chosen for the parameters. For example, when $\theta=0, \varepsilon=0$, and $u$ is assumed to be small (so that $f(u) \approx a u$ ), an analytical solution is easily determined.

Before any attempt is made to solve this equation numerically, we should look for any analytic "clues" that may help guide us in the choice and implementation of a numerical scheme. An analysis of the Fitzhugh-Nagumo equation produces two important pieces of information. First, using a technique called perturbation analysis, we anticipate a solution whose shape is similar to that of the action potential (see Figure 9.15). Second, using phase-plane analy-\\
sis, we find that the ordinary differential equation is very "sensitive" to the choices of the parameters $\theta, \varepsilon$, and $a$. That is to say that the numerical solutions might vary dramatically with small changes in any of these parameters.

The sensitive nature of the equation can be seen in the numerical results. Using the fourth-order Runge-Kutta method, we begin by choosing $\varepsilon=0.005$, $a=0.1, u(0)=0.001$, and $\theta=0.5184627034239536284$. This yields the solution given in Figure 9.17.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-486(1)}
\end{center}

Figure 9.17 Runge-Kutta solution 1

Note that all the qualitative features of the action potential are represented: a sharp rise in voltage followed by a sharp decline followed by a long slow recovery period. But, note that the numerical solution "blows up" to positive infinity on the right-hand side. Now by changing the last digit of $\theta$, yielding $\theta=$ 0.5184627034239536283 , we get the solution shown in Figure 9.18.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-486}
\end{center}

Figure 9.18 Runge-Kutta solution 2

This solution appears identical to the first solution except on the right-hand side, where it goes to negative infinity. This clearly shows how sensitive the numerical solution is to the choice of parameters.

A careful application of the fourth-order Runge-Kutta method also generates other possible solutions. For example, a numerical solution can be found in the form of a small slow pulse followed by a slightly larger pulse, both of which are considerably smaller than the "normal" solution.

A more advanced numerical method that can be applied to this ordinary differential equation is a technique called the finite elements method. In contrast\\
to the finite difference approach, where an exact solution is found to an approximation of the differential equation, the finite element approach is to find an approximate solution to the exact equation. This is accomplished by subdividing the $\xi$-axis with mesh width $\Delta \xi$. Over each interval a set of polynomials is defined. The higher the order of the set of polynomials, the more accurate the numerical solution will be. The polynomials are selected so that the values of the functions and the corresponding derivatives have certain properties at the boundaries of the interval. For the problem at hand we have selected over each interval six fifth-degree polynomials, called the Hermite quintics. The polynomials are then "plugged into" the differential equation. Clearly these polynomials cannot solve the differential equation on the complete interval, so we "force" the polynomials to work at a few points (called the Gaussian points) on each interval. Each Gaussian point now yields a nonlinear algebraic equation to solve, and therefore the method generates a system of coupled nonlinear algebraic equations to solve. The results of this type of approach used with the parameters stated previously are given in Figure 9.19.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-487}
\end{center}

Figure 9.19 Finite element solution

The advantage to this method is that it invokes conditions at both ends of the domain, thereby treating the problem as a boundary-value problem, as opposed to the fourth-order Runge-Kutta method, which treats the problem as an initial-value problem. The disadvantage to the method is the complexity of the technique and difficulties in programming.

The interested reader can find a survey on research that has been done on the various aspects of the Hodgkin-Huxley equation in an article entitled "The Electrophysics of a Nerve Fiber" by A. C. Scott in Reviews of Modern Physics (Volume 47, No. 2, April 1975). This article contains a very extensive list of references.

\section*{GAMMA FUNCTION}
Euler's integral definition of the gamma function* is


\begin{equation*}
\Gamma(x)=\int_{0}^{\infty} t^{x-1} e^{-t} d t \tag{1}
\end{equation*}


Convergence of the integral requires that $x-1>-1$, or $x>0$. The recurrence relation


\begin{equation*}
\Gamma(x+1)=x \Gamma(x) \tag{2}
\end{equation*}


which we saw in Section 6.5, can be obtained from (1) with integration by parts. Now when $x=1$,

$$
\Gamma(1)=\int_{0}^{\infty} e^{-t} d t=1
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-488}
\end{center}

Figure A.I and thus (2) gives

$$
\begin{aligned}
& \Gamma(2)=1 \Gamma(1)=1 \\
& \Gamma(3)=2 \Gamma(2)=2 \cdot 1 \\
& \Gamma(4)=3 \Gamma(3)=3 \cdot 2 \cdot 1
\end{aligned}
$$

and so on. In this manner it is seen that when $n$ is a positive integer,

$$
\Gamma(n+1)=n!
$$

For this reason the gamma function is often called the generalized factorial function.

Although the integral form (1) does not converge for $x<0$, it can be shown by means of alternative definitions that the gamma function is defined for all real and complex numbers except $x=-n, n=0,1,2, \ldots$ As a consequence, (2) is actually valid for $x \neq-n$. Considered as a function of a real variable $x$, the graph of $\Gamma(x)$ is as given in Figure A.1. Observe that the nonpositive integers correspond to vertical asymptotes of the graph.

In Problems 27-33 of Exercises 6.5 we utilized the fact that $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$. This result can be derived from (1) by setting $x=\frac{1}{2}$ :


\begin{equation*}
\Gamma\left(\frac{1}{2}\right)=\int_{0}^{\infty} t^{-1 / 2} e^{-t} d t \tag{3}
\end{equation*}

\footnotetext{\begin{itemize}
  \item This function was first defined by Leonhard Euler in his text Institutiones calculi integralis, published in 1768
\end{itemize}
}

When we let $t=u^{2}$,(3) can be written as

$$
\Gamma\left(\frac{1}{2}\right)=2 \int_{0}^{\infty} e^{-u^{2}} d u
$$

But

$$
\begin{gathered}
\int_{0}^{\infty} e^{-u^{2}} d u=\int_{0}^{\infty} e^{-v^{2}} d v \\
{\left[\Gamma\left(\frac{1}{2}\right)\right]^{2}=\left(2 \int_{0}^{\infty} e^{-u^{2}} d u\right)\left(2 \int_{0}^{\infty} e^{-v^{2}} d v\right)} \\
=4 \int_{0}^{\infty} \int_{0}^{\infty} e^{-\left(u^{2}+v^{2}\right)} d u d v
\end{gathered}
$$

Switching to polar coordinates $u=r \cos \theta, v=\sin \theta$ enables us to evaluate the double integral:

$$
\begin{gathered}
4 \int_{0}^{\infty} \int_{0}^{\infty} e^{-\left(u^{2}+v^{2}\right)} d u d v=4 \int_{0}^{\pi / 2} \int_{0}^{\infty} e^{-r^{2}} r d r d \theta=\pi \\
{\left[\Gamma\left(\frac{1}{2}\right)\right]^{2}=\pi \quad \text { or } \quad \Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}}
\end{gathered}
$$

Hence

\section*{EXAMPLE 1 Value of $\Gamma(-1 / 2)$}
Evaluate $\Gamma\left(-\frac{1}{2}\right)$.

Solution In view of (2) it follows that, with $x=-\frac{1}{2}$,

$$
\Gamma\left(\frac{1}{2}\right)=-\frac{1}{2} \Gamma\left(-\frac{1}{2}\right)
$$

Therefore

$$
\Gamma\left(-\frac{1}{2}\right)=-2 \Gamma\left(\frac{1}{2}\right)=-2 \sqrt{\pi}
$$

\section*{EXERCISES FOR APPENDIX I}
Answers to odd-numbered problems begin on page A-29.

\begin{enumerate}
  \item Evaluate.\\
(a) $\Gamma(5)$\\
(b) $\Gamma(7)$\\
(c) $\Gamma\left(-\frac{3}{2}\right)$\\
(d) $\Gamma\left(-\frac{5}{2}\right)$ 2. Use (1) and the fact that $\Gamma\left(\frac{6}{5}\right)=0.92$ to evaluate $\int_{0}^{\infty} x^{5} e^{-x^{5}} d x$.\\
[Hint: Let $t=x^{5}$.]

  \item Use (1) and the fact that $\Gamma\left(\frac{5}{3}\right)=0.89$ to evaluate $\int_{0}^{\infty} x^{4} e^{-x^{3}} d x$.

  \item Evaluate $\int_{0}^{1} x^{3}\left(\ln \frac{1}{x}\right)^{3} d x$. [Hint: Let $t=-\ln x$.]

  \item Use the fact that $\Gamma(x)>\int_{0}^{1} t^{x-1} e^{-t} d t$ to show that $\Gamma(x)$ is unbounded as\\
$x \rightarrow 0^{+}$.

  \item Use (1) to derive (2) for $x>0$.

\end{enumerate}

\section*{APPENDIX}
\section*{LAPLACE TRANSFORMS}
\begin{center}
\begin{tabular}{ll}
\hline
$f(t)$ & $\mathscr{L}\{f(t)\}=F(s)$ \\
\hline
1. 1 & $\frac{1}{s}$ \\
2. $t$ & $\frac{1}{s^{2}}$ \\
3. $t^{n}$ & $\frac{n!}{s^{n+1}}, n$ a positive integer \\
4. $t^{-1 / 2}$ & $\frac{\sqrt{\frac{\pi}{s}}}{2 s^{3 / 2}}$ \\
5. $t^{1 / 2}$ & $\frac{\Gamma(\alpha+1)}{s^{\alpha+1}}, \alpha>-1$ \\
6. $t^{\alpha}$ & $\frac{k}{s^{2}+k^{2}}$ \\
7. $\sin k t$ & $\frac{s}{s^{2}+k^{2}}$ \\
8. $\cos ^{2} k t$ & $\frac{2 k^{2}}{s\left(s^{2}+4 k^{2}\right)}$ \\
9. $\sin ^{2} k t$ & $\frac{s^{2}+2 k^{2}}{s\left(s^{2}+4 k^{2}\right)}$ \\
10. $\cos ^{2} k t$ & $\frac{1}{s-a}$ \\
11. $e^{a t}$ & $\frac{k}{s^{2}-k^{2}}$ \\
12. $\sinh ^{2} k t$ & $\frac{s}{s^{2}-k^{2}}$ \\
13. $\cosh ^{2} k t$ & $\frac{2 k^{2}}{s\left(s^{2}-4 k^{2}\right)}$ \\
14. $t^{n} e^{a t}$ & $\frac{s^{2}-2 k^{2}}{s\left(s^{2}-4 k^{2}\right)}$ \\
15t & $\frac{n!}{(s-a)^{2}}$ \\
15t1 &  \\
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|}
\hline
$f(t)$ & $\mathscr{L}\{f(t)\}=F(s)$ \\
\hline
18. $e^{a t} \sin k t$ & $\frac{k}{(s-a)^{2}+k^{2}}$ \\
\hline
19. $e^{a t} \cos k t$ & $\frac{s-a}{(s-a)^{2}+k^{2}}$ \\
\hline
20. $e^{a t} \sinh k t$ & $\frac{k}{(s-a)^{2}-k^{2}}$ \\
\hline
21. $e^{a t} \cosh k t$ & $\frac{s-a}{(s-a)^{2}-k^{2}}$ \\
\hline
22. $t \sin k t$ & $\frac{2 k s}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
23. $t \cos k t$ & $\frac{s^{2}-k^{2}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
24. $\sin k t+k t \cos k t$ & $\frac{2 k s^{2}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
25. $\sin k t-k t \cos k t$ & $\frac{2 k^{3}}{\left(s^{2}+k^{2}\right)^{2}}$ \\
\hline
26. $t \sinh k t$ & $\frac{2 k s}{\left(s^{2}-k^{2}\right)^{2}}$ \\
\hline
27. $t \cosh k t$ & $\frac{s^{2}+k^{2}}{\left(s^{2}-k^{2}\right)^{2}}$ \\
\hline
28. $\frac{e^{a t}-e^{b t}}{a-b}$ & $\frac{1}{(s-a)(s-b)}$ \\
\hline
29. $\frac{a e^{a t}-b e^{b t}}{a-b}$ & $\frac{s}{(s-a)(s-b)}$ \\
\hline
30. $1-\cos k t$ & $\frac{k^{2}}{s\left(s^{2}+k^{2}\right)}$ \\
\hline
31. $k t-\sin k t$ & $\frac{k^{3}}{s^{2}\left(s^{2}+k^{2}\right)}$ \\
\hline
32. $\frac{a \sin b t-b \sin a t}{a b\left(a^{2}-b^{2}\right)}$ & $\frac{1}{\left(s^{2}+a^{2}\right)\left(s^{2}+b^{2}\right)}$ \\
\hline
33. $\frac{\cos b t-\cos a t}{a^{2}-b^{2}}$ & $\frac{s}{\left(s^{2}+a^{2}\right)\left(s^{2}+b^{2}\right)}$ \\
\hline
34. $\sin k t$ sinh $k t$ & $\frac{2 k^{2} s}{s^{4}+4 k^{4}}$ \\
\hline
35. $\sin k t \cosh k t$ & $\frac{k\left(s^{2}+2 k^{2}\right)}{s^{4}+4 k^{4}}$ \\
\hline
36. $\cos k t \sinh k t$ & $\frac{k\left(s^{2}-2 k^{2}\right)}{s^{4}+4 k^{4}}$ \\
\hline
37. $\cos k t \cosh k t$ & $\frac{s^{3}}{s^{4}+4 k^{4}}$ \\
\hline
38. $J_{0}(k t)$ & $\frac{1}{\sqrt{s^{2}+k^{2}}}$ \\
\hline
\end{tabular}
\end{center}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-493}
\end{center}

\section*{REVIEW OF DETERMINANTS}
The determinant of a $2 \times 2$ matrix $\mathbf{A}$ is defined by

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-494}
\end{center}

Minors and Cofactors For an $n \times n$ matrix A, let $a_{i j}$ be the entry in the $i$ th row and $j$ th column. The minor $M_{i j}$ associated with $a_{i j}$ is the determinant of the $(n-1) \times(n-1)$ matrix obtained by deleting the $i$ th row and the $j$ th column of the matrix. The cofactor $C_{i j}$ associated with $a_{i j}$ is a signed minor, specifically

$$
C_{i j}=(-1)^{i+j} M_{i j}
$$

\section*{EXAMPLE 1 Cofactors}
The cofactors of the entries in the $3 \times 3$ matrix

\[
\left(\begin{array}{lll}
2 & 4 & 7  \tag{1}\\
1 & 2 & 3 \\
1 & 5 & 3
\end{array}\right)
\]

are

$$
\begin{aligned}
& C_{11}=(-1)^{1+1} M_{11} \quad C_{12}=(-1)^{1+2} M_{12} \quad C_{13}=(-1)^{1+3} M_{13} \\
& =\left|\begin{array}{ll}
2 & 3 \\
5 & 3
\end{array}\right|=-9 \quad=(-1)\left|\begin{array}{ll}
1 & 3 \\
1 & 3
\end{array}\right|=0 \quad=\left|\begin{array}{ll}
1 & 2 \\
1 & 5
\end{array}\right|=3 \\
& C_{21}=(-1)^{2+1} M_{21} \quad C_{22}=(-1)^{2+2} M_{22} \quad C_{23}=(-1)^{2+3} M_{23} \\
& =(-1)\left|\begin{array}{ll}
4 & 7 \\
5 & 3
\end{array}\right|=23 \quad=\left|\begin{array}{ll}
2 & 7 \\
1 & 3
\end{array}\right|=-1 \quad=(-1)\left|\begin{array}{ll}
2 & 4 \\
1 & 5
\end{array}\right|=-6 \\
& C_{31}=(-1)^{3+1} M_{31} \quad C_{32}=(-1)^{3+2} M_{32} \quad C_{33}=(-1)^{3+3} M_{33} \\
& =\left|\begin{array}{ll}
4 & 7 \\
2 & 3
\end{array}\right|=-2 \quad=(-1)\left|\begin{array}{ll}
2 & 7 \\
1 & 3
\end{array}\right|=1 \quad=\left|\begin{array}{ll}
2 & 4 \\
1 & 2
\end{array}\right|=0
\end{aligned}
$$

Expansion by Cofactors It can be proved that a determinant can be expanded in terms of cofactors:

Multiply the entries $a_{i j}$ in any row (or column) by their corresponding cofactors $C_{i j}$ and add the $n$ products.

Thus a $3 \times 3$ determinant* can be expanded into three $2 \times 2$ determinants, a $4 \times 4$ determinant can be expanded into four $3 \times 3$ determinants, and so on.

\section*{EXAMPLE 2 Determinant of a $\mathbf{3} \times \mathbf{3}$ Matrix}
Evaluate the determinant of the matrix in (1).

Solution Expanding by the first row gives

$$
\left|\begin{array}{lll}
2 & 4 & 7 \\
1 & 2 & 3 \\
1 & 5 & 3
\end{array}\right|=2\left|\begin{array}{ll}
2 & 3 \\
5 & 3
\end{array}\right|+4(-1)\left|\begin{array}{ll}
1 & 3 \\
1 & 3
\end{array}\right|+7\left|\begin{array}{ll}
1 & 2 \\
1 & 5
\end{array}\right|=3
$$

Alternatively, we can expand the determinant by, say, the second column:

$$
\left|\begin{array}{lll}
2 & 4 & 7 \\
1 & 2 & 3 \\
1 & 5 & 3
\end{array}\right|=4(-1)\left|\begin{array}{ll}
1 & 3 \\
1 & 3
\end{array}\right|+2\left|\begin{array}{ll}
2 & 7 \\
1 & 3
\end{array}\right|+5(-1)\left|\begin{array}{ll}
2 & 7 \\
1 & 3
\end{array}\right|=3
$$

We note that if a determinant has a row (or a column) containing many zero entries, then wisdom dictates that we expand the determinant by that row (or column).

Cramer's Rule Determinants are sometimes useful in solving algebraic systems of $n$ linear equations in $n$ unknowns:


\begin{gather*}
a_{11} x_{1}+a_{12} x_{2}+\cdots+a_{1 n} x_{n}=b_{1} \\
a_{21} x_{1}+a_{22} x_{2}+\cdots+a_{2 n} x_{n}=b_{2}  \tag{2}\\
\vdots \\
a_{n 1} x_{1}+a_{n 2} x_{2}+\cdots+a_{n n} x_{n}=b_{n}
\end{gather*}


Let $\mathbf{A}$ be the matrix of coefficients of (2) and let

$$
\operatorname{det} \mathbf{A}=\left|\begin{array}{llll}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots \\
a_{n 1} & a_{n 2} & \cdots & \vdots \\
a_{n n}
\end{array}\right|
$$

If

$$
\operatorname{det} \mathbf{A}_{k}=\left|\begin{array}{llllllll}
a_{11} & a_{12} & \cdots & a_{1, k-1} & b_{1} & a_{1, k+1} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2, k-1} & b_{2} & a_{2, k+1} & \cdots & a_{2 n} \\
\vdots & & & \vdots & \vdots & \vdots & & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n, k-1} & b_{n} & a_{n, k+1} & \cdots & a_{n}
\end{array}\right|
$$

is the same as det $\mathbf{A}$ except that its $k$ th column has been replaced by the column $b_{1}$\\
$b_{2}$\\
$\vdots$\\
$b_{n}$

\begin{itemize}
  \item Even though a determinant of a matrix of numbers is a number, it is sometimes convenient to refer to it as if it were an array.\\
then (2) has the unique solution
\end{itemize}


\begin{equation*}
x_{1}=\frac{\operatorname{det} \mathbf{A}_{1}}{\operatorname{det} \mathbf{A}}, \quad x_{2}=\frac{\operatorname{det} \mathbf{A}_{2}}{\operatorname{det} \mathbf{A}}, \quad \ldots, \quad x_{n}=\frac{\operatorname{det} \mathbf{A}_{n}}{\operatorname{det} \mathbf{A}} \tag{3}
\end{equation*}


whenever $\operatorname{det} \mathbf{A} \neq 0$. This method of solving (2) by determinants is known as Cramer's rule.*

\section*{EXAMPLE 3 Solution Using Cramer's Rule}
Solve the system

$$
\begin{array}{r}
3 x+2 y+z=7 \\
x-y+3 z=3 \\
5 x+4 y-2 z=1
\end{array}
$$

by Cramer's rule.

Solution The solution requires the calculation of four determinants:

$$
\begin{aligned}
\operatorname{det} \mathbf{A} & =\left|\begin{array}{rrr}
3 & 2 & 1 \\
1 & -1 & 3 \\
5 & 4 & -2
\end{array}\right|=13, \quad \operatorname{det} \mathbf{A}_{1}=\left|\begin{array}{rrr}
7 & 2 & 1 \\
3 & -1 & 3 \\
1 & 4 & -2
\end{array}\right|=-39 \\
\operatorname{det} \mathbf{A}_{2} & =\left|\begin{array}{rrr}
3 & 7 & 1 \\
1 & 3 & 3 \\
5 & 1 & -2
\end{array}\right|=78, \quad \operatorname{det} \mathbf{A}_{3}=\left|\begin{array}{rrr}
3 & 2 & 7 \\
1 & -1 & 3 \\
5 & 4 & 1
\end{array}\right|=52
\end{aligned}
$$

Hence (3) gives

$$
x=\frac{\operatorname{det} \mathbf{A}_{1}}{\operatorname{det} \mathbf{A}}=-3, \quad y=\frac{\operatorname{det} \mathbf{A}_{2}}{\operatorname{det} \mathbf{A}}=6, \quad z=\frac{\operatorname{det} \mathbf{A}_{3}}{\operatorname{det} \mathbf{A}}=4
$$

Homogeneous Systems If $b_{i}=0, i=1,2, \ldots, n$, then the system of equations (2) is said to be homogeneous. If at least one of the $b_{i}$ is not zero, the system is nonhomogeneous. Now if $\operatorname{det} \mathbf{A} \neq 0$, (3) implies that the only solution of a homogeneous system is $x_{1}=0, x_{2}=0, \ldots, x_{n}=0$. If $\operatorname{det} \mathbf{A}=0$, then a homogeneous system of $n$ linear equations in $n$ unknowns has infinitely many solutions. These solutions can be found by solving the system through elimination. If $\operatorname{det} \mathbf{A}=0$, then a nonhomogeneous system may have either infinitely many solutions or no solution at all.
\footnotetext{\begin{itemize}
  \item This rule was named after Gabriel Cramer (1704-1752), a Swiss mathematician who was the first to publish this result in 1750 .
\end{itemize}
}

\section*{EXERCISES FOR APPENDIX III}
Answers to odd-numbered problems begin on page A-29.

In Problems 1-8 evaluate the given determinant.

\begin{enumerate}
  \item $\left|\begin{array}{rrr}2 & 4 & 6 \\ -1 & 5 & 1 \\ 0 & 2 & -3\end{array}\right|$
  \item $\left|\begin{array}{rrr}1 & 4 & 2 \\ -2 & 6 & 3 \\ 9 & 8 & 4\end{array}\right|$
  \item $\left|\begin{array}{rrr}2 & 0 & 5 \\ 0 & 7 & 9 \\ -6 & 1 & 4\end{array}\right|$
  \item $\left|\begin{array}{rrr}79 & 81 & 40 \\ 22 & 16 & 59 \\ 0 & 0 & 0\end{array}\right|$
  \item $\left|\begin{array}{llll}1 & 2 & 3 & 4 \\ 1 & 1 & 0 & 0 \\ 8 & 7 & 0 & 0 \\ 9 & 5 & 3 & 0\end{array}\right|$
  \item $\left|\begin{array}{rrrrr}1 & 0 & 9 & 0 & 3 \\ 2 & 1 & 7 & 0 & 0 \\ 0 & 0 & 2 & 0 & 0 \\ -1 & 1 & 5 & 2 & 2 \\ 2 & 2 & 8 & 1 & 1\end{array}\right|$
  \item $\left|\begin{array}{ccc}e^{t} & e^{3 t} & e^{-t} \\ e^{t} & 3 e^{3 t} & -e^{-t} \\ e^{t} & 9 e^{3 t} & e^{-t}\end{array}\right|$
  \item $\left|\begin{array}{rrr}e^{2 t} & \sin t & \cos t \\ 2 e^{2 t} & \cos t & -\sin t \\ 4 e^{2 t} & -\sin t & -\cos t\end{array}\right|$
\end{enumerate}

In Problems 9-12 use Cramer's rule to solve the given system of equations.\\
9. $2 x+y=1$\\
10. $5 x+4 y=-1$\\
$3 x+2 y=-2$\\
$10 x-6 y=5$\\
11. $x+2 y+z=8$\\
12. $4 x+3 y+2 z=8$\\
$2 x-2 y+2 z=7$\\
$-x \quad+2 z=12$\\
$x-4 y+3 z=1$\\
$3 x+2 y+z=3$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item For the system
\end{enumerate}

$$
\begin{array}{r}
x-y+2 z=0 \\
2 x+y-z=0 \\
4 x-y+3 z=0
\end{array}
$$

let $\mathbf{A}$ denote the matrix of coefficients.

(a) Show that $\operatorname{det} \mathbf{A}=0$.

(b) Show that the system has infinitely many solutions.

(c) Explain the geometric significance of the system.

\begin{enumerate}
  \setcounter{enumi}{13}
  \item For the system
\end{enumerate}

$$
\begin{aligned}
& a_{1} x+b_{1} y=c_{1} \\
& a_{2} x+b_{2} y=c_{2},
\end{aligned}
$$

let $\mathbf{A}$ denote the matrix of coefficients.

(a) Explain the geometric significance of $\operatorname{det} \mathbf{A} \neq 0$.

(b) Explain the geometric significance of $\operatorname{det} \mathbf{A}=0$.

\section*{COMPLEX NUMBERS}
A complex number is any expression of the form

$$
z=a+b i, \quad \text { where } \quad i^{2}=-1
$$

The real numbers $a$ and $b$ are called the real and imaginary parts of $z$, respectively. In practice, the symbol $i$ is written $i=\sqrt{-1}$. The number $\bar{z}=a-b i$ is called the conjugate of $z$.

\section*{EXAMPLE 1 A Complex Number}
From the properties of radicals, we have

$$
\sqrt{-25}=\sqrt{25} \sqrt{-1}=5 i
$$

\section*{EXAMPLE 2 Conjugates of Complex Numbers}
The conjugates of the complex numbers $z_{1}=4+5 i$ and $z_{2}=3-2 i$ are, in turn, $\bar{z}_{1}=4-5 i$ and $\bar{z}_{2}=3+2 i$.

Sum, Difference, and Product The sum, difference, and product of two complex numbers $z_{1}=a_{1}+b_{1} i$ and $z_{2}=a_{2}+b_{2} i$ are defined as follows:

$$
\begin{aligned}
& \text { (i) } z_{1}+z_{2}=\left(a_{1}+a_{2}\right)+\left(b_{1}+b_{2}\right) i \\
& \text { (ii) } z_{1}-z_{2}=\left(a_{1}-a_{2}\right)+\left(b_{1}-b_{2}\right) i \\
& \text { (iii) } z_{1} z_{2}=\left(a_{1} a_{2}-b_{1} b_{2}\right)+\left(a_{1} b_{2}+b_{1} a_{2}\right) \text { i. }
\end{aligned}
$$

In other words, to add or subtract two complex numbers we simply add or subtract the corresponding real and imaginary parts. To multiply two complex numbers we use the distributive law and the fact that $i^{2}=-1$.

\section*{EXAMPLE 3 Addition/Subtraction/Multiplication}
$$
\text { If } \begin{aligned}
z_{1}=4+5 i \text { and } z_{2} & =3-2 i \text {, then } \\
z_{1}+z_{2} & =(4+3)+(5+(-2)) i=7+3 i \\
z_{1}-z_{2} & =(4-3)+(5-(-2)) i=1+7 i \\
z_{1} z_{2} & =(4+5 i)(3-2 i)
\end{aligned}
$$

$$
\begin{aligned}
& =(4+5 i) 3+(4+5 i)(-2 i) \\
& =12+15 i-8 i-10 i^{2} \\
& =(12+10)+(15-8) i=22+7 i
\end{aligned}
$$

The product of a complex number $z=a+b i$ and its conjugate $\bar{z}=a-b i$ is the real number.


\begin{equation*}
z \bar{z}=a^{2}+b^{2} \tag{1}
\end{equation*}


Quotient The quotient of two complex numbers $z_{1}$ and $z_{2}$ is found by multiplying the numerator and denominator of $z_{1} / z_{2}$ by the conjugate of the denominator $z_{2}$ and using (1). The next example illustrates the procedure.

\section*{EXAMPLE 4 Quotient of Complex Numbers}
$$
\begin{aligned}
\frac{z_{1}}{z_{2}} & =\frac{4+5 i}{3-2 i} \\
& =\frac{4+5 i}{3-2 i} \frac{3+2 i}{3+2 i} \\
& =\frac{12+15 i+8 i+10 i^{2}}{9+4}=\frac{2}{13}+\frac{23}{13} i
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-499}
\end{center}

Figure A. 2

Geometric Interpretation By taking $a$ and $b$ to be the $x$ - and $y$-coordinates of a point in the plane, we can interpret a complex number $z=a+b i$ as a vector from the origin terminating at $(a, b)$ (see Figure A.2). The length of the vector is called the modulus of $z$ and is written as $r$, or $|z|$. From the Pythagorean theorem it follows that

$$
r=|z|=\sqrt{a^{2}+b^{2}}
$$

If $\theta$ is an angle the vector makes with the positive $x$-axis, then from Figure A. 2 we see that

$$
a=r \cos \theta \quad \text { and } \quad b=r \sin \theta
$$

Thus


\begin{equation*}
z=r \cos \theta+i r \sin \theta \quad \text { or } \quad z=r(\cos \theta+i \sin \theta) \tag{2}
\end{equation*}


This latter form is called the polar form of the complex number $z$. The angle $\theta$ is called an argument of $z$.

Euler's Formula The power series $e^{X}=\sum_{n=0}^{\infty} \frac{X^{n}}{n!}$ is known to converge for all real and complex numbers. If we let $X=i \theta, \theta$ a real number, then


\begin{equation*}
e^{i \theta}=\sum_{n=0}^{\infty} \frac{(i \theta)^{n}}{n!}=1+i \theta+\frac{i^{2} \theta^{2}}{2!}+\frac{i^{3} \theta^{3}}{3!}+\frac{i^{4} \theta^{4}}{4!}+\frac{i^{5} \theta^{5}}{5!}+\frac{i^{6} \theta^{6}}{6!}+\frac{i^{7} \theta^{7}}{7!}+\cdots \tag{3}
\end{equation*}


Now $i^{2}=-1, i^{3}=-i, i^{4}=1, i^{5}=i$, and so on. Thus (3) can be separated into real and imaginary parts:


\begin{equation*}
e^{i \theta}=\left(1-\frac{\theta^{2}}{2!}+\frac{\theta^{4}}{4!}-\frac{\theta^{6}}{6!}+\cdots\right)+i\left(\theta-\frac{\theta^{3}}{3!}+\frac{\theta^{5}}{5!}-\frac{\theta^{7}}{7!}+\cdots\right) \tag{4}
\end{equation*}


But from calculus we recall that

$$
\cos \theta=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n)!} \theta^{2 n} \quad \text { and } \quad \sin \theta=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n+1)!} \theta^{2 n+1}
$$

where each series converges for every real number $\theta$. Hence (4) can be written as


\begin{equation*}
e^{i \theta}=\cos \theta+i \sin \theta \tag{5}
\end{equation*}


This last result is known as Euler's formula. Note that in view of (5), the polar form (2) of a complex number can be expressed in the compact form


\begin{equation*}
z=r e^{i \theta} \tag{6}
\end{equation*}


\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-500}
\end{center}

Figure A. 3

\section*{EXAMPLE 5 Polar Form}
Find the polar form (6) of $z=1-i$.

Solution The graph of the complex number is given in Figure A.3. Since $a=1$ and $b=-1$, the modulus of $z$ is

$$
r=\sqrt{1^{2}+(-1)^{2}}=\sqrt{2}
$$

As seen in Figure A.3, $\tan \theta=-1$ and so we can take an argument of $z$ to be $\theta=-\pi / 4$. Therefore, the polar form of the number is

$$
z=\sqrt{2} e^{-i \pi / 4}
$$

\section*{EXERCISES FOR APPENDIX IV}
Answers to odd-numbered problems begin on page A-29.

In Problems 1-10 let $z_{1}=2-i$ and $z_{2}=5+3 i$. Perform the indicated operation.

\begin{enumerate}
  \item $z_{1}+\bar{z}_{2}$
  \item $4 z_{1}+z_{2}$
  \item $2 z_{1}-3 z_{2}$
  \item $z_{1} z_{2}$
  \item $\left(z_{1}\right)^{2}$
  \item $\bar{z}_{1}\left(i+z_{2}\right)$
  \item $z_{1} / z_{2}$
  \item $z_{2} / z_{1}$
  \item $1 / z_{2}$
  \item $z_{1} / i$
\end{enumerate}

In Problems 11-20 write the given complex number in the polar form (6).\\
11. $z=i$\\
12. $z=-4 i$\\
13. $z=i^{2}$\\
14. $z=6 i^{5}$\\
15. $z=2+2 i$\\
16. $z=-\sqrt{5}-\sqrt{5} i$\\
17. $z=6+6 \sqrt{3} i$\\
18. $z=-10 \sqrt{3}+10 i$\\
19. $z=i(1-\sqrt{3} i)$\\
20. $z=-7+7 i$

In Problems 21 and 22 express the given complex number in the polar form in the form $z=a+b i$.

$\begin{array}{ll}\text { 21. } z=8 e^{-i \pi} & \text { 22. } z=2 e^{77 \pi / 4}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item Prove DeMoivre's theorem:* For any positive integer $n$,
\end{enumerate}

$$
[r(\cos \theta+i \sin \theta)]^{n}=r^{n}[\cos n \theta+i \sin n \theta]
$$

\begin{enumerate}
  \setcounter{enumi}{23}
  \item Use DeMoivre's theorem of Problem 23 to evaluate $(1+i)^{10}$.

  \item Use Euler's formula to show that

\end{enumerate}

$$
\cos \theta=\frac{e^{i \theta}+e^{-i \theta}}{2} \text { and } \sin \theta=\frac{e^{i \theta}-e^{-i \theta}}{2 i}
$$

\section*{ODD-NUMBERED PROBLEMS}
\section*{EXERCISES 1.1 (PAGE 9)}
\begin{enumerate}
  \item second-order linear

  \item first-order nonlinear

  \item fourth-order linear

  \item second-order nonlinear

  \item third-order linear

  \item $2 y^{\prime}+y=2\left(-\frac{1}{2}\right) e^{-x / 2}+e^{-x / 2}=0$

  \item $\frac{d y}{d x}-2 y-e^{3 x}$

\end{enumerate}

$=\left(3 e^{3 x}+20 e^{2 x}\right)-2\left(e^{3 x}+10 e^{2 x}\right)-e^{3 x}=0$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $y^{\prime}-25-y^{2}=25 \sec ^{2} 5 x-25\left(1+\tan ^{2} 5 x\right)$
\end{enumerate}

$=25 \sec ^{2} 5 x-25 \sec ^{2} 5 x=0$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $y^{\prime}+y-\sin x=\frac{1}{2} \cos x+\frac{1}{2} \sin x-10 e^{-x}+\frac{1}{2} \sin x$
\end{enumerate}

$$
-\frac{1}{2} \cos x+10 e^{-x}-\sin x=0
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $y x^{2}=-1$ implies $d\left(y x^{2}\right)=0$
\end{enumerate}

or $\quad 2 y x d x+x^{2} d y=0$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $y-2 x y^{\prime}-y\left(y^{\prime}\right)^{2}=y-2 x \frac{c_{1}}{2 y}-y \frac{c_{1}^{2}}{4 y^{2}}$
\end{enumerate}

$$
\begin{aligned}
& =\frac{y^{2}-\left(c_{1} x+\left(c_{1}^{2} / 4\right)\right)}{y} \\
& =\frac{y^{2}-y^{2}}{y}=0
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $y^{\prime}-\frac{1}{x} y-1=1+\ln x-\ln x-1=0$

  \item $\frac{d}{d t} \ln \frac{2-X}{1-X}=1, \quad\left[\frac{-1}{2-X}+\frac{1}{1-X}\right] \frac{d X}{d t}=1$ simplifies to $\frac{d X}{d t}=(2-X)(1-X)$

  \item The differential of $c_{1}=x e^{y / x} /(x+y)^{2}$ is

\end{enumerate}

$\left\{(x+y)^{2}\left[x e^{y / x}\left(x d y-y d x / x^{2}\right)+e^{y / x} d x\right]\right.$ $\left.-x e^{y / x} 2(x+y)(d x+d y)\right\} /(x+y)^{4}=0$.

Multiplying by $-x^{2}(x+y)^{3} e^{-y / x}$ and simplifying yields $\left(x^{2}+y^{2}\right) d x+\left(x^{2}-x y\right) d y=0$.

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $y^{\prime \prime}-6 y^{\prime}+13 y=5 e^{3 x} \cos 2 x-12 e^{3 x} \sin 2 x$
\end{enumerate}

$$
\begin{aligned}
& +12 e^{3 x} \sin 2 x-18 e^{3 x} \cos 2 x \\
& +13 e^{3 x} \cos 2 x=0
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $y^{\prime \prime}=\cosh x+\sinh x=y$

  \item $y^{\prime \prime}+\left(y^{\prime}\right)^{2}=-\frac{1}{\left(x+c_{1}\right)^{2}}+\frac{1}{\left(x+c_{1}\right)^{2}}=0$

  \item $x \frac{d^{2} y}{d x^{2}}+2 \frac{d y}{d x}=x\left(2 c_{2} x^{-3}\right)+2\left(-c_{2} x^{-2}\right)=0$

  \item $x^{2} y^{\prime \prime}-3 x y^{\prime}+4 y$

\end{enumerate}

$=x^{2}(5+2 \ln x)-3 x(3 x+2 x \ln x)$

$+4\left(x^{2}+x^{2} \ln x\right)$

$=9 x^{2}-9 x^{2}+6 x^{2} \ln x-6 x^{2} \ln x=0$\\
39. $y^{\prime \prime \prime}-3 y^{\prime \prime}+3 y^{\prime}-y$

$=x^{2} e^{x}+6 x e^{x}+6 e^{x}-3 x^{2} e^{x}-12 x e^{x}$

$-6 e^{x}+3 x^{2} e^{x}+6 x e^{x}-x^{2} e^{x}=0$

\begin{enumerate}
  \setcounter{enumi}{40}
  \item For $x<0, x y^{\prime}-2 y=x(-2 x)-2\left(-x^{2}\right)=0$; for $x \geq 0, x y^{\prime}-2 y=x(2 x)-2\left(x^{2}\right)=0$.

  \item $y-x y^{\prime}-\left(y^{\prime}\right)^{2}=c x+c^{2}-x(c)-c^{2}=0$; $k=-\frac{1}{4}$

  \item $y=-1 \quad$ 47. $m=2$ and $m=3$

  \item $m=\frac{1 \pm \sqrt{5}}{2}$

  \item For $y=x^{2}$,

\end{enumerate}

$x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=x^{2}(2)-4 x(2 x)+6 x^{2}$

$$
=8 x^{2}-8 x^{2}=0
$$

for $y=x^{3}$,

$x^{2} y^{\prime \prime}-4 x y^{\prime}+6 y=x^{2}(6 x)-4 x\left(3 x^{2}\right)+6 x^{3}$

$$
=12 x^{3}-12 x^{3}=0
$$

yes; yes

$\begin{array}{lll}\text { 53. (a) } y=0 & \text { (b) no real solution } & \text { (c) } y=1 \text { or } y=-1\end{array}$

\section*{EXERCISES 1.2 (PAGE 22)}
\begin{enumerate}
  \item $\frac{d v}{d t}+\frac{k}{m} v=g$

  \item (a) $k=g R^{2} \quad$ (b) $\frac{d^{2} r}{d t^{2}}-\frac{g R^{2}}{r^{2}}=0$

\end{enumerate}

(c) $v \frac{d v}{d r}-\frac{g R^{2}}{r^{2}}=0$

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-502}\\
9. $\frac{d h}{d t}=-\frac{1}{30 \sqrt{h}(10-h)}$\\
11. $\frac{d x}{d t}+k x=r, \quad k>0$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $m x^{\prime \prime}=-k \cos \theta \quad m y^{\prime \prime}=-m g-k \sin \theta$
\end{enumerate}

$$
\begin{array}{ll}
=-k \cdot \frac{1}{v} \frac{d x}{d t} & =-m g-k \cdot \frac{1}{v} \frac{d y}{d t} \\
=-|c| \frac{d x}{d t} & =-m g-|c| \frac{d y}{d t}
\end{array}
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item Using $\tan \phi=\frac{x}{y}, \tan \left(\frac{\pi}{2}-\theta\right)=\frac{d y}{d x}, \tan \theta=\frac{d x}{d y}$,
\end{enumerate}

and $\tan \phi=\tan 2 \theta=\frac{2 \tan \theta}{1-\tan ^{2} \theta}$,

we obtain $x\left(\frac{d x}{d y}\right)^{2}+2 y \frac{d x}{d y}=x$.

\begin{enumerate}
  \setcounter{enumi}{16}
  \item By combining Newton's second law of motion with his law of gravitation, we obtain
\end{enumerate}

$$
m \frac{d^{2} y}{d t^{2}}=-k_{1} \frac{m M}{y^{2}}
$$

where $M$ is the mass of the earth and $k_{1}$ is a constant of proportionality. Dividing by $m$ gives

$$
\frac{d^{2} y}{d t^{2}}=-\frac{k}{y^{2}}
$$

where $k=k_{1} M$. The constant $k$ is $g R^{2}$, where $R$ is the radius of the earth. This follows from the fact that on the surface of the earth $y=R$ so

$$
\begin{gathered}
k_{1} \frac{m M}{R^{2}}=m g \\
k_{1} M=g R^{2} \quad \text { or } \quad k=g R^{2}
\end{gathered}
$$

If $t=0$ is the time at which burnout occurs, then

$$
y(0)=R+y_{B}
$$

where $y_{B}$ is the distance from the earth's surface to the rocket at the time of burnout and

$$
y^{\prime}(0)=V_{B}
$$

is the corresponding velocity at that time.\\
19. $\frac{d y}{d x}=-\frac{y}{\sqrt{s^{2}-y^{2}}}$\\
21. $\frac{d A}{d t}=k(M-A), \quad k>0$

\section*{CHAPTER 1 REVIEW EXERCISES (PAGE 26)}
\begin{enumerate}
  \item ordinary, first-order, nonlinear 3. partial, second-order
\end{enumerate}

$\begin{array}{lll}\text { 9. } y=x^{2} & \text { 11. } y=\frac{x^{2}}{2} & \text { 13. } y=0, y=e^{x}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $y=0, y=\cos x, y=\sin x$

  \item $x<0$ or $x>1$

\end{enumerate}

$$
\text { 19. } \frac{d h}{d t}=-\frac{25 \sqrt{2 g}}{16 \pi} h^{-3 / 2}
$$

\section*{EXERCISES 2.1 (PAGE 32)}
\begin{enumerate}
  \item half-planes defined by either $y>0$ or $y<0$

  \item half-planes defined by either $x>0$ or $x<0$

  \item the regions defined by either $y>2, y<-2$, or $-2<y<2$

  \item any region not containing $(0,0) \quad 9$. the entire $x y$-plane

  \item $y=0, y=x^{3}$

  \item There is some interval around $x=0$ on which the unique solution is $y=0$.

  \item $y=0, y=x$. No, the given function is nondifferentiable at $x=0$.

  \item yes 19. no

\end{enumerate}

\section*{EXERCISES 2.2 (PAGE 38)}
\begin{enumerate}
  \item $y=-\frac{1}{5} \cos 5 x+c$

  \item $y=\frac{1}{3} e^{-3 x}+c$

  \item $y=x+5 \ln |x+1|+c \quad$ 7. $y=c x^{4}$

  \item $y^{-2}=2 x^{-1}+c \quad$ 11. $-3+3 x \ln |x|=x y^{3}+c x$

  \item $-3 e^{-2 y}=2 e^{3 x}+c \quad$ 15. $2+y^{2}=c\left(4+x^{2}\right)$

  \item $y^{2}=x-\ln |x+1|+c$

  \item $\frac{x^{3}}{3} \ln x-\frac{1}{9} x^{3}=\frac{y^{2}}{2}+2 y+\ln |y|+c$

  \item $S=c e^{k r}$

  \item $\frac{P}{1-P}=c e^{t}$ or $\quad P=\frac{c e^{t}}{1+c e^{t}}$

  \item $4 \cos y=2 x+\sin 2 x+c$

  \item $-2 \cos x+e^{y}+y e^{-y}+e^{-y}=c$

  \item $\left(e^{x}+1\right)^{-2}+2\left(e^{y}+1\right)^{-1}=c$

  \item $(y+1)^{-1}+\ln |y+1|=\frac{1}{2} \ln \left|\frac{x+1}{x-1}\right|+c$

  \item $y-5 \ln |y+3|=x-5 \ln |x+4|+c$ or $\left(\frac{y+3}{x+4}\right)^{5}=c_{1} e^{y-x}$

  \item $-\cot y=\cos x+c$

  \item $-y^{-1}=\tan ^{-1}\left(e^{x}\right)+c$

  \item $y=\sin \left(\frac{x^{2}}{2}+c\right)$

  \item $(1+\cos x)\left(1+e^{y}\right)=4$

  \item $\sqrt{y^{2}+1}=2 x^{2}+\sqrt{2}$ 45. $x=\tan (4 y-3 \pi / 4)$

  \item $x y=e^{-(1+1 / x)}$

  \item (a) $y=3 \frac{1-e^{6 x}}{1+e^{6 x}} \quad$ (b) $y=3$

\end{enumerate}

(c) $y=3 \frac{2-e^{6 x-2}}{2+e^{6 x-2}}$

$\begin{array}{lll}\text { 51. } y=1 & \text { 53. } y=1 & \text { 55. } y=1+\frac{1}{10} \tan \frac{x}{10}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{56}
  \item $y=-x-1+\tan (x+c)$

  \item $2 y-2 x+\sin 2(x+y)=c$

  \item $4(y-2 x+3)=(x+c)^{2}$

\end{enumerate}

\section*{EXERCISES 2.3 (PAGE 45)}
$\begin{array}{lll}\text { 1. homogeneous of degree } 3 & \text { 3. homogeneous of degree } 2\end{array}$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item not homogeneous 7. homogeneous of degree 0

  \item homogeneous of degree -2 11. $x \ln |x|+y=c x$

  \item $(x-y) \ln |x-y|=y+c(x-y)$ 15. $x+y \ln |x|=c y$

  \item $\ln \left(x^{2}+y^{2}\right)+2 \tan ^{-1}(y / x)=c \quad$ 19. $4 x=y(\ln |y|-c)^{2}$

  \item $y^{9}=c\left(x^{3}+y^{3}\right)^{2} \quad$ 23. $(y / x)^{2}=2 \ln |x|+c$

  \item $e^{2 x / y}=8 \ln |y|+c \quad$ 27. $x \cos (y / x)=c$

  \item $y+x=c x^{2} e^{y / x} \quad$ 31. $y^{3}+3 x^{3} \ln |x|=8 x^{3}$

  \item $y^{2}=4 x(x+y)^{2} \quad$ 35. $\ln |x|=e^{y / x}-1$

  \item $4 x \ln |y / x|+x \ln x+y-x=0$

  \item $3 x^{3 / 2} \ln x+3 x^{1 / 2} y+2 y^{3 / 2}=5 x^{3 / 2}$

  \item $(x+y) \ln |y|+x=0$

  \item $\ln |y|=-2(1-x / y)^{1 / 2}+\sqrt{2}$

  \item By homogeneity the equation can be written as

\end{enumerate}

$$
M(x / y, 1) d x+N(x / y, 1) d y=0
$$

With $v=x / y$, it follows that

$$
\begin{aligned}
M(v, 1)(v d y+y d v)+N(v, 1) d y & =0 \\
{[v M(v, 1)+N(v, 1)] d y+y M(v, 1) d v } & =0 \\
\frac{d y}{y}+\frac{M(v, 1) d v}{v M(v, 1)+N(v, 1)} & =0
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{46}
  \item $\frac{d y}{d x}=-\frac{M(x, y)}{N(x, y)}=-\frac{y^{n} M(x / y, 1)}{y^{n} N(x / y, 1)}$
\end{enumerate}

$$
=-\frac{M(x / y, 1)}{N(x / y, 1)}=G(x / y)
$$

\section*{EXERCISES 2.4 (PAGE 52)}
\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-504}\\
5. $x^{2} y^{2}-3 x+4 y=c \quad$ 7. not exact, but is homogeneous\\
9. $x y^{3}+y^{2} \cos x-\frac{1}{2} x^{2}=c$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item not exact

  \item $x y-2 x e^{x}+2 e^{x}-2 x^{3}=c$

  \item $x+y+x y-3 \ln |x y|=c \quad$ 17. $x^{3} y^{3}-\tan ^{-1} 3 x=c$

  \item $-\ln |\cos x|+\cos x \sin y=c$

  \item $y-2 x^{2} y-y^{2}-x^{4}=c$

  \item $x^{4} y-5 x^{3}-x y+y^{3}=c$

  \item $\frac{1}{3} x^{3}+x^{2} y+x y^{2}-y=\frac{4}{3}$

  \item $4 x y+x^{2}-5 x+3 y^{2}-y=8$

  \item $y^{2} \sin x-x^{3} y-x^{2}+y \ln y-y=0 \quad$ 31. $k=10$

  \item $k=1 \quad$ 35. $M(x, y)=y e^{x y}+y^{2}-\left(y / x^{2}\right)+h(x)$

  \item $M(x, y)=6 x y^{3}$

\end{enumerate}

$N(x, y)=4 y^{3}+9 x^{2} y^{2}$

$\partial M / \partial y=18 x y^{2}=\partial N / \partial x$

Solution is $3 x^{2} y^{3}+y^{4}=c$.

\begin{enumerate}
  \setcounter{enumi}{38}
  \item $M(x, y)=-x^{2} y^{2} \sin x+2 x y^{2} \cos x$
\end{enumerate}

$N(x, y)=2 x^{2} y \cos x$

$\partial M / \partial y=-2 x^{2} y \sin x+4 x y \cos x=\partial N / \partial x$

Solution is $x^{2} y^{2} \cos x=c$.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item $M(x, y)=2 x y^{2}+3 x^{2}$
\end{enumerate}

$N(x, y)=2 x^{2} y$

$\partial M / \partial y=4 x y=\partial N / \partial x$

Solution is $x^{2} y^{2}+x^{3}=c$.

\begin{enumerate}
  \setcounter{enumi}{42}
  \item A separable first-order differential equation can be written $h(y) d y-g(x) d x=0$. Identifying $M(x, y)=-g(x)$ and $N(x, y)=h(y)$, we find that $\partial M / \partial y=0=\partial N / \partial x$.
\end{enumerate}

\section*{EXERCISES 2.5 (PAGE 6O)}
\begin{enumerate}
  \item $y=c e^{5 x}, \quad-\infty<x<\infty$

  \item $y=\frac{1}{3}+c e^{-4 x}, \quad-\infty<x<\infty$

  \item $y=\frac{1}{4} e^{3 x}+c e^{-x}, \quad-\infty<x<\infty$

  \item $y=\frac{1}{3}+c e^{-x^{3}}, \quad-\infty<x<\infty$

  \item $y=x^{-1} \ln x+c x^{-1}, \quad 0<x<\infty$

  \item $x=-\frac{4}{5} y^{2}+c y^{-1 / 2}, \quad 0<y<\infty$

  \item $y=-\cos x+\frac{\sin x}{x}+\frac{c}{x}, \quad 0<x<\infty$

  \item $y=\frac{c}{e^{x}+1}, \quad-\infty<x<\infty$

  \item $y=\sin x+c \cos x, \quad-\pi / 2<x<\pi / 2$

  \item $y=\frac{1}{7} x^{3}-\frac{1}{5} x+c x^{-4}, \quad 0<x<\infty$

  \item $y=\frac{1}{2 x^{2}} e^{x}+\frac{c}{x^{2}} e^{-x}, \quad 0<x<\infty$

  \item $y=\sec x+c \csc x, \quad 0<x<\pi / 2$

  \item $x=\frac{1}{2} e^{y}-\frac{1}{2 y} e^{y}+\frac{1}{4 y^{2}} e^{y}+\frac{c}{y^{2}} e^{-y}, \quad 0<y<\infty$

  \item $y=e^{-3 x}+\frac{c}{x} e^{-3 x}, \quad 0<x<\infty$

  \item $x=2 y^{6}+c y^{4}, \quad 0<y<\infty$

  \item $y=e^{-x} \ln \left(e^{x}+e^{-x}\right)+c e^{-x}, \quad-\infty<x<\infty$

  \item $x=\frac{1}{y}+\frac{c}{y} e^{-y^{2}}, \quad 0<y<\infty$

  \item $(\sec \theta+\tan \theta) r=\theta-\cos \theta+c, \quad-\pi / 2<\theta<\pi / 2$

  \item $y=\frac{5}{3}(x+2)^{-1}+c(x+2)^{-4}, \quad-2<x<\infty$

  \item $y=10+c e^{-\sinh x}, \quad-\infty<x<\infty$

  \item $y=4-2 e^{-5 x}, \quad-\infty<x<\infty$

  \item $i(t)=E / R+\left(i_{0}-E / R\right) e^{-R t / L}, \quad-\infty<t<\infty$

  \item $y=\sin x \cos x-\cos x, \quad-\pi / 2<x<\pi / 2$

  \item $T(t)=50+150 e^{k t}, \quad-\infty<t<\infty$

  \item $(x+1) y=x \ln x-x+21, \quad 0<x<\infty$

  \item $y=\frac{2 x}{x-2}, \quad 2<x<\infty$

  \item $x=\frac{1}{2} y+8 / y, \quad 0<y<\infty$

  \item $y=\left\{\begin{array}{lr}\frac{1}{2}\left(1-e^{-2 x}\right), & 0 \leq x \leq 3 \\ \frac{1}{2}\left(e^{6}-1\right) e^{-2 x}, & x>3\end{array}\right.$

  \item $y=\left\{\begin{array}{lr}\frac{1}{2}+\frac{3}{2} e^{-x^{2}}, & 0 \leq x<1 \\ \left(\frac{1}{2} e+\frac{3}{2}\right) e^{-x^{2}}, & x \geq 1\end{array}\right.$

\end{enumerate}

\section*{EXERCISES 2.6 (PAGE 65)}
\begin{enumerate}
  \item $y^{3}=1+c x^{-3}$ 3. $y^{-3}=x+\frac{1}{3}+c e^{3 x}$

  \item $e^{x / y}=c x \quad$ 7. $y^{-3}=-\frac{9}{5} x^{-1}+\frac{49}{5} x^{-6}$

  \item $x^{-1}=2-y^{2}-e^{-y^{2} / 2}$, the equation is Bernoulli in the variable $x$.

  \item $y=2+\frac{1}{c e^{-3 x}-1 / 3}$

  \item $y=\frac{2}{x}+\frac{1}{c x^{-3}-x / 4}$

  \item $y=-e^{x}+\frac{1}{c e^{-x}-1}$

  \item $y=-2+\frac{1}{c e^{-x}-1}$

  \item $y=c x+1-\ln c ; y=2+\ln x$

  \item $y=c x-c^{3} ; 27 y^{2}=4 x^{3}$

  \item $y=c x-e^{c} ; y=x \ln x-x$

\end{enumerate}

\section*{EXERCISES 2.7 (PAGE 69)}
\begin{enumerate}
  \item $x^{2} e^{2 y}=2 x \ln x-2 x+c \quad$ 3. $e^{-x}=y \ln |y|+c y$

  \item $-e^{-y / x^{4}}=x^{2}+c$ 7. $x^{2}+y^{2}=x-1+c e^{-x}$

  \item $\ln (\tan y)=x+c x^{-1} \quad$ 11. $x^{3} y^{3}=2 x^{3}-9 \ln |x|+c$

  \item $e^{y}=-e^{-x} \cos x+c e^{-x}$ 15. $y^{2} \ln x=y e^{y}-e^{y}+c$

  \item $y=\ln \left|\cos \left(c_{1}-x\right)\right|+c_{2}$

  \item $y=-\frac{1}{c_{1}}\left(1-c_{1}^{2} x^{2}\right)^{1 / 2}+c_{2}$

  \item The given equation is a Clairaut equation in $u=y^{\prime}$. The solution is $y=c_{1} x^{2} / 2+x+c_{1}^{3} x+c_{2}$.

  \item $y=c_{1}+c_{2} x^{2} \quad$ 25. $\frac{1}{3} y^{3}-c_{1} y=x+c_{2}$

  \item $y=-\sqrt{1-x^{2}}$

\end{enumerate}

\section*{EXERCISES 2.8 (PAGE 72)}
\begin{enumerate}
  \item $y_{1}(x)=1-x$
\end{enumerate}

$y_{2}(x)=1-\frac{x}{1!}+\frac{x^{2}}{2!}$

$y_{3}(x)=1-\frac{x}{1!}+\frac{x^{2}}{2!}-\frac{x^{3}}{3!}$

$y_{4}(x)=1-\frac{x}{1!}+\frac{x^{2}}{2!}-\frac{x^{3}}{3!}+\frac{x^{4}}{4!}$

$y_{n}(x) \rightarrow e^{-x}$ as $n \rightarrow \infty$\\
3. $y_{1}(x)=1+x^{2}$

$y_{2}(x)=1+\frac{x^{2}}{1!}+\frac{x^{4}}{2!}$

$y_{3}(x)=1+\frac{x^{2}}{1!}+\frac{x^{4}}{2!}+\frac{x^{6}}{3!}$

$y_{4}(x)=1+\frac{x^{2}}{1!}+\frac{x^{4}}{2!}+\frac{x^{6}}{3!}+\frac{x^{8}}{4!}$

$y_{n}(x) \rightarrow e^{x^{2}}$ as $n \rightarrow \infty$\\
5. $y_{1}(x)=y_{2}(x)=y_{3}(x)=y_{4}(x)=0$

$y_{n}(x) \rightarrow 0$ as $n \rightarrow \infty$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item (a) $y_{1}(x)=x$
\end{enumerate}

$$
\begin{aligned}
& y_{2}(x)=x+\frac{1}{3} x^{3} \\
& y_{3}(x)=x+\frac{1}{3} x^{3}+\frac{2}{15} x^{5}+\frac{1}{63} x^{7}
\end{aligned}
$$

(b) $y=\tan x$

(c) The Maclaurin series expansion of $\tan x$ is $x+\frac{1}{3} x^{3}+\frac{2}{15} x^{5}+\frac{17}{315} x^{7}+\cdots,|x|<\pi / 2$.

\section*{CHAPTER 2 REVIEW EXERCISES (PAGE 73)}
\begin{enumerate}
  \item the regions defined by $x^{2}+y^{2}>25$ and $x^{2}+y^{2}<25$

  \item false

  \item (a) linear in $x$ (b) homogeneous, exact, linear in $y$

\end{enumerate}

(c) Clairaut (d) Bernoulli in $x$ (e) separable

(f) separable, Ricatti (g) linear in $x$ (h) homogeneous

(i) Bernoulli (j) homogeneous, exact, Bernoulli

(k) separable, homogeneous, exact, linear in $x$ and in $y$

(I) exact, linear in $y$ (m) homogeneous (n) separable

(o) Clairaut (p) Ricatti

$\begin{array}{ll}\text { 7. } 2 y^{2} \ln y-y^{2}=4 x e^{x}-4 e^{x}-1 & \text { 9. } 2 y^{2}+x^{2}=9 x^{6}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $e^{x y}-4 y^{3}=5$

  \item $y=\frac{1}{4}-320\left(x^{2}+4\right)^{-4}$

  \item $y=\frac{1}{x^{4}-x^{4} \ln |x|}$

  \item $x^{2}-\sin \frac{1}{y^{2}}=c$

  \item $y_{1}(x)=1+x+\frac{1}{3} x^{3}$

\end{enumerate}

$y_{2}(x)=1+x+x^{2}+\frac{2}{3} x^{3}+\frac{1}{6} x^{4}+\frac{2}{15} x^{5}+\frac{1}{63} x^{7}$

\section*{EXERCISES 3.1 (PAGE 8O)}
\begin{enumerate}
  \item $x^{2}+y^{2}=c_{2}^{2} \quad$ 3. $2 y^{2}+x^{2}=c_{2}$

  \item $2 \ln |y|=x^{2}+y^{2}+c_{2}$

  \item $y^{2}=2 x+c_{2}$

  \item $2 x^{2}+3 y^{2}=c_{2}$

  \item $x^{3}+y^{3}=c_{2}$

  \item $y^{2} \ln |y|+x^{2}=c_{2} y^{2}$

  \item $y^{2}-x^{2}=c_{2} x$

  \item $2 y^{2}=2 \ln |x|+x^{2}+c_{2}$

  \item $y=\frac{1}{4}-\frac{1}{6} x^{2}+c_{2} x^{-4}$

  \item $2 y^{3}=3 x^{2}+c_{2}$

  \item $2 \ln (\cosh y)+x^{2}=c_{2}$

  \item $y^{5 / 3}=x^{5 / 3}+c_{2}$

  \item $y=2-x+3 e^{-x}$

  \item $r=c_{2} \sin \theta$

  \item $r^{2}=c_{2} \cos 2 \theta$

  \item $r=c_{2} \csc \theta$

  \item Let $\beta$ be the angle of inclination, measured from the positive $x$-axis, of the tangent line to a member of the given family, and $\phi$ the angle of inclination of the tangent to a trajectory. At the point where the curves intersect, the angle between the tangents is $\alpha$. From the accompanying figures we conclude that there exist two possible cases and that $\phi=\beta \pm \alpha$. Thus the slope of the tangent line to a trajectory is

\end{enumerate}

$$
\begin{aligned}
\frac{d y}{d x} & =\tan \phi=\tan (\beta \pm \alpha) \\
& =\frac{\tan \beta \pm \tan \alpha}{1 \mp \tan \beta \tan \alpha} \\
& =\frac{f(x, y) \pm \tan \alpha}{1 \mp f(x, y) \tan \alpha}
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-505}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-505(1)}
\end{center}

(b)

\begin{enumerate}
  \setcounter{enumi}{36}
  \item $\mp \frac{2}{\sqrt{3}} \tan ^{-1}\left(\frac{y}{x}\right)+\ln c_{2}\left(x^{2}+y^{2}\right)=0$

  \item Since the given equation is quadratic in $c_{1}$, it follows from the quadratic formula that

\end{enumerate}

$$
c_{1}=-x \pm \sqrt{x^{2}+y^{2}}
$$

Differentiating this last expression and solving for $d y / d x$ gives

and

$$
\begin{aligned}
& \frac{d y}{d x}=\frac{-x+\sqrt{x^{2}+y^{2}}}{y} \\
& \frac{d y}{d x}=\frac{-x-\sqrt{x^{2}+y^{2}}}{y}
\end{aligned}
$$

These two equations correspond to choosing $c_{1}>0$ and $c_{1}<0$ in the given family, respectively. Forming the product of these derivatives yields

$$
\left(\frac{d y}{d x}\right)_{(1)} \cdot\left(\frac{d y}{d x}\right)_{(2)}=\frac{x^{2}-x^{2}-y^{2}}{y^{2}}=-1
$$

This shows that the family is self-orthogonal.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item The differential equation of the orthogonal family is $(x-y) d x+(x+y) d y=0$. The verification follows by substituting $x=c_{2} e^{-t} \cos t$ and $y=c_{2} e^{-t} \sin t$ into the equation.
\end{enumerate}

\section*{EXERCISES 3.2 (PAGE 89)}
\begin{enumerate}
  \item $7.9 \mathrm{yr} ; 10 \mathrm{yr}$

  \item 760

  \item 11 h

  \item 136.5 h

  \item $I(15)=0.00098 I_{0}$, or $I(15)$ is approximately $0.1 \%$ of $I_{0}$.

  \item $15,600 \mathrm{yr}$

  \item $T(1)=36.67^{\circ}$; approximately 3.06 min

  \item $i(t)=\frac{3}{5}-\frac{3}{5} e^{-500 t} ; i \rightarrow \frac{3}{5}$ as $t \rightarrow \infty$

  \item $q(t)=\frac{1}{100}-\frac{1}{100} e^{-50 t} ; i(t)=\frac{1}{2} e^{-50 t}$

  \item $i(t)=\left\{\begin{array}{lr}60-60 e^{-t / 10}, & 0 \leq t \leq 20 \\ 60\left(e^{2}-1\right) e^{-t / 10}, & t>20\end{array}\right.$

  \item $A(t)=200-170 e^{-t / 50}$

  \item $A(t)=1000-1000 e^{-t / 100}$

  \item 64.38 lb

  \item (a) $v(t)=\frac{m g}{k}+\left(v_{0}-\frac{m g}{k}\right) e^{-k t / m}$

\end{enumerate}

(b) $v \rightarrow \frac{m g}{k}$ as $t \rightarrow \infty$

(c) $s(t)=\frac{m g}{k} t-\frac{m}{k}\left(v_{0}-\frac{m g}{k}\right) e^{-k t / m}$

$$
+\frac{m}{k}\left(v_{0}-\frac{m g}{k}\right)+s_{0}
$$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $E(t)=E_{0} e^{-\left(t-t_{1}\right) / R C}$

  \item (a) $P(t)=P_{0} e^{\left(k_{1}-k_{2}\right) t}$

\end{enumerate}

(b) $k_{1}>k_{2}$, births surpass deaths so population increases. $k_{1}=k_{2}$, a constant population since the number of births equals the number of deaths. $k_{1}<k_{2}$, deaths surpass births so population decreases.\\
33. From $r^{2} d \theta=\frac{L}{M} d t$ we get

$$
A=\frac{1}{2} \int_{\theta_{1}}^{\theta_{2}} r^{2} d \theta=\frac{1}{2} \frac{L}{M} \int_{a}^{b} d t=\frac{1}{2} \frac{L}{M}(b-a)
$$

\section*{EXERCISES 3.3 (PAGE 99)}
\section*{1. $1834 ; 2000$ \\
 3. $1,000,000 ; 52.9 \mathrm{mo}$}
\begin{enumerate}
  \setcounter{enumi}{4}
  \item (a) Separating variables gives
\end{enumerate}

$$
\frac{d P}{P(a-b \ln P)}=d t
$$

so

$$
\begin{array}{rlrl}
-(1 / b) \ln |a-b \ln P| & =t+c_{1} & \\
a-b \ln P & =c_{2} e^{-b t} & & \left(e^{-b c_{1}}=c_{2}\right) \\
\ln P & =(a / b)-c e^{-b t} & \left(c_{2} / b=c\right) \\
P(t) & =e^{a / b} \cdot e^{-c e^{-\infty} .} & &
\end{array}
$$

(b) If $P(0)=P_{0}$, then

$$
P_{0}=e^{a / b} e^{-c}=e^{a / b-c}
$$

and so

$$
\begin{aligned}
\ln P_{0} & =(a / b)-c \\
c & =(a / b)-\ln P_{0} .
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $29.3 \mathrm{~g} ; X \rightarrow 60$ as $t \rightarrow \infty ; 0 \mathrm{~g}$ of $A$ and 30 g of $B$

  \item For $\alpha \neq \beta$ the differential equation separates as

\end{enumerate}

$$
\frac{1}{\alpha-\beta}\left[-\frac{1}{\alpha-X}+\frac{1}{\beta-X}\right] d x=k d t
$$

It follows immediately that

or

$$
\begin{array}{r}
\frac{1}{\alpha-\beta}[\ln |\alpha-X|-\ln |\beta-X|]=k t+c \\
\frac{1}{\alpha-\beta} \ln \left|\frac{\alpha-X}{\beta-X}\right|=k t+c
\end{array}
$$

For $\alpha=\beta$ the differential equation can be written as

$$
(\alpha-X)^{-2} d X=k d t
$$

It follows that $(\alpha-X)^{-1}=k t+c$ or

$$
X=\alpha-\frac{1}{k t+c}
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item (a) $v^{2}=\left(2 g R^{2} / y\right)+v_{0}^{2}-2 g R$. We note that as $y$ increases, $v$ decreases. In particular, if $v_{0}^{2}-2 g R<0$, then there must be some value of $y$ for which $v=0$; the rocket stops and returns to earth under the influence of gravity. However, if $v_{0}^{2}-2 g R \geq 0$, then $v>0$ for all values of $y$. Hence we should have $v_{0} \geq \sqrt{2 g R}$.
\end{enumerate}

(b) With the values $R=4000 \mathrm{mi}, g=32 \mathrm{ft} / \mathrm{s}^{2}$, $1 \mathrm{ft}=1 / 5280 \mathrm{mi}$, and $1 \mathrm{~s}=1 / 3600 \mathrm{~h}$, it follows that $v_{0} \geq 25,067 \mathrm{mi} / \mathrm{h}$.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item Using the condition $y^{\prime}(1)=0$, we find
\end{enumerate}

$$
\frac{d y}{d x}=\frac{1}{2}\left[x^{v_{1} / v_{2}}-x^{-v_{1} / v_{2}}\right]
$$

Now if $v_{1}=v_{2}$, then $y=\frac{1}{4} x^{2}-\frac{1}{2} \ln x-\frac{1}{4}$; if $v_{1} \neq v_{2}$, then

$$
y=\frac{1}{2}\left[\frac{x^{1+\left(v_{1} / v_{2}\right)}}{1+\frac{v_{1}}{v_{2}}}-\frac{x^{1-\left(v_{1} / v_{2}\right)}}{1-\frac{v_{1}}{v_{2}}}\right]+\frac{v_{1} v_{2}}{v_{2}^{2}-v_{1}^{2}}
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $2 h^{1 / 2}=-\frac{1}{25} t+2 \sqrt{20} ; t=50 \sqrt{20} \mathrm{~s}$

  \item To evaluate the indefinite integral of the left side of

\end{enumerate}

$$
\frac{\sqrt{100-y^{2}}}{y} d y=-d x
$$

we use the substitution $y=10 \cos \theta$. It follows that

$$
x=10 \ln \left(\frac{10+\sqrt{100-y^{2}}}{y}\right)-\sqrt{100-y^{2}}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item Under the substitution $w=x^{2}$, the differential equation becomes
\end{enumerate}

$$
w=y \frac{d w}{d y}+\frac{1}{4}\left(\frac{d w}{d y}\right)^{2}
$$

which is Clairaut's equation. The solution is

$$
x^{2}=c y+\frac{c^{2}}{4}
$$

If $2 c_{1}=c$, then we recognize

$$
x^{2}=2 c_{1} y+c_{1}^{2}
$$

as describing a family of parabolas.\\
21. $-\gamma \ln y+\delta y=\alpha \ln x-\beta x+c$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item (a) The equation $2 \frac{d^{2} \theta}{d t^{2}} \frac{d \theta}{d t}+2 \frac{g}{l} \sin \theta \frac{d \theta}{d t}=0$ is the same as
\end{enumerate}

$$
\frac{d}{d t}\left(\frac{d \theta}{d t}\right)^{2}+2 \frac{g}{l} \sin \theta \frac{d \theta}{d t}=0
$$

Integrating this last equation with respect to $t$ and using the initial conditions gives the result.

(b) From (a),

$$
d t=\sqrt{\frac{l}{2 g}} \frac{d \theta}{\sqrt{\cos \theta-\cos \theta_{0}}}
$$

Integrating this last equation gives the time for the pendulum to move from $\theta=\theta_{0}$ to $\theta=0$ :

$$
t=\sqrt{\frac{l}{2 g}} \int_{0}^{\theta_{0}} \frac{d \theta}{\sqrt{\cos \theta-\cos \theta_{0}}}
$$

The period is the total time $T$ to go from $\theta=\theta_{0}$ to $\theta=-\theta_{0}$ and back again to $\theta=\theta_{0}$. This is

$$
\begin{aligned}
T & =4 \sqrt{\frac{l}{2 g}} \int_{0}^{\theta_{0}} \frac{d \theta}{\sqrt{\cos \theta-\cos \theta_{0}}} \\
& =2 \sqrt{\frac{2 l}{g}} \int_{0}^{\theta_{0}} \frac{d \theta}{\sqrt{\cos \theta-\cos \theta_{0}}}
\end{aligned}
$$

\section*{CHAPTER 3 REVIEW EXERCISES (PAGE 104)}
\begin{enumerate}
  \item $y^{3}+3 / x=c_{2} \quad$ 3. $2(y-2)^{2}+(x-1)^{2}=c_{2}^{2}$

  \item $P(45)=8.99$ billion

  \item $x(t)=\frac{\alpha c_{1} e^{\alpha k_{1} t}}{1+c_{1} e^{\alpha k_{1} t}}, y(t)=c_{2}\left(1+c_{1} e^{\alpha k_{1} t}\right)^{k_{2} / k_{1}}$

  \item (a) $T(t)=\frac{T_{2}+B T_{1}}{1+B}+\frac{T_{1}-T_{2}}{1+B} e^{k(1+B) t}$

\end{enumerate}

(b) $\frac{T_{2}+B T_{1}}{1+B} \quad$ (c) $\frac{T_{2}+B T_{1}}{1+B}$

\section*{EXERCISES 4.1 (PAGE 129)}
\begin{enumerate}
  \item $y=\frac{1}{2} e^{x}-\frac{1}{2} e^{-x} \quad$ 3. $y=\frac{3}{5} e^{4 x}+\frac{2}{5} e^{-x}$
\end{enumerate}

$\begin{array}{ll}\text { 5. } y=3 x-4 x \ln x & \text { 7. } y=0, y=x^{2}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item (a) $y=e^{x} \cos x-e^{x} \sin x \quad$ (b) no solution
\end{enumerate}

(c) $y=e^{x} \cos x+e^{-\pi / 2} e^{x} \sin x$

(d) $y=c_{2} e^{x} \sin x$, where $c_{2}$ is arbitrary

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $(-\infty, 2)$ 13. $\lambda=n, n=1,2,3, \ldots \quad$ 15. dependent

  \item dependent 19. dependent 21. independent

  \item $W\left(x^{1 / 2}, x^{2}\right)=\frac{3}{2} x^{3 / 2} \neq 0$ on $(0, \infty)$

  \item $W(\sin x, \csc x)=-2 \cot x$. $W=0$ only at $x=\pi / 2$ in the interval.

  \item $W\left(e^{x}, e^{-x}, e^{4 x}\right)=-30 e^{4 x} \neq 0$ on $(-\infty, \infty)$

  \item no

  \item (a) $y^{\prime \prime}-2 y^{3}=\frac{2}{x^{3}}-2\left(\frac{1}{x}\right)^{3}=0$

\end{enumerate}

(b) $y^{\prime \prime}-2 y^{3}=\frac{2 c}{x^{2}}-2 \frac{c^{3}}{x^{3}}=\frac{2}{x^{3}} c\left(1-c^{2}\right) \neq 0$ for $c \neq 0, \pm 1$

\begin{enumerate}
  \setcounter{enumi}{32}
  \item The functions satisfy the differential equation and are linearly independent on the interval since
\end{enumerate}

$$
W\left(e^{-3 x}, e^{4 x}\right)=7 e^{x} \neq 0 ; \quad y=c_{1} e^{-3 x}+c_{2} e^{4 x}
$$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item The functions satisfy the differential equation and are linearly independent on the interval since
\end{enumerate}

$$
\begin{aligned}
& W\left(e^{x} \cos 2 x, e^{x} \sin 2 x\right)=2 e^{2 x} \neq 0 \\
& y=c_{1} e^{x} \cos 2 x+c_{2} e^{x} \sin 2 x
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{36}
  \item The functions satisfy the differential equation and are linearly independent on the interval since
\end{enumerate}

$$
W\left(x^{3}, x^{4}\right)=x^{6} \neq 0 ; \quad y=c_{1} x^{3}+c_{2} x^{4}
$$

\begin{enumerate}
  \setcounter{enumi}{38}
  \item The functions satisfy the differential equation and are linearly independent on the interval since
\end{enumerate}

$$
\begin{aligned}
& W\left(x, x^{-2}, x^{-2} \ln x\right)=9 x^{-6} \neq 0 \\
& y=c_{1} x+c_{2} x^{-2}+c_{3} x^{-2} \ln x
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{40}
  \item $e^{2 x}$ and $e^{5 x}$ form a fundamental set of solutions of the homogeneous equation; $6 e^{x}$ is a particular solution of the nonhomogeneous equation.

  \item $e^{2 x}$ and $x e^{2 x}$ form a fundamental set of solutions of the homogeneous equation; $x^{2} e^{2 x}+x-2$ is a particular solution of the nonhomogeneous equation.

  \item (a) The accompanying graphs show that $y_{1}$ and $y_{2}$ are not multiples of each other. Also,

\end{enumerate}

$$
\begin{aligned}
x^{2} y_{1}^{\prime \prime}-4 x y_{1}^{\prime}+6 y_{1} & =x^{2}(6 x)-4 x\left(3 x^{2}\right)+6 x^{3} \\
& =12 x^{3}-12 x^{3}=0 .
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-508}
\end{center}

(a)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-508(1)}
\end{center}

(b)\\
For $x \geq 0$ the demonstration that $y_{2}$ is a solution of the equation is exactly as given above for $y_{1}$.

For $x<0, y_{2}=-x^{3}$ and so

$$
\begin{aligned}
x^{2} y_{2}^{\prime \prime}-4 x y_{2}^{\prime}+6 y_{2} & =x^{2}(-6 x)-4 x\left(-3 x^{2}\right)+6\left(-x^{3}\right) \\
& =-12 x^{3}+12 x^{3}=0
\end{aligned}
$$

(b) For $x \geq 0$,

$$
W\left(y_{1}, y_{2}\right)=\left|\begin{array}{rr}
x^{3} & x^{3} \\
3 x^{2} & 3 x^{2}
\end{array}\right|=3 x^{5}-3 x^{5}=0
$$

For $x<0$,

$$
W\left(y_{1}, y_{2}\right)=\left|\begin{array}{rr}
x^{3} & -x^{3} \\
3 x^{2} & -3 x^{2}
\end{array}\right|=-3 x^{5}+3 x^{5}=0
$$

Thus $W\left(y_{1}, y_{2}\right)=0$ for every real value of $x$.

(c) No, $a_{2}(x)=x^{2}$ is zero at $x=0$.

(d) Since $Y_{1}=y_{1}$, we need only show that

$$
\begin{aligned}
x^{2} Y_{2}^{\prime \prime}-4 x Y_{2}^{\prime}+6 Y_{2} & =x^{2}(2)-4 x(2 x)+6 x^{2} \\
& =8 x^{2}-8 x^{2}=0
\end{aligned}
$$

and $W\left(x^{3}, x^{2}\right)=-x^{4}$. Thus $Y_{1}$ and $Y_{2}$ are linearly independent solutions on the interval.

(e) $Y_{1}=x^{3}, Y_{2}=x^{2}$, or $y_{2}=|x|^{3}$

(f) Neither; we form a general solution on an interval for which $a_{2}(x) \neq 0$ for every $x$ in the interval. The linear combination

$$
y=c_{1} Y_{1}+c_{2} Y_{2}
$$

would be a general solution of the equation on, say, the interval $(0, \infty)$.

\begin{enumerate}
  \setcounter{enumi}{46}
  \item (a) Since $y_{1}$ and $y_{2}$ are solutions of the given differential equation, we have
\end{enumerate}

$$
\begin{aligned}
& a_{2}(x) y_{1}^{\prime \prime}+a_{1}(x) y_{1}^{\prime}+a_{0}(x) y_{1}=0 \\
& a_{2}(x) y_{2}^{\prime \prime}+a_{1}(x) y_{2}^{\prime}+a_{0}(x) y_{2}=0
\end{aligned}
$$

and

We multiply the first equation by $y_{2}$ and the second by $y_{1}$ and subtract the first from the second:

$$
a_{2}(x)\left[y_{1} y_{2}^{\prime \prime}-y_{2} y_{1}^{\prime \prime}\right]+a_{1}(x)\left[y_{1} y_{2}^{\prime}-y_{2} y_{1}^{\prime}\right]=0
$$

Now it is easily verified that

$$
\frac{d W}{d x}=\frac{d}{d x}\left(y_{1} y_{2}^{\prime}-y_{2} y_{1}^{\prime}\right)=y_{1} y_{2}^{\prime \prime}-y_{2} y_{1}^{\prime \prime}
$$

and so it follows that

$$
a_{2}(x) \frac{d W}{d x}+a_{1}(x) W=0
$$

(b) Since this last equation is a linear first-order differential equation, the integrating factor is

$$
e^{\int\left[a_{1}(x) / a_{2}(x)\right] d x}
$$

Therefore, from

$$
\frac{d}{d x}\left[e^{\int\left[a_{1}(x) / a_{2}(x)\right] d x} W\right]=0
$$

we obtain $W=c e^{-\int\left[a_{1}(x) / a_{2}(x)\right] d x}$.

(c) Substituting $x=x_{0}$ in the given result, we find $c=W\left(x_{0}\right)$.

(d) Since an exponential function is never zero when $W\left(x_{0}\right) \neq 0$, it follows from part (c) that $W \neq 0$. On the other hand, if $W\left(x_{0}\right)=0$, we have immediately that $W=0$.

\begin{enumerate}
  \setcounter{enumi}{48}
  \item From part (c) of Problem 47 we have
\end{enumerate}

$$
\begin{aligned}
W\left(y_{1}, y_{2}\right) & =W\left(y_{1}\left(x_{0}\right), y_{2}\left(x_{0}\right)\right) e^{-\int_{x_{0}}^{2} d t / t} \\
& =\left|\begin{array}{ll}
k_{1} & k_{3} \\
k_{2} & k_{4}
\end{array}\right| e^{-\ln \left(x / x_{0}\right)} \\
& =\left(k_{1} k_{4}-k_{3} k_{2}\right)\left(\frac{x_{0}}{x}\right)
\end{aligned}
$$

EXERCISES 4.2 (PAGE 137)

\begin{enumerate}
  \item $y_{2}=e^{-5 x}$
  \item $y_{2}=x e^{2 x}$
  \item $y_{2}=\sin 4 x$
  \item $y_{2}=\sinh x$
  \item $y_{2}=x e^{2 x / 3}$
  \item $y_{2}=x^{4} \ln \mid x$
\end{enumerate}

\includegraphics[max width=\textwidth, center]{2024_07_17_9719f7b5e669c3c92088g-509(1)}\\
19. $y_{2}=x$\\
21. $y_{2}=x \ln x$\\
23. $y_{2}=x^{3}$\\
25. $y_{2}=x^{2}$\\
27. $y_{2}=3 x+2$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $y_{2}=\frac{1}{2}[\tan x \sec x+\ln |\sec x+\tan x|]$
  \item $y_{2}=e^{2 x}, y_{p}=-\frac{1}{2}$
  \item $y_{2}=e^{2 x}, y_{p}=\frac{5}{2} e^{3 x}$
\end{enumerate}

\section*{EXERCISES 4.3 (PAGE 144)}
\begin{enumerate}
  \item $y=c_{1}+c_{2} e^{-x / 4} \quad$ 3. $y=c_{1} e^{-6 x}+c_{2} e^{6 x}$

  \item $y=c_{1} \cos 3 x+c_{2} \sin 3 x$ 7. $y=c_{1} e^{3 x}+c_{2} e^{-2 x}$

  \item $y=c_{1} e^{-4 x}+c_{2} x e^{-4 x}$

  \item $y=c_{1} e^{(-3+\sqrt{29}) x / 2}+c_{2} e^{(-3-\sqrt{29}) x / 2}$

  \item $y=c_{1} e^{2 x / 3}+c_{2} e^{-x / 4} \quad$ 15. $y=e^{2 x}\left(c_{1} \cos x+c_{2} \sin x\right)$

  \item $y=e^{-x / 3}\left(c_{1} \cos \frac{\sqrt{2}}{3} x+c_{2} \sin \frac{\sqrt{2}}{3} x\right)$

  \item $y=c_{1}+c_{2} e^{-x}+c_{3} e^{5 x}$

  \item $y=c_{1} e^{x}+e^{-x / 2}\left(c_{2} \cos \frac{\sqrt{3}}{2} x+c_{3} \sin \frac{\sqrt{3}}{2} x\right)$

  \item $y=c_{1} e^{-x}+c_{2} e^{3 x}+c_{3} x e^{3 x}$

  \item $y=c_{1} e^{x}+e^{-x}\left(c_{2} \cos x+c_{3} \sin x\right)$

  \item $y=c_{1} e^{-x}+c_{2} x e^{-x}+c_{3} x^{2} e^{-x}$

  \item $y=c_{1}+c_{2} x+e^{-x / 2}\left(c_{3} \cos \frac{\sqrt{3}}{2} x+c_{4} \sin \frac{\sqrt{3}}{2} x\right)$

  \item $y=c_{1} \cos \frac{\sqrt{3}}{2} x+c_{2} \sin \frac{\sqrt{3}}{2} x$

\end{enumerate}

$$
+c_{3} x \cos \frac{\sqrt{3}}{2} x+c_{4} x \sin \frac{\sqrt{3}}{2} x
$$

\begin{enumerate}
  \setcounter{enumi}{32}
  \item $y=c_{1}+c_{2} e^{-2 x}+c_{3} e^{2 x}+c_{4} \cos 2 x+c_{5} \sin 2 x$

  \item $y=c_{1} e^{x}+c_{2} x e^{x}+c_{3} e^{-x}+c_{4} x e^{-x}+c_{5} e^{-5 x}$

  \item $y=2 \cos 4 x-\frac{1}{2} \sin 4 x$

  \item $y=-\frac{3}{4} e^{-5 x}+\frac{3}{4} e^{-x}$

  \item $y=-e^{x / 2} \cos (x / 2)+e^{x / 2} \sin (x / 2)$

  \item $y=0$

  \item $y=e^{2(x-1)}-e^{x-1}$

  \item $y=\frac{5}{36}-\frac{5}{36} e^{-6 x}+\frac{1}{6} x e^{-6 x}$

  \item $y=-\frac{1}{6} e^{2 x}+\frac{1}{6} e^{-x} \cos \sqrt{3} x-\frac{\sqrt{3}}{6} e^{-x} \sin \sqrt{3} x$

  \item $y=2-2 e^{x}+2 x e^{x}-\frac{1}{2} x^{2} e^{x}$

  \item $y=e^{5 x}-x e^{5 x}$ 55. $y=-2 \cos x$

  \item $\frac{d^{3} y}{d x^{3}}+6 \frac{d^{2} y}{d x^{2}}-15 \frac{d y}{d x}-100 y=0$

  \item $y=c_{1} e^{x}+e^{4 x}\left(c_{2} \cos x+c_{3} \sin x\right)$

  \item $y^{\prime \prime}-3 y^{\prime}-18 y=0$

  \item $y^{\prime \prime \prime}-7 y^{\prime \prime}=0$

  \item $y=e^{-\sqrt{2} x / 2}\left(c_{1} \cos \frac{\sqrt{2}}{2} x+c_{2} \sin \frac{\sqrt{2}}{2} x\right)$

\end{enumerate}

$$
+e^{\sqrt{2} x / 2}\left(c_{3} \cos \frac{\sqrt{2}}{2} x+c_{4} \sin \frac{\sqrt{2}}{2} x\right)
$$

\section*{EXERCISES 4.4 (PAGE 155)}
\begin{enumerate}
  \item $y=c_{1} e^{-x}+c_{2} e^{-2 x}+3$
  \item $y=c_{1} e^{5 x}+c_{2} x e^{5 x}+\frac{6}{5} x+\frac{3}{5}$
  \item $y=c_{1} e^{-2 x}+c_{2} x e^{-2 x}+x^{2}-4 x+\frac{7}{2}$
  \item $y=c_{1} \cos \sqrt{3} x+c_{2} \sin \sqrt{3} x+\left(-4 x^{2}+4 x-\frac{4}{3}\right) e^{3 x}$
  \item $y=c_{1}+c_{2} e^{x}+3 x$
  \item $y=c_{1} e^{x / 2}+c_{2} x e^{x / 2}+12+\frac{1}{2} x^{2} e^{x / 2}$
  \item $y=c_{1} \cos 2 x+c_{2} \sin 2 x-\frac{3}{4} x \cos 2 x$
  \item $y=c_{1} \cos x+c_{2} \sin x-\frac{1}{2} x^{2} \cos x+\frac{1}{2} x \sin x$
  \item $y=c_{1} e^{x} \cos 2 x+c_{2} e^{x} \sin 2 x+\frac{1}{4} x e^{x} \sin 2 x$
  \item $y=c_{1} e^{-x}+c_{2} x e^{-x}-\frac{1}{2} \cos x+\frac{12}{25} \sin 2 x-\frac{9}{25} \cos 2 x$
  \item $y=c_{1}+c_{2} x+c_{3} e^{6 x}-\frac{1}{4} x^{2}-\frac{6}{37} \cos x+\frac{1}{37} \sin x$
  \item $y=c_{1} e^{x}+c_{2} x e^{x}+c_{3} x^{2} e^{x}-x-3-\frac{2}{3} x^{3} e^{x}$
  \item $y=c_{1} \cos x+c_{2} \sin x+c_{3} x \cos x$
\end{enumerate}

$$
+c_{4} x \sin x+x^{2}-2 x-3
$$

$\begin{array}{ll}\text { 27. } y_{p}=4+\frac{4}{3} \cos 2 x & \text { 29. } y=\sqrt{2} \sin 2 x-\frac{1}{2}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $y=-200+200 e^{-x / 5}-3 x^{2}+30 x$

  \item $y=-10 e^{-2 x} \cos x+9 e^{-2 x} \sin x+7 e^{-4 x}$

  \item $x=\frac{F_{0}}{2 \omega^{2}} \sin \omega t-\frac{F_{0}}{2 \omega} t \cos \omega t$

  \item $y=-\frac{1}{6} \cos x-\frac{\pi}{4} \sin x+\frac{1}{2} x \sin x+\frac{1}{3} \sin 2 x$

  \item $y=11-11 e^{x}+9 x e^{x}+2 x-12 x^{2} e^{x}+\frac{1}{2} e^{5 x}$

  \item $y=6 \cos x-6(\cot 1) \sin x+x^{2}-1$

  \item $y=\left\{\begin{array}{lr}\cos 2 x+\frac{5}{6} \sin 2 x+\frac{1}{3} \sin x, & 0 \leq x \leq \pi / 2 \\ \frac{2}{3} \cos 2 x+\frac{5}{6} \sin 2 x, & x>\pi / 2\end{array}\right.$

\end{enumerate}

\section*{EXERCISES 4.5 (PAGE 161)}
\begin{enumerate}
  \item $(D+5) y=9 \sin x \quad$ 3. $\left(3 D^{2}-5 D+1\right) y=e^{x}$

  \item $\left(D^{3}-4 D^{2}+5 D\right) y=4 x \quad$ 7. $(3 D-2)(3 D+2)$

  \item $(D-6)(D+2)$ 11. $D(D+5)^{2}$

  \item $(D-1)(D-2)(D+5) \quad$ 15. $D(D+2)\left(D^{2}-2 D+4\right)$

\end{enumerate}

$\begin{array}{llll}\text { 21. } D^{4} & \text { 23. } D(D-2) & \text { 25. } D^{2}+4 & \text { 27. } D^{3}\left(D^{2}+16\right)\end{array}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $(D+1)(D-1)^{3}$ 31. $D\left(D^{2}-2 D+5\right)$
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-509}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{38}
  \item $1, e^{5 x}, x e^{5 x}$
\end{enumerate}

EXERCISES 4.6 (PAGE 167)

$$
\text { 1. } y=c_{1} e^{-3 x}+c_{2} e^{3 x}-6 \quad \text { 3. } y=c_{1}+c_{2} e^{-x}+3 x
$$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item $y=c_{1} e^{-2 x}+c_{2} x e^{-2 x}+\frac{1}{2} x+1$

  \item $y=c_{1}+c_{2} x+c_{3} e^{-x}+\frac{2}{3} x^{4}-\frac{8}{3} x^{3}+8 x^{2}$

  \item $y=c_{1} e^{-3 x}+c_{2} e^{4 x}+\frac{1}{7} x e^{4 x}$

  \item $y=c_{1} e^{-x}+c_{2} e^{3 x}-e^{x}+3$

  \item $y=c_{1} \cos 5 x+c_{2} \sin 5 x+\frac{1}{4} \sin x$

  \item $y=c_{1} e^{-3 x}+c_{2} x e^{-3 x}-\frac{1}{49} x e^{4 x}+\frac{2}{343} e^{4 x}$

  \item $y=c_{1} e^{-x}+c_{2} e^{x}+\frac{1}{6} x^{3} e^{x}-\frac{1}{4} x^{2} e^{x}+\frac{1}{4} x e^{x}-5$

  \item $y=e^{x}\left(c_{1} \cos 2 x+c_{2} \sin 2 x\right)+\frac{1}{3} e^{x} \sin x$

  \item $y=c_{1} \cos 5 x+c_{2} \sin 5 x-2 x \cos 5 x$

  \item $y=e^{-x / 2}\left(c_{1} \cos \frac{\sqrt{3}}{2} x+c_{2} \sin \frac{\sqrt{3}}{2} x\right)$

\end{enumerate}

$$
+\sin x+2 \cos x-x \cos x
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $y=c_{1}+c_{2} x+c_{3} e^{-8 x}+\frac{11}{256} x^{2}+\frac{7}{32} x^{3}-\frac{1}{16} x^{4}$

  \item $y=c_{1} e^{x}+c_{2} x e^{x}+c_{3} x^{2} e^{x}+\frac{1}{6} x^{3} e^{x}+x-13$

  \item $y=c_{1}+c_{2} x+c_{3} e^{x}+c_{4} x e^{x}+\frac{1}{2} x^{2} e^{x}+\frac{1}{2} x^{2}$

  \item $y=c_{1} e^{x / 2}+c_{2} e^{-x / 2}+c_{3} \cos \frac{x}{2}+c_{4} \sin \frac{x}{2}+\frac{1}{8} x e^{x / 2}$

  \item $y=\frac{5}{8} e^{-8 x}+\frac{5}{8} e^{8 x}-\frac{1}{4}$

  \item $y=-\frac{41}{125}+\frac{41}{125} e^{5 x}-\frac{1}{10} x^{2}+\frac{9}{25} x$

  \item $y=-\pi \cos x-\frac{11}{3} \sin x-\frac{8}{3} \cos 2 x+2 x \cos x$

  \item $y=2 e^{2 x} \cos 2 x-\frac{3}{64} e^{2 x} \sin 2 x+\frac{1}{8} x^{3}+\frac{3}{16} x^{2}+\frac{3}{32} x$

  \item $y_{p}=A x e^{x}+B e^{x} \cos 2 x+C e^{x} \sin 2 x$

\end{enumerate}

\begin{itemize}
  \item Exe $^{x} \cos 2 x+$ Fxe $^{x} \sin 2 x$
\end{itemize}

\section*{EXERCISES 4.7 (PAGE 174)}
\begin{enumerate}
  \item $y=c_{1} \cos x+c_{2} \sin x+x \sin x+\cos x \ln |\cos x|$; $(-\pi / 2, \pi / 2)$
  \item $y=c_{1} \cos x+c_{2} \sin x+\frac{1}{2} \sin x-\frac{1}{2} x \cos x$
\end{enumerate}

$=c_{1} \cos x+c_{3} \sin x-\frac{1}{2} x \cos x ; \quad(-\infty, \infty)$\\
5. $y=c_{1} \cos x+c_{2} \sin x+\frac{1}{2}-\frac{1}{6} \cos 2 x ; \quad(-\infty, \infty)$\\
7. $y=c_{1} e^{x}+c_{2} e^{-x}+\frac{1}{4} x e^{x}-\frac{1}{4} x e^{-x}$

$=c_{1} e^{x}+c_{2} e^{-x}+\frac{1}{2} x \sinh x ; \quad(-\infty, \infty)$\\
9. $y=c_{1} e^{2 x}+c_{2} e^{-2 x}$

$$
\begin{aligned}
& +\frac{1}{4}\left(e^{2 x} \ln |x|-e^{-2 x} \int_{x_{0}}^{x} \frac{e^{4 t}}{t} d t\right) \\
& x_{0}>0 ; \quad(0, \infty)
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $y=c_{1} e^{-x}+c_{2} e^{-2 x}+\left(e^{-x}+e^{-2 x}\right) \ln \left(1+e^{x}\right)$; $(-\infty, \infty)$

  \item $y=c_{1} e^{-2 x}+c_{2} e^{-x}-e^{-2 x} \sin e^{x} ; \quad(-\infty, \infty)$

  \item $y=c_{1} e^{x}+c_{2} x e^{x}-\frac{1}{2} e^{x} \ln \left(1+x^{2}\right)+x e^{x} \tan ^{-1} x$; $(-\infty, \infty)$

  \item $y=c_{1} e^{-x}+c_{2} x e^{-x}+\frac{1}{2} x^{2} e^{-x} \ln x-\frac{3}{4} x^{2} e^{-x}$; $(0, \infty)$

  \item $y=c_{1} e^{x} \cos 3 x+c_{2} e^{x} \sin x$

\end{enumerate}

$-\frac{1}{27} e^{x} \cos 3 x \ln |\sec 3 x+\tan 3 x|$

$(-\pi / 6, \pi / 6)$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $y=c_{1}+c_{2} \cos x+c_{3} \sin x-\ln |\cos x|$
\end{enumerate}

$-\sin x \ln |\sec x+\tan x| ; \quad(-\pi / 2, \pi / 2)$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $y=c_{1} e^{x}+c_{2} e^{2 x}+c_{3} e^{-x}+\frac{1}{8} e^{3 x} ; \quad(-\infty, \infty)$

  \item $y=\frac{1}{4} e^{-x / 2}+\frac{3}{4} e^{x / 2}+\frac{1}{8} x^{2} e^{x / 2}-\frac{1}{4} x e^{x / 2}$

  \item $y=\frac{4}{9} e^{-4 x}+\frac{25}{36} e^{2 x}-\frac{1}{4} e^{-2 x}+\frac{1}{9} e^{-x}$

  \item $y=c_{1} x+c_{2} x \ln x+\frac{2}{3} x(\ln x)^{3}$

  \item $y=c_{1} x^{-1 / 2} \cos x+c_{2} x^{-1 / 2} \sin x+x^{-1 / 2}$

  \item (a) $y_{p_{1}}=4 x^{2}-16 x+21 \quad$ (b) $y_{p_{2}}=x e^{-x} \ln x$\\
(c) $y_{p}=4 x^{2}-16 x+21+x e^{-x} \ln x$

\end{enumerate}

\section*{CHAPTER 4 REVIEW EXERCISES (PAGE 177)}
\begin{enumerate}
  \item $y=0$

  \item False; the functions $f_{1}(x)=0$ and $f_{2}(x)=e^{x}$ are linearly dependent on $(-\infty, \infty)$ but $f_{2}$ is not a constant multiple of $f_{1}$.

  \item $(-\infty, 0) ;(0, \infty)$ 7. false 9. $y_{p}=A+B x e^{x}$

  \item $y_{2}=\sin 2 x \quad$ 13. $y=c_{1} e^{(1+\sqrt{3}) x}+c_{2} e^{(1-\sqrt{3}) x}$

  \item $y=c_{1}+c_{2} e^{-5 x}+c_{3} x e^{-5 x}$

  \item $y=c_{1} e^{-x / 3}+e^{-3 x / 2}\left(c_{2} \cos \frac{\sqrt{7}}{2} x+c_{3} \sin \frac{\sqrt{7}}{2} x\right)$

  \item $y=e^{3 x / 2}\left(c_{1} \cos \frac{\sqrt{11}}{2} x+c_{2} \sin \frac{\sqrt{11}}{2} x\right)$

\end{enumerate}

$$
+\frac{4}{5} x^{3}+\frac{36}{25} x^{2}+\frac{46}{125} x-\frac{222}{625}
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $y=c_{1}+c_{2} e^{2 x}+c_{3} e^{3 x}+\frac{1}{5} \sin x-\frac{1}{5} \cos x+\frac{4}{3} x$

  \item $y=e^{x-\pi} \cos x$

  \item $y=e^{x}\left(c_{1} \cos x+c_{2} \sin x\right)$

\end{enumerate}

$-e^{x} \cos x \ln |\sec x+\tan x|$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $y=\frac{2}{5} e^{x / 2}-\frac{2}{5} e^{3 x}+x e^{3 x}-4$
\end{enumerate}

\section*{EXERCISES 5.1 (PAGE 189)}
\begin{enumerate}
  \item A weight of 4 lb ( $\frac{1}{8}$ slug), attached to a spring, is released from a point 3 units above the equilibrium position with an initial upward velocity of $2 \mathrm{ft} / \mathrm{s}$. The spring costant is $3 \mathrm{lb} / \mathrm{ft}$.

  \item $x(t)=2 \sqrt{2} \sin \left(5 t-\frac{\pi}{4}\right)$

  \item $x(t)=\sqrt{5} \sin (\sqrt{2} t+3.6052)$

  \item $x(t)=\frac{\sqrt{101}}{10} \sin (10 t+1.4711) \quad$ 9. $8 \mathrm{lb} \quad$ 11. $\sqrt{2} \pi / 8$

  \item $x(t)=-\frac{1}{4} \cos 4 \sqrt{6} t$

  \item (a) $x(\pi / 12)=-1 / 4 ; \quad x(\pi / 8)=-1 / 2$;

\end{enumerate}

$$
x(\pi / 6)=-1 / 4 ; \quad x(\pi / 4)=1 / 2
$$

$$
x(9 \pi / 32)=\sqrt{2} / 4
$$

(b) $4 \mathrm{ft} / \mathrm{s}$; downward

(c) $t=(2 n+1) \pi / 16, \quad n=0,1,2, \ldots$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item (a) the $20-\mathrm{kg}$ mass (b) the $20-\mathrm{kg}$ mass; the $50-\mathrm{kg}$ mass
\end{enumerate}

(c) $t=n \pi, n=0,1,2, \ldots$; at the equilibrium position; the $50-\mathrm{kg}$ mass is moving upward whereas the $20-\mathrm{kg}$ mass is moving upward when $n$ is even and downward when $n$ is odd.\\
19. $x(t)=\frac{1}{2} \cos 2 t+\frac{3}{4} \sin 2 t$

$$
=\frac{\sqrt{13}}{4} \sin (2 t+0.5880)
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item (a) $x(t)=-\frac{2}{3} \cos 10 t+\frac{1}{2} \sin 10 t$
\end{enumerate}

$$
=\frac{5}{6} \sin (10 t-0.927)
$$

$\begin{array}{lll}\text { (b) } 5 / 6 \mathrm{ft} ; \pi / 5 & \text { (c) } 15 \text { cycles } & \text { (d) } 0.721 \mathrm{~s}\end{array}$

(e) $(2 n+1) \pi / 20+0.0927, n=0,1,2, \ldots$

(f) $x(3)=-0.597 \mathrm{ft}$

(g) $x^{\prime}(3)=-5.814 \mathrm{ft} / \mathrm{s} \quad$ (h) $x^{\prime \prime}(3)=59.702 \mathrm{ft} / \mathrm{s}^{2}$

(i) $\pm 8 \frac{1}{3} \mathrm{ft} / \mathrm{s}$

(j) $0.1451+n \pi / 5 ; 0.3545+n \pi / 5, n=0,1,2, \ldots$

(k) $0.3545+n \pi / 5, n=0,1,2, \ldots$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $120 \mathrm{lb} / \mathrm{ft} ; x(t)=\frac{\sqrt{3}}{12} \sin 8 \sqrt{3} t$

  \item Using $x(t)=c_{1} \cos \omega t+c_{2} \sin \omega t, x(0)=x_{0}$, and $x^{\prime}(0)=v_{0}$, we find $c_{1}=x_{0}$ and $c_{2}=v_{0} / \omega$. The result follows from $A=\sqrt{c_{1}^{2}+c_{2}^{2}}$.

  \item $x(t)=2 \sqrt{2} \cos \left(5 t+\frac{5 \pi}{4}\right)$

  \item When $\omega t+\phi=(2 m+1) \pi / 2,\left|x^{\prime \prime}\right|=A \omega^{2}$. But $T=$ $2 \pi / \omega$ implies $\omega=2 \pi / T$ and $\omega^{2}=4 \pi^{2} / T^{2}$. Therefore, the magnitude of the acceleration is $\left|x^{\prime \prime}\right|=4 \pi^{2} A / T^{2}$.

\end{enumerate}

\section*{EXERCISES 5.2 (PAGE 197)}
\begin{enumerate}
  \item A $2-\mathrm{lb}$ weight is attached to a spring whose constant is $1 \mathrm{lb} / \mathrm{ft}$. The system is damped with a resisting force numerically equal to 2 times the instantaneous velocity. The weight starts from the equilibrium position with an upward velocity of $1.5 \mathrm{ft} / \mathrm{s}$.

  \item (a) above (b) heading upward

  \item (a) below (b) heading upward

  \item $\frac{1}{4} s ; \frac{1}{2} s, x\left(\frac{1}{2}\right)=e^{-2}$; that is, the weight is approximately 0.14 ft below the equilibrium position.

\end{enumerate}

$\begin{array}{ll}\text { 9. (a) } x(t)=\frac{4}{3} e^{-2 t}-\frac{1}{3} e^{-8 t} & \text { (b) } x(t)=-\frac{2}{3} e^{-2 t}+\frac{5}{3} e^{-8 t}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item (a) $x(t)=e^{-2 t}\left[-\cos 4 t-\frac{1}{2} \sin 4 t\right]$
\end{enumerate}

(b) $x(t)=\frac{\sqrt{5}}{2} e^{-2 t} \sin (4 t+4.249) \quad$ (c) $t=1.249 \mathrm{~s}$\\
13. (a) $\beta>\frac{5}{2}$\\
(b) $\beta=\frac{5}{2}$\\
(c) $0<\beta<\frac{5}{2}$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $x(t)=\frac{2}{7} e^{-7 t} \sin 7 t \quad$ 17. $v_{0}>2 \mathrm{ft} / \mathrm{s}$

  \item Suppose $\gamma=\sqrt{\omega^{2}-\lambda^{2}}$. Then the derivative of $x(t)=A e^{-\lambda t} \sin (\gamma t+\phi)$ is

\end{enumerate}

$$
x^{\prime}(t)=A e^{-\lambda t}[\gamma \cos (\gamma t+\phi)-\lambda \sin (\gamma t+\phi)]
$$

So $x^{\prime}(t)=0$ implies

$$
\tan (\gamma t+\phi)=\frac{\gamma}{\lambda}
$$

from which it follows that

$$
t=\frac{1}{\gamma}\left[\tan ^{-1} \frac{\gamma}{\lambda}+k \pi-\phi\right]
$$

The difference between the $t$ values between two successive maxima (or minima) is then

$$
t_{k+2}-t_{k}=(k+2)(\pi / \gamma)-k(\pi / \gamma)=2 \pi / \gamma
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $t_{k+1}^{*}-t_{k}^{*}=\frac{(2 k+3) \pi / 2-\phi}{\sqrt{\omega^{2}-\lambda^{2}}}-\frac{(2 k+1) \pi / 2-\phi}{\sqrt{\omega^{2}-\lambda^{2}}}$
\end{enumerate}

$$
=\frac{\pi}{\sqrt{\omega^{2}-\lambda^{2}}}
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item Let the quasi-period $2 \pi / \sqrt{\omega^{2}-\lambda^{2}}$ be denoted by $T_{q}$. From equation (15) we find
\end{enumerate}

$$
\begin{aligned}
& \frac{x_{n}}{x_{n+2}}=\frac{x(t)}{x\left(t+T_{q}\right)} \\
& =\frac{e^{-\lambda t} \sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)}{e^{-\lambda\left(t+T_{q}\right)} \sin \left(\sqrt{\omega^{2}-\lambda^{2}}\left(t+T_{q}\right)+\phi\right)} \\
& =e^{\lambda T_{q}}
\end{aligned}
$$

since

$\sin \left(\sqrt{\omega^{2}-\lambda^{2}} t+\phi\right)=\sin \left(\sqrt{\omega^{2}-\lambda^{2}}\left(t+T_{q}\right)+\phi\right)$.

Therefore

$$
\ln \left(\frac{x_{n}}{x_{n+2}}\right)=\lambda T_{q}=\frac{2 \pi \lambda}{\sqrt{\omega^{2}-\lambda^{2}}}
$$

\section*{EXERCISES 5.3 (PAGE 206)}
\begin{enumerate}
  \item $x(t)=e^{-t / 2}\left(-\frac{4}{3} \cos \frac{\sqrt{47}}{2} t-\frac{64}{3 \sqrt{47}} \sin \frac{\sqrt{47}}{2} t\right)$
\end{enumerate}

$$
+\frac{10}{3}(\cos 3 t+\sin 3 t)
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $x(t)=\frac{1}{4} e^{-4 t}+t e^{-4 t}-\frac{1}{4} \cos 4 t$

  \item $x(t)=-\frac{1}{2} \cos 4 t+\frac{9}{4} \sin 4 t+\frac{1}{2} e^{-2 t} \cos 4 t-2 e^{-2 t} \sin 4 t$

  \item $m \frac{d^{2} x}{d t^{2}}=-k(x-h)-\beta \frac{d x}{d t}$ or

\end{enumerate}

$\frac{d^{2} x}{d t^{2}}+2 \lambda \frac{d x}{d t}+\omega^{2} x=\omega^{2} h(t), \quad$ where

$2 \lambda=\beta / m \quad$ and $\quad \omega^{2}=k / m$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item (a) $x(t)=\frac{2}{3} \sin 4 t-\frac{1}{3} \sin 8 t$
\end{enumerate}

(b) $t=n \pi / 4, n=0,1,2, \ldots$\\
(c) $t=\pi / 6+n \pi / 2, \quad n=0,1,2, \ldots$

and $t=\pi / 3+n \pi / 2, \quad n=0,1,2, \ldots$

(d) $\sqrt{3} / 2 \mathrm{~cm},-\sqrt{3} / 2 \mathrm{~cm}$

(e)

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-512}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{10}
  \item (a) $g^{\prime}(\gamma)=0$ implies $\gamma\left(\gamma^{2}-\omega^{2}+2 \lambda^{2}\right)=0$, so either $\gamma=0$ or $\gamma=\sqrt{\omega^{2}-2 \lambda^{2}}$. The first derivative test can be used to verify that $g(\gamma)$ is a maximum at the latter value.
\end{enumerate}

(b) $g\left(\sqrt{\omega^{2}-2 \lambda^{2}}\right)=F_{0} / 2 \lambda \sqrt{\omega^{2}-\lambda^{2}}$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $x_{p}=-5 \cos 2 t+5 \sin 2 t$
\end{enumerate}

$$
=5 \sqrt{2} \sin \left(2 t-\frac{\pi}{4}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item (a) $x(t)=x_{c}+x_{p}$
\end{enumerate}

$$
=c_{1} \cos \omega t+c_{2} \sin \omega t+\frac{F_{0}}{\omega^{2}-\gamma^{2}} \cos \gamma t,
$$

where the initial conditions imply that

$$
c_{1}=-F_{0} /\left(\omega^{2}-\gamma^{2}\right) \text { and } c_{2}=0
$$

(b) By L'Hôpital's rule the given limit is the same as

$$
\lim _{\gamma \rightarrow \omega} \frac{F_{0}(-t \sin \gamma t)}{-2 \gamma}=\frac{F_{0}}{2 \omega} t \sin \omega t
$$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $x(t)=-\cos 2 t-\frac{1}{8} \sin 2 t+\frac{3}{4} t \sin 2 t+\frac{5}{4} t \cos 2 t$

  \item (a) Recall that

\end{enumerate}

$$
\begin{aligned}
& \cos (u-v)=\cos u \cos v+\sin u \sin v \\
& \cos (u+v)=\cos u \cos v-\sin u \sin v
\end{aligned}
$$

Subtracting gives

$$
\sin u \sin v=\frac{1}{2}[\cos (u-v)-\cos (u+v)]
$$

Setting $u=\frac{1}{2}(\gamma-\omega) t$ and $v=\frac{1}{2}(\gamma+\omega) t$ then gives

$$
\sin \frac{1}{2}(\gamma-\omega) t \sin \frac{1}{2}(\gamma+\omega) t=\frac{1}{2}[\cos \omega t-\cos \gamma t]
$$

from which the result follows.

(b) For small $\varepsilon, \gamma \approx \omega$ so $\gamma+\omega \approx 2 \gamma$ and therefore

$$
\begin{aligned}
& \frac{-2 F_{0}}{(\omega+\gamma)(\omega-\gamma)} \sin \frac{1}{2}(\gamma-\omega) t \sin \frac{1}{2}(\gamma+\omega) t \\
& \approx \frac{F_{0}}{2 \gamma \varepsilon} \sin \varepsilon t \sin \frac{1}{2}(2 \gamma) t .
\end{aligned}
$$

(c) By L'Hôpital's rule the given limit is the same as

$\lim _{\varepsilon \rightarrow 0} \frac{F_{0} t \cos \varepsilon t \sin \gamma t}{2 \gamma}=\frac{F_{0}}{2 \gamma} t \sin \gamma t=\frac{F_{0}}{2 \omega} t \sin \omega t$.

\section*{EXERCISES 5.4 (PAGE 212)}
\begin{enumerate}
  \item $q(t)=-\frac{15}{4} \cos 4 t+\frac{15}{4} ; i(t)=15 \sin 4 t$

  \item underdamped 5. $4.568 \mathrm{C} ; 0.0509 \mathrm{~s}$

  \item $q(t)=10-10 e^{-31}(\cos 3 t+\sin 3 t)$; $i(t)=60 e^{-3 t} \sin 3 t ; 10.432 \mathrm{C}$

  \item $q_{p}=\frac{100}{13} \sin t+\frac{150}{13} \cos t ; i_{p}=\frac{100}{13} \cos t-\frac{150}{13} \sin t$

  \item $q(t)=-\frac{1}{2} e^{-10 t}(\cos 10 t+\sin 10 t)+\frac{3}{2} ; \frac{3}{2} \mathrm{C}$

  \item Show that $d Z / d C=0$ when $C=1 / L \gamma^{2}$. At this value, $Z$ is a minimum and, correspondingly, the amplitude $E_{0} / Z$ is a maximum.

  \item $q(t)=\left(q_{0}-\frac{E_{0} C}{1-\gamma^{2} L C}\right) \cos \frac{t}{\sqrt{L C}}$

\end{enumerate}

$$
+\sqrt{L C} i_{0} \sin \frac{t}{\sqrt{L C}}+\frac{E_{0} C}{1-\gamma^{2} L C} \cos \gamma t
$$

$i(t)=i_{0} \cos \frac{t}{\sqrt{L C}}$

$$
\begin{aligned}
& -\frac{1}{\sqrt{L C}}\left(q_{0}-\frac{E_{0} C}{1-\gamma^{2} L C}\right) \sin \frac{t}{\sqrt{L C}} \\
& -\frac{E_{0} C \gamma}{1-\gamma^{2} L C} \sin \gamma t
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $\theta(t)=\frac{1}{2} \cos 4 t+\frac{\sqrt{3}}{2} \sin 4 t ; \quad 1 ; \pi / 2 ; 2 / \pi$
\end{enumerate}

\section*{CHAPTER 5 REVIEW EXERCISES (PAGE 215)}
\section*{1. $8 \mathrm{ft} \quad$ 3. $\frac{5}{4} \mathrm{~m}$}
\begin{enumerate}
  \setcounter{enumi}{4}
  \item False; there could be an impressed force driving the system. 7. overdamped 9. $\frac{9}{2} \mathrm{lb} / \mathrm{ft}$

  \item $x(t)=-\frac{2}{3} e^{-2 t}+\frac{1}{3} e^{-4 t} \quad$ 13. $0<m \leq 2$

  \item $\gamma=8 \sqrt{3} / 3$

  \item $x(t)=e^{-4 t}\left(\frac{26}{17} \cos 2 \sqrt{2} t+\frac{28 \sqrt{2}}{17} \sin 2 \sqrt{2} t\right)+\frac{8}{17} e^{-t}$

  \item (a) $q(t)=-\frac{1}{150} \sin 100 t+\frac{1}{75} \sin 50 t$

\end{enumerate}

(b) $i(t)=-\frac{2}{3} \cos 100 t+\frac{2}{3} \cos 50 t$

(c) $t=n \pi / 50, \quad n=0,1,2, \ldots$

\section*{EXERCISES 6.1 (PAGE 229)}
\begin{enumerate}
  \item $y=c_{1} x^{-1}+c_{2} x^{2} \quad$ 3. $y=c_{1}+c_{2} \ln x$

  \item $y=c_{1} \cos (2 \ln x)+c_{2} \sin (2 \ln x)$

  \item $y=c_{1} x^{(2-\sqrt{6})}+c_{2} x^{(2+\sqrt{6})}$

  \item $y_{1}=c_{1} \cos \left(\frac{1}{5} \ln x\right)+c_{2} \sin \left(\frac{1}{5} \ln x\right)$

  \item $y=c_{1} x^{-2}+c_{2} x^{-2} \ln x$

  \item $y=x\left[c_{1} \cos (\ln x)+c_{2} \sin (\ln x)\right]$

  \item $y=x^{-1 / 2}\left[c_{1} \cos \left(\frac{\sqrt{3}}{6} \ln x\right)+c_{2} \sin \left(\frac{\sqrt{3}}{6} \ln x\right)\right]$

  \item $y=c_{1} x^{3}+c_{2} \cos (\sqrt{2} \ln x)+c_{3} \sin (\sqrt{2} \ln x)$

  \item $y=c_{1} x^{-1}+c_{2} x^{2}+c_{3} x^{4}$

  \item $y=c_{1}+c_{2} x+c_{3} x^{2}+c_{4} x^{-3}$

  \item $y=2-2 x^{-2}$

  \item $y=\cos (\ln x)+2 \sin (\ln x)$

  \item $y=2(-x)^{1 / 2}-5(-x)^{1 / 2} \ln (-x)$

  \item $y=c_{1}+c_{2} \ln x+\frac{x^{2}}{4}$

  \item $y=c_{1} x^{-1 / 2}+c_{2} x^{-1}+\frac{1}{15} x^{2}-\frac{1}{6} x$

  \item $y=c_{1} x+c_{2} x \ln x+x(\ln x)^{2}$

  \item $y=c_{1} x^{-1}+c_{2} x^{-8}+\frac{1}{30} x^{2}$

  \item $y=x^{2}\left[c_{1} \cos (3 \ln x)+c_{2} \sin (3 \ln x)\right]+\frac{4}{13}+\frac{3}{10} x$

  \item $y=c_{1} x^{2}+c_{2} x^{-10}-\frac{1}{7} x^{-3}$

  \item $u(r)=\left(\frac{u_{0}-u_{1}}{b-a}\right) \frac{a b}{r}+\frac{u_{1} b-u_{0} a}{b-a}$

  \item $y=c_{1}(x-1)^{-1}+c_{2}(x-1)^{4}$

  \item $y=c_{1} \cos (\ln (x+2))+c_{2} \sin (\ln (x+2))$

\end{enumerate}

\section*{EXERCISES 6.2 (PAGE 239)}
\begin{enumerate}
  \item $(-1,1]$

  \item $\left[-\frac{1}{2}, \frac{1}{2}\right)$

  \item $[2,4]$

  \item $(-5,15)$

  \item $\{0\}$

  \item $x+x^{2}+\frac{1}{3} x^{3}-\frac{1}{30} x^{5}+\cdots$

  \item $x-\frac{2}{3} x^{3}+\frac{2}{15} x^{5}-\frac{4}{315} x^{7}+\cdots$

  \item $x^{2}-\frac{2}{3} x^{4}+\frac{23}{45} x^{6}-\frac{44}{105} x^{8}+\cdots$

  \item $x+\frac{1}{3} x^{3}+\frac{2}{15} x^{5}+\frac{17}{315} x^{7}+\cdots$

  \item $1+\frac{1}{2} x^{2}-\frac{1}{12} x^{4}+\frac{1}{24} x^{6}-\cdots$

  \item $y=c e^{-x} ; \quad y=c_{0} \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!} x^{n}$

  \item $y=c e^{x^{3} / 3} ; \quad y=c_{0} \sum_{n=0}^{\infty} \frac{1}{n!}\left(\frac{x^{3}}{3}\right)^{n}$

  \item $y=c /(1-x) ; \quad y=c_{0} \sum_{n=0}^{\infty} x^{n}$

  \item $y=C_{1} \cos x+C_{2} \sin x$;

\end{enumerate}

$$
y=c_{0} \sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n)!} x^{2 n}+c_{1} \sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2 n+1)!} x^{2 n+1}
$$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $y=C_{1}+C_{2} e^{x}$;
\end{enumerate}

$$
\begin{aligned}
y & =c_{0}+c_{1} \sum_{n=0}^{\infty} \frac{x^{n}}{n!}=c_{0}-c_{1}+c_{1} \sum_{n=0}^{\infty} \frac{x^{n}}{n!} \\
& =c_{0}-c_{1}+c_{1} e^{x}
\end{aligned}
$$

EXERCISES 6.3 (PAGE 247)

\begin{enumerate}
  \item $y_{1}(x)=c_{0}\left[1+\frac{1}{3 \cdot 2} x^{3}+\frac{1}{6 \cdot 5 \cdot 3 \cdot 2} x^{6}\right.$
\end{enumerate}

$$
\left.+\frac{1}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2} x^{9}+\cdots\right]
$$

$y_{2}(x)=c_{1}\left[x+\frac{1}{4 \cdot 3} x^{4}+\frac{1}{7 \cdot 6 \cdot 4 \cdot 3} x^{7}\right.$

$$
\left.+\frac{1}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3} x^{10}+\cdots\right]
$$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $y_{1}(x)=c_{0}\left[1-\frac{1}{2!} x^{2}-\frac{3}{4!} x^{4}-\frac{21}{6!} x^{6}-\cdots\right]$
\end{enumerate}

$$
y_{2}(x)=c_{1}\left[x+\frac{1}{3!} x^{3}+\frac{5}{5!} x^{5}+\frac{45}{7!} x^{7}+\cdots\right]
$$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item $y_{1}(x)=c_{0}\left[1-\frac{1}{3!} x^{3}+\frac{4^{2}}{6!} x^{6}-\frac{7^{2} \cdot 4^{2}}{9!} x^{9}+\cdots\right]$
\end{enumerate}

$$
y_{2}(x)=c_{1}\left[x-\frac{2^{2}}{4!} x^{4}+\frac{5^{2} \cdot 2^{2}}{7!} x^{7}\right.
$$

$\left.-\frac{8^{2} \cdot 5^{2} \cdot 2^{2}}{10!} x^{10}+\cdots\right]$\\
7. $y_{1}(x)=c_{0} ; \quad y_{2}(x)=c_{1} \sum_{n=1}^{\infty} \frac{1}{n} x^{n}$\\
9. $y_{1}(x)=c_{0} \sum_{n=0}^{\infty} x^{2 n} ; \quad y_{2}(x)=c_{1} \sum_{n=0}^{\infty} x^{2 n+1}$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $y_{1}(x)=c_{0}\left[1+\frac{1}{4} x^{2}-\frac{7}{4 \cdot 4!} x^{4}+\frac{23 \cdot 7}{8 \cdot 6!} x^{6}-\cdots\right]$ $y_{2}(x)=c_{1}\left[x-\frac{1}{6} x^{3}+\frac{14}{2 \cdot 5!} x^{5}-\frac{34 \cdot 14}{4 \cdot 7!} x^{7}-\cdots\right]$

  \item $y_{1}(x)=c_{0}\left[1+\frac{1}{2} x^{2}+\frac{1}{6} x^{3}+\frac{1}{6} x^{4}+\cdots\right]$ $y_{2}(x)=c_{1}\left[x+\frac{1}{2} x^{2}+\frac{1}{2} x^{3}+\frac{1}{4} x^{4}+\cdots\right]$

  \item $y(x)=-2\left[1+\frac{1}{2!} x^{2}+\frac{1}{3!} x^{3}+\frac{1}{4!} x^{4}+\cdots\right]+6 x$ $=8 x-2 e^{x}$

  \item $y(x)=3-12 x^{2}+4 x^{4}$

  \item $y_{1}(x)=c_{0}\left[1-\frac{1}{6} x^{3}+\frac{1}{120} x^{5}+\cdots\right]$ $y_{2}(x)=c_{1}\left[x-\frac{1}{12} x^{4}+\frac{1}{180} x^{6}+\cdots\right]$

  \item $y_{1}(x)=c_{0}\left[1-\frac{1}{2} x^{2}+\frac{1}{6} x^{3}-\frac{1}{40} x^{5}+\cdots\right]$ $y_{2}(x)=c_{1}\left[x-\frac{1}{6} x^{3}+\frac{1}{12} x^{4}-\frac{1}{60} x^{5}+\cdots\right]$

  \item $y_{1}(x)=c_{0}\left[1+\frac{1}{3!} x^{3}+\frac{4}{6!} x^{6}+\frac{7 \cdot 4}{9!} x^{9}+\cdots\right]$

\end{enumerate}

$$
\begin{aligned}
& +c_{1}\left[x+\frac{2}{4!} x^{4}+\frac{5 \cdot 2}{7!} x^{7}+\frac{8 \cdot 5 \cdot 2}{10!} x^{10}+\cdots\right] \\
& +\frac{1}{2!} x^{2}+\frac{3}{5!} x^{5}+\frac{6 \cdot 3}{8!} x^{8}+\frac{9 \cdot 6 \cdot 3}{11!} x^{11}+\cdots
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item For $n=1: y=x$; for $n=2: y=1-2 x^{2}$.
\end{enumerate}

\section*{EXERCISES 6.4 (PAGE 264)}
\begin{enumerate}
  \item $x=0$, irregular singular point

  \item $x=-3$, regular singular point; $x=3$, irregular singular point

  \item $x=0,2 i,-2 i$, regular singular points

  \item $x=-3,2$, regular singular points

  \item $x=0$, irregular singular point; $x=-5,5,2$, regular singular points

  \item $r_{1}=\frac{3}{2}, r_{2}=0$;

\end{enumerate}

$y(x)=C_{1} x^{3 / 2}\left[1-\frac{2}{5} x+\frac{2^{2}}{7 \cdot 5 \cdot 2} x^{2}\right.$

$$
\begin{gathered}
\left.-\frac{2^{3}}{9 \cdot 7 \cdot 5 \cdot 3!} x^{3}+\cdots\right] \\
+C_{2}\left[1+2 x-2 x^{2}+\frac{2^{3}}{3 \cdot 3!} x^{3}-\cdots\right]
\end{gathered}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $r_{1}=\frac{7}{8}, r_{2}=0$;
\end{enumerate}

$y(x)=C_{1} x^{7 / 8}\left[1-\frac{2}{15} x+\frac{2^{2}}{23 \cdot 15 \cdot 2} x^{2}\right.$

$$
\begin{array}{r}
\left.-\frac{2^{3}}{31 \cdot 23 \cdot 15 \cdot 3!} x^{3}+\cdots\right] \\
+C_{2}\left[1-2 x+\frac{2^{2}}{9 \cdot 2} x^{2}-\frac{2^{3}}{17 \cdot 9 \cdot 3!} x^{3}+\cdots\right]
\end{array}
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $r_{1}=\frac{1}{3}, r_{2}=0$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x^{1 / 3}\left[1+\frac{1}{3} x+\frac{1}{3^{2} \cdot 2} x^{2}+\frac{1}{3^{3} \cdot 3!} x^{3}+\cdots\right] \\
& +C_{2}\left[1+\frac{1}{2} x+\frac{1}{5 \cdot 2} x^{2}+\frac{1}{8 \cdot 5 \cdot 2} x^{3}+\cdots\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $r_{1}=\frac{5}{2}, r_{2}=0$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x^{5 / 2}\left[1+\frac{2 \cdot 2}{7} x+\frac{2^{2} \cdot 3}{9 \cdot 7} x^{2}\right. \\
& \left.\quad+\frac{2^{3} \cdot 4}{11 \cdot 9 \cdot 7} x^{3}+\cdots\right] \\
& +C_{2}\left[1+\frac{1}{3} x-\frac{1}{6} x^{2}-\frac{1}{6} x^{3}-\cdots\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $r_{1}=\frac{2}{3}, r_{2}=\frac{1}{3}$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x^{2 / 3}\left[1-\frac{1}{2} x+\frac{5}{28} x^{2}-\frac{1}{21} x^{3}+\cdots\right] \\
& +C_{2} x^{1 / 3}\left[1-\frac{1}{2} x+\frac{1}{5} x^{2}-\frac{7}{120} x^{3}+\cdots\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $r_{1}=1, r_{2}=-\frac{1}{2}$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x\left[1+\frac{1}{5} x+\frac{1}{5 \cdot 7} x^{2}+\frac{1}{5 \cdot 7 \cdot 9} x^{3}+\cdots\right] \\
& +C_{2} x^{-1 / 2}\left[1+\frac{1}{2} x+\frac{1}{2 \cdot 4} x^{2}\right. \\
& \left.+\frac{1}{2 \cdot 4 \cdot 6} x^{3}+\cdots\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $r_{1}=0, r_{2}=-1$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x^{-1} \sum_{n=0}^{\infty} \frac{1}{(2 n)!} x^{2 n} \\
& +C_{2} x^{-1} \sum_{n=0}^{\infty} \frac{1}{(2 n+1)!} x^{2 n+1} \\
= & \frac{1}{x}\left[C_{1} \cosh x+C_{2} \sinh x\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $r_{1}=4, r_{2}=0$;
\end{enumerate}

$y(x)=C_{1}\left[1+\frac{2}{3} x+\frac{1}{3} x^{2}\right]+C_{2} \sum_{n=0}^{\infty}(n+1) x^{n+4}$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $r_{1}=r_{2}=0$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} y_{1}(x)+C_{2}\left[y_{1}(x) \ln x+y_{1}(x)\right. \\
& \left.\times\left(-x+\frac{1}{4} x^{2}-\frac{1}{3 \cdot 3!} x^{3}+\frac{1}{4 \cdot 4!} x^{4}-\cdots\right)\right],
\end{aligned}
$$

where $y_{1}(x)=\sum_{n=0}^{\infty} \frac{1}{n!} x^{n}=e^{x}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $r_{1}=r_{2}=0$;
\end{enumerate}

$y(x)=C_{1} y_{1}(x)+C_{2}\left[y_{1}(x) \ln x+y_{1}(x)\right.$

$$
\left.\times\left(2 x+\frac{5}{4} x^{2}+\frac{23}{27} x^{3}+\cdots\right)\right]
$$

where $y_{1}(x)=\sum_{n=0}^{\infty} \frac{(-1)^{n}}{(n!)^{2 n}} x^{n}$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $r_{1}=r_{2}=1$;
\end{enumerate}

$y(x)=C_{1} x e^{-x}+C_{2} x e^{-x}$

$$
\times\left[\ln x+x+\frac{1}{4} x^{2}+\frac{1}{3 \cdot 3!} x^{3}+\cdots\right]
$$

\begin{enumerate}
  \setcounter{enumi}{32}
  \item $r_{1}=2, r_{2}=0$;
\end{enumerate}

$$
y(x)=C_{1} x^{2}+C_{2}\left[\frac{1}{2} x^{2} \ln x-\frac{1}{2}+x-\frac{1}{3!} x^{3}+\cdots\right]
$$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item The method of Frobenius yields only the trivial solution $y(x)=0$.

  \item The assumption $y=\sum_{n=0}^{\infty} c_{n} x^{n+r}$ leads to

\end{enumerate}

$$
c_{n}[(n+r)(n+r+2)-8]=0
$$

for $n \geq 0$. For $n=0$ and $c_{0} \neq 0$ we have $r^{2}+2 r-8=0$ and so $r_{1}=2, r_{2}=-4$. For these values we are forced to take $c_{n}=0$ for $n>0$. Hence a solution exists of the form $y=c_{0} x^{r}$. It follows that the general solution on $0<x<\infty$ is $y=C_{1} x^{2}+C_{2} x^{-4}$.

\begin{enumerate}
  \setcounter{enumi}{38}
  \item $r(r-1)+\frac{5}{3} r-\frac{1}{3}=0 ; \quad r_{1}=\frac{1}{3}, r_{2}=-1$
\end{enumerate}

\section*{EXERCISES 6.5 (PAGE 275)}
\begin{enumerate}
  \item $y=c_{1} J_{1 / 3}(x)+c_{2} J_{-1 / 3}(x)$ 3. $y=c_{1} J_{5 / 2}(x)+c_{2} J_{-5 / 2}(x)$

  \item $y=c_{1} J_{0}(x)+c_{2} Y_{0}(x)$ 7. $y=c_{1} J_{2}(3 x)+c_{2} Y_{2}(3 x)$

  \item After we use the change of variables, the differential equation becomes

\end{enumerate}

$$
x^{2} v^{\prime \prime}+x v^{\prime}+\left(\lambda^{2} x^{2}-\frac{1}{4}\right) v=0
$$

Since the solution of the last equation is

$$
v=c_{1} J_{1 / 2}(\lambda x)+c_{2} J_{-1 / 2}(\lambda x)
$$

we find

$$
y=c_{1} x^{-1 / 2} J_{1 / 2}(\lambda x)+c_{2} x^{-1 / 2} J_{-1 / 2}(\lambda x)
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item After substituting into the differential equation, we find
\end{enumerate}

$$
\begin{aligned}
x y^{\prime \prime}+(1+2 n) y^{\prime}+ & x y \\
& =x^{-n-1}\left[x^{2} J_{n}^{\prime \prime}+x J_{n}^{\prime}+\left(x^{2}-n^{2}\right) J_{n}\right] \\
& =x^{-n-1} \cdot 0=0
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item From Problem 10 with $n=\frac{1}{2}$ we find $y=x^{1 / 2} J_{1 / 2}(x)$; from Problem 11 with $n=-\frac{1}{2}$ we find $y=x^{1 / 2} J_{-1 / 2}(x)$.

  \item From Problem 10 with $n=-1$ we find $y=x^{-1} J_{-1}(x)$; from Problem 11 with $n=1$ we find $y=x^{-1} J_{1}(x)$, but since $J_{-1}(x)=-J_{1}(x)$, no new solution results.

  \item From Problem 12 with $\lambda=1$ and $v= \pm \frac{3}{2}$ we find $y=\sqrt{x} J_{3 / 2}(x)$ and $y=\sqrt{x J_{-3 / 2}}(x)$.

  \item Using the hint, we can write

\end{enumerate}

$$
\begin{aligned}
x J_{v}^{\prime}(x)= & -v \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1+v+n)}\left(\frac{x}{2}\right)^{2 n+v} \\
& +2 \sum_{n=0}^{\infty} \frac{(-1)^{n}(n+v)}{n!(n+v) \Gamma(n+v)}\left(\frac{x}{2}\right)^{2 n+v} \\
= & -v \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1+v+n)}\left(\frac{x}{2}\right)^{2 n+v} \\
& +x \sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(n+v)}\left(\frac{x}{2}\right)^{2 n+v-1} \\
= & -v J_{v}(x)+x J_{v-1}(x) .
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item Subtracting the equations
\end{enumerate}

$$
\begin{aligned}
x J_{v}^{\prime}(x) & =v J_{v}(x)-x J_{v+1}(x) \\
x J_{v}^{\prime}(x) & =-v J_{v}(x)+x J_{v-1}(x) \\
\text { gives } \quad 2 v J_{v}(x) & =x J_{v+1}(x)+x J_{v-1}(x) .
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item From Problem $20, \frac{d}{d r}\left[r J_{1}(r)\right]=r J_{0}(r)$. Therefore
\end{enumerate}

$$
\begin{aligned}
\int_{0}^{x} r J_{0}(r) d r & =\int_{0}^{x} \frac{d}{d r}\left[r J_{1}(r)\right] d r=\left.r J_{1}(r)\right|_{0} ^{x} \\
& =x J_{1}(x)
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item Start with
\end{enumerate}

$$
x^{n} J_{0}=x^{n-1} x J_{0}=x^{n-1} \frac{d}{d x}\left(x J_{1}\right)
$$

and then integrate by parts.

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $J_{-1 / 2}(x)=\sqrt{\frac{2}{\pi x}} \cos x$

  \item $J_{-3 / 2}(x)=\sqrt{\frac{2}{\pi x}}\left[-\sin x-\frac{\cos x}{x}\right]$

  \item $J_{-5 / 2}(x)=\sqrt{\frac{2}{\pi x}}\left[\frac{3}{x} \sin x+\left(\frac{3}{x^{2}}-1\right) \cos x\right]$

  \item $J_{-7 / 2}(x)=\sqrt{\frac{2}{\pi x}}\left[\left(1-\frac{15}{x^{2}}\right) \sin x+\left(\frac{6}{x}-\frac{15}{x^{3}}\right) \cos x\right]$

  \item $y=c_{1} I_{v}(x)+c_{2} I_{-v}(x), \quad v \neq$ integer

  \item Since $1 / \Gamma(1-m+n)=0$ when $n \leq m-1, m$ a positive integer,

\end{enumerate}

$$
\begin{aligned}
J_{-m}(x) & =\sum_{n=0}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1-m+n)}\left(\frac{x}{2}\right)^{2 n-m} \\
& =\sum_{n=m}^{\infty} \frac{(-1)^{n}}{n!\Gamma(1-m+n)}\left(\frac{x}{2}\right)^{2 n-m} \\
& =\sum_{k=0}^{\infty} \frac{(-1)^{k+m}}{(k+m)!\Gamma(1+k)}\left(\frac{x}{2}\right)^{2 k+m}(n=k+m) \\
& =(-1)^{m} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{\Gamma(1+k+m) k!}\left(\frac{x}{2}\right)^{2 k+m} \\
& =(-1)^{m} J_{m}(x) .
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{38}
  \item (a) $P_{6}(x)=\frac{1}{16}\left(231 x^{6}-315 x^{4}+105 x^{2}-5\right)$
\end{enumerate}

$$
P_{7}(x)=\frac{1}{16}\left[429 x^{7}-693 x^{5}+315 x^{3}-35 x\right]
$$

(b) $y=P_{6}(x)$ satisfies $\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+42 y=0$. $y=P_{7}(x)$ satisfies $\left(1-x^{2}\right) y^{\prime \prime}-2 x y^{\prime}+56 y=0$.

\begin{enumerate}
  \setcounter{enumi}{40}
  \item If $x=\cos \theta$, then $\frac{d y}{d \theta}=\frac{d y}{d x} \frac{d x}{d \theta}=-\sin \theta \frac{d y}{d x} \quad$ and $\frac{d^{2} y}{d \theta^{2}}=\sin ^{2} \theta \frac{d^{2} y}{d x^{2}}-\cos \theta \frac{d y}{d x}$. Now the original equation can be written as
\end{enumerate}

$$
\frac{d^{2} y}{d \theta^{2}}+\frac{\cos \theta}{\sin \theta} \frac{d y}{d \theta}+n(n+1) y=0
$$

and so

$$
\sin ^{2} \theta \frac{d^{2} y}{d x^{2}}-2 \cos \theta \frac{d y}{d x}+n(n+1) y=0
$$

Since $x=\cos \theta$ and $\sin ^{2} \theta=1-\cos ^{2} \theta=1-x^{2}$, we obtain

$$
\left(1-x^{2}\right) \frac{d^{2} y}{d x^{2}}-2 x \frac{d y}{d x}+n(n+1) y=0
$$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item Using binomial series, we have formally
\end{enumerate}

$$
\begin{aligned}
\left(1-2 x t+t^{2}\right)^{-1 / 2}= & 1+\frac{1}{2}\left(2 x t-t^{2}\right)+\frac{1 \cdot 3}{2^{2} 2!} \\
& \times\left(2 x t-t^{2}\right)^{2}+\cdots
\end{aligned}
$$

Grouping by powers of $t$, we then find

$$
\begin{aligned}
\left(1-2 x t+t^{2}\right)^{-1 / 2} & =1 \cdot t^{0}+x \cdot t+\frac{1}{2}\left(3 x^{2}-1\right) t^{2}+\cdots \\
& =P_{0}(x) t^{0}+P_{1}(x) t+P_{2}(x) t^{2}+\cdots
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{44}
  \item For $k=1, P_{2}(x)=\frac{1}{2}\left[3 x P_{1}(x)-P_{0}(x)\right]$
\end{enumerate}

$$
\begin{aligned}
& =\frac{1}{2}\left(3 x^{2}-1\right) \\
\text { For } k=2, P_{3}(x) & =\frac{1}{3}\left[5 x P_{2}(x)-2 P_{1}(x)\right] \\
& =\frac{1}{2}\left(5 x^{3}-3 x\right) .
\end{aligned}
$$

For $k=3, P_{4}(x)=\frac{1}{4}\left[7 x P_{3}(x)-3 P_{2}(x)\right]$

$$
=\frac{1}{8}\left(35 x^{4}-30 x^{2}+3\right)
$$

For $k=4, P_{5}(x)=\frac{1}{5}\left[9 x P_{4}(x)-4 P_{3}(x)\right]$

$$
=\frac{1}{8}\left(63 x^{5}-70 x^{3}+15 x\right)
$$

For $k=5, P_{6}(x)=\frac{1}{6}\left[11 x P_{5}(x)-5 P_{4}(x)\right]$

$$
=\frac{1}{16}\left(231 x^{6}-315 x^{4}+105 x^{2}-5\right)
$$

\begin{enumerate}
  \setcounter{enumi}{46}
  \item For $n=0,1,2,3$, the values of the integrals are $2, \frac{2}{3}, \frac{2}{5}$, and $\frac{2}{7}$, respectively. In general,
\end{enumerate}

$$
\int_{-1}^{1} P_{n}^{2}(x) d x=\frac{2}{2 n+1}, \quad n=0,1,2, \ldots .
$$

\begin{enumerate}
  \setcounter{enumi}{48}
  \item $y_{2}$ is obtained from (4) of Section 4.2.
\end{enumerate}

\section*{CHAPTER 6 REVIEW EXERCISES (PAGE 278)}
\begin{enumerate}
  \item $y=c_{1} x^{-1 / 3}+c_{2} x^{1 / 2}$

  \item $y(x)=c_{1} x^{2}+c_{2} x^{3}+x^{4}-x^{2} \ln x$

  \item The singular points are $x=0, x=-1+\sqrt{3} i$, $x=-1-\sqrt{3}$. All other finite values of $x$, real or complex, are ordinary points.

  \item regular singular point $x=0$; irregular singular point $x=5$

  \item regular singular points $x=-3, x=3$; irregular singular point $x=0$

  \item $|x|<\infty$

  \item $y_{1}(x)=c_{0}\left[1-\frac{1}{3 \cdot 2} x^{3}+\frac{1}{6 \cdot 5 \cdot 3 \cdot 2} x^{6}\right.$

\end{enumerate}

$$
\left.-\frac{1}{9 \cdot 8 \cdot 6 \cdot 5 \cdot 3 \cdot 2} x^{9}+\cdots\right]
$$

$y_{2}(x)=c_{1}\left[x-\frac{1}{4 \cdot 3} x^{4}+\frac{1}{7 \cdot 6 \cdot 4 \cdot 3} x^{7}\right.$

$$
\left.-\frac{1}{10 \cdot 9 \cdot 7 \cdot 6 \cdot 4 \cdot 3} x^{10}+\cdots\right]
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $y_{1}(x)=c_{0}\left[1+\frac{3}{2} x^{2}+\frac{1}{2} x^{3}+\frac{5}{8} x^{4}+\cdots\right]$
\end{enumerate}

$y_{2}(x)=c_{1}\left[x+\frac{1}{2} x^{3}+\frac{1}{4} x^{4}+\cdots\right]$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $r_{1}=1, r_{2}=-\frac{1}{2}$;
\end{enumerate}

$$
\begin{aligned}
y(x)= & C_{1} x\left[1+\frac{1}{5} x+\frac{1}{7 \cdot 5 \cdot 2} x^{2}\right. \\
& \left.\quad+\frac{1}{9 \cdot 7 \cdot 5 \cdot 3 \cdot 2} x^{3}+\cdots\right] \\
& +C_{2} x^{-1 / 2}\left[1-x-\frac{1}{2} x^{2}-\frac{1}{3^{2} \cdot 2} x^{3}-\cdots\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $r_{1}=3, r_{2}=0$;
\end{enumerate}

$y_{1}(x)=C_{3}\left[x^{3}+\frac{5}{4} x^{4}+\frac{11}{8} x^{5}+\cdots\right]$

$$
\begin{aligned}
y(x)=C_{1} y_{1}(x)+C_{2} & {\left[-\frac{1}{36} y_{1}(x) \ln x+y_{1}(x)\right.} \\
& \left.\times\left(-\frac{1}{3} \frac{1}{x^{3}}+\frac{1}{4} \frac{1}{x^{2}}+\frac{1}{16} \frac{1}{x}+\cdots\right)\right]
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $r_{1}=r_{2}=0 ; \quad y(x)=C_{1} e^{x}+C_{2} e^{x} \ln x$

  \item $y(x)=c_{0}\left[1-\frac{1}{2^{2}} x^{2}+\frac{1}{2^{4}(1.2)^{2}} x^{4}-\frac{1}{2^{6}(1 \cdot 2 \cdot 3)^{2}} x^{6}+\cdots\right]$

\end{enumerate}

\section*{EXERCISES 7.1 (PAGE 288)}
\begin{enumerate}
  \item $\frac{2}{s} e^{-s}-\frac{1}{s}$

  \item $\frac{1}{s^{2}}-\frac{1}{s^{2}} e^{-s}$

  \item $\frac{1+e^{-s \pi}}{s^{2}+1}$

  \item $\frac{e^{-s}}{s}+\frac{e^{-s}}{s^{2}}$

  \item $\frac{1}{s}-\frac{1}{s^{2}}+\frac{e^{-s}}{s^{2}}$

  \item $\frac{e^{7}}{s-1}$

  \item $\frac{1}{(s-4)^{2}}$

  \item $\frac{1}{s^{2}+2 s+2}$

  \item $\frac{s^{2}-1}{\left(s^{2}+1\right)^{2}}$

  \item $\frac{48}{s^{5}}$

  \item $\frac{4}{s^{2}}-\frac{10}{s}$

  \item $\frac{2}{s^{3}}+\frac{6}{s^{2}}-\frac{3}{s}$

  \item $\frac{6}{s^{4}}+\frac{6}{s^{3}}+\frac{3}{s^{2}}+\frac{1}{s}$

  \item $\frac{1}{s}+\frac{1}{s-4}$

  \item $\frac{1}{s}+\frac{2}{s-2}+\frac{1}{s-4}$

  \item $\frac{8}{s^{3}}-\frac{15}{s^{2}+9}$

  \item Use $\sinh k t=\frac{e^{k t}-e^{-k t}}{2}$ to show that

\end{enumerate}

$$
\mathscr{L}\{\sinh k t\}=\frac{k}{s^{2}-k^{2}}
$$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item $\frac{1}{2(s-2)}-\frac{1}{2 s}$

  \item $\frac{2}{s^{2}+16}$

  \item $\frac{1}{2}\left(\frac{s}{s^{2}+9}+\frac{s}{s^{2}+1}\right)$

  \item $\frac{1}{2}\left(\frac{3}{s^{2}+9}-\frac{1}{s^{2}+1}\right)$

  \item The result follows by letting $u=s t$ in

\end{enumerate}

$$
\mathscr{L}\left\{t^{\alpha}\right\}=\int_{0}^{\infty} t^{\alpha} e^{-s t} d t
$$

\begin{enumerate}
  \setcounter{enumi}{44}
  \item $\frac{\frac{1}{2} \Gamma\left(\frac{1}{2}\right)}{s^{3 / 2}}=\frac{\sqrt{\pi}}{2 s^{3 / 2}}$

  \item On $0 \leq t \leq 1, e^{-s t} \geq e^{-s}(s>0)$. Therefore

\end{enumerate}

$$
\int_{0}^{1} e^{-s t} \frac{1}{t^{2}} d t \geq e^{-s} \int_{0}^{1} \frac{1}{t^{2}} d t
$$

The latter integral diverges.

\section*{EXERCISES 7.2 (PAGE 295)}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-516}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{8}
  \item $\frac{1}{4} e^{-t / 4} \quad$ 11. $\frac{5}{7} \sin 7 t \quad$ 13. $\cos (t / 2) \quad$ 15. $\frac{1}{4} \sinh 4 t$

  \item $2 \cos 3 t-2 \sin 3 t$

  \item $\frac{1}{3}-\frac{1}{3} e^{-3 t} \quad$ 21. $\frac{3}{4} e^{-3 t}+\frac{1}{4} e^{t}$

  \item $0.3 e^{0.1 t}+0.6 e^{-0.2 t}$

  \item $\frac{1}{2} e^{2 t}-e^{3 t}+\frac{1}{2} e^{6 t}$

  \item $-\frac{1}{3} e^{-t}+\frac{8}{15} e^{2 t}-\frac{1}{5} e^{-3 t}$

  \item $\frac{1}{4} t-\frac{1}{8} \sin 2 t$

  \item $-\frac{1}{4} e^{-2 t}+\frac{1}{4} \cos 2 t+\frac{1}{4} \sin 2 t$

  \item $\frac{1}{3} \sin t-\frac{1}{6} \sin 2 t$

  \item $1 / s$

\end{enumerate}

EXERCISES 7.3 (PAGE 3O4)

\begin{enumerate}
  \item $\frac{1}{(s-10)^{2}} \quad$ 3. $\frac{6}{(s+2)^{4}} \quad$ 5. $\frac{3}{(s-1)^{2}+9}$

  \item $\frac{3}{(s-5)^{2}-9}$ 9. $\frac{1}{(s-2)^{2}}+\frac{2}{(s-3)^{2}}+\frac{1}{(s-4)^{2}}$

  \item $\frac{1}{2}\left[\frac{1}{s+1}-\frac{s+1}{(s+1)^{2}+4}\right]$

  \item $\frac{1}{2} t^{2} e^{-2 t} \quad$ 15. $e^{3 t} \sin t$

  \item $e^{-2 t} \cos t-2 e^{-2 t} \sin t$

  \item $e^{-t}-t e^{-t}$

  \item $5-t-5 e^{-t}-4 t e^{-t}-\frac{3}{2} t^{2} e^{-t}$

  \item $\frac{e^{-s}}{s^{2}}$

  \item $\frac{e^{-2 s}}{s^{2}}+2 \frac{e^{-2 s}}{s}$

  \item $\frac{s}{s^{2}+4} e^{-\pi s}$

  \item $\frac{6 e^{-s}}{(s-1)^{4}}$

  \item $\frac{1}{2}(t-2)^{2} U(t-2) \quad$ 33. $-\sin t \mathscr{U}(t-\pi)$

  \item $U(t-1)-e^{-(t-1)} U(t-1)$

  \item $\frac{s^{2}-4}{\left(s^{2}+4\right)^{2}}$

  \item $\frac{6 s^{2}+2}{\left(s^{2}-1\right)^{3}}$

  \item $\frac{12 s-24}{\left[(s-2)^{2}+36\right]^{2}}$

  \item $\frac{1}{2} t \sin t$

  \item (c)

  \item (f) 49. (a)

  \item $f(t)=2-4 U(t-3) ; \mathscr{L}\{f(t)\}=\frac{2}{s}-\frac{4}{s} e^{-3 s}$

  \item $f(t)=t^{2} U(t-1)$

\end{enumerate}

$$
\begin{aligned}
&=(t-1)^{2} U(t-1)+2(t-1) U(t-1)+U(t-1) \\
& \mathscr{L}\{f(t)\}=2 \frac{e^{-s}}{s^{3}}+2 \frac{e^{-s}}{s^{2}}+\frac{e^{-s}}{s}
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{54}
  \item $f(t)=t-t U(t-2)$
\end{enumerate}

$$
=t-(t-2) U(t-2)-2 U(t-2)
$$

$$
\mathscr{L}\{f(t)\}=\frac{1}{s^{2}}-\frac{e^{-2 s}}{s^{2}}-2 \frac{e^{-2 s}}{s}
$$

\begin{enumerate}
  \setcounter{enumi}{56}
  \item $f(t)=\mathscr{U}(t-a)-\mathscr{U}(t-b) ; \mathscr{L}\{f(t)\}=\frac{e^{-a s}}{s}-\frac{e^{-b s}}{s}$

  \item $f(t)$

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-517}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{60}
  \item $\frac{e^{-t}-e^{3 t}}{t}$ 63. $\frac{\sin 2 t}{t}$
\end{enumerate}

\section*{EXERCISES 7.4 (PAGE 313 )}
\begin{enumerate}
  \item Since $f^{\prime}(t)=e^{t}, f(0)=1$, it follows from (1) that $\mathscr{L}\left\{e^{t}\right\}=s \mathscr{L}\left\{e^{r}\right\}-1$. Solving gives $\mathscr{L}\left\{e^{r}\right\}=1 /(s-1)$.

  \item $\left(s^{2}+3 s\right) F(s)-s-2$

  \item $F(s)=\frac{2 s-1}{(s-1)^{2}}$

  \item $\frac{1}{s(s-1)}$ 9. $\frac{s+1}{s\left[(s+1)^{2}+1\right]}$ $\begin{array}{llll}\text { 11. } \frac{1}{s^{2}(s-1)} & \text { 13. } \frac{3 s^{2}+1}{s^{2}\left(s^{2}+1\right)^{2}} & \text { 15. } \frac{6}{s^{5}} & \text { 17. } \frac{48}{s^{8}}\end{array}$

  \item $\frac{s-1}{(s+1)\left[(s-1)^{2}+1\right]} \quad$ 21. $\int_{0}^{t} f(\tau) e^{-5(t-\tau)} d \tau$

\end{enumerate}

$\begin{array}{lll}\text { 23. } 1-e^{-t} & \text { 25. }-\frac{1}{3} e^{-t}+\frac{1}{3} e^{2 t} & \text { 27. } \frac{1}{4} t \sin 2 t\end{array}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item The result follows from letting $u=t-\tau$ in the first integral.

  \item $\frac{\left(1-e^{-a s}\right)^{2}}{s\left(1-e^{-2 a s}\right)}=\frac{1-e^{-a s}}{s\left(1+e^{-a s}\right)}$

  \item $\frac{a}{s}\left(\frac{1}{b s}-\frac{1}{e^{b s}-1}\right)$

  \item $\frac{\operatorname{coth}(\pi s / 2)}{s^{2}+1}$

  \item $\frac{1}{s^{2}+1}$

\end{enumerate}

\section*{EXERCISES 7.5 (PAGE 324)}
\begin{enumerate}
  \item $y=-1+e^{t} \quad$ 3. $y=t e^{-4 t}+2 e^{-4 t}$

  \item $y=\frac{4}{3} e^{-t}-\frac{1}{3} e^{-4 t} \quad$ 7. $y=\frac{1}{9} t+\frac{2}{27}-\frac{2}{27} e^{3 t}+\frac{10}{9} t e^{3 t}$

  \item $y=\frac{1}{20} t^{5} e^{2 t} \quad$ 11. $y=\cos t-\frac{1}{2} \sin t-\frac{1}{2} t \cos t$

  \item $y=\frac{1}{2}-\frac{1}{2} e^{t} \cos t+\frac{1}{2} e^{t} \sin t$

  \item $y=-\frac{8}{9} e^{-t / 2}+\frac{1}{9} e^{-2 t}+\frac{5}{18} e^{t}+\frac{1}{2} e^{-t} \quad$ 17. $y=\cos t$

  \item $y=\left[5-5 e^{-(t-1)}\right] U(t-1)$

  \item $y=-\frac{1}{4}+\frac{1}{2} t+\frac{1}{4} e^{-2 t}-\frac{1}{4} U(t-1)-\frac{1}{2}(t-1) U(t-1)$

\end{enumerate}

$$
+\frac{1}{4} e^{-2(t-1)} U(t-1)
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $y=\cos 2 t-\frac{1}{6} \sin 2(t-2 \pi) U(t-2 \pi)$
\end{enumerate}

$$
+\frac{1}{3} \sin (t-2 \pi) U(t-2 \pi)
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $y=\sin t+[1-\cos (t-\pi)] U(t-\pi)$
\end{enumerate}

$$
-[1-\cos (t-2 \pi)] U(t-2 \pi)
$$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $y=(e+1) t e^{-t}+(e-1) e^{-t} \quad$ 29. $f(t)=\sin t$

  \item $f(t)=-\frac{1}{8} e^{-t}+\frac{1}{8} e^{t}+\frac{3}{4} t e^{t}+\frac{1}{4} t^{2} e^{t} \quad$ 33. $f(t)=e^{-t}$

  \item $f(t)=\frac{3}{8} e^{2 t}+\frac{1}{8} e^{-2 t}+\frac{1}{2} \cos 2 t+\frac{1}{4} \sin 2 t$

  \item $y=\sin t-\frac{1}{2} t \sin t$

  \item $i(t)=20,000\left[t e^{-100 t}-(t-1) e^{-100(t-1)} U(t-1)\right]$

  \item $q(t)=\frac{E_{0} C}{1-k R C}\left(e^{-k t}-e^{-t / R C}\right)$;

\end{enumerate}

$$
q(t)=\frac{E_{0}}{R} t e^{-t / R C}
$$

\begin{enumerate}
  \setcounter{enumi}{42}
  \item $q(t)=\frac{2}{5} U(t-3)-\frac{2}{5} e^{-5(t-3)} U(t-3)$

  \item $i(t)=\frac{1}{101} e^{-10 t}-\frac{1}{101} \cos t+\frac{10}{101} \sin t$

\end{enumerate}

$$
\begin{aligned}
& -\frac{10}{101} e^{-10(t-3 \pi / 2)} U\left(t-\frac{3 \pi}{2}\right) \\
& +\frac{10}{101} \cos \left(t-\frac{3 \pi}{2}\right) U\left(t-\frac{3 \pi}{2}\right) \\
& +\frac{1}{101} \sin \left(t-\frac{3 \pi}{2}\right) U\left(t-\frac{3 \pi}{2}\right)
\end{aligned}
$$

\section*{A-16}
\begin{enumerate}
  \setcounter{enumi}{46}
  \item $i(t)=\frac{t}{R}+\frac{L}{R^{2}}\left(e^{-R t / L}-1\right)$
\end{enumerate}

$$
+\frac{1}{R} \sum_{n=1}^{\infty}\left(e^{-R(t-n) / L}-1\right) \mathscr{( t - n )}
$$

For $0 \leq t<2$,

$$
i(t)=\left\{\begin{array}{l}
\frac{t}{R}+\frac{L}{R^{2}}\left(e^{-R t / L}-1\right), \quad 0 \leq t<1 \\
\frac{t}{R}+\frac{L}{R^{2}}\left(e^{-R t / L}-1\right) \\
\quad+\frac{1}{R}\left(e^{-R(t-1) / L}-1\right), \quad 1 \leq t<2
\end{array}\right.
$$

\begin{enumerate}
  \setcounter{enumi}{48}
  \item $q(t)=\frac{3}{5} e^{-10 t}+6 t e^{-10 t}-\frac{3}{5} \cos 10 t$;
\end{enumerate}

$$
i(t)=-60 t e^{-10 t}+6 \sin 10 t
$$

steady-state current is $6 \sin 10 t$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item $q(t)=\frac{E_{0}}{L\left(k^{2}+\frac{1}{L C}\right)}\left[e^{-k t}-\cos (t / \sqrt{L C})\right]$
\end{enumerate}

$$
+\frac{k E_{0} \sqrt{C / L}}{k^{2}+\frac{1}{L C}} \sin (t / \sqrt{L C})
$$

\begin{enumerate}
  \setcounter{enumi}{52}
  \item $x(t)=-\frac{3}{2} e^{-7 t / 2} \cos \frac{\sqrt{15}}{2} t-\frac{7 \sqrt{15}}{10} e^{-7 t / 2} \sin \frac{\sqrt{15}}{2} t$

  \item $y(x)=\frac{w_{0}}{E I}\left(\frac{L^{2}}{4} x^{2}-\frac{L}{6} x^{3}+\frac{1}{24} x^{4}\right)$;

\end{enumerate}

$$
\frac{17 w_{0} L^{4}}{384 E I} ; \frac{w_{0} L^{4}}{8 E I}
$$

\begin{enumerate}
  \setcounter{enumi}{56}
  \item $y(x)=\frac{w_{0} L^{2}}{16 E I} x^{2}-\frac{w_{0} L}{12 E I} x^{3}+\frac{w_{0}}{24 E I} x^{4}$
\end{enumerate}

$$
-\frac{w_{0}}{24 E I}\left(x-\frac{L}{2}\right)^{4} U\left(x-\frac{L}{2}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{58}
  \item $y=\frac{1}{3} t^{3}+\frac{1}{2} c t^{2}$
\end{enumerate}

\section*{EXERCISES 7.6 (PAGE 331)}
\begin{enumerate}
  \item $y=e^{3(t-2)} U(t-2)$

  \item $y=\sin t+\sin t U(t-2 \pi)$

  \item $y=-\cos t थ\left(t-\frac{\pi}{2}\right)+\cos t \mathscr{U}\left(t-\frac{3 \pi}{2}\right)$

  \item $y=\frac{1}{2}-\frac{1}{2} e^{-2 t}+\left[\frac{1}{2}-\frac{1}{2} e^{-2(t-1)}\right] U(t-1)$

  \item $y=e^{-2(t-2 \pi)} \sin t थ(t-2 \pi)$

  \item $y=e^{-2 t} \cos 3 t+\frac{2}{3} e^{-2 t} \sin 3 t$

\end{enumerate}

$$
\begin{aligned}
& +\frac{1}{3} e^{-2(t-\pi)} \sin 3(t-\pi) U(t-\pi) \\
& +\frac{1}{3} e^{-2(t-3 \pi)} \sin 3(t-3 \pi) U(t-3 \pi)
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $y(x)= \begin{cases}\frac{P_{0}}{E I}\left(\frac{L}{4} x^{2}-\frac{1}{6} x^{3}\right), & 0 \leq x<L / 2 \\ \frac{P_{0} L^{2}}{4 E I}\left(\frac{1}{2} x-\frac{L}{12}\right), & L / 2 \leq x \leq L\end{cases}$

  \item From (7) with $f(t)=e^{-s t}$, we have

\end{enumerate}

$$
\mathscr{L}\left\{\delta\left(t-t_{0}\right)\right\}=\int_{0}^{\infty} e^{-s t} \delta\left(t-t_{0}\right) d t=e^{-s t_{0}}
$$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $y=e^{-t} \cos t+e^{-(t-3 \pi)} \sin t U(t-3 \pi)$

  \item $i(t)=\frac{1}{L} e^{-R t / L}$; no

\end{enumerate}

\section*{CHAPTER 7 REVIEW EXERCISES (PAGE 332)}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-518}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $\frac{4 s}{\left(s^{2}+4\right)^{2}}$

  \item $\frac{1}{6} t^{5} \quad$ 15. $\frac{1}{2} t^{2} e^{5 t}$

  \item $e^{5 t} \cos 2 t+\frac{5}{2} e^{5 t} \sin 2 t$

  \item $\cos \pi(t-1) \cup(t-1)+\sin \pi(t-1) \cup(t-1)$

  \item -5 23. $e^{-k s} F(s-a)$

  \item (a) $f(t)=t-(t-1) U(t-1)-\Psi(t-4)$

\end{enumerate}

(b) $\mathscr{L}\{f(t)\}=\frac{1}{s^{2}}-\frac{1}{s^{2}} e^{-s}-\frac{1}{s} e^{-4 s}$

(c) $\mathscr{L}\left\{e^{t} f(t)\right\}=\frac{1}{(s-1)^{2}}-\frac{1}{(s-1)^{2}} e^{-(s-1)}$

$-\frac{1}{s-1} e^{-4(s-1)}$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item (a) $f(t)=2+(t-2) U(t-2)$
\end{enumerate}

(b) $\mathscr{L}\{f(t)\}=\frac{2}{s}+\frac{1}{s^{2}} e^{-2 s}$

(c) $\mathscr{L}\left\{e^{t} f(t)\right\}=\frac{2}{s-1}+\frac{1}{(s-1)^{2}} e^{-2(s-1)}$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $y=5 t e^{t}+\frac{1}{2} t^{2} e^{t}$

  \item $y=5 \mathscr{U}(t-\pi)-5 e^{2(t-\pi)} \cos \sqrt{2}(t-\pi) \mathscr{U}(t-\pi)$

\end{enumerate}

$$
+5 \sqrt{2} e^{2(t-\pi)} \sin \sqrt{2}(t-\pi) U(t-\pi)
$$

\begin{enumerate}
  \setcounter{enumi}{32}
  \item $y=-\frac{2}{125}-\frac{2}{25} t-\frac{1}{5} t^{2}+\frac{127}{125} e^{5 t}$
\end{enumerate}

$$
-\left[-\frac{37}{125}-\frac{12}{25}(t-1)-\frac{1}{5}(t-1)^{2}\right.
$$

$\left.+\frac{37}{125} e^{5(t-1)}\right] U(t-1)$

\begin{enumerate}
  \setcounter{enumi}{34}
  \item $y=1+t+\frac{1}{2} t^{2}$

  \item $i(t)=-9+2 t+9 e^{-t / 5}$

  \item $y(x)=\frac{w_{0}}{12 E I L}\left[-\frac{1}{5} x^{5}+\frac{L}{2} x^{4}-\frac{L^{2}}{2} x^{3}+\frac{L^{3}}{4} x^{2}\right.$

\end{enumerate}

$$
\left.+\frac{1}{5}\left(x-\frac{L}{2}\right)^{5} U\left(x-\frac{L}{2}\right)\right]
$$

EXERCISES 8.1 (PAGE 342)

\begin{enumerate}
  \item $x=c_{1} e^{t}+c_{2} t e^{t}$
\end{enumerate}

$y=\left(c_{1}-c_{2}\right) e^{t}+c_{2} t e^{t}$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $x=c_{1} \cos t+c_{2} \sin t+t+1$
\end{enumerate}

$y=c_{1} \sin t-c_{2} \cos t+t-1$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item $x=\frac{1}{2} c_{1} \sin t+\frac{1}{2} c_{2} \cos t-2 c_{3} \sin \sqrt{6} t-2 c_{4} \cos \sqrt{6} t$ $y=c_{1} \sin t+c_{2} \cos t+c_{3} \sin \sqrt{6} t+c_{4} \cos \sqrt{6} t$

  \item $x=c_{1} e^{2 t}+c_{2} e^{-2 t}+c_{3} \sin 2 t+c_{4} \cos 2 t+\frac{1}{5} e^{t}$

\end{enumerate}

$y=c_{1} e^{2 t}+c_{2} e^{-2 t}-c_{3} \sin 2 t-c_{4} \cos 2 t-\frac{1}{5} e^{t}$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item $x=c_{1}-c_{2} \cos t+c_{3} \sin t+\frac{17}{15} e^{3 t}$
\end{enumerate}

$y=c_{1}+c_{2} \sin t+c_{3} \cos t-\frac{4}{15} e^{3 t}$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $x=c_{1} e^{t}+c_{2} e^{-t / 2} \cos \frac{\sqrt{3}}{2} t+c_{3} e^{-t / 2} \sin \frac{\sqrt{3}}{2} t$
\end{enumerate}

$$
\begin{aligned}
y= & \left(-\frac{3}{2} c_{2}-\frac{\sqrt{3}}{2} c_{3}\right) e^{-t / 2} \cos \frac{\sqrt{3}}{2} t \\
& +\left(\frac{\sqrt{3}}{2} c_{2}-\frac{3}{2} c_{3}\right) e^{-t / 2} \sin \frac{\sqrt{3}}{2} t
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $x=c_{1} e^{4 t}+\frac{4}{3} e^{t}$
\end{enumerate}

$$
y=-\frac{3}{4} c_{1} e^{4 t}+c_{2}+5 e^{t}
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $x=c_{1}+c_{2} t+c_{3} e^{t}+c_{4} e^{-t}-\frac{1}{2} t^{2}$
\end{enumerate}

$y=\left(c_{1}-c_{2}+2\right)+\left(c_{2}+1\right) t+c_{4} e^{-t}-\frac{1}{2} t^{2}$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $x=c_{1} e^{t}+c_{2} e^{-t / 2} \sin \frac{\sqrt{3}}{2} t+c_{3} e^{-t / 2} \cos \frac{\sqrt{3}}{2} t$
\end{enumerate}

$$
\begin{aligned}
y= & c_{1} e^{t}+\left(-\frac{1}{2} c_{2}-\frac{\sqrt{3}}{2} c_{3}\right) e^{-t / 2} \sin \frac{\sqrt{3}}{2} t \\
& +\left(\frac{\sqrt{3}}{2} c_{2}-\frac{1}{2} c_{3}\right) e^{-t / 2} \cos \frac{\sqrt{3}}{2} t \\
z= & c_{1} e^{t}+\left(-\frac{1}{2} c_{2}+\frac{\sqrt{3}}{2} c_{3}\right) e^{-t / 2} \sin \frac{\sqrt{3}}{2} t \\
& +\left(-\frac{\sqrt{3}}{2} c_{2}-\frac{1}{2} c_{3}\right) e^{-t / 2} \cos \frac{\sqrt{3}}{2} t
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $x=-6 c_{1} e^{-t}-3 c_{2} e^{-2 t}+2 c_{3} e^{3 t}$
\end{enumerate}

$y=c_{1} e^{-t}+c_{2} e^{-2 t}+c_{3} e^{3 t}$

$z=5 c_{1} e^{-t}+c_{2} e^{-2 t}+c_{3} e^{3 t}$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $x=-c_{1} e^{-t}+c_{2}+\frac{1}{3} t^{3}-2 t^{2}+5 t$
\end{enumerate}

$y=c_{1} e^{-t}+2 t^{2}-5 t+5$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $x=e^{-3 t+3}-t e^{-3 t+3}$
\end{enumerate}

$y=-e^{-3 t+3}+2 t e^{-3 t+3}$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $D x-D y=0$
\end{enumerate}

$(D-1) x-y=0$

\section*{EXERCISES 8.2 (PAGE 348)}
\begin{enumerate}
  \item $x=-\frac{1}{3} e^{-2 t}+\frac{1}{3} e^{t}$
\end{enumerate}

$y=\frac{1}{3} e^{-2 t}+\frac{2}{3} e^{t}$

\begin{enumerate}
  \setcounter{enumi}{2}
  \item $x=-\cos 3 t-\frac{5}{3} \sin 3 t$ $y=2 \cos 3 t-\frac{7}{3} \sin 3 t$
  \item $x=-2 e^{3 t}+\frac{5}{2} e^{2 t}-\frac{1}{2}$
\end{enumerate}

$y=\frac{8}{3} e^{3 t}-\frac{5}{2} e^{2 t}-\frac{1}{6}$\\
7. $x=-\frac{1}{2} t-\frac{3}{4} \sqrt{2} \sin \sqrt{2} t$

$y=-\frac{1}{2} t+\frac{3}{4} \sqrt{2} \sin \sqrt{2} t$\\
9. $x=8+\frac{2}{3!} t^{3}+\frac{1}{4!} t^{4}$

$$
y=-\frac{2}{3!} t^{3}+\frac{1}{4!} t^{4}
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $x=\frac{1}{2} t^{2}+t+1-e^{-t}$ $y=-\frac{1}{3}+\frac{1}{3} e^{-t}+\frac{1}{3} t e^{-t}$

  \item $x_{1}=\frac{1}{5} \sin t+\frac{2 \sqrt{6}}{15} \sin \sqrt{6} t+\frac{2}{5} \cos t-\frac{2}{5} \cos \sqrt{6} t$ $x_{2}=\frac{2}{5} \sin t-\frac{\sqrt{6}}{15} \sin \sqrt{6} t+\frac{4}{5} \cos t+\frac{1}{5} \cos \sqrt{6} t$

\end{enumerate}

$\begin{array}{ll}\text { 15. (b) } i_{2}=\frac{100}{9}-\frac{100}{9} e^{-900 t} & \text { (c) } i_{1}=20-20 e^{-900 t}\end{array}$ $i_{3}=\frac{80}{9}-\frac{80}{9} e^{-900 t}$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $i_{2}=-\frac{20}{13} e^{-2 t}+\frac{375}{1469} e^{-15 t}+\frac{145}{113} \cos t+\frac{85}{113} \sin t$ $i_{3}=\frac{30}{13} e^{-2 t}+\frac{250}{1469} e^{-15 t}-\frac{280}{113} \cos t+\frac{810}{113} \sin t$

  \item $i_{1}=\frac{6}{5}-\frac{6}{5} e^{-100 t} \cos 100 t$ $i_{2}=\frac{6}{5}-\frac{6}{5} e^{-100 t} \cos 100 t-\frac{6}{5} e^{-100 t} \sin 100 t$

  \item (b) $q=50 e^{-t} \sin (t-1) U(t-1)$

\end{enumerate}

\section*{EXERCISES 8.3 (PAGE 354)}
\begin{enumerate}
  \item $x_{1}^{\prime}=x_{2}$
\end{enumerate}

$x_{2}^{\prime}=-4 x_{1}+3 x_{2}+\sin 3 t$\\
3. $x_{1}^{\prime}=x_{2}$

$x_{2}^{\prime}=x_{3}$

$x_{3}^{\prime}=10 x_{1}-6 x_{2}+3 x_{3}+t^{2}+1$\\
5. $x_{1}^{\prime}=x_{2}$

$x_{2}^{\prime}=x_{3}$

$x_{3}^{\prime}=x_{4}$

$x_{4}^{\prime}=-x_{1}-4 x_{2}+2 x_{3}+t$\\
7. $x_{1}^{\prime}=x_{2}$

$x_{2}^{\prime}=\frac{t}{t+1} x_{1}$\\
9. $x^{\prime}=-2 x+y+5 t$

$y^{\prime}=2 x+y-2 t$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $D x=t^{2}+5 t-2$
\end{enumerate}

$D y=-x+5 t-2$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item The system is degenerate.

  \item $D x=u$

\end{enumerate}

$D y=v$

$D u=w$

$D v=10 t^{2}-4 u+3 v$

$D w=4 x+4 v-3 w$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $x_{1}=\frac{25}{2} e^{-t / 25}+\frac{25}{2} e^{-3 t / 25}$
\end{enumerate}

$$
x_{2}=\frac{25}{4} e^{-t / 25}-\frac{25}{4} e^{-3 t / 25}
$$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item $x_{1}^{\prime}=\frac{1}{50} x_{2}-\frac{3}{50} x_{1}$
\end{enumerate}

$x_{2}^{\prime}=\frac{3}{50} x_{1}-\frac{7}{100} x_{2}+\frac{1}{100} x_{3}$

$x_{3}^{\prime}=\frac{1}{20} x_{2}-\frac{1}{20} x_{3}$

\section*{EXERCISES 8.4 (PAGE 372)}
\begin{enumerate}
  \item (a) $\left(\begin{array}{rr}2 & 11 \\ 2 & -1\end{array}\right)$ (b) $\left(\begin{array}{rr}-6 & 1 \\ 14 & -19\end{array}\right)$ (c) $\left(\begin{array}{rr}2 & 28 \\ 12 & -12\end{array}\right)$

  \item (a) $\left(\begin{array}{rr}-11 & 6 \\ 17 & -22\end{array}\right)$

\end{enumerate}

(b) $\left(\begin{array}{rr}-32 & 27 \\ -4 & -1\end{array}\right)$

(c) $\left(\begin{array}{rr}19 & -18 \\ -30 & 31\end{array}\right)$

(d) $\left(\begin{array}{rr}19 & 6 \\ 3 & 22\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item (a) $\left(\begin{array}{rr}9 & 24 \\ 3 & 8\end{array}\right)$
\end{enumerate}

(b) $\left(\begin{array}{rr}3 & 8 \\ -6 & -16\end{array}\right)$

(c) $\left(\begin{array}{ll}0 & 0 \\ 0 & 0\end{array}\right)$

(d) $\left(\begin{array}{rr}-4 & -5 \\ 8 & 10\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item (a) 180 (b) $\left(\begin{array}{rrr}4 & 8 & 10 \\ 8 & 16 & 20 \\ 10 & 20 & 25\end{array}\right)$ (c) $\left(\begin{array}{r}6 \\ 12 \\ -5\end{array}\right)$

  \item (a) $\left(\begin{array}{rr}7 & 38 \\ 10 & 75\end{array}\right)$ (b) $\left(\begin{array}{rr}7 & 38 \\ 10 & 75\end{array}\right) \quad$ 11. $\binom{-14}{1}$

  \item $\binom{-38}{-2}$ 15. singular

  \item nonsingular; $\mathbf{A}^{-1}=\frac{1}{4}\left(\begin{array}{rr}-5 & -8 \\ 3 & 4\end{array}\right)$

  \item nonsingular; $\mathbf{A}^{-1}=\frac{1}{2}\left(\begin{array}{rrr}0 & -1 & 1 \\ 2 & 2 & -2 \\ -4 & -3 & 5\end{array}\right)$

  \item nonsingular; $\mathbf{A}^{-1}=-\frac{1}{9}\left(\begin{array}{rrr}-2 & -2 & -1 \\ -13 & 5 & 7 \\ 8 & -1 & -5\end{array}\right)$

  \item $\operatorname{det} \mathbf{A}(t)=2 e^{3 t} \neq 0$ for every value of $t$;

\end{enumerate}

$$
\mathbf{A}^{-1}(t)=\frac{1}{2 e^{3 t}}\left(\begin{array}{rr}
3 e^{4 t} & -e^{4 t} \\
-4 e^{-t} & 2 e^{-t}
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item $\frac{d \mathbf{X}}{d t}=\left(\begin{array}{r}-5 e^{-t} \\ -2 e^{-t} \\ 7 e^{-t}\end{array}\right) \quad$ 27. $\frac{d \mathbf{X}}{d t}=4\binom{1}{-1} e^{2 t}-12\binom{2}{1} e^{-3 t}$

  \item (a) $\left(\begin{array}{cc}4 e^{4 t} & -\pi \sin \pi t \\ 2 & 6 t\end{array}\right)$ (b) $\left(\begin{array}{cc}\frac{1}{4} e^{8}-\frac{1}{4} & 0 \\ 4 & 6\end{array}\right)$

\end{enumerate}

(c) $\left(\begin{array}{cc}\frac{1}{4} e^{4 t}-\frac{1}{4} & (1 / \pi) \sin \pi t \\ t^{2} & t^{3}-t\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $x=3, y=1, z=-5$
\end{enumerate}

$\begin{array}{ll}\text { 33. } x=2+4 t, y=-5-t, z=t & \text { 35. } x=-\frac{1}{2}, y=\frac{3}{2}, z=\frac{7}{2}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{36}
  \item $x_{1}=1, x_{2}=0, x_{3}=2, x_{4}=0$

  \item $\lambda_{1}=6, \lambda_{2}=1, \mathbf{K}_{1}=\binom{2}{7}, \mathbf{K}_{2}=\binom{1}{1}$

  \item $\lambda_{1}=\lambda_{2}=-4, \mathbf{K}_{1}=\binom{1}{-4}$

  \item $\lambda_{1}=0, \lambda_{2}=4, \lambda_{3}=-4$,

\end{enumerate}

$$
\mathbf{K}_{1}=\left(\begin{array}{r}
9 \\
45 \\
25
\end{array}\right), \mathbf{K}_{2}=\left(\begin{array}{l}
1 \\
1 \\
1
\end{array}\right), \mathbf{K}_{3}=\left(\begin{array}{l}
1 \\
9 \\
1
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{46}
  \item $\lambda_{1}=\lambda_{2}=\lambda_{3}=-2$,
\end{enumerate}

$$
\mathbf{K}_{1}=\left(\begin{array}{r}
2 \\
-1 \\
0
\end{array}\right), \mathbf{K}_{2}=\left(\begin{array}{l}
0 \\
0 \\
1
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{48}
  \item $\lambda_{1}=3 i, \lambda_{2}=-3 i$,
\end{enumerate}

$$
\mathbf{K}_{1}=\binom{1-3 i}{5}, \mathbf{K}_{2}=\binom{1+3 i}{5}
$$

\begin{enumerate}
  \setcounter{enumi}{50}
  \item $\frac{d}{d t}\left(\begin{array}{ll}a_{11}(t) & a_{12}(t) \\ a_{21}(t) & a_{22}(t)\end{array}\right)\binom{x_{1}(t)}{x_{2}(t)}$
\end{enumerate}

$=\frac{d}{d t}\binom{a_{11}(t) x_{1}(t)+a_{12}(t) x_{2}(t)}{a_{21}(t) x_{1}(t)+a_{22}(t) x_{2}(t)}$

$=\binom{a_{11}(t) x_{1}^{\prime}(t)+a_{11}^{\prime}(t) x_{1}(t)+a_{12}(t) x_{2}^{\prime}(t)+a_{12}^{\prime}(t) x_{2}(t)}{a_{21}(t) x_{1}^{\prime}(t)+a_{21}^{\prime}(t) x_{1}(t)+a_{22}(t) x_{2}^{\prime}(t)+a_{22}^{\prime}(t) x_{2}(t)}$

$=\binom{a_{11}(t) x_{1}^{\prime}(t)+a_{12}(t) x_{2}^{\prime}(t)+a_{11}^{\prime}(t) x_{1}(t)+a_{12}^{\prime}(t) x_{2}(t)}{a_{21}(t) x_{1}^{\prime}(t)+a_{22}(t) x_{2}^{\prime}(t)+a_{21}^{\prime}(t) x_{1}(t)+a_{22}^{\prime}(t) x_{2}(t)}$

$=\left(\begin{array}{ll}a_{11}(t) & a_{12}(t) \\ a_{21}(t) & a_{22}(t)\end{array}\right)\binom{x_{1}^{\prime}(t)}{x_{2}^{\prime}(t)}+\left(\begin{array}{ll}a_{11}^{\prime}(t) & a_{12}^{\prime}(t) \\ a_{21}^{\prime}(t) & a_{22}^{\prime}(t)\end{array}\right)\binom{x_{1}(t)}{x_{2}(t)}$

$=\mathbf{A}(t) \mathbf{X}^{\prime}(t)+\mathbf{A}^{\prime}(t) \mathbf{X}(t)$

\begin{enumerate}
  \setcounter{enumi}{52}
  \item Since $\mathbf{A}^{-1}$ exists, $\mathbf{A B}=\mathbf{A C}$ implies $\mathbf{A}^{-1}(\mathbf{A B})=$ $\mathbf{A}^{-1}(\mathbf{A C}),\left(\mathbf{A}^{-1} \mathbf{A}\right) \mathbf{B}=\left(\mathbf{A}^{-1} \mathbf{A}\right) \mathbf{C}, \mathbf{I B}=\mathbf{I C}$, or $\mathbf{B}=\mathbf{C}$.

  \item No, since in general $\mathbf{A B} \neq \mathbf{B A}$.

\end{enumerate}

\section*{EXERCISES 8.5 (PAGE 388)}
\begin{enumerate}
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rr}3 & -5 \\ 4 & 8\end{array}\right) \mathbf{X}$, where $\mathbf{X}=\binom{x}{y}$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}-3 & 4 & -9 \\ 6 & -1 & 0 \\ 10 & 4 & 3\end{array}\right) \mathbf{X}$, where $\mathbf{X}=\left(\begin{array}{l}x \\ y \\ z\end{array}\right)$
  \item $\mathbf{X}^{\prime}=\left(\begin{array}{rrr}1 & -1 & 1 \\ 2 & 1 & -1 \\ 1 & 1 & 1\end{array}\right) \mathbf{X}+\left(\begin{array}{c}0 \\ -3 t^{2} \\ t^{2}\end{array}\right)+\left(\begin{array}{r}t \\ 0 \\ -t\end{array}\right)$
\end{enumerate}

$$
+\left(\begin{array}{r}
-1 \\
0 \\
2
\end{array}\right) \text {, where } \mathbf{X}=\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $\frac{d x}{d t}=4 x+2 y+e^{t}$
\end{enumerate}

$$
\frac{d y}{d t}=-x+3 y-e^{t}
$$

\begin{enumerate}
  \setcounter{enumi}{8}
  \item $\frac{d x}{d t}=x-y+2 z+e^{-t}-3 t$
\end{enumerate}

$$
\begin{aligned}
& \frac{d y}{d t}=3 x-4 y+z+2 e^{-t}+t \\
& \frac{d z}{d t}=-2 x+5 y+6 z+2 e^{-t}-t
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $\mathbf{X}^{\prime}=\binom{-5 e^{-5 t}}{-10 e^{-5 t}}$
\end{enumerate}

$$
\left(\begin{array}{ll}
3 & -4 \\
4 & -7
\end{array}\right) \mathbf{X}=\binom{3-8}{4-14} e^{-5 t}=\binom{-5}{-10} e^{-5 t}=\mathbf{X}^{\prime}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $X^{\prime}=\binom{\frac{3}{2}}{-3}$
\end{enumerate}

$$
\left(\begin{array}{rr}
-1 & \frac{1}{4} \\
1 & -1
\end{array}\right) \mathbf{X}=\binom{1+\frac{1}{2}}{-1-2} e^{-3 / / 2}=\binom{\frac{3}{2}}{-3} e^{-3 / / 2}=\mathbf{X}^{\prime}
$$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $\frac{d \mathbf{X}}{d t}=\left(\begin{array}{l}0 \\ 0 \\ 0\end{array}\right)$
\end{enumerate}

$$
\left(\begin{array}{rrr}
1 & 2 & 1 \\
6 & -1 & 0 \\
-1 & -2 & -1
\end{array}\right) \mathbf{X}=\left(\begin{array}{c}
1+12-13 \\
6-6 \\
-1-12+13
\end{array}\right)=\left(\begin{array}{l}
0 \\
0 \\
0
\end{array}\right)=\frac{d \mathbf{X}}{d t}
$$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Yes; $W\left(\mathbf{X}_{1}, \mathbf{X}_{2}\right)=-2 e^{-8 t} \neq 0$ implies $\mathbf{X}_{1}$ and $\mathbf{X}_{2}$ are linearly independent on $(-\infty, \infty)$.

  \item No; $W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \mathbf{X}_{3}\right)=$

\end{enumerate}

$$
\left|\begin{array}{rrr}
1+t & 1 & 3+2 t \\
-2+2 t & -2 & -6+4 t \\
4+2 t & 4 & 12+4 t
\end{array}\right|=0 \text { for every } t
$$

The solution vectors are linearly dependent on $(-\infty, \infty)$. Note that $\mathbf{X}_{3}=2 \mathbf{X}_{1}+\mathbf{X}_{2}$.\\
21. $\frac{d \mathbf{X}_{p}}{d t}=\binom{2}{-1}$

$$
\begin{aligned}
\left(\begin{array}{ll}
1 & 4 \\
3 & 2
\end{array}\right) \mathbf{X}_{p}+\binom{2}{-4} t-\binom{7}{18} \\
\quad=\binom{(2-4) t+9+2 t-7}{(6-2) t+17-4 t-18}=\binom{2}{-1}=\frac{d \mathbf{X}_{p}}{d t}
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $\mathbf{X}_{p}^{\prime}=\binom{2 e^{t}+t e^{t}}{-t e^{t}}$
\end{enumerate}

$$
\begin{aligned}
\left(\begin{array}{ll}
2 & 1 \\
3 & 4
\end{array}\right) \mathbf{X}_{p}-\binom{1}{7} e^{t} & =\binom{3 e^{t}+t e^{t}-e^{t}}{7 e^{t}-t e^{t}-7 e^{t}} \\
& =\binom{2 e^{t}+t e^{t}}{-t e^{t}}=\mathbf{X}_{p}^{\prime}
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{24}
  \item Let $\mathbf{X}_{1}=\left(\begin{array}{r}6 \\ -1 \\ -5\end{array}\right) e^{-t}, \mathbf{X}_{2}=\left(\begin{array}{r}-3 \\ 1 \\ 1\end{array}\right) e^{-2 t}$,
\end{enumerate}

$\mathbf{X}_{3}=\left(\begin{array}{l}2 \\ 1 \\ 1\end{array}\right) e^{3 t}$, and $\mathbf{A}=\left(\begin{array}{lll}0 & 6 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0\end{array}\right)$. Then

$\mathbf{A} \mathbf{X}_{1}=\left(\begin{array}{r}-6 \\ 1 \\ 5\end{array}\right) e^{-t}=\mathbf{X}_{1}^{\prime}$,

$\mathbf{A} \mathbf{X}_{2}=\left(\begin{array}{r}6 \\ -2 \\ -2\end{array}\right) e^{-2 t}=\mathbf{X}_{2}^{\prime}$

$\mathbf{A} \mathbf{X}_{3}=\left(\begin{array}{l}6 \\ 3 \\ 3\end{array}\right) e^{3 t}=\mathbf{X}_{3}^{\prime}$, and

$W\left(\mathbf{X}_{1}, \mathbf{X}_{2}, \mathbf{X}_{3}\right)=\left|\begin{array}{rrr}6 e^{-t} & -3 e^{-2 t} & 2 e^{3 t} \\ -e^{-t} & e^{-2 t} & e^{3 t} \\ -5 e^{-t} & e^{-2 t} & e^{3 t}\end{array}\right|$

$$
=20 \neq 0 \text {. }
$$

Therefore, $\mathbf{X}_{1}, \mathbf{X}_{2}, \mathbf{X}_{3}$ form a fundamental set of solutions of $\mathbf{X}^{\prime}=\mathbf{A} \mathbf{X}$ on $(-\infty, \infty)$. By definition,

$$
\mathbf{X}=c_{1} \mathbf{X}_{1}+c_{2} \mathbf{X}_{2}+c_{3} \mathbf{X}_{3}
$$

is the general solution.

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $\boldsymbol{\Phi}(t)=\left(\begin{array}{rr}e^{2 t} & e^{7 t} \\ -2 e^{2 t} & 3 e^{7 t}\end{array}\right)$
\end{enumerate}

$$
\Phi^{-1}(t)=\frac{1}{5 e^{9 t}}\left(\begin{array}{cc}
3 e^{7 t} & -e^{7 t} \\
2 e^{2 t} & e^{2 t}
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{28}
  \item $\boldsymbol{\Phi}(t)=\left(\begin{array}{cc}-e^{t} & -t e^{t} \\ 3 e^{t} & 3 t e^{t}-e^{t}\end{array}\right)$
\end{enumerate}

$\Phi^{-1}(t)=\frac{1}{e^{2 t}}\left(\begin{array}{cc}3 t e^{t}-e^{t} & t e^{t} \\ -3 e^{t} & -e^{t}\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{30}
  \item $\Psi(t)=\left(\begin{array}{rr}\frac{3}{5} e^{2 t}+\frac{2}{5} e^{7 t} & -\frac{1}{5} e^{2 t}+\frac{1}{5} e^{7 t} \\ -\frac{6}{5} e^{2 t}+\frac{6}{5} e^{7 t} & \frac{2}{5} e^{2 t}+\frac{3}{5} e^{7 t}\end{array}\right)$

  \item $\Psi(t)=\left(\begin{array}{cc}3 t e^{t}+e^{t} & t e^{t} \\ -9 t e^{t} & -3 t e^{t}+e^{t}\end{array}\right)$

  \item $\mathbf{X}\left(t_{0}\right)=\Phi\left(t_{0}\right) \mathbf{C}$ implies $\mathbf{C}=\boldsymbol{\Phi}^{-1}\left(t_{0}\right) \mathbf{X}\left(t_{0}\right)$. Substituting in $\mathbf{X}=\boldsymbol{\Phi}(t) \mathbf{C}$ gives $\mathbf{X}=\boldsymbol{\Phi}(t) \boldsymbol{\Phi}^{-1}\left(t_{0}\right) \mathbf{X}_{0}$.

  \item Comparing $\mathbf{X}=\Phi(t) \Phi^{-1}\left(t_{0}\right) \mathbf{X}_{0}$ and $\mathbf{X}=\Psi(t) \mathbf{X}_{0}$ implies $\left[\Psi(t)-\Phi(t) \Phi^{-1}\left(t_{0}\right)\right] \mathbf{X}_{0}=\mathbf{0}$. Since this last equation is to hold for any $\mathbf{X}_{0}$, we conclude that $\Psi(t)=\Phi(t) \Phi^{-1}\left(t_{0}\right)$.

\end{enumerate}

EXERCISES 8.6 (PAGE 402)

\begin{enumerate}
  \item $\mathbf{X}=c_{1}\binom{1}{2} e^{5 t}+c_{2}\binom{1}{-1} e^{-t}$

  \item $\mathbf{X}=c_{1}\binom{2}{1} e^{-3 t}+c_{2}\binom{2}{5} e^{t}$

  \item $\mathbf{X}=c_{1}\binom{5}{2} e^{8 t}+c_{2}\binom{1}{4} e^{-10 t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}1 \\ 0 \\ 0\end{array}\right) e^{t}+c_{2}\left(\begin{array}{l}2 \\ 3 \\ 1\end{array}\right) e^{2 t}+c_{3}\left(\begin{array}{l}1 \\ 0 \\ 2\end{array}\right) e^{-t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{r}-1 \\ 0 \\ 1\end{array}\right) e^{-t}+c_{2}\left(\begin{array}{l}1 \\ 4 \\ 3\end{array}\right) e^{3 t}+c_{3}\left(\begin{array}{r}1 \\ -1 \\ 3\end{array}\right) e^{-2 t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{r}4 \\ 0 \\ -1\end{array}\right) e^{-t}+c_{2}\left(\begin{array}{r}-12 \\ 6 \\ 5\end{array}\right) e^{-t / 2}+c_{3}\left(\begin{array}{r}4 \\ 2 \\ -1\end{array}\right) e^{-3 / 2}$

  \item $\mathbf{X}=3\binom{1}{1} e^{t / 2}+2\binom{0}{1} e^{-t / 2}$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{2 \cos t+\sin t} e^{4 t}+c_{2}\binom{\sin t}{2 \sin t-\cos t} e^{4 t}$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{-\cos t-\sin t} e^{4 t}+c_{2}\binom{\sin t}{-\sin t+\cos t} e^{4 t}$

  \item $\mathbf{X}=c_{1}\binom{5 \cos 3 t}{4 \cos 3 t+3 \sin 3 t}+c_{2}\binom{5 \sin 3 t}{4 \sin 3 t-3 \cos 3 t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}1 \\ 0 \\ 0\end{array}\right)+c_{2}\left(\begin{array}{r}-\cos t \\ \cos t \\ \sin t\end{array}\right)+c_{3}\left(\begin{array}{r}\sin t \\ -\sin t \\ \cos t\end{array}\right)$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}0 \\ 2 \\ 1\end{array}\right) e^{t}+c_{2}\left(\begin{array}{c}\sin t \\ \cos t \\ \cos t\end{array}\right) e^{t}+c_{3}\left(\begin{array}{c}\cos t \\ -\sin t \\ -\sin t\end{array}\right) e^{t}$

  \item $\mathbf{X}=\left(\begin{array}{c}28 \\ -5 \\ 25\end{array}\right) e^{2 t}+c_{2}\left(\begin{array}{c}5 \cos 3 t \\ -4 \cos 3 t-3 \sin 3 t \\ 0\end{array}\right) e^{-2 t}$

\end{enumerate}

$$
+c_{3}\left(\begin{array}{c}
5 \sin 3 t \\
-4 \sin 3 t+3 \cos 3 t \\
0
\end{array}\right) e^{-2 t}
$$

\begin{enumerate}
  \setcounter{enumi}{26}
  \item $\mathbf{X}=-\left(\begin{array}{r}25 \\ -7 \\ 6\end{array}\right) e^{t}-\left(\begin{array}{c}\cos 5 t-5 \sin 5 t \\ \cos 5 t \\ \cos 5 t\end{array}\right)$ $+6\left(\begin{array}{c}5 \cos 5 t+\sin 5 t \\ \sin 5 t \\ \sin 5 t\end{array}\right)$

  \item $\mathbf{X}=c_{1}\binom{1}{3}+c_{2}\left\{\binom{1}{3} t+\binom{\frac{1}{4}}{-\frac{1}{4}}\right\}$

  \item $\mathbf{X}=c_{1}\binom{1}{1} e^{2 t}+c_{2}\left\{\binom{1}{1} t e^{2 t}+\binom{-\frac{1}{3}}{0} e^{2 t}\right\}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}1 \\ 1 \\ 1\end{array}\right) e^{t}+c_{2}\left(\begin{array}{l}1 \\ 1 \\ 0\end{array}\right) e^{2 t}+c_{3}\left(\begin{array}{l}1 \\ 0 \\ 1\end{array}\right) e^{2 t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{r}-4 \\ -5 \\ 2\end{array}\right)+c_{2}\left(\begin{array}{r}2 \\ 0 \\ -1\end{array}\right) e^{5 t}$ $+c_{3}\left\{\left(\begin{array}{r}2 \\ 0 \\ -1\end{array}\right) t e^{5 t}+\left(\begin{array}{c}-\frac{1}{2} \\ -\frac{1}{2} \\ -1\end{array}\right) e^{5 t}\right\}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}0 \\ 1 \\ 1\end{array}\right) e^{t}+c_{2}\left\{\left(\begin{array}{l}0 \\ 1 \\ 1\end{array}\right) t e^{t}+\left(\begin{array}{l}0 \\ 1 \\ 0\end{array}\right) e^{t}\right\}$ $+c_{3}\left\{\left(\begin{array}{l}0 \\ 1 \\ 1\end{array}\right) \frac{t^{2}}{2} e^{t}+\left(\begin{array}{l}0 \\ 1 \\ 0\end{array}\right) t e^{t}+\left(\begin{array}{l}\frac{1}{2} \\ 0 \\ 0\end{array}\right) e^{t}\right\}$

  \item $\mathbf{X}=-7\binom{2}{1} e^{4 t}+13\binom{2 t+1}{t+1} e^{4 t}$

  \item $\mathbf{X}=\binom{\frac{6}{5} e^{5 t}-\frac{1}{5} e^{-5 t}}{\frac{2}{5} e^{5 t}+\frac{3}{5} e^{-5 t}}$

  \item $\mathbf{X}=c_{1} t^{2}\binom{3}{1}+c_{2} t^{4}\binom{1}{1}$

\end{enumerate}

EXERCISES 8.7 (PAGE 408)

\begin{enumerate}
  \item $\mathbf{X}=c_{1}\binom{-1}{1} e^{-t}+c_{2}\binom{-3}{1} e^{t}+\binom{-1}{3}$

  \item $\mathbf{X}=c_{1}\binom{1}{-1} e^{-2 t}+c_{2}\binom{1}{1} e^{4 t}+\binom{-\frac{1}{4}}{\frac{3}{4}} t^{2}$

\end{enumerate}

$+\binom{\frac{1}{4}}{-\frac{1}{4}} t+\binom{-2}{\frac{3}{4}}$

\begin{enumerate}
  \setcounter{enumi}{4}
  \item $\mathbf{X}=c_{1}\binom{1}{-3} e^{3 t}+c_{2}\binom{1}{9} e^{7 t}+\binom{\frac{55}{36}}{-\frac{19}{4}} e^{t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{l}1 \\ 0 \\ 0\end{array}\right) e^{t}+c_{2}\left(\begin{array}{l}1 \\ 1 \\ 0\end{array}\right) e^{2 t}+c_{3}\left(\begin{array}{l}1 \\ 2 \\ 2\end{array}\right) e^{5 t}-\left(\begin{array}{c}\frac{3}{2} \\ \frac{7}{2} \\ 2\end{array}\right) e^{4 t}$

  \item $\mathbf{X}=13\binom{1}{-1} e^{t}+2\binom{-4}{6} e^{2 t}+\binom{-9}{6}$

  \item $\mathbf{X}=c_{1}\binom{1}{1}+c_{2}\binom{1}{-1} e^{2 t}+\binom{-\frac{3}{2}}{-\frac{3}{2}} t+\binom{-\frac{5}{2}}{1}$

\end{enumerate}

\section*{EXERCISES 8.8 (PAGE 412 )}
\begin{enumerate}
  \item $\mathbf{X}=c_{1}\binom{1}{1}+c_{2}\binom{3}{2} e^{t}-\binom{11}{11} t-\binom{15}{10}$

  \item $\mathbf{X}=c_{1}\binom{2}{1} e^{t / 2}+c_{2}\binom{10}{3} e^{3 t / 2}-\binom{\frac{13}{2}}{\frac{13}{4}} t e^{t / 2}-\binom{\frac{15}{2}}{\frac{9}{4}} e^{t / 2}$

  \item $\mathbf{X}=c_{1}\binom{2}{1} e^{t}+c_{2}\binom{1}{1} e^{2 t}+\binom{3}{3} e^{t}+\binom{4}{2} t e^{t}$

  \item $\mathbf{X}=c_{1}\binom{4}{1} e^{3 t}+c_{2}\binom{-2}{1} e^{-3 t}+\binom{-12}{0} t-\binom{\frac{4}{3}}{\frac{4}{3}}$

  \item $\mathbf{X}=c_{1}\binom{1}{-1} e^{t}+c_{2}\binom{-t}{\frac{1}{2}-t} e^{t}+\binom{\frac{1}{2}}{-2} e^{-t}$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{\sin t}+c_{2}\binom{\sin t}{-\cos t}$ $+\binom{\cos t}{\sin t} t+\binom{-\sin t}{\cos t} \ln |\cos t|$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{\sin t} e^{t}+c_{2}\binom{\sin t}{-\cos t} e^{t}+\binom{\cos t}{\sin t} t e^{t}$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{-\sin t}+c_{2}\binom{\sin t}{\cos t}+\binom{\cos t}{-\sin t} t$ $+\binom{-\sin t}{\sin t \tan t}-\binom{\sin t}{\cos t} \ln |\cos t|$

  \item $\mathbf{X}=c_{1}\binom{2 \sin t}{\cos t} e^{t}+c_{2}\binom{2 \cos t}{-\sin t} e^{t}+\binom{3 \sin t}{\frac{3}{2} \cos t} t e^{t}$ $+\binom{\cos t}{-\frac{1}{2} \sin t} e^{t} \ln |\sin t|+\binom{2 \cos t}{-\sin t} e^{t} \ln |\cos t|$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{r}1 \\ -1 \\ 0\end{array}\right)+c_{2}\left(\begin{array}{l}1 \\ 1 \\ 0\end{array}\right) e^{2 t}+c_{3}\left(\begin{array}{l}0 \\ 0 \\ 1\end{array}\right) e^{3 t}$

\end{enumerate}

$+\left(\begin{array}{c}-\frac{1}{4} e^{2 t}+\frac{1}{2} t e^{2 t} \\ -e^{t}+\frac{1}{4} e^{2 t}+\frac{1}{2} t e^{2 t} \\ \frac{1}{2} t^{2} e^{3 t}\end{array}\right)$

\begin{enumerate}
  \setcounter{enumi}{20}
  \item $\mathbf{X}=\binom{2}{2} t e^{2 t}+\binom{-1}{1} e^{2 t}+\binom{-2}{2} t e^{4 t}+\binom{2}{0} e^{4 t}$

  \item $\mathbf{X}=\binom{-2}{4} e^{2 t}+\binom{7}{-9} e^{7 t}+\binom{20}{60} t e^{7 t}$

  \item (b) $\binom{i_{1}}{i_{2}}=2\binom{1}{3} e^{-2 t}+\frac{6}{29}\binom{3}{-1} e^{-12 t}$ $+\binom{\frac{332}{29}}{\frac{276}{29}} \sin t-\binom{\frac{76}{29}}{\frac{168}{29}} \cos t$

\end{enumerate}

\section*{EXERCISES 8.9 (PAGE 415)}
\begin{enumerate}
  \item $\left(\begin{array}{ll}\cosh t & \sinh t \\ \sinh t & \cosh t\end{array}\right),\binom{\cosh t-\sinh t}{\sinh t-\cosh t}$
  \item $\mathbf{X}=\left(\begin{array}{ll}\cosh t & \sinh t \\ \sinh t & \cosh t\end{array}\right)\binom{c_{1}}{c_{2}}=c_{1}\binom{\cosh t}{\sinh t}+c_{2}\binom{\sinh t}{\cosh t}$
  \item $\mathbf{X}=c_{1}\binom{\cosh t}{\sinh t}+c_{2}\binom{\sinh t}{\cosh t}-\binom{1}{1}$
  \item $\mathbf{X}=c_{1}\binom{1}{0} e^{t}+c_{2}\binom{0}{1} e^{2 t}+\binom{-t-1}{\frac{1}{2} e^{4 t}}$
  \item $\mathbf{P}=\left(\begin{array}{ll}1 & 1 \\ 1 & 3\end{array}\right), \mathbf{P}^{-1}=\left(\begin{array}{rr}\frac{3}{2} & -\frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2}\end{array}\right)$,
\end{enumerate}

$$
\mathbf{D}=\left(\begin{array}{ll}
3 & 0 \\
0 & 5
\end{array}\right), \mathbf{P D P}^{-1}=\left(\begin{array}{rr}
2 & 1 \\
-3 & 6
\end{array}\right)
$$

\begin{enumerate}
  \setcounter{enumi}{10}
  \item $e^{t \mathbf{A}}=e^{\mathbf{P D P}^{-1}}$
\end{enumerate}

$$
\begin{aligned}
& =\mathbf{I}+t \mathbf{P D} \mathbf{P}^{-1}+\frac{t^{2}}{2!}\left(\mathbf{P D} \mathbf{P}^{-1}\right)^{2}+\cdots \\
& =\mathbf{P} \mathbf{P}^{-1}+t \mathbf{P D} \mathbf{P}^{-1}+\frac{t^{2}}{2!} \mathbf{P D}^{2} \mathbf{P}^{-1}+\cdots \\
& =\mathbf{P}\left[\mathbf{I}+t \mathbf{D}+\frac{t^{2}}{2!} \mathbf{D}^{2}+\cdots\right] \mathbf{P}^{-1} \\
& =\mathbf{P} e^{t \mathbf{D}} \mathbf{P}^{-1}
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $\mathbf{X}=\left(\begin{array}{ll}\frac{3}{2} e^{3 t}-\frac{1}{2} e^{5 t} & -\frac{1}{2} e^{3 t}+\frac{1}{2} e^{5 t} \\ \frac{3}{2} e^{3 t}-\frac{3}{2} e^{5 t} & -\frac{1}{2} e^{3 t}+\frac{3}{2} e^{5 t}\end{array}\right)\binom{c_{1}}{c_{2}}$
\end{enumerate}

\section*{CHAPTER 8 REVIEW EXERCISES}
 (PAGE 418 )\begin{enumerate}
  \item true 3. $\left(\begin{array}{rr}-2 & 1 \\ \frac{3}{2} & -\frac{1}{2}\end{array}\right)$ 5. true 7. false 9. true

  \item false

  \item $x=-c_{1} e^{t}-\frac{3}{2} c_{2} e^{2 t}+\frac{5}{2}$

\end{enumerate}

$y=c_{1} e^{t}+c_{2} e^{2 t}-3$

\begin{enumerate}
  \setcounter{enumi}{14}
  \item $x=c_{1} e^{t}+c_{2} e^{5 t}+t e^{t}$
\end{enumerate}

$$
y=-c_{1} e^{t}+3 c_{2} e^{5 t}-t e^{t}+2 e^{t}
$$

\begin{enumerate}
  \setcounter{enumi}{16}
  \item $x=-\frac{1}{4}+\frac{9}{8} e^{-2 t}+\frac{1}{8} e^{2 t}$
\end{enumerate}

$y=t+\frac{9}{4} e^{-2 t}-\frac{1}{4} e^{2 t}$

\begin{enumerate}
  \setcounter{enumi}{18}
  \item (a) $\left(\begin{array}{c}t^{3}+3 t^{2}+5 t-2 \\ -t^{3}-t+2 \\ 4 t^{3}+12 t^{2}+8 t+1\end{array}\right)$ (b) $\left(\begin{array}{c}3 t^{2}+6 t+5 \\ -3 t^{2}-1 \\ 12 t^{2}+24 t+8\end{array}\right)$

  \item $D x=u$

\end{enumerate}

$D y=v$

$D u=-2 u+v-2 x-\ln t+10 t-4$

$D v=-u-x+5 t-2$

\begin{enumerate}
  \setcounter{enumi}{22}
  \item $\mathbf{X}=c_{1}\binom{1}{-1} e^{t}+c_{2}\left\{\binom{1}{-1} t e^{t}+\binom{0}{1} e^{t}\right\}$

  \item $\mathbf{X}=c_{1}\binom{\cos 2 t}{-\sin 2 t} e^{t}+c_{2}\binom{\sin 2 t}{\cos 2 t} e^{t}$

  \item $\mathbf{X}=c_{1}\left(\begin{array}{r}-1 \\ 1 \\ 0\end{array}\right)+c_{2}\left(\begin{array}{r}-1 \\ 0 \\ 1\end{array}\right)+c_{3}\left(\begin{array}{l}1 \\ 1 \\ 1\end{array}\right) e^{3 t}$

  \item $\mathbf{X}=c_{1}\binom{1}{0} e^{2 t}+c_{2}\binom{4}{1} e^{4 t}+\binom{16}{-4} t+\binom{11}{-1}$

  \item $\mathbf{X}=c_{1}\binom{\cos t}{\cos t-\sin t}+c_{2}\binom{\sin t}{\sin t+\cos t}-\binom{1}{1}$

\end{enumerate}

$$
+\binom{\sin t}{\sin t+\cos t} \ln |\csc t-\cot t|
$$

\section*{EXERCISES 9.1 (PAGE 424)}
1.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-524}
\end{center}

3.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-524(1)}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{4}
  \item a family of vertical lines $x=c-4$

  \item a family of hyperbolas $x^{2}-y^{2}=c$

  \item a family of circles $x^{2}+(y+1)^{2}=c^{2}$ with center at $(0,-1)$

  \item a family of hyperbolas $x y+y^{2}=c$

  \item a family of straight lines $y=c(x-2)+1$ passing through $(2,1)$

  \item 
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-524(2)}
\end{center}

17.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-524(4)}
\end{center}

19.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-524(3)}
\end{center}

21.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-525(1)}
\end{center}

$\begin{array}{ll}\text { 23. } y=\frac{\alpha-c \gamma}{c \delta-\beta} & \text { 25. } 3 x+2 y=-\frac{3}{2}\end{array}$\\
27. $y= \pm \sqrt{2} x$\\
29. $y=4 x ; y=-x$

EXERCISES 9.2 (PAGE 431)

\begin{enumerate}
  \item $y=1-x+\tan (x+\pi / 4)$

  \item (a)

\end{enumerate}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
1.00 & 5.0000 \\
1.10 & 3.8000 \\
1.20 & 2.9800 \\
1.30 & 2.4260 \\
1.40 & 2.0582 \\
1.50 & 1.8207 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{4}
  \item (a)
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-525}
\end{center}

(b)

(b)

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
1.00 & 5.0000 \\
1.05 & 4.4000 \\
1.10 & 3.8950 \\
1.15 & 3.4707 \\
1.20 & 3.1151 \\
1.25 & 2.8179 \\
1.30 & 2.5702 \\
1.35 & 2.3647 \\
1.40 & 2.1950 \\
1.45 & 2.0557 \\
1.50 & 1.9424 \\
\hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.05 & 0.0500 \\
0.10 & 0.1001 \\
0.15 & 0.1506 \\
0.20 & 0.2018 \\
0.25 & 0.2538 \\
0.30 & 0.3070 \\
0.35 & 0.3617 \\
0.40 & 0.4183 \\
0.45 & 0.4770 \\
0.50 & 0.5384 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{6}
  \item (a)
\end{enumerate}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.10 & 0.1000 \\
0.20 & 0.1905 \\
0.30 & 0.2731 \\
0.40 & 0.3492 \\
0.50 & 0.4198 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{8}
  \item (a)
\end{enumerate}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{n}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.5000 \\
0.10 & 0.5250 \\
0.20 & 0.5431 \\
0.30 & 0.5548 \\
0.40 & 0.5613 \\
0.50 & 0.5639 \\
\hline
\end{tabular}
\end{center}

(b)

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{n}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.05 & 0.0500 \\
0.10 & 0.0976 \\
0.15 & 0.1429 \\
0.20 & 0.1863 \\
0.25 & 0.2278 \\
0.30 & 0.2676 \\
0.35 & 0.3058 \\
0.40 & 0.3427 \\
0.45 & 0.3782 \\
0.50 & 0.4124 \\
\hline
\end{tabular}
\end{center}

(b) $\qquad$\\
$0.00 \quad 0.5000$

$0.05 \quad 0.5125$

$0.10 \quad 0.5232$

$0.15 \quad 0.5322$

$0.20 \quad 0.5395$

$0.25 \quad 0.5452$

$0.30 \quad 0.5496$

$0.35 \quad 0.5527$

$0.40 \quad 0.5547$

$0.45 \quad 0.5559$

$0.50 \quad 0.5565$

(b)

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
1.00 & 1.0000 \\
1.05 & 1.0000 \\
1.10 & 1.0049 \\
1.15 & 1.0147 \\
1.20 & 1.0298 \\
1.25 & 1.0506 \\
1.30 & 1.0775 \\
1.35 & 1.1115 \\
1.40 & 1.1538 \\
1.45 & 1.2057 \\
1.50 & 1.2696 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{12}
  \item (a) $h=0.1$
\end{enumerate}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$x_{n}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ & $x_{n}$ & $y_{n}$ \\
\hline
1.00 & 5.0000 & 1.00 & 5.0000 \\
\hline
1.10 & 3.9900 & 1.05 & 4.4475 \\
\hline
1.20 & 3.2545 & 1.10 & 3.9763 \\
\hline
1.30 & 2.7236 & 1.15 & 3.5751 \\
\hline
1.40 & 2.3451 & 1.20 & 3.2342 \\
\hline
\multirow[t]{5}{*}{1.50} & 2.0801 & 1.25 & 2.9452 \\
\hline
 &  & \begin{tabular}{l}
1.30 \\
135 \\
\end{tabular} & \begin{tabular}{l}
2.7009 \\
2.4952 \\
\end{tabular} \\
\hline
 &  & 1.40 & 2.3226 \\
\hline
 &  & 1.45 & 2.1786 \\
\hline
 &  & 1.50 & 2.0592 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{12}
  \item (b) $h=0.1$
\end{enumerate}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.10 & 0.1005 \\
0.20 & 0.2030 \\
0.30 & 0.3098 \\
0.40 & 0.4234 \\
0.50 & 0.5470 \\
\hline
\end{tabular}
\end{center}

$h=0.05$

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
 &  \\
0.00 & 0.0000 \\
0.05 & 0.0501 \\
0.10 & 0.1004 \\
0.15 & 0.1512 \\
0.20 & 0.2028 \\
0.25 & 0.2554 \\
0.30 & 0.3095 \\
0.35 & 0.3652 \\
0.40 & 0.4230 \\
0.45 & 0.4832 \\
0.50 & 0.5465 \\
\hline
\end{tabular}
\end{center}

(c) $h=0.1$

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{n}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.10 & 0.0952 \\
0.20 & 0.1822 \\
0.30 & 0.2622 \\
0.40 & 0.3363 \\
0.50 & 0.4053 \\
\hline
\end{tabular}
\end{center}

(d) $h=0.1$

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$x_{n}$ & $y_{n}$ & $x_{n}$ & $y_{n}$ \\
\hline
0.00 & 0.5000 & 0.00 & 0.5000 \\
\hline
0.10 & 0.5215 & 0.05 & 0.5116 \\
\hline
0.20 & 0.5362 & 0.10 & 0.5214 \\
\hline
0.30 & 0.5449 & 0.15 & 0.5294 \\
\hline
0.40 & 0.5490 & 0.20 & 0.5359 \\
\hline
\multirow{5}{*}{0.50} & 0.5503 & 0.25 & 0.5408 \\
\hline
 &  & \begin{tabular}{l}
0.30 \\
0.35 \\
\end{tabular} & \begin{tabular}{l}
0.5444 \\
0.5469 \\
\end{tabular} \\
\hline
 &  & 0.40 & 0.5484 \\
\hline
 &  & 0.45 & 0.5492 \\
\hline
 &  & 0.50 & 0.5495 \\
\hline
\end{tabular}
\end{center}

(e) $h=0.1$

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$x_{n}$ & $y_{n}$ & $\boldsymbol{x}_{n}$ & $y_{n}$ \\
\hline
1.00 & 1.0000 & 1.00 & 1.0000 \\
\hline
1.10 & 1.0095 & 1.05 & 1.0024 \\
\hline
1.20 & 1.0404 & 1.10 & 1.0100 \\
\hline
1.30 & 1.0967 & 1.15 & 1.0228 \\
\hline
1.40 & 1.1866 & 1.20 & 1.0414 \\
\hline
\multirow[t]{6}{*}{1.50} & 1.3260 & 1.25 & 1.0663 \\
\hline
 &  & 1.30 & 1.0984 \\
\hline
 &  & 1.35 & 1.1389 \\
\hline
 &  & 1.40 & 1.1895 \\
\hline
 &  & 1.45 & 1.2526 \\
\hline
 &  & 1.50 & 1.3315 \\
\hline
\end{tabular}
\end{center}

15.

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{$h=0.05$} & \multirow[t]{2}{*}{$x_{n}$} & \multirow[t]{2}{*}{Euler} & \begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} \\
\hline
$x_{n}$ & $\boldsymbol{y}_{n}$ &  &  &  \\
\hline
 &  & 1.0 & 1.0000 & 1.0000 \\
\hline
0.00 & 0.0000 & 1.1 & 1.2000 & 1.2469 \\
\hline
0.05 & 0.0488 & 1.2 & 1.4938 & 1.6668 \\
\hline
0.10 & 0.0953 & 1.3 & 1.9711 & 2.6427 \\
\hline
0.15 & 0.1397 & 1.4 & 2.9060 & 8.7989 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{16}
  \item Using $y^{\prime}=f(x, y)$ gives
\end{enumerate}

$$
\begin{aligned}
\int_{x_{n}}^{x_{n+1}} y^{\prime} d x & =\int_{x_{n}}^{x_{n+1}} f(x, y) d x \\
y\left(x_{n+1}\right)-y\left(x_{n}\right) & \approx f\left(x_{n}, y_{n}\right)\left(x_{n+1}-x_{n}\right) \\
& =h f\left(x_{n}, y_{n}\right) \\
y\left(x_{n+1}\right) & \approx y\left(x_{n}\right)+h f\left(x_{n, y_{n}}\right)
\end{aligned}
$$

We write this as

$$
y_{n+1}=y_{n}+h f\left(x_{n}, y_{n}\right)
$$

EXERCISES 9.3 (PAGE 434)

\begin{enumerate}
  \item (a)
\end{enumerate}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
 &  \\
1.00 & 5.0000 \\
1.10 & 3.9900 \\
1.20 & 3.2545 \\
1.30 & 2.7236 \\
1.40 & 2.3451 \\
1.50 & 2.0801 \\
\hline
\end{tabular}
\end{center}

(b)

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
1.00 & 5.0000 \\
1.05 & 4.4475 \\
1.10 & 3.9763 \\
1.15 & 3.5751 \\
1.20 & 3.2342 \\
1.25 & 2.9452 \\
1.30 & 2.7009 \\
1.35 & 2.4952 \\
1.40 & 2.3226 \\
1.45 & 2.1786 \\
1.50 & 2.0592 \\
\hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
3. (a) & $x_{n}$ & $y_{n}$ & (b) & $x_{n}$ & $y_{n}$ & 11. & $x_{n}$ & Euler & \multicolumn{2}{|c|}{}\begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} & \begin{tabular}{l}
Three-Term \\
Taylor \\
\end{tabular} \\
\hline
 & 0.00 & 0.0000 &  & 0.00 & 0.0000 &  &  &  & \multicolumn{2}{|c|}{\multirow{2}{*}}{1.0000} & \multirow[b]{2}{*}{1.0000} \\
\hline
 & 0.10 & 0.1000 &  & 0.05 & 0.0500 &  & 1.0 & 1.0000 &  &  &  \\
\hline
 & 0.20 & 0.2020 &  & 0.10 & 0.1003 &  & 1.1 & 1.2000 & \multicolumn{2}{|c|}{1.2469} & 1.2400 \\
\hline
 & 0.30 & 0.3082 &  & 0.15 & 0.1510 &  & 1.2 & 1.4938 & \multicolumn{2}{|c|}{1.6668} & 1.6345 \\
\hline
 & 0.40 & 0.4211 &  & 0.20 & 0.2025 &  & 1.3 & 1.9711 & \multicolumn{2}{|c|}{2.6427} & 2.4600 \\
\hline
 & 0.50 & 0.5438 &  & 0.25 & 0.2551 &  & 1.4 & 2.9060 & \multicolumn{2}{|c|}{8.7988} & 5.6353 \\
\hline
 &  &  &  & 0.30 & 0.3090 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.35 & 0.3647 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.40 & 0.4223 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.45 & 0.4825 & 15. &  & Improved &  & ree-Term & True \\
\hline
 &  &  &  & 0.50 & 0.5456 &  & $x_{n}$ & Euler &  & ylor & Value \\
\hline
5. (a) &  &  & (b) & $x_{-}$ & $\boldsymbol{v}_{\mathrm{n}}$ &  & 1.00 & 5.0000 &  & 000 & 5.0000 \\
\hline
 & $x_{n}$ & $y_{n}$ &  & $x_{n}$ & $y_{n}$ &  & 1.10 & 5.5300 &  & 5300 & 5.5310 \\
\hline
 & 0.00 & 0.0000 &  & 0.00 & 0.0000 &  & 1.20 & 6.1262 &  & 1262 & 6.128 \\
\hline
 & 0.10 & 0.0950 &  & 0.05 & 0.0488 &  & 1.30 & 6.7954 &  & 7954 & 6.799 ? \\
\hline
 & 0.20 & 0.1818 &  & 0.10 & 0.0952 &  & 1.40 & 7.5454 &  & 5454 & 7.5511 \\
\hline
 & 0.30 & 0.2617 &  & 0.15 & 0.1397 &  & 1.50 & 8.3847 &  & 3847 & 8.392 \\
\hline
 & 0.40 & 0.3357 &  & 0.20 & 0.1822 &  &  &  &  &  &  \\
\hline
 & 0.50 & 0.4046 &  & 0.25 & 0.2230 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.30 & 0.2622 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.35 & 0.2999 & $E X$ & ERC & ES 9.4 & PAGE & 438) &  \\
\hline
 &  &  &  & 0.40 & 0.3363 &  &  &  &  &  &  \\
\hline
 &  &  &  & \begin{tabular}{l}
0.45 \\
0.50 \\
\end{tabular} & \begin{tabular}{l}
0.3714 \\
0.4053 \\
\end{tabular} & 1. & $\boldsymbol{x}_{n}$ & $y_{n}$ & 3. & $x_{n}$ & $\boldsymbol{y}_{n}$ \\
\hline
 &  &  &  &  &  &  &  &  &  &  &  \\
\hline
7. (a) &  &  & (b) &  &  &  & 1.00 & 5.0000 &  & 0.00 & 0.0000 \\
\hline
 & $x_{n}$ & $\boldsymbol{y}_{n}$ &  & $x_{n}$ & $y_{n}$ &  & 1.10 & 3.9724 &  & 0.10 & 0.1003 \\
\hline
 &  &  &  &  &  &  & 1.20 & 3.2284 &  & 0.20 & 0.2027 \\
\hline
 & 0.00 & 0.5000 &  & 0.00 & 0.5000 &  & 1.30 & 2.6945 &  & 0.30 & 0.3093 \\
\hline
 & 0.10 & 0.5213 &  & 0.05 & 0.5116 &  & 1.40 & 2.3163 &  & 0.40 & 0.4228 \\
\hline
 & 0.20 & 0.5355 &  & 0.10 & 0.5213 &  & 1.50 & 2.0533 &  & 0.50 & 0.5463 \\
\hline
 & 0.30 & 0.5438 &  & 0.15 & 0.5293 &  &  &  &  &  &  \\
\hline
 & 0.40 & 0.5475 &  & 0.20 & 0.5357 &  &  &  &  &  &  \\
\hline
 & 0.50 & 0.5482 &  & 0.25 & 0.5406 & 5. &  &  & 7. &  &  \\
\hline
 &  &  &  & \begin{tabular}{l}
0.30 \\
0.35 \\
\end{tabular} & \begin{tabular}{l}
0.5441 \\
0.5466 \\
\end{tabular} & 5. & $x_{n}$ & $\boldsymbol{y}_{n}$ & 1. & $x_{n}$ & $y_{n}$ \\
\hline
 &  &  &  & 0.40 & 0.5480 &  &  &  &  &  &  \\
\hline
 &  &  &  & 0.45 & 0.5487 &  & \begin{tabular}{l}
0.00 \\
0.10 \\
\end{tabular} & \begin{tabular}{l}
0.0000 \\
0.0953 \\
\end{tabular} &  & \begin{tabular}{l}
0.00 \\
0.10 \\
\end{tabular} & \begin{tabular}{l}
0.5000 \\
0.5213 \\
\end{tabular} \\
\hline
 &  &  &  & 0.50 & 0.5490 &  & 0.20 & 0.1823 &  & 0.20 & 0.5358 \\
\hline
 &  &  &  &  &  &  & 0.30 & 0.2624 &  & 0.30 & 0.5443 \\
\hline
9. (a) & $x_{n}$ & $\boldsymbol{y}_{n}$ & (b) & $\boldsymbol{x}_{n}$ & $\boldsymbol{y}_{n}$ &  & 0.40 & 0.3365 &  & 0.40 & 0.5482 \\
\hline
 &  &  &  & $n_{n}$ & $y_{n}$ &  & 0.50 & 0.4055 &  & 0.50 & 0.5493 \\
\hline
 & 1.00 & 1.0000 &  & 1.00 & 1.0000 &  &  &  &  &  &  \\
\hline
 & 1.10 & 1.0100 &  & 1.05 & 1.0025 &  &  &  &  &  &  \\
\hline
 & 1.20 & 1.0410 &  & 1.10 & 1.0101 & 9. &  &  &  & $(5) \approx 35$ & 7678 \\
\hline
 & 1.30 & 1.0969 &  & 1.15 & 1.0229 & 3. & $\boldsymbol{x}_{n}$ & $y_{n}$ &  &  &  \\
\hline
 & 1.40 & 1.1857 &  & 1.20 & 1.0415 &  &  &  &  &  &  \\
\hline
 & 1.50 & 1.3226 &  & 1.25 & 1.0663 &  & 1.00 & 1.0000 &  &  &  \\
\hline
 &  &  &  & 1.30 & 1.0983 &  & 1.10 & 1.0101 &  &  &  \\
\hline
 &  &  &  & 1.35 & 1.1387 &  & 1.20 & 1.0417 &  &  &  \\
\hline
 &  &  &  & 1.40 & 1.1891 &  & 1.30 & 1.0989 &  &  &  \\
\hline
 &  &  &  & 1.45 & 1.2518 &  & 1.40 & 1.1905 &  &  &  \\
\hline
 &  &  &  & 1.50 & 1.3301 &  & 1.50 & 1.3333 &  &  &  \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{12}
  \item \begin{center}
\begin{tabular}{lr}
1.93 & 12.50 \\
\hline
\multicolumn{1}{r}{$\boldsymbol{x}_{n}$} & \multicolumn{1}{c}{$\boldsymbol{y}_{\boldsymbol{n}}$} \\
\hline
1.00 & 1.0000 \\
1.10 & 1.2511 \\
1.20 & 1.6934 \\
1.30 & 2.9425 \\
1.40 & 903.0283 \\
\hline
\end{tabular}
\end{center}

\end{enumerate}

\section*{EXERCISES 9.5 (PAGE 442)}
\begin{enumerate}
  \item $y(x)=-x+e^{x} ; y(0.2)=1.0214, y(0.4)=1.0918$, $y(0.6)=1.2221, y(0.8)=1.4255$
\end{enumerate}

\section*{3.}
\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-528(1)}
\end{center}

7.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-528(2)}
\end{center}

\begin{center}
\begin{tabular}{ll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
0.00 & 0.0000 \\
0.10 & 0.1003 \\
0.20 & 0.2027 \\
0.30 & 0.3093 \\
0.40 & 0.4228 \\
0.50 & 0.5463 \\
0.60 & 0.6842 \\
0.70 & 0.8423 \\
0.80 & 1.0297 \\
0.90 & 1.2603 \\
1.00 & 1.5576 \\
\hline
 &  \\
\hline
$\boldsymbol{x}_{n}$ & $\boldsymbol{y}_{\boldsymbol{n}}$ \\
\hline
 &  \\
0.00 & 0.0000 \\
0.10 & 0.0003 \\
0.20 & 0.0026 \\
0.30 & 0.0087 \\
0.40 & 0.0200 \\
0.50 & 0.0379 \\
0.60 & 0.0629 \\
0.70 & 0.0956 \\
0.80 & 0.1360 \\
0.90 & 0.1837 \\
1.00 & 0.2384 \\
\hline
 &  \\
\hline
\end{tabular}
\end{center}

9 .

\begin{center}
\begin{tabular}{ll}
\hline
$x_{n}$ & $y_{n}$ \\
\hline
0.00 & 1.0000 \\
0.10 & 1.0052 \\
0.20 & 1.0214 \\
0.30 & 1.0499 \\
0.40 & 1.0918 \\
\hline
\end{tabular}
\end{center}

\section*{EXERCISES 9.6 (PAGE 446)}
\begin{enumerate}
  \item The improved Euler method is a second-order Runge-Kutta method, so letting $k=3, a=x_{n}, x=x_{n+1}=x_{n}+h$, we get
\end{enumerate}

$$
y\left(x_{n+1}\right)=y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) h+y^{\prime \prime}\left(x_{n}\right) \frac{h^{2}}{2}+y^{(3)}(c) \frac{h^{3}}{3!}
$$

The derivation of the Runge-Kutta method requires that the formula agree with the Taylor series through the $h^{2}$ term, so the local truncation error is $y^{(3)}(c)\left(h^{3} / 3\right.$ !).

\begin{enumerate}
  \setcounter{enumi}{2}
  \item For the fourth-order Runge-Kutta method, we let $k=4, a=x_{n}, x=x_{n+1}=x_{n}+h$ and get
\end{enumerate}

$$
y\left(x_{n+1}\right)=y\left(x_{n}\right)+y^{\prime}\left(x_{n}\right) h+\cdots+y^{(4)}\left(x_{n}\right) \frac{h^{4}}{4!}+y^{(5)}(c) \frac{h^{5}}{5!}
$$

The derivation of this Runge-Kutta method requires that the formula agree with the Taylor series through the $h^{4}$ term, so the local truncation error is $y^{(5)}(c)\left(h^{5} / 5\right.$ !).

\begin{enumerate}
  \setcounter{enumi}{4}
  \item (a) $y_{1}=1.2200$
\end{enumerate}

(b) $y^{(3)}(c) \frac{h^{3}}{3!}=8 e^{2 c} \frac{h^{3}}{3!} \leq 8 e^{2(0.1)} \frac{(0.1)^{3}}{3!}=0.001629$

(c) Actual value is $y(0.1)=e^{2(0.1)}=1.221403$.

Error is $1.221403-1.22=0.001403 \leq 0.001629$

(d) If $h=0.05, y_{2}=1.221025$.

(e) Error with $h=0.1$ is 0.001403 .

Error with $h=0.05$ is

$1.221403-1.221025=0.000378$.

\begin{enumerate}
  \setcounter{enumi}{6}
  \item (a) $y_{1}=1.221400$
\end{enumerate}

(b) $y^{(5)}(c) \frac{h^{5}}{5!}=32 e^{2 c} \frac{h^{5}}{5!} \leq 32 e^{2(0.1)} \frac{(0.1)^{5}}{5!}$

$$
=3.257 \times 10^{-6}
$$

(c) Actual value is $y(0.1)=e^{2(0.1)}=1.221402758$.

Error is $1.221402758-1.2214=2.758 \times 10^{-6}$

$$
\leq 3.257 \times 10^{-6}
$$

(d) If $h=0.05, y_{2}=1.22140257$.

(e) Error with $h=0.1$ is $2.758 \times 10^{-6}$.

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-528}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{8}
  \item (a) $y_{1}=0.8250$
\end{enumerate}

(b) $\begin{aligned} y^{(3)}(c) \frac{h^{3}}{3!} & =10 e^{-2 c} \frac{h^{3}}{3!} \leq 10 e^{-2(0)} \frac{(0.1)^{3}}{3!} \\ & =0.001667\end{aligned}$

(c) Actual value is $y(0.1)=0.8234$.

Error is $0.8250-0.8234=0.001600 \leq 0.001667$.\\
(d) If $h=0.05, y_{2}=0.8238$.

(e) Error with $h=0.1$ is 0.001600 .

Error with $h=0.05$ is

$0.008238-0.008234=0.0004$.

\begin{enumerate}
  \setcounter{enumi}{10}
  \item (a) $y_{1}=0.82341667$
\end{enumerate}

(b) $y^{(5)}(c) \frac{h^{5}}{5!}=40 e^{-2 c} \frac{h^{5}}{5!} \leq 40 e^{2(0)} \frac{(0.1)^{5}}{5!}$

$$
=3.333 \times 10^{-6}
$$

(c) Actual value is $y(0.1)=0.8234134413$.

Error is $3.225 \times 10^{-6} \leq 3.333 \times 10^{-6}$.

(d) If $h=0.05, y_{2}=0.82341363$.

(e) Error with $h=0.1$ is $3.225 \times 10^{-6}$.

Error with $h=0.05$ is $1.854 \times 10^{-7}$.

\begin{enumerate}
  \setcounter{enumi}{12}
  \item (a) $\left|y^{(3)}(c) \frac{h^{3}}{3!}\right|=114 e^{-3(c-1)} \frac{h^{3}}{3!}$
\end{enumerate}

(b) $114 e^{-3(c-1)} \frac{h^{3}}{3!} \leq 114 e^{-3(1-1)} \frac{(0.1)^{3}}{3!}=0.019$

(c) From Problem 3 in Exercises 9.2 with $h=0.1$, $y_{5}=2.0801$. From Problem 3 in Exercises 9.2 with $h=0.05, y_{10}=2.0592$.

(d) The error with $h=0.1$ is 0.0269 .

The error with $h=0.05$ is 0.0060 .

\begin{enumerate}
  \setcounter{enumi}{14}
  \item (a) $\left|y^{(5)}(c) \frac{h^{5}}{5!}\right|=1026 e^{-3(c-1)} \frac{h^{5}}{5!}$
\end{enumerate}

(b) $1026 e^{-3(c-1)} \frac{h^{5}}{5!} \leq 1026 e^{-3(1-1)} \frac{(0.1)^{5}}{5!}$

$$
=8.55 \times 10^{-5}
$$

(c) From calculation with $h=0.1, y_{5}=2.05333883$.

From calculation with $h=0.05, y_{10}=2.05322299$.

(d) The error with $h=0.1$ is 0.00012259 .

The error with $h=0.05$ is 0.00006757 .

\begin{enumerate}
  \setcounter{enumi}{16}
  \item (a) $y^{(3)}(c) \frac{h^{3}}{3!}=\frac{2}{(c+1)^{3}} \frac{h^{3}}{3!}$
\end{enumerate}

(b) $\frac{2}{(c+1)^{3}} \frac{h^{3}}{3!} \leq 2 \frac{(0.1)^{3}}{3!}=0.0003333$

(c) From Problem 13(c) in Exercises 9.2 with $h=0.1$, $y_{5}=0.40528104$. From Problem 13(c) in Exercises 9.2 with $h=0.05, y_{10}=0.40541888$.

(d) The error with $h=0.1$ is 0.0001840683428 .

The error with $h=0.05$ is 0.00004622850912 .

\begin{enumerate}
  \setcounter{enumi}{18}
  \item (a) $y^{(5)}(c) \frac{h^{5}}{5!}=\frac{24}{(c+1)^{5}} \frac{h^{5}}{5!}$
\end{enumerate}

(b) $\frac{24}{(c+1)^{5}} \frac{h^{3}}{5!} \leq 24 \frac{(0.1)^{3}}{5!}=2.0000 \times 10^{-6}$

(c) From calculation with $h=0.1, y_{5}=0.40546517$.

From calculation with $h=0.05, y_{10}=0.40546511$. (d) The error with $h=0.1$ is $5.978114648 \times 10^{-8}$. The error with $h=0.05$ is $3.388367642 \times 10^{-9}$.

\section*{EXERCISES 9.7 (PAGE 451)}
\begin{enumerate}
  \item $y(x)=-2 e^{2 x}+5 x e^{2 x} ; y(0.2)=-1.4918$, $y_{2}=-1.6800$
  \item $y_{1}=-1.4928, y_{2}=-1.4919$
  \item $y_{1}=1.4640, y_{2}=1.4640$
  \item $x_{1}=8.3055, y_{1}=3.4199$;
\end{enumerate}

$x_{2}=8.3055, y_{2}=3.4199$\\
9. $x_{1}=-3.9123, y_{1}=4.2857$;

$x_{2}=-3.9123, y_{2}=4.2857$

\section*{EXERCISES 9.8 (PAGE 455)}
$$
\begin{aligned}
& \text { 1. } y_{1}=-5.677 \\
& y_{2}=-2.5807 \\
& y_{3}=6.3226
\end{aligned}
$$

$$
\text { 3. } \begin{aligned}
y_{1} & =-0.2259 \\
y_{2} & =-0.3356 \\
y_{3} & =-0.3308 \\
y_{4} & =-0.2167
\end{aligned}
$$

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $y_{1}=3.8842$
\end{enumerate}

$y_{2}=2.9640$

$y_{3}=2.2064$

$y_{4}=1.5826$

$y_{5}=1.0681$

$y_{6}=0.6430$

$y_{7}=0.2913$\\
9. $y_{1}=0.2660$

$y_{2}=0.5097$

$y_{3}=0.7357$

$y_{4}=0.9471$

$y_{5}=1.1465$

$y_{6}=1.3353$\\
11. $y_{1}=0.3492$

$y_{7}=1.5149$

$y_{2}=0.7202$

$y_{3}=1.1363$

$y_{4}=1.6233$

$y_{5}=2.2118$

$y_{6}=2.9386$

$y_{7}=3.8490$

$y_{8}=1.6855$

$y_{9}=1.8474$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item (c) $y_{0}=-2.2755$
\end{enumerate}

$y_{1}=-2.0755$

$y_{2}=-1.8589$

$y_{3}=-1.6126$

$y_{4}=-1.3275$

\section*{CHAPTER 9 REVIEW EXERCISES (PAGE 457)}
\begin{enumerate}
  \item All isoclines $y=c x$ are solutions of the differential equation.
\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-530}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{2}
  \item Comparison of Numerical Methods with $h=0.1$
\end{enumerate}

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & Euler & \begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} & \begin{tabular}{l}
Three-Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 2.0000 & 2.0000 & 2.0000 & 2.0000 \\
1.10 & 2.1386 & 2.1549 & 2.1556 & 2.1556 \\
1.20 & 2.3097 & 2.3439 & 2.3453 & 2.3454 \\
1.30 & 2.5136 & 2.5672 & 2.5694 & 2.5695 \\
1.40 & 2.7504 & 2.8246 & 2.8277 & 2.8278 \\
1.50 & 3.0201 & 3.1157 & 3.1198 & 3.1197 \\
\hline
\end{tabular}
\end{center}

Comparison of Numerical Methods with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & Euler & \begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} & \begin{tabular}{l}
Three-Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} \\
\hline
 &  &  &  &  \\
1.00 & 2.0000 & 2.0000 & 2.0000 & 2.0000 \\
1.05 & 2.0693 & 2.0735 & 2.0735 & 2.0736 \\
1.10 & 2.1469 & 2.1554 & 2.1556 & 2.1556 \\
1.15 & 2.2329 & 2.2459 & 2.2462 & 2.2462 \\
1.20 & 2.3272 & 2.3450 & 2.3454 & 2.3454 \\
1.25 & 2.4299 & 2.4527 & 2.4532 & 2.4532 \\
1.30 & 2.5410 & 2.5689 & 2.5695 & 2.5695 \\
1.35 & 2.6604 & 2.6937 & 2.6944 & 2.6944 \\
1.40 & 2.7883 & 2.8269 & 2.8278 & 2.8278 \\
1.45 & 2.9245 & 2.9686 & 2.9696 & 2.9696 \\
1.50 & 3.0690 & 3.1187 & 3.1198 & 3.1197 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{4}
  \item Comparison of Numerical Methods with $h=0.1$
\end{enumerate}

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & Euler & \begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} & \begin{tabular}{l}
Three-Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} \\
\hline
 &  &  &  &  \\
0.50 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
0.60 & 0.6000 & 0.6048 & 0.6050 & 0.6049 \\
0.70 & 0.7095 & 0.7191 & 0.7195 & 0.7194 \\
0.80 & 0.8283 & 0.8427 & 0.8433 & 0.8431 \\
0.90 & 0.9559 & 0.9752 & 0.9759 & 0.9757 \\
1.00 & 1.0921 & 1.1163 & 1.1172 & 1.1169 \\
\hline
\end{tabular}
\end{center}

Comparison of Numerical Methods with $h=0.05$

\begin{center}
\begin{tabular}{lllll}
\hline
$\boldsymbol{x}_{\boldsymbol{n}}$ & Euler & \begin{tabular}{l}
Improved \\
Euler \\
\end{tabular} & \begin{tabular}{l}
Three-Term \\
Taylor \\
\end{tabular} & \begin{tabular}{l}
Runge- \\
Kutta \\
\end{tabular} \\
\hline
0.50 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
0.55 & 0.5500 & 0.5512 & 0.5512 & 0.5512 \\
0.60 & 0.6024 & 0.6049 & 0.6049 & 0.6049 \\
0.65 & 0.6573 & 0.6609 & 0.6610 & 0.6610 \\
0.70 & 0.7144 & 0.7193 & 0.7194 & 0.7194 \\
0.75 & 0.7739 & 0.7800 & 0.7802 & 0.7801 \\
0.80 & 0.8356 & 0.8430 & 0.8431 & 0.8431 \\
0.85 & 0.8996 & 0.9082 & 0.9083 & 0.9083 \\
0.90 & 0.9657 & 0.9755 & 0.9757 & 0.9757 \\
0.95 & 1.0340 & 1.0451 & 1.0453 & 1.0452 \\
1.00 & 1.1044 & 1.1168 & 1.1170 & 1.1169 \\
\hline
\end{tabular}
\end{center}

\begin{enumerate}
  \setcounter{enumi}{6}
  \item $h=0.2: y(0.2) \approx 3.2$
\end{enumerate}

$h=0.1: y(0.2) \approx 3.23$\\
9. $x(0.2) \approx 1.62, y(0.2) \approx 1.84$

\section*{EXERCISES FOR APPENDIX I (PAGE APP-2)}
\begin{enumerate}
  \item (a) 24\\
(b) 720\\
(c) $4 \sqrt{\pi} / 3$\\
(d) $-8 \sqrt{\pi} / 15$
  \item 0.297
  \item $\Gamma(x)>\int_{0}^{1} t^{x-1} e^{-t} d t>e^{-1} \int_{0}^{1} t^{x-1} d t=\frac{1}{x e}$
\end{enumerate}

for $x>0$. As $x \rightarrow 0^{+}, 1 / x \rightarrow+\infty$.

\section*{EXERCISES FOR APPENDIX III (PAGE APP-1O)}
\begin{enumerate}
  \item -58

  \item 248

  \item $12 \quad$ 7. $16 e^{3 t}$

  \item $x=4, y=-7$

  \item $x=4, y=\frac{3}{2}, z=1$

  \item Let $z=t$, $t$ any real number. The solution is $x=-t / 3$, $y=5 t / 3, z=t$; the system represents the line of intersection of two planes.

\end{enumerate}

EXERCISES FOR APPENDIX IV (PAGE APP-13)

$\begin{array}{lll}\text { 1. } 7-4 i & \text { 3. }-11-11 i & \text { 5. } 3-4 i \\ \text { 7. } \frac{7}{34}-\frac{11}{34} i & \text { 9. } \frac{5}{34}-\frac{3}{34} i & \text { 11. } z=e^{i \pi / 2}\end{array}$

\begin{enumerate}
  \setcounter{enumi}{12}
  \item $z=e^{i \pi}$

  \item $z=2 \sqrt{2} e^{i \pi / 4}$

  \item $z=12 e^{i \pi / 3}$

  \item $z=2 e^{i \pi / 6}$

  \item $z=-8$

\end{enumerate}

Abel, Niels Henrik, 132

Abel's formula, 132

Absolute convergence of a power series, 264

Absolute error, 85

Acceleration due to gravity, 24

Action potential, 459

Adams-Bashforth/Adams-Moulton method, 439-440

Almost periodic functions, 268

Amplitude of vibrations, 187

Annihilator operator, 158

Applications of differential equations

atomic physics, 83

chemistry, $96-98$

continuous compounding of interest, 21-22

cooling, I6-17, 84-85

deflection of beams, 19-20, 322-323

discharge through an orifice, 18-19

dissemination of a drug, $91-92$

escape velocity, 98

freely falling body, 12

memory, 25, 92-93

mixtures, 8

networks, 346-347

pendulum motion, 14,212

population growth, $20,81,93$

radioactive decay, 81,83

rotating string, $15-16$

series circuits, $16,85-86$

spread of a disease, 21

spring-mass systems, 12-13

suspended wire, 17-18

twisted shaft, 212

Axis of symmetry, 19

Axon, 459

Backward difference, 452

Beams, static deflection of, 19-20, 322-323

Beats, 208

Bernoulli, Jakob, 62

Bernoulli's differential equation, 62

Bessel, Friedrich Wilhelm, 265

Bessel functions

differential recurrence relations for, 270

of first kind, 267

graphs of, 268

modified, 276

numerical values of, 269

properties of, 269

of second kind, 268

spherical, $270-271$\\
Bessel's differential equation, 265

parametric, 269

solution of, 266

Boundary conditions, 114

Boundary-value problem, 114

Branch point, 346

Buckling of a thin column under its own weight, 247-248

BVP, 114

Calculation of order alpha, 443

Canonical form of a system of linear differential equations, 351

Carbon dating, 84

Catenary, 18

Cauchy, Augustin-Louis, 222

Cauchy-Euler differential equation, 222

method of solution for, 223

reduction to constant coefficients, 228

Central difference, $452-453$

Chaos, 179

Characteristic equation of a matrix, 369

Characteristic values, 368

Characteristic vectors, 368

Chemical reactions, $96-98$

Circuits, differential equations of, $16,85,86,209$

Circular frequency, 186

Clairaut, Alexis Claude, 62

Clairaut's differential equation, 64

Cofactor, 361, APP-7

Complementary function, 127

Complete solution, 8

Complex numbers, APP-11

argument of, APP-12

conjugate of, APP-11

difference of, APP-11

imaginary part of, APP-11

modulus of, 244, APP-12

polar form of, APP-12

product of, APP-11

quotient of, APP-12

real part of, APP-11

sum of, APP-11

vector interpretation of, APP-12

Constant doubling time, 106

Continuing method, 440

Continuous compounding of interest, 21

Convolution integral, 308

Convolution theorem, 309

inverse form of, 310

Cooling, Newton's law of, 16, 84-85

Coupled springs, 344

Cover-up method, 294-295

Cramer, Gabriel, APP-9

Cramer's rule, 170, APP-8

Critically damped circuit, 209

Critically damped spring-mass system, 193

Curvature, 20

Damped amplitude, 196

Damped motion, 192

Damping constant, 192

Damping factor, 193

Daphnia, 93

Decay, radioactive, 81,83

Deflection curve, 19

Degenerate system of differential equations, 352-353

DeMoivre, Abraham, APP-14

DeMoivre's theorem, APP-14

Derivatives of Laplace transforms, 303

Determinants, APP-7

expansion by cofactors, APP-7

Difference equation, 453

Difference quotients, 452

Differential equation, 2

of a family of curves, 76

linear, 3

nonlinear, 3

order of, 3

ordinary, 2

partial, 2

Differential operator, 157

Dirac, Paul Adrian Maurice, 328

Dirac delta function, 328

Laplace transform of, 328-329

Direction field, 422

Discharge through an orifice, differential equation of, 18-19

Discretization error, 443

Distributions, 330

Double pendulum, 350

Drosophila, 93

Effective spring constant, 191

Eigenvalues of a matrix, 367

Eigenvectors of a matrix, 367

Elastic curve, 19

Electrical networks, 346

Electrical vibrations, 209

Electromotive force, 16

Elementary row operations, 364

notation for, 364

Elimination method

for systems of linear algebraic equations, 364

for systems of linear differential equations, 336

Emf, 16

Equation of motion, 186

Equidimensional equation, 222

Equilibrium position, 9, 184-185

Errors

discretization, 443

formula, 443 global truncation, 444,445

local truncation, 443,445

round off, 442

Escape velocity, 98

Essential parameters, 8

Euler, Leonhard, 139

Euler's constant, 269

Euler's formula, 139, APP-13

Euler's method, 426

Exact differential, 47

criterion for, 48

Exact differential equation, 47

Excitation function, 129

Existence and uniqueness of a solution, $30,112,378$

Explicit solution, 5

Exponential growth, 81-83, 106

Exponential order, 283

Exponents of a singularity, 253

Extreme displacement, 186

Family of solutions, 8

Fick's law, 92

Finite difference equation, 453

Finite differences, 452

Finite elements method, 462

First-order chemical reactions, 96

First-order differential equations applications of, 76, 81, 93

solution methods for, $33,40,46,54,62$

First translation theorem, 297 inverse form of, 298

Fitzhugh-Nagumo equation, 460

Forced motion, 200

Forcing function, 129

Forward difference, 452

Free motion of a spring-mass system damped, 192

undamped, 185

Frequency, 186

Frobenius, Ferdinand Georg, 251

Frobenius, method of, 251

Full-wave rectification of sine function, 314

Fundamental matrix, 385

Fundamental set of solutions existence of, 124 of a linear differential equation, 123

of a system of linear differential equations, 381

Galloping Gertie, 218

Gamma function, 289

Gauss, Karl Friedrich, 365

Gauss-Jordan elimination, 364

Gaussian elimination, 364

General solution

of a differential equation, 8

of a linear differential equation, 57,124,127

of a system of linear first-order differential equations, 381,383

Generalized factorial function, APP-1

Generating function, 274

Geometric sequence, 107

Global truncation error, 444

Gompertz curve, 96

Growth and decay, 81

Half life, 83

Half-wave rectification of sine function, 314

Heart pacemaker, 92

Heaviside, Oliver, 295

Heaviside's expansion theorem, 295

Hermite, Charles, 247

Hermite's differential equation, 247

Heun's formula, 429

Hodgkin-Huxley equation, 460

Homogeneous first-order differential equations, 42

Homogeneous function, 40

Homogeneous higher-order differential equations, 138

Homogeneous systems

of algebraic equations, 369 , APP-9

of linear first-order differential equations, $351,376,391$

Hooke, Robert, 184

Hooke's law, 184

Identity matrix, 359

Impedance, 212

Implicit solution, 5

Impressed force, 200

Improved Euler's method, 429

Indicial equation, 253

Indicial roots, 253

Initial conditions, 29,112

Initial-value problem

for a differential equation, 29,112

for a system of differential equations, 377

Input function, 129

Integral equation, 319

Integral transform, 281

Integrating factor, 55

Integrodifferential equation, 320

Interest compounded continuously, 21-22, 89-90

Interior mesh points, 453

Interval of convergence of a power series, 231

Inverse Laplace transform, 290

Inverse matrix, $360-361$

Irregular singular point, 248

at infinity, 263

Isocline, 422

Isogonal trajectories, 80

IVP, 29

Jordan, Wilhelm, 365

Kepler's second law of planetary motion, 92

Kirchhoff's laws, 16, 85, 209, 346

Kutta, Martin W., 435

Laplace, Pierre Simon, Marquis de, 282

Laplace transform

behavior as $s$ approaches infinity, 294

convolution theorem for, 309

definition of, 282

of derivatives, 308 differentiation of, 303

of Dirac delta function, 329

existence of, 284

of an initial-value problem, 314

of an integral, 309

inverse of, 290

linearity of, 283

of a periodic function, 311

table of, APP-4

translations theorems for, 297, 301

Law of Malthus, 104

Law of mass action, 98

Lazer-McKenna model, 219

Legendre, Adrien Marie, 265

Legendre polynomials, 273

generating function for, 274

graphs of, 273

properties of, 273

recurrence relation for, 274

Rodrigues' formula for, 277

Legendre's differential equation, 265

solution of, 271

Libby, Willard, 84

Lineal element, 422

Linear dependence

of functions, 115

of solution vectors, 379

Linear independence

of eigenvectors, 370

of functions, 116

of solution vectors, 379,380

of solutions, 122

Linear operator, 157-158, 283

Linear ordinary differential equations, 3

applications of, 75,182

complementary function for, 127

first-order, 54

general solution of, 124,127

higher-order, 111

homogeneous, 120

nonhomogeneous, 120

particular solution of, 125

superposition principles for, 120,128

Linear system

of algebraic equations, 364

of differential equations, 351,375

Linear transform, 283

Linearity property, 281

Local truncation error, 443,445

Logarithmic decrement, 200

Logistic equation, 21, 93

Logistic function, 93

Logistic growth model, 108

Losing a solution, 36

Lotka, A. J., 102

Lotka and Volterra, equations of, 102

$L-R$ series circuit, differential equation of, 85

$L-R-C$ series circuit, differential equation of, 209

Malthus, law of, 104

Malthus, Thomas R., 106

Mathematical model, 11-12

Matrices

addition of, 357

associative law of, 359

augmented, 364

characteristic equation of, 369

column, 356

definition of, 355

derivative of, 363

determinant of, 359

difference of, 357

distributive law of, 359

eigenvalues of, 368

eigenvectors of, 368

elementary row operations of, 364

equality of, 356

exponential, 413-414

fundamental, 385

integral of, 363

inverse of, 361

multiples of, 356

multiplicative identity, 359

multiplicative inverse, 360

nonsingular, 361

product of, 357-358

reduced row-echelon form of, 365

row-echelon form of, 365

singular, 361

size, 356

square, 356

transpose of, 360

vector, 356

Wronski, 386

zero, 359

Matrix form of a linear system, 376

Meander function, 314

Mechanical resonance, 203, 204

Mesh points, 453

Method of Frobenius, 251

Milne's method, 44!

Minor, 361, APP-7

Mixtures, 87

Modified Bessel function of the first kind, 276

Modified logistic equation, 100

Modulus of a complex number, 244, APP-12

Multiplicity of eigenvalues, 398

Multistep method, 440)

Natural frequency, 186

Natural period, 186

Nerve impulse models, 459

Neumann's function, 268

Newton's law of cooling, 16-17, 84-85

Newton's second law of motion, 184-85

Nonhomogeneous linear differential equation, 120

Nonhomogeneous systems

of algebraic equations, APP-9

of linear differential equations, 351

Nonlinear differential equation, 3

Nonsingular matrix, 361

Normal form of a system of linear differential equations, 351 $n$ th-order system, 350

Numerical methods

Adams-Bashforth/Adams-Moulton, 439-440

errors in, $442-446$

Euler's, 426,450

finite difference, 453

Heun's, 429

improved Euler's, 429

Milne's, 441

Runge-Kutta, 436, 449

stability of, 445

three-term Taylor, 433

Operator, differential, 157,366

Order of a differential equation, 3

Ordinary differential equation, 2

Ordinary point, 240

Orthogonal curves, 76

Orthogonal trajectories, 77

Output, 129

Overdamped circuit, 209

Overdamped spring-mass system, 193

Parametric Bessel equation, 279

Partial differential equation, 2

Partial fractions, 291

Particular solution, 8,125

Peano, Guiseppe, 31

Pendulum, 14, 212

Percentage relative error, 427

Period, 186 of a pendulum, 103, 212

Periodic functions, Laplace transform of, 311

Phase angle, 188

Physical pendulum, 14

Picard, Charles Emile, 30

Picard's method of successive approximations, 70

Piecewise continuous functions, 283

Polar curves, orthogonal, 79

Polar form of a complex number, APP-12

Population dynamics, 106

Population growth, 20

Power series, review of, 230

Power series solutions, 235, 241

Predator-prey, 102-103

Predictor-corrector methods, 439

Pure resonance, 207

Quasi frequency, 196

Quasi period, 196

Radioactive decay, 81,83

Radius of convergence of a power series, 231

Rational roots of a polynomial equation, 142

$R-C$ series circuit, differential equation of, 86

Reactance, 212

Reactions, chemical, $96-98,100$

Rectangular pulse, 307

Rectified sine waves, 314

Recurrence relation, 236

Reduced row-echelon form of a matrix, 365

Reduction of order, 133

Regular singular point, 248

at infinity, 263

Relative error, 427

Resonance

electrical, 211

mechanical, 203-204

Resonance curve, 204

Response of the system, 85, 129

Ricatti, Jacobo Francesco, 62

Ricatti's differential equation, 63

Rodrigues, Olinde, 277

Rodrigues' formula, 277

Rotating string, 15

Round-off error, 442

Row-echelon form of a matrix, 365

Runge, Carl D. T., 435

Runge-Kutta methods, 436

Sawtooth function, 314

Schwartz, Laurent, 330

Second-order chemical reaction, 96

Second translation theorem, 301 inverse form of, 302

Self-orthogonal family of curves, 81

Separable first-order differential equations, 34

Series

power, 231

solutions of ordinary differential equations, 235 . $241-242,251$

Series circuits, $16,85-86$

Sifting property, 331

Simple harmonic electrical vibrations, 210

Simple harmonic motion, 185

Simple pendulum, 14

Single-step numerical method, 440

Singular matrix, 361

Singular point of a differential equation, 240

at infinity, 263

irregular, 248

regular, 248

Singular solution, 8

Sliding bead, 103

Slope field, 422

Solution of an ordinary differential equation, 4

complete, 8

explicit, 5

general, $8-9$

implicit, 5

losing a, 36

$n$-parameter family of, 8

number of, 6

particular, 8

singular, 8

trivial, 5

Solution of a system of linear differential equations, 336,377

general, 381,383

particular, 382

Spherical Bessel functions, 270-271

Spread of a disease, 21,95\\
Spring-mass systems, 12, 184, 192, 200

Square wave, 314

Stability of a numerical method, 445

Staircase function, 307

Starting methods, 440

State of a system, 12

Steady-state current, 86

Steady-state solution, 202

Stefan's law of radiation, 101

Substitutions, 67

Superposition principle for homogeneous linear differential equations, 120

for homogeneous linear systems, 378

for nonhomogeneous linear differential equations, 128

Synthetic division, 142

Systems of linear differential equations, methods for solving

by Laplace transform, 343

by matrices, $391,405,409,414$

by systematic elimination using differential operators, 336

Tacoma Narrows bridge collapse, 218

Tangent lines, method of, 426

Third-order chemical reactions, 100

Three-term Taylor method, 432-433

Total differential, 47

Tractrix, 102

Trajectories, orthogonal, $76-77$

Transient solution, 202

Transient term, 86

Translation theorems for Laplace transform, 297, 301

Transpose of a matrix, 360

Triangular wave, 314

Trivial solution, 5

Truncation errors global, 444,445

local, 443, 445

Twisted shaft, 212

Two-point boundary-value problem, 114

Undamped motion of a spring-mass system, 185

Underdamped circuit, 209

Underdamped spring-mass system, 193

Undetermined coefficients annihilator approach for linear differential equations, 162

superposition approach for linear differential equations, 146

for systems of linear first-order differential equations, 405

Uniqueness theorems, $30,112,378$

Unit impulse, 328

Unit step function, 299

Laplace transform of, 301

Units, 13

Variables, separable, 34

Variation of parameters

for linear differential equations, 169

for systems of linear differential equations, 409

Vectors, definition of, 356 solutions of systems of linear differential equations, 377

I-6 INDEX

Verhulst, P. F., 93, 108

Vibrations of spring-mass systems, 184-209

Volterra, Vito, 102

Volterra integral equation, 319

Weight, 185\\
Wronski, Josef Maria H., 118

Wronski matrix, 386

Wronskian, 118

Abel's formula for, 132

Zero matrix, 359

\begin{enumerate}
  \item $\int u d v=u v-\int v d u$

  \item $\int \frac{d u}{u}=\ln |u|+C$

  \item $\int a^{u} d u=\frac{1}{\ln a} a^{u}+C$

  \item $\int \cos u d u=\sin u+C$

  \item $\int \csc ^{2} u d u=-\cot u+C$

  \item $\int \csc u \cot u d u=-\csc u+C$

  \item $\int \cot u d u=\ln |\sin u|+C$

  \item $\int \csc u d u=\ln |\csc u-\cot u|+C$

  \item $\int \frac{d u}{a^{2}+u^{2}}=\frac{1}{a} \tan ^{-1} \frac{u}{a}+C$

  \item $\int \frac{d u}{a^{2}-u^{2}}=\frac{1}{2 a} \ln \left|\frac{u+a}{u-a}\right|+C$

  \item $\int \sin ^{2} u d u=\frac{1}{2} u-\frac{1}{4} \sin 2 u+C$

  \item $\int \tan ^{2} u d u=\tan u-u+C$

  \item $\int \sin ^{3} u d u=-\frac{1}{3}\left(2+\sin ^{2} u\right) \cos u+C$

  \item $\int \tan ^{3} u d u=\frac{1}{2} \tan ^{2} u+\ln |\cos u|+C$

  \item $\int \sec ^{3} u d u=\frac{1}{2} \sec u \tan u+\frac{1}{2} \ln |\sec u+\tan u|+C$

  \item $\int \sin ^{n} u d u=-\frac{1}{n} \sin ^{n-1} u \cos u+\frac{n-1}{n} \int \sin ^{n-2} u d u$

  \item $\int \tan ^{n} u d u=\frac{1}{n-1} \tan ^{n-1} u-\int \tan ^{n-2} u d u$

  \item $\int \sec ^{n} u d u=\frac{1}{n-1} \tan u \sec ^{n-2} u+\frac{n-2}{n-1} \int \sec ^{n-2} u d u$

  \item $\int \sin a u \sin b u d u=\frac{\sin (a-b) u}{2(a-b)}-\frac{\sin (a+b) u}{2(a+b)}+C$

  \item $\int \sin a u \cos b u d u=-\frac{\cos (a-b) u}{2(a-b)}-\frac{\cos (a+b) u}{2(a+b)}+C$

  \item $\int u \cos u d u=\cos u+u \sin u+C$

  \item $\int u^{n} \cos u d u=u^{n} \sin u-n \int u^{n-1} \sin u d u$

  \item $\int \sin ^{n} u \cos ^{m} u d u=-\frac{\sin ^{n-1} u \cos ^{m+1} u}{n+m}+\frac{n-1}{n+m} \int \sin ^{n-2} u \cos ^{m} u d u=\frac{\sin ^{n+1} u \cos ^{m-1} u}{n+m}+\frac{m-1}{n+m} \int \sin ^{n} u \cos ^{m-2} u d u$

  \item $\int u^{n} d u=\frac{1}{n+1} u^{n+1}+C, n \neq-1$

  \item $\int e^{u} d u=e^{u}+C$

  \item $\int \sin u d u=-\cos u+C$

  \item $\int \sec ^{2} u d u=\tan u+C$

  \item $\int \sec u \tan u d u=\sec u+C$

  \item $\int \tan u d u=-\ln |\cos u|+C$

  \item $\int \sec u d u=\ln |\sec u+\tan u|+C$

  \item $\int \frac{d u}{\sqrt{a^{2}-u^{2}}}=\sin ^{-1} \frac{u}{a}+C$

  \item $\int \frac{d u}{u \sqrt{u^{2}-a^{2}}}=\frac{1}{a} \sec ^{-1} \frac{u}{a}+C$

  \item $\int \frac{d u}{u^{2}-a^{2}}=\frac{1}{2 a} \ln \left|\frac{u-a}{u+a}\right|+C$

  \item $\int \cos ^{2} u d u=\frac{1}{2} u+\frac{1}{4} \sin 2 u+C$

  \item $\int \cot ^{2} u d u=-\cot u-u+C$

  \item $\int \cos ^{3} u d u=\frac{1}{3}\left(2+\cos ^{2} u\right) \sin u+C$

  \item $\int \cot ^{3} u d u=-\frac{1}{2} \cot ^{2} u-\ln |\sin u|+C$

  \item $\int \csc ^{3} u d u=-\frac{1}{2} \csc u \cot u+\frac{1}{2} \ln |\csc u-\cot u|+C$

  \item $\int \cos ^{n} u d u=\frac{1}{n} \cos ^{n-1} u \sin u+\frac{n-1}{n} \int \cos ^{n-2} u d u$

  \item $\int \cot ^{n} u d u=\frac{-1}{n-1} \cot ^{n-1} u-\int \cot ^{n-2} u d u$

  \item $\int \csc ^{n} u d u=\frac{-1}{n-1} \cot u \csc ^{n-2} u+\frac{n-2}{n-1} \int \csc ^{n-2} u d u$

  \item $\int \cos a u \cos b u d u=\frac{\sin (a-b) u}{2(a-b)}+\frac{\sin (a+b) u}{2(a+b)}+C$

  \item $\int u \sin u d u=\sin u-u \cos u+C$

  \item $\int u^{n} \sin u d u=-u^{n} \cos u+n \int u^{n-1} \cos u d u$

  \item $\int \sin ^{-1} u d u=u \sin ^{-1} u+\sqrt{1-u^{2}}+C$

  \item $\int \tan ^{-1} u d t=\tan ^{-1} t \psi-\frac{1}{2} \ln \left(1+u^{2}\right)+C$

  \item $\int u \cos ^{-1} u d u=\frac{2 u^{2}-1}{4} \cos ^{-1} u-\frac{u \sqrt{1-u^{2}}}{4}+C$

  \item $\int u e^{2 u} d u=\frac{1}{u^{2}}(a u-1) e^{2 u}+C$

  \item $\int e^{\pi *} \sin b u d u=\frac{e^{a \omega}}{a^{2}+b^{2}}(a \sin b u-b \cos b u)+C$

  \item $\int \ln u d u=u \ln u-u+C$

  \item $\int u^{n} \ln u d u=\frac{u^{n-1}}{(n+1)^{2}}[(n+1) \ln u-1]+C$

  \item $\int \ln \left(u^{2}+a^{2}\right) d u=u \ln \left(u^{2}+a^{2}\right)-2 u+2 a \tan ^{-1} \frac{4}{a}+C$

  \item $\int \sinh u d u=\cosh u+C$

  \item $\int \tanh u d u=\ln$ cosh $u+C$

  \item $\int \operatorname{sech}^{2} u d u=\tanh u+C$

  \item $\int \operatorname{sech} u$ tanh $u d u=-\operatorname{sech} u+C$

  \item $\int \sqrt{a^{2}+u^{2}} d u=\frac{u}{2} \sqrt{a^{2}+u^{2}}+\frac{a^{2}}{2} \ln \left|u+\sqrt{a^{2}+u^{2}}\right|+C$

  \item $\int u^{2} \sqrt{a^{2}+u^{2}} d u=\frac{4}{8}\left(a^{2}+2 u^{2}\right) \sqrt{a^{2}+u^{2}}-\frac{a^{2}}{8} \ln \left|u+\sqrt{a^{2}+u^{2}}\right|+C$

  \item $\int \frac{\sqrt{a^{2}+u^{2}}}{u} d u=\sqrt{a^{2}+u^{2}}-a \ln \left|\frac{a+\sqrt{a^{2}+u^{2}}}{u}\right|+C$

  \item $\int \frac{d u}{\sqrt{a^{2}+u^{2}}}=\ln \left|u+\sqrt{a^{2}+u^{2}}\right|+C$

  \item $\int \frac{d u}{u \sqrt{a^{2}+u^{2}}}=-\frac{1}{a} \ln \left|\frac{\sqrt{a^{2}+u^{2}}+a}{u}\right|+C$

  \item $\int \sqrt{u^{2}-a^{3}} d u=\frac{u}{2} \sqrt{u^{2}-a^{2}}-\frac{a^{2}}{2} \ln \left|u+\sqrt{u^{2}-a^{2}}\right|+C$

  \item $\int u^{2} \sqrt{u^{2}-a^{2}} d u=\frac{u}{8}\left(2 u^{2}-a^{2}\right) \sqrt{u^{2}-a^{2}}-\frac{a^{2}}{8} \ln \left|u+\sqrt{u^{2}-a^{2}}\right|+C$

  \item $\int \frac{\sqrt{u^{2}-a^{2}}}{u} d u=\sqrt{u^{2}-a^{2}}-a \cos ^{-1} \frac{a}{u}+C$

  \item $\left.\int \frac{d u}{\sqrt{u^{2}-a^{2}}}=\ln \right\rvert\, u+\sqrt{u^{2}-a^{2} \mid}+C$

  \item $\int \frac{d u}{u^{2} \sqrt{u^{2}-a^{2}}}=\frac{\sqrt{u^{2}-a^{2}}}{a^{2} u}+C$

  \item $\int \sqrt{a^{2}-u^{2}} d u=\frac{u}{2} \sqrt{a^{2}-u^{2}}+\frac{a^{2}}{2} \sin ^{-1} \frac{u}{a}+C$

  \item $\int \cos ^{-1} u d u=u \cos ^{-1} u+\sqrt{1-u^{2}}+C$

  \item $\int u \sin ^{-1} u d u=\frac{2 u^{2}-1}{4} \sin ^{-1} u+\frac{u \sqrt{1-u^{2}}}{4}+C$

  \item $\int u \tan ^{-1} u d u=\frac{u^{2}+1}{2} \tan ^{-1} u=\frac{u}{2}+C$

  \item $\int u^{n} e^{m u} d u=\frac{1}{a} u^{n} e^{* *}-\frac{n}{a} \int u^{*-1} e^{\infty o n} d u$

  \item $\int e^{e a} \cos b u d u=\frac{e^{2 a}}{a^{2}+b^{2}}(a \cos b u+b \sin b u)+C$

  \item $\int \frac{1}{u \ln u} d u=\ln |\ln u|+C$

  \item $\int u^{m} \ln u d u=\frac{u^{m-1} \ln u}{m+1}-\frac{n}{m+1} \int u^{m} \ln ^{n-1} u d u ; \quad m \neq-1$

  \item $\int \ln \left|u^{2}-a^{2}\right| d u=u \ln \left|u^{2}-a^{2}\right|-2 u+a \ln \left|\frac{u+a}{u-a}\right|+C$

  \item $\int \cosh u d u=\sinh u+C$

  \item $\int \operatorname{coth} u d u=\ln |\sinh u|+C$

  \item $\int \operatorname{csch}^{2} u d u=-\operatorname{coth} u+C$

  \item $\int$ esch $u \operatorname{coth} u d u=-\operatorname{csch} u+C$

  \item $\left.\int \frac{\sqrt{a^{2}+u^{2}}}{u^{2}} d u=-\frac{\sqrt{a^{2}+u^{2}}}{u}+\ln \right\rvert\, u+\sqrt{a^{2}+u^{2} \mid}+C$

  \item $\int \frac{u^{2} d u}{\sqrt{a^{2}+u^{2}}}=\frac{u}{2} \sqrt{a^{2}+u^{2}}=\frac{a^{2}}{2} \ln \left|u+\sqrt{a^{2}+u^{2}}\right|+C$

  \item $\int \frac{d u}{u^{2} \sqrt{a^{2}+u^{2}}}=-\frac{\sqrt{a^{2}+u^{2}}}{a^{2} u}+C$

  \item $\left.\int \frac{\sqrt{u^{2}-a^{2}}}{u^{2}} d u=-\frac{\sqrt{u^{2}-a^{2}}}{u}+\ln \right\rvert\, u+\sqrt{u^{2}-a^{2} \mid}+C$

  \item $\int \frac{u^{2} d u}{\sqrt{u^{2}-a^{2}}}=\frac{u}{2} \sqrt{u^{2}-a^{2}}+\frac{a^{2}}{2} \ln \left|u+\sqrt{u^{2}-a^{2}}\right|+C$

  \item $\int \frac{d u}{\left(u^{2}-a^{2}\right)^{3 / 2}}=\frac{u}{a^{2} \sqrt{u^{2}-a^{2}}}+C$

  \item $\int u^{2} \sqrt{a^{2}-u^{2}} d u=\frac{u}{8}\left(2 u^{2}-u^{2}\right) \sqrt{a^{2}-u^{2}}+\frac{a^{4}}{8} \sin ^{-1} \frac{u}{a}+C$

\end{enumerate}

\begin{center}
\includegraphics[max width=\textwidth]{2024_07_17_9719f7b5e669c3c92088g-539}
\end{center}

Normandie Bridge, France

\section*{BROOKS/COLE CENGAGE learning}
For your coumseand lesimifizsalliticns: Vitit \href{http://acodemiccengage.com}{acodemiccengage.com} Piurth-e any of our products at yaur local collegestorm-or at aur preferced online store wwwilchapters:com

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}

\begin{itemize}
  \item 
\end{itemize}


\end{document}